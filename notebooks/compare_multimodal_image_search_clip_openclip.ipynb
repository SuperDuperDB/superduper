{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "238520e0",
   "metadata": {},
   "source": [
    "# Compare two Multimodal search CLIP models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ebe1497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/CLIP.git\n",
      "  Cloning https://github.com/openai/CLIP.git to /private/var/folders/5k/k58wnkmx6x1cdgy02s9v8hnr0000gn/T/pip-req-build-x9h2o9tw\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /private/var/folders/5k/k58wnkmx6x1cdgy02s9v8hnr0000gn/T/pip-req-build-x9h2o9tw\n",
      "  Resolved https://github.com/openai/CLIP.git to commit a1d071733d7111c9c014f024669f959182114e33\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: ftfy in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from clip==1.0) (6.1.1)\n",
      "Requirement already satisfied: regex in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from clip==1.0) (2023.6.3)\n",
      "Requirement already satisfied: tqdm in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from clip==1.0) (4.65.0)\n",
      "Requirement already satisfied: torch in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from clip==1.0) (2.0.1)\n",
      "Requirement already satisfied: torchvision in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from clip==1.0) (0.15.2)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from ftfy->clip==1.0) (0.2.6)\n",
      "Requirement already satisfied: filelock in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from torch->clip==1.0) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from torch->clip==1.0) (4.7.1)\n",
      "Requirement already satisfied: sympy in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from torch->clip==1.0) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from torch->clip==1.0) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from torch->clip==1.0) (3.1.2)\n",
      "Requirement already satisfied: numpy in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from torchvision->clip==1.0) (1.25.1)\n",
      "Requirement already satisfied: requests in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from torchvision->clip==1.0) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from torchvision->clip==1.0) (10.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from jinja2->torch->clip==1.0) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from sympy->torch->clip==1.0) (1.3.0)\n",
      "Requirement already satisfied: datasets in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (2.14.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from datasets) (1.25.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from datasets) (12.0.1)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from datasets) (0.16.4)\n",
      "Requirement already satisfied: packaging in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: filelock in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: clip in /Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages (1.0)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement open_clip (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for open_clip\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/openai/CLIP.git\n",
    "!pip install datasets\n",
    "!pip install clip open_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82f746a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_model_name = \"ViT-B/32\"\n",
    "open_clip_model_name = 'ViT-B-32'\n",
    "open_clip_pretrained='laion2b_s34b_b79k'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b5ef986",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:Note: NumExpr detected 10 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "import clip\n",
    "import pymongo\n",
    "from superduperdb.misc.superduper import superduper\n",
    "from superduperdb.models.torch.wrapper import TorchModel\n",
    "from superduperdb.datalayer.mongodb.query import Collection\n",
    "from superduperdb.core import Document as D\n",
    "from superduperdb.encoders.pillow.image import pil_image as i\n",
    "from IPython.display import display\n",
    "\n",
    "pymongo.MongoClient().drop_database('documents')\n",
    "pymongo.MongoClient().drop_database('_filesystem:documents')\n",
    "\n",
    "db = pymongo.MongoClient().documents\n",
    "db = superduper(db)\n",
    "\n",
    "collection = Collection(name='tiny-imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaa0a06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from superduperdb.core.document import Document as D\n",
    "from superduperdb.encoders.pillow.image import pil_image as i\n",
    "from datasets import load_dataset\n",
    "import random\n",
    "\n",
    "dataset = load_dataset(\"zh-plus/tiny-imagenet\")['valid']\n",
    "dataset = [D({'image': i(r['image'])}) for r in dataset]\n",
    "dataset = random.sample(dataset, 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c32a91a5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:found 0 uris\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<pymongo.results.InsertManyResult at 0x17e0e5390>,\n",
       " TaskWorkflow(database=<superduperdb.datalayer.base.datalayer.Datalayer object at 0x17c1387f0>, G=<networkx.classes.digraph.DiGraph object at 0x17e0e5a80>))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.execute(collection.insert_many(dataset, encoders=(i,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d37264",
   "metadata": {},
   "source": [
    "We can verify that the images are correctly stored:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7282a0fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=64x64>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = db.execute(collection.find_one())['image'].x\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ac82f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduperdb.core.vector_index import VectorIndex\n",
    "from superduperdb.core.watcher import Watcher\n",
    "from superduperdb.encoders.torch.tensor import tensor\n",
    "import torch\n",
    "\n",
    "def add_clip_index(index_name, model_identifier, model, preprocess, text_tokenizer,):\n",
    "    t = tensor(torch.float, shape=(512,))\n",
    "\n",
    "    text_model = TorchModel(\n",
    "        identifier=model_identifier+\"_text\",\n",
    "        object=model,\n",
    "        preprocess=text_tokenizer,\n",
    "        forward_method='encode_text',\n",
    "        encoder=t\n",
    "    )\n",
    "    print(len(text_model.predict('this is a test', one=True)))\n",
    "    visual_model = TorchModel(\n",
    "        identifier=model_identifier+\"_image\",\n",
    "        preprocess=preprocess,\n",
    "        object=model.visual,\n",
    "        encoder=t,\n",
    "    )\n",
    "    x = db.execute(collection.find_one())['image'].x\n",
    "    print(len(visual_model.predict(x, one=True)))\n",
    "\n",
    "\n",
    "    db.add(\n",
    "        VectorIndex(\n",
    "            index_name,\n",
    "            indexing_watcher=Watcher(\n",
    "                model=visual_model,\n",
    "                key='image',\n",
    "                select=collection.find(),\n",
    "            ),\n",
    "            compatible_watcher=Watcher(\n",
    "                model=text_model,\n",
    "                key='text',\n",
    "                active=False,\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "916792d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:model/openai_clip_model_image/0 already exists - doing nothing\n",
      "WARNING:root:model/openai_clip_model_image/0 already exists - doing nothing\n",
      "WARNING:root:model/openai_clip_model_image/0 already exists - doing nothing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing chunk 0/0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:35<00:00, 28.28it/s]\n",
      "WARNING:root:encoder/torch.float32[512]/0 already exists - doing nothing\n",
      "INFO:root:loading hashes: 'openai_clip_index'\n",
      "/Users/levkonstantinovskiy/Documents/GitHub/new/superduperdb-stealth/superduperdb/encoders/torch/tensor.py:25: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:212.)\n",
      "  return torch.from_numpy(array)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "openai_model, openai_preprocess = clip.load(openai_model_name, device='cpu')\n",
    "openai_tokenizer = lambda x: clip.tokenize(x)[0]\n",
    "add_clip_index(\"openai_clip_index\", \"openai_clip_model\", openai_model, openai_preprocess, openai_tokenizer,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87350419",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /var/folders/5k/k58wnkmx6x1cdgy02s9v8hnr0000gn/T/tmpwzxpz683\n",
      "INFO:torch.distributed.nn.jit.instantiator:Writing /var/folders/5k/k58wnkmx6x1cdgy02s9v8hnr0000gn/T/tmpwzxpz683/_remote_module_non_scriptable.py\n",
      "INFO:root:Loaded ViT-B-32 model config.\n",
      "INFO:root:Loading pretrained ViT-B-32 weights (laion2b_s34b_b79k).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:model/open_clip_clip_model_image/0 already exists - doing nothing\n",
      "WARNING:root:model/open_clip_clip_model_image/0 already exists - doing nothing\n",
      "WARNING:root:model/open_clip_clip_model_image/0 already exists - doing nothing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing chunk 0/0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:38<00:00, 25.95it/s]\n",
      "WARNING:root:encoder/torch.float32[512]/1 already exists - doing nothing\n",
      "INFO:root:loading hashes: 'open_clip_clip_index'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import open_clip\n",
    "open_clip_model, _, open_clip_preprocess = open_clip.create_model_and_transforms(open_clip_model_name, pretrained=open_clip_pretrained, device='cpu' )\n",
    "\n",
    "open_clip_tokenizer = lambda x: open_clip.get_tokenizer(open_clip_model_name)(x)[0] \n",
    "add_clip_index(\"open_clip_clip_index\", \"open_clip_clip_model\", open_clip_model, open_clip_preprocess, open_clip_tokenizer,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2fcbde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet gradio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "191f698d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:loading hashes: 'openai_clip_index'\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 16\u001b[0m\n\u001b[1;32m     11\u001b[0m collection \u001b[39m=\u001b[39m Collection(name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtiny-imagenet\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m cursor \u001b[39m=\u001b[39m db\u001b[39m.\u001b[39mexecute(\n\u001b[1;32m     14\u001b[0m     collection\u001b[39m.\u001b[39mlike(D({\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mmushroom\u001b[39m\u001b[39m'\u001b[39m}), vector_index\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mopenai_clip_index\u001b[39m\u001b[39m'\u001b[39m, n\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\u001b[39m.\u001b[39mfind({})\n\u001b[1;32m     15\u001b[0m )\n\u001b[0;32m---> 16\u001b[0m [(row[\u001b[39m'\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mx) \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m out]\n\u001b[1;32m     18\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_extract\u001b[39m(out):\n\u001b[1;32m     19\u001b[0m     \u001b[39mreturn\u001b[39;00m [(row[\u001b[39m'\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mx) \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m out]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'out' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import pymongo\n",
    "from superduperdb.misc.superduper import superduper\n",
    "from superduperdb.datalayer.mongodb.query import Collection\n",
    "from superduperdb.core.document import Document as D\n",
    "import clip \n",
    "import open_clip\n",
    "\n",
    "db = pymongo.MongoClient().documents\n",
    "db = superduper(db)\n",
    "\n",
    "collection = Collection(name='tiny-imagenet')\n",
    "\n",
    "cursor = db.execute(\n",
    "    collection.like(D({'text': 'mushroom'}), vector_index='openai_clip_index', n=10).find({})\n",
    ")\n",
    "[(row['image'].x) for row in out]\n",
    "\n",
    "def _extract(out):\n",
    "    return [(row['image'].x) for row in out]\n",
    "_extract(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0faa637",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_image_vectors(query):\n",
    "    code = (\n",
    "    f\"\"\"\n",
    "    import pymongo\n",
    "    from superduperdb.misc.superduper import superduper\n",
    "    from superduperdb.datalayer.mongodb.query import Collection\n",
    "    from superduperdb.core.document import Document as D\n",
    "    import clip \n",
    "\n",
    "    db = pymongo.MongoClient().documents\n",
    "    db = superduper(db)\n",
    "\n",
    "    collection = Collection(name='tiny-imagenet')\n",
    "\n",
    "    openai_cursor = db.execute(collection.like(D({{'text': '{query}'}}), vector_index='{'openai_clip_index'}', n=20).find({{}})\n",
    "    open_clip_cursor = db.execute(collection.like(D({{'text': '{query}'}}), vector_index='{'open_clip_clip_index'}', n=20).find({{}})\n",
    "\n",
    "    \"\"\"\n",
    " )\n",
    "    return (_extract(db.execute(collection.like(D({'text': query}), vector_index='openai_clip_index', n=20).find({}))), _extract(db.execute(collection.like(D({'text': query}), vector_index='open_clip_clip_index', n=20).find({}))), code)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d889d3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduperdb.core.document import Document as D\n",
    "from superduperdb.encoders.pillow.image import pil_image as i\n",
    "from datasets import load_dataset\n",
    "import random\n",
    "import pymongo\n",
    "from superduperdb import superduper\n",
    "from superduperdb.datalayer.mongodb.query import Collection\n",
    "import clip\n",
    "\n",
    "\n",
    "db = pymongo.MongoClient().documents\n",
    "db = superduper(db)\n",
    "\n",
    "collection = Collection(name='tiny-imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3a7685",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5k/k58wnkmx6x1cdgy02s9v8hnr0000gn/T/ipykernel_18414/3144161703.py:15: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
      "  openai_gallery = gr.Gallery(\n",
      "/var/folders/5k/k58wnkmx6x1cdgy02s9v8hnr0000gn/T/ipykernel_18414/3144161703.py:18: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
      "  open_clip_gallery = gr.Gallery(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7875\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7875/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    with gr.Row():\n",
    "        with gr.Tab(\"Multi-modal search: compare two models\"):\n",
    "            vector_query = gr.Textbox(value=\"mushroom\", show_label=False)\n",
    "            b2 = gr.Button(\"Submit\")\n",
    "    with gr.Row():\n",
    "        code = gr.Code(label=\"Code\", language=\"python\")\n",
    "    with gr.Row():\n",
    "        gr.Label(\"Similar images from CLIP\", show_label=False)\n",
    "    with gr.Row():\n",
    "        \n",
    "        openai_gallery = gr.Gallery(\n",
    "                label=\"Trained on OpenAI dataset\", show_label=True, elem_id=\"gallery\"\n",
    "            ).style(columns=[6], rows=[3], object_fit=\"contain\", height=\"auto\")\n",
    "        open_clip_gallery = gr.Gallery(\n",
    "                label=\"Trained on open source LAION-2B\", show_label=True, elem_id=\"gallery\"\n",
    "            ).style(columns=[6], rows=[3], object_fit=\"contain\", height=\"auto\")   \n",
    "\n",
    "        \n",
    "    b2.click(find_image_vectors, inputs=vector_query, outputs=[openai_gallery, open_clip_gallery, code])\n",
    "    \n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
