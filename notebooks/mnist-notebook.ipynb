{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a6ac9b2",
   "metadata": {},
   "source": [
    "# MNIST: Handwritten digit recognition with SuperDuperDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c096450",
   "metadata": {},
   "source": [
    "The [MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database) is the classic hello-world for machine learning and AI.\n",
    "\n",
    "In this tutorial we implement MNIST classification using the paradigmatic \"LeNet\" based on the un-preprocessed images.\n",
    "\n",
    "First we import the SuperDuperDB client, and create a fresh collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32752579",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduperdb.mongodb.client import SuperDuperClient\n",
    "\n",
    "import io\n",
    "import numpy\n",
    "import PIL.Image\n",
    "import PIL.JpegImagePlugin\n",
    "import PIL.PngImagePlugin\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "the_client = SuperDuperClient()\n",
    "docs = the_client.mnist.digits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5938a97",
   "metadata": {},
   "source": [
    "The data is available as `PIL.Image` images with labels in the `torchvision` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a767f640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "mnist_data = list(torchvision.datasets.MNIST(root='./data', download=True))\n",
    "random.shuffle(mnist_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6c4852",
   "metadata": {},
   "source": [
    "SuperDuperDB is based on MongoDB, which does not support images and tensors and other special data types out of the box. In order to remedy this, we create custom SuperDuperDB **types**.\n",
    "These types handle:\n",
    "    \n",
    "- How to store images as bytes in SuperDuperDB and how to reinstantiate the images from the bytes\n",
    "- How to store tensors in SuperDuperDB and how to retrieve these from the database again\n",
    "\n",
    "We do this by creating the classes in python with `.encode` and `.decode` methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37eb3b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image:\n",
    "    types = (PIL.JpegImagePlugin.JpegImageFile, PIL.Image.Image,\n",
    "             PIL.PngImagePlugin.PngImageFile)\n",
    "\n",
    "    @staticmethod\n",
    "    def encode(x):\n",
    "        buffer = io.BytesIO()\n",
    "        x.save(buffer, format='png')\n",
    "        return buffer.getvalue()\n",
    "\n",
    "    @staticmethod\n",
    "    def decode(bytes_):\n",
    "        return PIL.Image.open(io.BytesIO(bytes_))\n",
    "\n",
    "\n",
    "class FloatTensor:\n",
    "    types = (torch.FloatTensor, torch.Tensor)\n",
    "\n",
    "    @staticmethod\n",
    "    def encode(x):\n",
    "        x = x.numpy()\n",
    "        assert x.dtype == numpy.float32\n",
    "        return memoryview(x).tobytes()\n",
    "\n",
    "    @staticmethod\n",
    "    def decode(bytes_):\n",
    "        array = numpy.frombuffer(bytes_, dtype=numpy.float32)\n",
    "        return torch.from_numpy(array).type(torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fcc7a8",
   "metadata": {},
   "source": [
    "Once these classes are ready, we can add instances of these to SuperDuperDB, giving each type a suitable name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d53db4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.create_type('image', Image(), serializer='dill')\n",
    "docs.create_type('float_tensor', FloatTensor(), serializer='dill')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fde0ff4",
   "metadata": {},
   "source": [
    "Now we have these custom types, we can insert the data into SuperDuperDB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab329bef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_, jobs = docs.insert_many([{'img': x[0], 'class': x[1]} for x in mnist_data[:-1000]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029370c4",
   "metadata": {},
   "source": [
    "When data is inserted into SuperDuperDB, certain actions/ jobs are triggered. These include downloading content into the database from provided URIs, and running model **watchers** over the added data, if these have been added.\n",
    "\n",
    "The second output from the `insert_many` statement give a dictionary of ids of the asynchronous jobs which were created.\n",
    "These can also be seen in the job list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34754835",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'identifier': 'c58b349f-54d5-4d43-b7d5-2c57985af6df',\n",
       "  'time': datetime.datetime(2023, 4, 3, 12, 38, 39, 293000),\n",
       "  'status': 'pending',\n",
       "  'method': '_download_content'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.database.list_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935f0f4c",
   "metadata": {},
   "source": [
    "In this case, only one job was created - to download content. We can watch the stdout/stderr of this job like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f94ed471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 0 urls\n"
     ]
    }
   ],
   "source": [
    "docs.watch_job(jobs['_download_content'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69d8bad",
   "metadata": {},
   "source": [
    "You can see that all data apart from the final 1000 have been added:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e686e9ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.count_documents({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb82b244",
   "metadata": {},
   "source": [
    "You'll see that when we fetch data from the database, it's in exactly the form that we want. For example, the images have been saved and recalled as `PIL.Image` types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0db28bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAs0lEQVR4nGNgGCxAVhK3XPOLRzjl1v/+84WBgYGBgQlTjluekaEVl8bbf/4cZ8cuxb3+39/7ytjlOOr//P0TjcPM1X/+/K3C4hAGBgaGkG9//qwRxS5nd+PPnws4zFT5//fvcSHsbin49PfPXOxmmmz98+evHzdWuaAXf3C6Rffvnz+P0rHJ8Jus+/vv70Ls4bLkz58/7yNZscpN/P7nz2tBLBIsDAwMDMe+L9j1Cau+QQYA4DNFs76YvGIAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.find_one()['img']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f47ac2",
   "metadata": {},
   "source": [
    "Now that we've added the data to SuperDuperDB, we're ready to create a model. This is a simple PyTorch model implementing the iconic [LeNet architecture](https://en.wikipedia.org/wiki/LeNet). In addition to the standard PyTorch `.forward` method, SuperDuperDB allows users to specify `.preprocess` and `.postprocess` methods which define respectively:\n",
    "\n",
    "- how the data is converted from the in-database form, to tensor\n",
    "- from the output form back into the form to be stored in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1af679f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label(x):\n",
    "    return torch.tensor(x)\n",
    "\n",
    "\n",
    "class LeNet5(torch.nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),\n",
    "            torch.nn.BatchNorm2d(6),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "            torch.nn.BatchNorm2d(16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc = torch.nn.Linear(400, 120)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.fc1 = torch.nn.Linear(120, 84)\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(84, num_classes)\n",
    "\n",
    "    def preprocess(self, x):\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((32, 32)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(0.1307,), std=(0.3081,))]\n",
    "        )(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "    def postprocess(self, x):\n",
    "        return int(x.topk(1)[1].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac1be87",
   "metadata": {},
   "source": [
    "Let's test this model on a single image. `Collection.apply_model` applies the `preprocess`, `forward` and `postprocess` methods serially, creating a singleton batch prior to the `forward` and unpacking the batch after the `forward`. A similar logic is applied in all functionality which involves applying a model to the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "793093a8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.apply_model(LeNet5(10), docs.find()[23]['img'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce812615",
   "metadata": {},
   "source": [
    "Now that we have our model we need a target for learning - for this we use `label`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5615985",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.create_model('lenet', LeNet5(10), serializer='dill')\n",
    "docs.create_function('label', label, serializer='dill')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fead4f",
   "metadata": {},
   "source": [
    "Finally we need a loss function - this is a vanilla `torch` function, so we don't need to write extra code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a055b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.create_objective('classification', torch.nn.CrossEntropyLoss(), serializer='dill')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3637fcfd",
   "metadata": {},
   "source": [
    "And a metric to measure performance. Defined metrics are applied serially over individual data points, and the results are averaged:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "552eb1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(x, y):\n",
    "    return x == y\n",
    "\n",
    "docs.create_metric('accuracy', accuracy, serializer='dill')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dd18b1",
   "metadata": {},
   "source": [
    "When measuring performance, SuperDuperDB requires users to create a separate validation set, which is saved for posterity and reproducibility reasons - edits and deletes on the main collection don't affect this validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43a550cd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:00, 13155.22it/s]\n"
     ]
    }
   ],
   "source": [
    "docs.create_validation_set('classification', sample_size=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483f5746",
   "metadata": {},
   "source": [
    "Now we're ready to create the model using the `Collection.create_imputation`. This trains a model to predict one part of the data using another part, specified respectively by `model_key` and `target_key`; these are subkeys of the collection documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81f37e03",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "jobs = docs.create_imputation(\n",
    "    'predictor',\n",
    "    'lenet',  # encoding model\n",
    "    'img',    # key which we apply encoding model to\n",
    "    'label',  # target model\n",
    "    'class',  # key which we apply target model to\n",
    "    objective='classification',\n",
    "    metrics=['accuracy'],\n",
    "    trainer_kwargs={'n_iterations': 1000, 'validation_interval': 50},\n",
    "    validation_sets=('classification',)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485729b4",
   "metadata": {},
   "source": [
    "This command creates two jobs, one to train the model, and another to apply the model to the data after training. As before, the jobs are spawned asynchronously. We can watch the output of the jobs, but in the meantime we can also do other things in our environment, and with the database. Stopping the `watch_job` command, simply breaks the connection to the logs (doesn't stop the job)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21a86159",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: VALID; iteration: 0; epoch: 0; classification/accuracy: 0.096; objective: 2.3062571843465167; \n",
      "fold: TRAIN; iteration: 0; epoch: 0; objective: 2.3081090450286865; \n",
      "fold: TRAIN; iteration: 1; epoch: 0; objective: 2.3022372722625732; \n",
      "fold: TRAIN; iteration: 2; epoch: 0; objective: 2.286705732345581; \n",
      "fold: TRAIN; iteration: 3; epoch: 0; objective: 2.2725465297698975; \n",
      "fold: TRAIN; iteration: 4; epoch: 0; objective: 2.2787575721740723; \n",
      "fold: TRAIN; iteration: 5; epoch: 0; objective: 2.2775518894195557; \n",
      "fold: TRAIN; iteration: 6; epoch: 0; objective: 2.258601665496826; \n",
      "fold: TRAIN; iteration: 7; epoch: 0; objective: 2.2561283111572266; \n",
      "fold: TRAIN; iteration: 8; epoch: 0; objective: 2.2857656478881836; \n",
      "fold: TRAIN; iteration: 9; epoch: 0; objective: 2.2720184326171875; \n",
      "fold: TRAIN; iteration: 10; epoch: 0; objective: 2.2582945823669434; \n",
      "fold: TRAIN; iteration: 11; epoch: 0; objective: 2.2527074813842773; \n",
      "fold: TRAIN; iteration: 12; epoch: 0; objective: 2.2392578125; \n",
      "fold: TRAIN; iteration: 13; epoch: 0; objective: 2.2482974529266357; \n",
      "fold: TRAIN; iteration: 14; epoch: 0; objective: 2.2210693359375; \n",
      "fold: TRAIN; iteration: 15; epoch: 0; objective: 2.2369070053100586; \n",
      "fold: TRAIN; iteration: 16; epoch: 0; objective: 2.2266435623168945; \n",
      "fold: TRAIN; iteration: 17; epoch: 0; objective: 2.2176647186279297; \n",
      "fold: TRAIN; iteration: 18; epoch: 0; objective: 2.221522808074951; \n",
      "fold: TRAIN; iteration: 19; epoch: 0; objective: 2.1940650939941406; \n",
      "fold: TRAIN; iteration: 20; epoch: 0; objective: 2.1993215084075928; \n",
      "fold: TRAIN; iteration: 21; epoch: 0; objective: 2.2120184898376465; \n",
      "fold: TRAIN; iteration: 22; epoch: 0; objective: 2.2112157344818115; \n",
      "fold: TRAIN; iteration: 23; epoch: 0; objective: 2.187382698059082; \n",
      "fold: TRAIN; iteration: 24; epoch: 0; objective: 2.1922290325164795; \n",
      "fold: TRAIN; iteration: 25; epoch: 0; objective: 2.1966609954833984; \n",
      "fold: TRAIN; iteration: 26; epoch: 0; objective: 2.1766116619110107; \n",
      "fold: TRAIN; iteration: 27; epoch: 0; objective: 2.160541534423828; \n",
      "fold: TRAIN; iteration: 28; epoch: 0; objective: 2.157588005065918; \n",
      "fold: TRAIN; iteration: 29; epoch: 0; objective: 2.14666748046875; \n",
      "fold: TRAIN; iteration: 30; epoch: 0; objective: 2.168260097503662; \n",
      "fold: TRAIN; iteration: 31; epoch: 0; objective: 2.1384613513946533; \n",
      "fold: TRAIN; iteration: 32; epoch: 0; objective: 2.1463348865509033; \n",
      "fold: TRAIN; iteration: 33; epoch: 0; objective: 2.1242058277130127; \n",
      "fold: TRAIN; iteration: 34; epoch: 0; objective: 2.1153225898742676; \n",
      "fold: TRAIN; iteration: 35; epoch: 0; objective: 2.096585273742676; \n",
      "fold: TRAIN; iteration: 36; epoch: 0; objective: 2.1232049465179443; \n",
      "fold: TRAIN; iteration: 37; epoch: 0; objective: 2.1364901065826416; \n",
      "fold: TRAIN; iteration: 38; epoch: 0; objective: 2.087503433227539; \n",
      "fold: TRAIN; iteration: 39; epoch: 0; objective: 2.0593152046203613; \n",
      "fold: TRAIN; iteration: 40; epoch: 0; objective: 2.1174216270446777; \n",
      "fold: TRAIN; iteration: 41; epoch: 0; objective: 2.0935802459716797; \n",
      "fold: TRAIN; iteration: 42; epoch: 0; objective: 2.0583770275115967; \n",
      "fold: TRAIN; iteration: 43; epoch: 0; objective: 2.068593978881836; \n",
      "fold: TRAIN; iteration: 44; epoch: 0; objective: 2.0672807693481445; \n",
      "fold: TRAIN; iteration: 45; epoch: 0; objective: 2.0819759368896484; \n",
      "fold: TRAIN; iteration: 46; epoch: 0; objective: 2.027374505996704; \n",
      "fold: TRAIN; iteration: 47; epoch: 0; objective: 2.0323641300201416; \n",
      "fold: TRAIN; iteration: 48; epoch: 0; objective: 2.01857328414917; \n",
      "fold: TRAIN; iteration: 49; epoch: 0; objective: 2.0299620628356934; \n",
      "validating model...\n"
     ]
    }
   ],
   "source": [
    "docs.watch_job(jobs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e4b3b5",
   "metadata": {},
   "source": [
    "We can continue watching the job, by executing the command again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d0117e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: VALID; iteration: 0; epoch: 0; classification/accuracy: 0.096; objective: 2.3062571843465167; \n",
      "fold: TRAIN; iteration: 0; epoch: 0; objective: 2.3081090450286865; \n",
      "fold: TRAIN; iteration: 1; epoch: 0; objective: 2.3022372722625732; \n",
      "fold: TRAIN; iteration: 2; epoch: 0; objective: 2.286705732345581; \n",
      "fold: TRAIN; iteration: 3; epoch: 0; objective: 2.2725465297698975; \n",
      "fold: TRAIN; iteration: 4; epoch: 0; objective: 2.2787575721740723; \n",
      "fold: TRAIN; iteration: 5; epoch: 0; objective: 2.2775518894195557; \n",
      "fold: TRAIN; iteration: 6; epoch: 0; objective: 2.258601665496826; \n",
      "fold: TRAIN; iteration: 7; epoch: 0; objective: 2.2561283111572266; \n",
      "fold: TRAIN; iteration: 8; epoch: 0; objective: 2.2857656478881836; \n",
      "fold: TRAIN; iteration: 9; epoch: 0; objective: 2.2720184326171875; \n",
      "fold: TRAIN; iteration: 10; epoch: 0; objective: 2.2582945823669434; \n",
      "fold: TRAIN; iteration: 11; epoch: 0; objective: 2.2527074813842773; \n",
      "fold: TRAIN; iteration: 12; epoch: 0; objective: 2.2392578125; \n",
      "fold: TRAIN; iteration: 13; epoch: 0; objective: 2.2482974529266357; \n",
      "fold: TRAIN; iteration: 14; epoch: 0; objective: 2.2210693359375; \n",
      "fold: TRAIN; iteration: 15; epoch: 0; objective: 2.2369070053100586; \n",
      "fold: TRAIN; iteration: 16; epoch: 0; objective: 2.2266435623168945; \n",
      "fold: TRAIN; iteration: 17; epoch: 0; objective: 2.2176647186279297; \n",
      "fold: TRAIN; iteration: 18; epoch: 0; objective: 2.221522808074951; \n",
      "fold: TRAIN; iteration: 19; epoch: 0; objective: 2.1940650939941406; \n",
      "fold: TRAIN; iteration: 20; epoch: 0; objective: 2.1993215084075928; \n",
      "fold: TRAIN; iteration: 21; epoch: 0; objective: 2.2120184898376465; \n",
      "fold: TRAIN; iteration: 22; epoch: 0; objective: 2.2112157344818115; \n",
      "fold: TRAIN; iteration: 23; epoch: 0; objective: 2.187382698059082; \n",
      "fold: TRAIN; iteration: 24; epoch: 0; objective: 2.1922290325164795; \n",
      "fold: TRAIN; iteration: 25; epoch: 0; objective: 2.1966609954833984; \n",
      "fold: TRAIN; iteration: 26; epoch: 0; objective: 2.1766116619110107; \n",
      "fold: TRAIN; iteration: 27; epoch: 0; objective: 2.160541534423828; \n",
      "fold: TRAIN; iteration: 28; epoch: 0; objective: 2.157588005065918; \n",
      "fold: TRAIN; iteration: 29; epoch: 0; objective: 2.14666748046875; \n",
      "fold: TRAIN; iteration: 30; epoch: 0; objective: 2.168260097503662; \n",
      "fold: TRAIN; iteration: 31; epoch: 0; objective: 2.1384613513946533; \n",
      "fold: TRAIN; iteration: 32; epoch: 0; objective: 2.1463348865509033; \n",
      "fold: TRAIN; iteration: 33; epoch: 0; objective: 2.1242058277130127; \n",
      "fold: TRAIN; iteration: 34; epoch: 0; objective: 2.1153225898742676; \n",
      "fold: TRAIN; iteration: 35; epoch: 0; objective: 2.096585273742676; \n",
      "fold: TRAIN; iteration: 36; epoch: 0; objective: 2.1232049465179443; \n",
      "fold: TRAIN; iteration: 37; epoch: 0; objective: 2.1364901065826416; \n",
      "fold: TRAIN; iteration: 38; epoch: 0; objective: 2.087503433227539; \n",
      "fold: TRAIN; iteration: 39; epoch: 0; objective: 2.0593152046203613; \n",
      "fold: TRAIN; iteration: 40; epoch: 0; objective: 2.1174216270446777; \n",
      "fold: TRAIN; iteration: 41; epoch: 0; objective: 2.0935802459716797; \n",
      "fold: TRAIN; iteration: 42; epoch: 0; objective: 2.0583770275115967; \n",
      "fold: TRAIN; iteration: 43; epoch: 0; objective: 2.068593978881836; \n",
      "fold: TRAIN; iteration: 44; epoch: 0; objective: 2.0672807693481445; \n",
      "fold: TRAIN; iteration: 45; epoch: 0; objective: 2.0819759368896484; \n",
      "fold: TRAIN; iteration: 46; epoch: 0; objective: 2.027374505996704; \n",
      "fold: TRAIN; iteration: 47; epoch: 0; objective: 2.0323641300201416; \n",
      "fold: TRAIN; iteration: 48; epoch: 0; objective: 2.01857328414917; \n",
      "fold: TRAIN; iteration: 49; epoch: 0; objective: 2.0299620628356934; \n",
      "validating model...\n",
      "saving\n",
      "fold: VALID; iteration: 50; epoch: 0; classification/accuracy: 0.48; objective: 2.0219791690508524; \n",
      "fold: TRAIN; iteration: 50; epoch: 0; objective: 2.033715009689331; \n",
      "fold: TRAIN; iteration: 51; epoch: 0; objective: 1.9919772148132324; \n",
      "fold: TRAIN; iteration: 52; epoch: 0; objective: 2.019590377807617; \n",
      "fold: TRAIN; iteration: 53; epoch: 0; objective: 1.9990795850753784; \n",
      "fold: TRAIN; iteration: 54; epoch: 0; objective: 1.9565140008926392; \n",
      "fold: TRAIN; iteration: 55; epoch: 0; objective: 1.9503870010375977; \n",
      "fold: TRAIN; iteration: 56; epoch: 0; objective: 1.9740147590637207; \n",
      "fold: TRAIN; iteration: 57; epoch: 0; objective: 1.954717755317688; \n",
      "fold: TRAIN; iteration: 58; epoch: 0; objective: 1.9439958333969116; \n",
      "fold: TRAIN; iteration: 59; epoch: 0; objective: 1.9213652610778809; \n",
      "fold: TRAIN; iteration: 60; epoch: 0; objective: 1.9409905672073364; \n",
      "fold: TRAIN; iteration: 61; epoch: 0; objective: 1.9290080070495605; \n",
      "fold: TRAIN; iteration: 62; epoch: 0; objective: 1.9331779479980469; \n",
      "fold: TRAIN; iteration: 63; epoch: 0; objective: 1.9104089736938477; \n",
      "fold: TRAIN; iteration: 64; epoch: 0; objective: 1.8951201438903809; \n",
      "fold: TRAIN; iteration: 65; epoch: 0; objective: 1.8655165433883667; \n",
      "fold: TRAIN; iteration: 66; epoch: 0; objective: 1.8926646709442139; \n",
      "fold: TRAIN; iteration: 67; epoch: 0; objective: 1.8465890884399414; \n",
      "fold: TRAIN; iteration: 68; epoch: 0; objective: 1.9001809358596802; \n",
      "fold: TRAIN; iteration: 69; epoch: 0; objective: 1.8546675443649292; \n",
      "fold: TRAIN; iteration: 70; epoch: 0; objective: 1.8455396890640259; \n",
      "fold: TRAIN; iteration: 71; epoch: 0; objective: 1.817573070526123; \n",
      "fold: TRAIN; iteration: 72; epoch: 0; objective: 1.8031963109970093; \n",
      "fold: TRAIN; iteration: 73; epoch: 0; objective: 1.8387943506240845; \n",
      "fold: TRAIN; iteration: 74; epoch: 0; objective: 1.7978041172027588; \n",
      "fold: TRAIN; iteration: 75; epoch: 0; objective: 1.7910287380218506; \n",
      "fold: TRAIN; iteration: 76; epoch: 0; objective: 1.7763752937316895; \n",
      "fold: TRAIN; iteration: 77; epoch: 0; objective: 1.7476165294647217; \n",
      "fold: TRAIN; iteration: 78; epoch: 0; objective: 1.7492125034332275; \n",
      "fold: TRAIN; iteration: 79; epoch: 0; objective: 1.7251211404800415; \n",
      "fold: TRAIN; iteration: 80; epoch: 0; objective: 1.7180700302124023; \n",
      "fold: TRAIN; iteration: 81; epoch: 0; objective: 1.7298002243041992; \n",
      "fold: TRAIN; iteration: 82; epoch: 0; objective: 1.7614489793777466; \n",
      "fold: TRAIN; iteration: 83; epoch: 0; objective: 1.702236294746399; \n",
      "fold: TRAIN; iteration: 84; epoch: 0; objective: 1.6473324298858643; \n",
      "fold: TRAIN; iteration: 85; epoch: 0; objective: 1.6482374668121338; \n",
      "fold: TRAIN; iteration: 86; epoch: 0; objective: 1.635256290435791; \n",
      "fold: TRAIN; iteration: 87; epoch: 0; objective: 1.6560020446777344; \n",
      "fold: TRAIN; iteration: 88; epoch: 0; objective: 1.5548033714294434; \n",
      "fold: TRAIN; iteration: 89; epoch: 0; objective: 1.6052991151809692; \n",
      "fold: TRAIN; iteration: 90; epoch: 0; objective: 1.622694730758667; \n",
      "fold: TRAIN; iteration: 91; epoch: 0; objective: 1.5869351625442505; \n",
      "fold: TRAIN; iteration: 92; epoch: 0; objective: 1.5462051630020142; \n",
      "fold: TRAIN; iteration: 93; epoch: 0; objective: 1.5534275770187378; \n",
      "fold: TRAIN; iteration: 94; epoch: 0; objective: 1.5471246242523193; \n",
      "fold: TRAIN; iteration: 95; epoch: 0; objective: 1.5577175617218018; \n",
      "fold: TRAIN; iteration: 96; epoch: 0; objective: 1.5518537759780884; \n",
      "fold: TRAIN; iteration: 97; epoch: 0; objective: 1.5534095764160156; \n",
      "fold: TRAIN; iteration: 98; epoch: 0; objective: 1.507837176322937; \n",
      "fold: TRAIN; iteration: 99; epoch: 0; objective: 1.5786226987838745; \n",
      "validating model...\n",
      "saving\n",
      "fold: VALID; iteration: 100; epoch: 0; classification/accuracy: 0.728; objective: 1.470482877890269; \n",
      "fold: TRAIN; iteration: 100; epoch: 0; objective: 1.4630029201507568; \n",
      "fold: TRAIN; iteration: 101; epoch: 0; objective: 1.5214991569519043; \n",
      "fold: TRAIN; iteration: 102; epoch: 0; objective: 1.397486925125122; \n",
      "fold: TRAIN; iteration: 103; epoch: 0; objective: 1.409949779510498; \n",
      "fold: TRAIN; iteration: 104; epoch: 0; objective: 1.4497480392456055; \n",
      "fold: TRAIN; iteration: 105; epoch: 0; objective: 1.4949108362197876; \n",
      "fold: TRAIN; iteration: 106; epoch: 0; objective: 1.437696933746338; \n",
      "fold: TRAIN; iteration: 107; epoch: 0; objective: 1.436039924621582; \n",
      "fold: TRAIN; iteration: 108; epoch: 0; objective: 1.343278408050537; \n",
      "fold: TRAIN; iteration: 109; epoch: 0; objective: 1.3710774183273315; \n",
      "fold: TRAIN; iteration: 110; epoch: 0; objective: 1.3524757623672485; \n",
      "fold: TRAIN; iteration: 111; epoch: 0; objective: 1.3065590858459473; \n",
      "fold: TRAIN; iteration: 112; epoch: 0; objective: 1.3751028776168823; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 113; epoch: 0; objective: 1.4243282079696655; \n",
      "fold: TRAIN; iteration: 114; epoch: 0; objective: 1.2730684280395508; \n",
      "fold: TRAIN; iteration: 115; epoch: 0; objective: 1.3489559888839722; \n",
      "fold: TRAIN; iteration: 116; epoch: 0; objective: 1.1814117431640625; \n",
      "fold: TRAIN; iteration: 117; epoch: 0; objective: 1.3357967138290405; \n",
      "fold: TRAIN; iteration: 118; epoch: 0; objective: 1.2825517654418945; \n",
      "fold: TRAIN; iteration: 119; epoch: 0; objective: 1.3534013032913208; \n",
      "fold: TRAIN; iteration: 120; epoch: 0; objective: 1.2315753698349; \n",
      "fold: TRAIN; iteration: 121; epoch: 0; objective: 1.183465838432312; \n",
      "fold: TRAIN; iteration: 122; epoch: 0; objective: 1.2979278564453125; \n",
      "fold: TRAIN; iteration: 123; epoch: 0; objective: 1.1404298543930054; \n",
      "fold: TRAIN; iteration: 124; epoch: 0; objective: 1.2049496173858643; \n",
      "fold: TRAIN; iteration: 125; epoch: 0; objective: 1.1770222187042236; \n",
      "fold: TRAIN; iteration: 126; epoch: 0; objective: 1.127610445022583; \n",
      "fold: TRAIN; iteration: 127; epoch: 0; objective: 1.1073715686798096; \n",
      "fold: TRAIN; iteration: 128; epoch: 0; objective: 1.0467859506607056; \n",
      "fold: TRAIN; iteration: 129; epoch: 0; objective: 1.192195177078247; \n",
      "fold: TRAIN; iteration: 130; epoch: 0; objective: 1.0237492322921753; \n",
      "fold: TRAIN; iteration: 131; epoch: 0; objective: 1.1570299863815308; \n",
      "fold: TRAIN; iteration: 132; epoch: 0; objective: 1.1530778408050537; \n",
      "fold: TRAIN; iteration: 133; epoch: 0; objective: 1.1185415983200073; \n",
      "fold: TRAIN; iteration: 134; epoch: 0; objective: 1.0342204570770264; \n",
      "fold: TRAIN; iteration: 135; epoch: 0; objective: 1.000462532043457; \n",
      "fold: TRAIN; iteration: 136; epoch: 0; objective: 1.0449432134628296; \n",
      "fold: TRAIN; iteration: 137; epoch: 0; objective: 1.0968983173370361; \n",
      "fold: TRAIN; iteration: 138; epoch: 0; objective: 0.9834425449371338; \n",
      "fold: TRAIN; iteration: 139; epoch: 0; objective: 1.0495821237564087; \n",
      "fold: TRAIN; iteration: 140; epoch: 0; objective: 0.9856009483337402; \n",
      "fold: TRAIN; iteration: 141; epoch: 0; objective: 1.0393867492675781; \n",
      "fold: TRAIN; iteration: 142; epoch: 0; objective: 0.9772046804428101; \n",
      "fold: TRAIN; iteration: 143; epoch: 0; objective: 0.9327888488769531; \n",
      "fold: TRAIN; iteration: 144; epoch: 0; objective: 1.0302332639694214; \n",
      "fold: TRAIN; iteration: 145; epoch: 0; objective: 0.9951748847961426; \n",
      "fold: TRAIN; iteration: 146; epoch: 0; objective: 0.9452139139175415; \n",
      "fold: TRAIN; iteration: 147; epoch: 0; objective: 0.9076563119888306; \n",
      "fold: TRAIN; iteration: 148; epoch: 0; objective: 0.8915069103240967; \n",
      "fold: TRAIN; iteration: 149; epoch: 0; objective: 0.9069746136665344; \n",
      "validating model...\n",
      "saving\n",
      "fold: VALID; iteration: 150; epoch: 0; classification/accuracy: 0.844; objective: 0.9092001179854076; \n",
      "fold: TRAIN; iteration: 150; epoch: 0; objective: 0.9613026976585388; \n",
      "fold: TRAIN; iteration: 151; epoch: 0; objective: 0.9928408265113831; \n",
      "fold: TRAIN; iteration: 152; epoch: 0; objective: 0.8800116181373596; \n",
      "fold: TRAIN; iteration: 153; epoch: 0; objective: 0.9675692915916443; \n",
      "fold: TRAIN; iteration: 154; epoch: 0; objective: 0.8531095385551453; \n",
      "fold: TRAIN; iteration: 155; epoch: 0; objective: 0.8969034552574158; \n",
      "fold: TRAIN; iteration: 156; epoch: 0; objective: 0.8625054359436035; \n",
      "fold: TRAIN; iteration: 157; epoch: 0; objective: 0.8597906231880188; \n",
      "fold: TRAIN; iteration: 158; epoch: 0; objective: 0.8123831152915955; \n",
      "fold: TRAIN; iteration: 159; epoch: 0; objective: 0.9096454381942749; \n",
      "fold: TRAIN; iteration: 160; epoch: 0; objective: 0.8913353681564331; \n",
      "fold: TRAIN; iteration: 161; epoch: 0; objective: 0.8562260270118713; \n",
      "fold: TRAIN; iteration: 162; epoch: 0; objective: 0.7630282640457153; \n",
      "fold: TRAIN; iteration: 163; epoch: 0; objective: 0.8133261203765869; \n",
      "fold: TRAIN; iteration: 164; epoch: 0; objective: 0.7809194922447205; \n",
      "fold: TRAIN; iteration: 165; epoch: 0; objective: 0.7882856130599976; \n",
      "fold: TRAIN; iteration: 166; epoch: 0; objective: 0.7901067137718201; \n",
      "fold: TRAIN; iteration: 167; epoch: 0; objective: 0.8203201293945312; \n",
      "fold: TRAIN; iteration: 168; epoch: 0; objective: 0.7843412756919861; \n",
      "fold: TRAIN; iteration: 169; epoch: 0; objective: 0.7375901937484741; \n",
      "fold: TRAIN; iteration: 170; epoch: 0; objective: 0.6953242421150208; \n",
      "fold: TRAIN; iteration: 171; epoch: 0; objective: 0.7553883194923401; \n",
      "fold: TRAIN; iteration: 172; epoch: 0; objective: 0.7305445671081543; \n",
      "fold: TRAIN; iteration: 173; epoch: 0; objective: 0.7002148628234863; \n",
      "fold: TRAIN; iteration: 174; epoch: 0; objective: 0.7412077188491821; \n",
      "fold: TRAIN; iteration: 175; epoch: 0; objective: 0.783499538898468; \n",
      "fold: TRAIN; iteration: 176; epoch: 0; objective: 0.8078474402427673; \n",
      "fold: TRAIN; iteration: 177; epoch: 0; objective: 0.7469646334648132; \n",
      "fold: TRAIN; iteration: 178; epoch: 0; objective: 0.6090302467346191; \n",
      "fold: TRAIN; iteration: 179; epoch: 0; objective: 0.7196595072746277; \n",
      "fold: TRAIN; iteration: 180; epoch: 0; objective: 0.78682541847229; \n",
      "fold: TRAIN; iteration: 181; epoch: 0; objective: 0.6678661108016968; \n",
      "fold: TRAIN; iteration: 182; epoch: 0; objective: 0.6205844283103943; \n",
      "fold: TRAIN; iteration: 183; epoch: 0; objective: 0.6828123331069946; \n",
      "fold: TRAIN; iteration: 184; epoch: 0; objective: 0.6168977618217468; \n",
      "fold: TRAIN; iteration: 185; epoch: 0; objective: 0.6379950046539307; \n",
      "fold: TRAIN; iteration: 186; epoch: 0; objective: 0.6760406494140625; \n",
      "fold: TRAIN; iteration: 187; epoch: 0; objective: 0.6566789746284485; \n",
      "fold: TRAIN; iteration: 188; epoch: 0; objective: 0.6091455221176147; \n",
      "fold: TRAIN; iteration: 189; epoch: 0; objective: 0.6794807314872742; \n",
      "fold: TRAIN; iteration: 190; epoch: 0; objective: 0.7776758074760437; \n",
      "fold: TRAIN; iteration: 191; epoch: 0; objective: 0.6398364305496216; \n",
      "fold: TRAIN; iteration: 192; epoch: 0; objective: 0.6890007853507996; \n",
      "fold: TRAIN; iteration: 193; epoch: 0; objective: 0.661967396736145; \n",
      "fold: TRAIN; iteration: 194; epoch: 0; objective: 0.5776137709617615; \n",
      "fold: TRAIN; iteration: 195; epoch: 0; objective: 0.6048082113265991; \n",
      "fold: TRAIN; iteration: 196; epoch: 0; objective: 0.5280308723449707; \n",
      "fold: TRAIN; iteration: 197; epoch: 0; objective: 0.7023494243621826; \n",
      "fold: TRAIN; iteration: 198; epoch: 0; objective: 0.5461812019348145; \n",
      "fold: TRAIN; iteration: 199; epoch: 0; objective: 0.5802761912345886; \n",
      "validating model...\n",
      "saving\n",
      "fold: VALID; iteration: 200; epoch: 0; classification/accuracy: 0.864; objective: 0.5880270600318909; \n",
      "fold: TRAIN; iteration: 200; epoch: 0; objective: 0.6006607413291931; \n",
      "fold: TRAIN; iteration: 201; epoch: 0; objective: 0.6400421857833862; \n",
      "fold: TRAIN; iteration: 202; epoch: 0; objective: 0.6499030590057373; \n",
      "fold: TRAIN; iteration: 203; epoch: 0; objective: 0.6127077341079712; \n",
      "fold: TRAIN; iteration: 204; epoch: 0; objective: 0.6032575964927673; \n",
      "fold: TRAIN; iteration: 205; epoch: 0; objective: 0.6112935543060303; \n",
      "fold: TRAIN; iteration: 206; epoch: 0; objective: 0.5345421433448792; \n",
      "fold: TRAIN; iteration: 207; epoch: 0; objective: 0.6612241268157959; \n",
      "fold: TRAIN; iteration: 208; epoch: 0; objective: 0.5442929863929749; \n",
      "fold: TRAIN; iteration: 209; epoch: 0; objective: 0.46604588627815247; \n",
      "fold: TRAIN; iteration: 210; epoch: 0; objective: 0.47216808795928955; \n",
      "fold: TRAIN; iteration: 211; epoch: 0; objective: 0.544294536113739; \n",
      "fold: TRAIN; iteration: 212; epoch: 0; objective: 0.5687744617462158; \n",
      "fold: TRAIN; iteration: 213; epoch: 0; objective: 0.5673447251319885; \n",
      "fold: TRAIN; iteration: 214; epoch: 0; objective: 0.5773466229438782; \n",
      "fold: TRAIN; iteration: 215; epoch: 0; objective: 0.6495652794837952; \n",
      "fold: TRAIN; iteration: 216; epoch: 0; objective: 0.4575427770614624; \n",
      "fold: TRAIN; iteration: 217; epoch: 0; objective: 0.5968286991119385; \n",
      "fold: TRAIN; iteration: 218; epoch: 0; objective: 0.5567829012870789; \n",
      "fold: TRAIN; iteration: 219; epoch: 0; objective: 0.6467909812927246; \n",
      "fold: TRAIN; iteration: 220; epoch: 0; objective: 0.5359638333320618; \n",
      "fold: TRAIN; iteration: 221; epoch: 0; objective: 0.5667701363563538; \n",
      "fold: TRAIN; iteration: 222; epoch: 0; objective: 0.5458613634109497; \n",
      "fold: TRAIN; iteration: 223; epoch: 0; objective: 0.5183739066123962; \n",
      "fold: TRAIN; iteration: 224; epoch: 0; objective: 0.4549981355667114; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 225; epoch: 0; objective: 0.5535433292388916; \n",
      "fold: TRAIN; iteration: 226; epoch: 0; objective: 0.5155364871025085; \n",
      "fold: TRAIN; iteration: 227; epoch: 0; objective: 0.3822382986545563; \n",
      "fold: TRAIN; iteration: 228; epoch: 0; objective: 0.5093151926994324; \n",
      "fold: TRAIN; iteration: 229; epoch: 0; objective: 0.4552822411060333; \n",
      "fold: TRAIN; iteration: 230; epoch: 0; objective: 0.45513057708740234; \n",
      "fold: TRAIN; iteration: 231; epoch: 0; objective: 0.4466818869113922; \n",
      "fold: TRAIN; iteration: 232; epoch: 0; objective: 0.4828426241874695; \n",
      "fold: TRAIN; iteration: 233; epoch: 0; objective: 0.4763830900192261; \n",
      "fold: TRAIN; iteration: 234; epoch: 0; objective: 0.4937799870967865; \n",
      "fold: TRAIN; iteration: 235; epoch: 0; objective: 0.49009740352630615; \n",
      "fold: TRAIN; iteration: 236; epoch: 0; objective: 0.5070496201515198; \n",
      "fold: TRAIN; iteration: 237; epoch: 0; objective: 0.5286771059036255; \n",
      "fold: TRAIN; iteration: 238; epoch: 0; objective: 0.5148768424987793; \n",
      "fold: TRAIN; iteration: 239; epoch: 0; objective: 0.6306504607200623; \n",
      "fold: TRAIN; iteration: 240; epoch: 0; objective: 0.5087630152702332; \n",
      "fold: TRAIN; iteration: 241; epoch: 0; objective: 0.412151575088501; \n",
      "fold: TRAIN; iteration: 242; epoch: 0; objective: 0.44413742423057556; \n",
      "fold: TRAIN; iteration: 243; epoch: 0; objective: 0.5575826168060303; \n",
      "fold: TRAIN; iteration: 244; epoch: 0; objective: 0.4284028112888336; \n",
      "fold: TRAIN; iteration: 245; epoch: 0; objective: 0.4791298806667328; \n",
      "fold: TRAIN; iteration: 246; epoch: 0; objective: 0.5087383389472961; \n",
      "fold: TRAIN; iteration: 247; epoch: 0; objective: 0.4457493722438812; \n",
      "fold: TRAIN; iteration: 248; epoch: 0; objective: 0.4914531409740448; \n",
      "fold: TRAIN; iteration: 249; epoch: 0; objective: 0.5565534830093384; \n",
      "validating model...\n",
      "saving\n",
      "fold: VALID; iteration: 250; epoch: 0; classification/accuracy: 0.896; objective: 0.42862788736820223; \n",
      "fold: TRAIN; iteration: 250; epoch: 0; objective: 0.3792019188404083; \n",
      "fold: TRAIN; iteration: 251; epoch: 0; objective: 0.4179498553276062; \n",
      "fold: TRAIN; iteration: 252; epoch: 0; objective: 0.43324920535087585; \n",
      "fold: TRAIN; iteration: 253; epoch: 0; objective: 0.370967835187912; \n",
      "fold: TRAIN; iteration: 254; epoch: 0; objective: 0.4331158399581909; \n",
      "fold: TRAIN; iteration: 255; epoch: 0; objective: 0.3822261691093445; \n",
      "fold: TRAIN; iteration: 256; epoch: 0; objective: 0.3906915783882141; \n",
      "fold: TRAIN; iteration: 257; epoch: 0; objective: 0.39299049973487854; \n",
      "fold: TRAIN; iteration: 258; epoch: 0; objective: 0.4945288598537445; \n",
      "fold: TRAIN; iteration: 259; epoch: 0; objective: 0.4355197846889496; \n",
      "fold: TRAIN; iteration: 260; epoch: 0; objective: 0.35509562492370605; \n",
      "fold: TRAIN; iteration: 261; epoch: 0; objective: 0.36622780561447144; \n",
      "fold: TRAIN; iteration: 262; epoch: 0; objective: 0.35377657413482666; \n",
      "fold: TRAIN; iteration: 263; epoch: 0; objective: 0.5161538124084473; \n",
      "fold: TRAIN; iteration: 264; epoch: 0; objective: 0.44381505250930786; \n",
      "fold: TRAIN; iteration: 265; epoch: 0; objective: 0.3582504391670227; \n",
      "fold: TRAIN; iteration: 266; epoch: 0; objective: 0.47265389561653137; \n",
      "fold: TRAIN; iteration: 267; epoch: 0; objective: 0.37154820561408997; \n",
      "fold: TRAIN; iteration: 268; epoch: 0; objective: 0.39213961362838745; \n",
      "fold: TRAIN; iteration: 269; epoch: 0; objective: 0.5670366883277893; \n",
      "fold: TRAIN; iteration: 270; epoch: 0; objective: 0.397899866104126; \n",
      "fold: TRAIN; iteration: 271; epoch: 0; objective: 0.3656572997570038; \n",
      "fold: TRAIN; iteration: 272; epoch: 0; objective: 0.4276888966560364; \n",
      "fold: TRAIN; iteration: 273; epoch: 0; objective: 0.29994237422943115; \n",
      "fold: TRAIN; iteration: 274; epoch: 0; objective: 0.39402535557746887; \n",
      "fold: TRAIN; iteration: 275; epoch: 0; objective: 0.3250919580459595; \n",
      "fold: TRAIN; iteration: 276; epoch: 0; objective: 0.39301827549934387; \n",
      "fold: TRAIN; iteration: 277; epoch: 0; objective: 0.393205463886261; \n",
      "fold: TRAIN; iteration: 278; epoch: 0; objective: 0.3417448103427887; \n",
      "fold: TRAIN; iteration: 279; epoch: 0; objective: 0.30082404613494873; \n",
      "fold: TRAIN; iteration: 280; epoch: 0; objective: 0.4877666234970093; \n",
      "fold: TRAIN; iteration: 281; epoch: 0; objective: 0.32329678535461426; \n",
      "fold: TRAIN; iteration: 282; epoch: 0; objective: 0.30617961287498474; \n",
      "fold: TRAIN; iteration: 283; epoch: 0; objective: 0.4084044396877289; \n",
      "fold: TRAIN; iteration: 284; epoch: 0; objective: 0.31741440296173096; \n",
      "fold: TRAIN; iteration: 285; epoch: 0; objective: 0.25707778334617615; \n",
      "fold: TRAIN; iteration: 286; epoch: 0; objective: 0.32813262939453125; \n",
      "fold: TRAIN; iteration: 287; epoch: 0; objective: 0.30421167612075806; \n",
      "fold: TRAIN; iteration: 288; epoch: 0; objective: 0.31296855211257935; \n",
      "fold: TRAIN; iteration: 289; epoch: 0; objective: 0.3650311529636383; \n",
      "fold: TRAIN; iteration: 290; epoch: 0; objective: 0.405612975358963; \n",
      "fold: TRAIN; iteration: 291; epoch: 0; objective: 0.3057957589626312; \n",
      "fold: TRAIN; iteration: 292; epoch: 0; objective: 0.35872817039489746; \n",
      "fold: TRAIN; iteration: 293; epoch: 0; objective: 0.32269105315208435; \n",
      "fold: TRAIN; iteration: 294; epoch: 0; objective: 0.30096635222435; \n",
      "fold: TRAIN; iteration: 295; epoch: 0; objective: 0.2698895037174225; \n",
      "fold: TRAIN; iteration: 296; epoch: 0; objective: 0.2848523259162903; \n",
      "fold: TRAIN; iteration: 297; epoch: 0; objective: 0.28866472840309143; \n",
      "fold: TRAIN; iteration: 298; epoch: 0; objective: 0.34119006991386414; \n",
      "fold: TRAIN; iteration: 299; epoch: 0; objective: 0.4392628073692322; \n",
      "validating model...\n",
      "saving\n",
      "fold: VALID; iteration: 300; epoch: 0; classification/accuracy: 0.908; objective: 0.33637697498003644; \n",
      "fold: TRAIN; iteration: 300; epoch: 0; objective: 0.32733920216560364; \n",
      "fold: TRAIN; iteration: 301; epoch: 0; objective: 0.21240098774433136; \n",
      "fold: TRAIN; iteration: 302; epoch: 0; objective: 0.41601163148880005; \n",
      "fold: TRAIN; iteration: 303; epoch: 0; objective: 0.35932230949401855; \n",
      "fold: TRAIN; iteration: 304; epoch: 0; objective: 0.2564830482006073; \n",
      "fold: TRAIN; iteration: 305; epoch: 0; objective: 0.23330363631248474; \n",
      "fold: TRAIN; iteration: 306; epoch: 0; objective: 0.30548930168151855; \n",
      "fold: TRAIN; iteration: 307; epoch: 0; objective: 0.34311768412590027; \n",
      "fold: TRAIN; iteration: 308; epoch: 0; objective: 0.3667440414428711; \n",
      "fold: TRAIN; iteration: 309; epoch: 0; objective: 0.30486157536506653; \n",
      "fold: TRAIN; iteration: 310; epoch: 0; objective: 0.36689645051956177; \n",
      "fold: TRAIN; iteration: 311; epoch: 0; objective: 0.3299083411693573; \n",
      "fold: TRAIN; iteration: 312; epoch: 0; objective: 0.34193524718284607; \n",
      "fold: TRAIN; iteration: 313; epoch: 0; objective: 0.26142120361328125; \n",
      "fold: TRAIN; iteration: 314; epoch: 0; objective: 0.3401843309402466; \n",
      "fold: TRAIN; iteration: 315; epoch: 0; objective: 0.2592041790485382; \n",
      "fold: TRAIN; iteration: 316; epoch: 0; objective: 0.34069114923477173; \n",
      "fold: TRAIN; iteration: 317; epoch: 0; objective: 0.24785834550857544; \n",
      "fold: TRAIN; iteration: 318; epoch: 0; objective: 0.2871306538581848; \n",
      "fold: TRAIN; iteration: 319; epoch: 0; objective: 0.3412711024284363; \n",
      "fold: TRAIN; iteration: 320; epoch: 0; objective: 0.3413122296333313; \n",
      "fold: TRAIN; iteration: 321; epoch: 0; objective: 0.40158435702323914; \n",
      "fold: TRAIN; iteration: 322; epoch: 0; objective: 0.3325254023075104; \n",
      "fold: TRAIN; iteration: 323; epoch: 0; objective: 0.33514007925987244; \n",
      "fold: TRAIN; iteration: 324; epoch: 0; objective: 0.3176891505718231; \n",
      "fold: TRAIN; iteration: 325; epoch: 0; objective: 0.3552955389022827; \n",
      "fold: TRAIN; iteration: 326; epoch: 0; objective: 0.3209134042263031; \n",
      "fold: TRAIN; iteration: 327; epoch: 0; objective: 0.3909457325935364; \n",
      "fold: TRAIN; iteration: 328; epoch: 0; objective: 0.3770485818386078; \n",
      "fold: TRAIN; iteration: 329; epoch: 0; objective: 0.33780819177627563; \n",
      "fold: TRAIN; iteration: 330; epoch: 0; objective: 0.3136414587497711; \n",
      "fold: TRAIN; iteration: 331; epoch: 0; objective: 0.4300249516963959; \n",
      "fold: TRAIN; iteration: 332; epoch: 0; objective: 0.3151557445526123; \n",
      "fold: TRAIN; iteration: 333; epoch: 0; objective: 0.3261483311653137; \n",
      "fold: TRAIN; iteration: 334; epoch: 0; objective: 0.19813816249370575; \n",
      "fold: TRAIN; iteration: 335; epoch: 0; objective: 0.20286738872528076; \n",
      "fold: TRAIN; iteration: 336; epoch: 0; objective: 0.269804447889328; \n",
      "fold: TRAIN; iteration: 337; epoch: 0; objective: 0.2886205017566681; \n",
      "fold: TRAIN; iteration: 338; epoch: 0; objective: 0.36026501655578613; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 339; epoch: 0; objective: 0.3074381947517395; \n",
      "fold: TRAIN; iteration: 340; epoch: 0; objective: 0.3056694269180298; \n",
      "fold: TRAIN; iteration: 341; epoch: 0; objective: 0.2689163386821747; \n",
      "fold: TRAIN; iteration: 342; epoch: 0; objective: 0.4783170819282532; \n",
      "fold: TRAIN; iteration: 343; epoch: 0; objective: 0.2096068561077118; \n",
      "fold: TRAIN; iteration: 344; epoch: 0; objective: 0.30004701018333435; \n",
      "fold: TRAIN; iteration: 345; epoch: 0; objective: 0.34730494022369385; \n",
      "fold: TRAIN; iteration: 346; epoch: 0; objective: 0.24603012204170227; \n",
      "fold: TRAIN; iteration: 347; epoch: 0; objective: 0.23784461617469788; \n",
      "fold: TRAIN; iteration: 348; epoch: 0; objective: 0.43941783905029297; \n",
      "fold: TRAIN; iteration: 349; epoch: 0; objective: 0.25239431858062744; \n",
      "validating model...\n",
      "saving\n",
      "fold: VALID; iteration: 350; epoch: 0; classification/accuracy: 0.924; objective: 0.2839222768942515; \n",
      "fold: TRAIN; iteration: 350; epoch: 0; objective: 0.18687936663627625; \n",
      "fold: TRAIN; iteration: 351; epoch: 0; objective: 0.2784036695957184; \n",
      "fold: TRAIN; iteration: 352; epoch: 0; objective: 0.4113312065601349; \n",
      "fold: TRAIN; iteration: 353; epoch: 0; objective: 0.24529673159122467; \n",
      "fold: TRAIN; iteration: 354; epoch: 0; objective: 0.24334320425987244; \n",
      "fold: TRAIN; iteration: 355; epoch: 0; objective: 0.18089912831783295; \n",
      "fold: TRAIN; iteration: 356; epoch: 0; objective: 0.26141878962516785; \n",
      "fold: TRAIN; iteration: 357; epoch: 0; objective: 0.3048517405986786; \n",
      "fold: TRAIN; iteration: 358; epoch: 0; objective: 0.2512724995613098; \n",
      "fold: TRAIN; iteration: 359; epoch: 0; objective: 0.4257057309150696; \n",
      "fold: TRAIN; iteration: 360; epoch: 0; objective: 0.2626422643661499; \n",
      "fold: TRAIN; iteration: 361; epoch: 0; objective: 0.22774197161197662; \n",
      "fold: TRAIN; iteration: 362; epoch: 0; objective: 0.3186015188694; \n",
      "fold: TRAIN; iteration: 363; epoch: 0; objective: 0.20647844672203064; \n",
      "fold: TRAIN; iteration: 364; epoch: 0; objective: 0.19183798134326935; \n",
      "fold: TRAIN; iteration: 365; epoch: 0; objective: 0.29252249002456665; \n",
      "fold: TRAIN; iteration: 366; epoch: 0; objective: 0.279130220413208; \n",
      "fold: TRAIN; iteration: 367; epoch: 0; objective: 0.2545214891433716; \n",
      "fold: TRAIN; iteration: 368; epoch: 0; objective: 0.2996353805065155; \n",
      "fold: TRAIN; iteration: 369; epoch: 0; objective: 0.26975616812705994; \n",
      "fold: TRAIN; iteration: 370; epoch: 0; objective: 0.3082443177700043; \n",
      "fold: TRAIN; iteration: 371; epoch: 0; objective: 0.26561659574508667; \n",
      "fold: TRAIN; iteration: 372; epoch: 0; objective: 0.20775066316127777; \n",
      "fold: TRAIN; iteration: 373; epoch: 0; objective: 0.3712126910686493; \n",
      "fold: TRAIN; iteration: 374; epoch: 0; objective: 0.23828181624412537; \n",
      "fold: TRAIN; iteration: 375; epoch: 0; objective: 0.3730657696723938; \n",
      "fold: TRAIN; iteration: 376; epoch: 0; objective: 0.24508802592754364; \n",
      "fold: TRAIN; iteration: 377; epoch: 0; objective: 0.3081861436367035; \n",
      "fold: TRAIN; iteration: 378; epoch: 0; objective: 0.32848602533340454; \n",
      "fold: TRAIN; iteration: 379; epoch: 0; objective: 0.31829822063446045; \n",
      "fold: TRAIN; iteration: 380; epoch: 0; objective: 0.3035294711589813; \n",
      "fold: TRAIN; iteration: 381; epoch: 0; objective: 0.1739950329065323; \n",
      "fold: TRAIN; iteration: 382; epoch: 0; objective: 0.29250890016555786; \n",
      "fold: TRAIN; iteration: 383; epoch: 0; objective: 0.3344763219356537; \n",
      "fold: TRAIN; iteration: 384; epoch: 0; objective: 0.2981609106063843; \n",
      "fold: TRAIN; iteration: 385; epoch: 0; objective: 0.19190776348114014; \n",
      "fold: TRAIN; iteration: 386; epoch: 0; objective: 0.2520509958267212; \n",
      "fold: TRAIN; iteration: 387; epoch: 0; objective: 0.2925015091896057; \n",
      "fold: TRAIN; iteration: 388; epoch: 0; objective: 0.317429780960083; \n",
      "fold: TRAIN; iteration: 389; epoch: 0; objective: 0.22670146822929382; \n",
      "fold: TRAIN; iteration: 390; epoch: 0; objective: 0.3707813322544098; \n",
      "fold: TRAIN; iteration: 391; epoch: 0; objective: 0.2841989994049072; \n",
      "fold: TRAIN; iteration: 392; epoch: 0; objective: 0.18612051010131836; \n",
      "fold: TRAIN; iteration: 393; epoch: 0; objective: 0.24501964449882507; \n",
      "fold: TRAIN; iteration: 394; epoch: 0; objective: 0.31465092301368713; \n",
      "fold: TRAIN; iteration: 395; epoch: 0; objective: 0.19883140921592712; \n",
      "fold: TRAIN; iteration: 396; epoch: 0; objective: 0.3865222930908203; \n",
      "fold: TRAIN; iteration: 397; epoch: 0; objective: 0.26271262764930725; \n",
      "fold: TRAIN; iteration: 398; epoch: 0; objective: 0.2674364149570465; \n",
      "fold: TRAIN; iteration: 399; epoch: 0; objective: 0.22897827625274658; \n",
      "validating model...\n",
      "saving\n",
      "fold: VALID; iteration: 400; epoch: 0; classification/accuracy: 0.944; objective: 0.250561593969663; \n",
      "fold: TRAIN; iteration: 400; epoch: 0; objective: 0.281922310590744; \n",
      "fold: TRAIN; iteration: 401; epoch: 0; objective: 0.3457414507865906; \n",
      "fold: TRAIN; iteration: 402; epoch: 0; objective: 0.228633314371109; \n",
      "fold: TRAIN; iteration: 403; epoch: 0; objective: 0.1818254441022873; \n",
      "fold: TRAIN; iteration: 404; epoch: 0; objective: 0.2040930986404419; \n",
      "fold: TRAIN; iteration: 405; epoch: 0; objective: 0.3946213126182556; \n",
      "fold: TRAIN; iteration: 406; epoch: 0; objective: 0.3301994800567627; \n",
      "fold: TRAIN; iteration: 407; epoch: 0; objective: 0.2838810980319977; \n",
      "fold: TRAIN; iteration: 408; epoch: 0; objective: 0.1726371794939041; \n",
      "fold: TRAIN; iteration: 409; epoch: 0; objective: 0.28292781114578247; \n",
      "fold: TRAIN; iteration: 410; epoch: 0; objective: 0.27844786643981934; \n",
      "fold: TRAIN; iteration: 411; epoch: 0; objective: 0.2795228064060211; \n",
      "fold: TRAIN; iteration: 412; epoch: 0; objective: 0.22660930454730988; \n",
      "fold: TRAIN; iteration: 413; epoch: 0; objective: 0.20764125883579254; \n",
      "fold: TRAIN; iteration: 414; epoch: 0; objective: 0.2597474753856659; \n",
      "fold: TRAIN; iteration: 415; epoch: 0; objective: 0.24133355915546417; \n",
      "fold: TRAIN; iteration: 416; epoch: 0; objective: 0.30185598134994507; \n",
      "fold: TRAIN; iteration: 417; epoch: 0; objective: 0.1887924075126648; \n",
      "fold: TRAIN; iteration: 418; epoch: 0; objective: 0.20796024799346924; \n",
      "fold: TRAIN; iteration: 419; epoch: 0; objective: 0.16175317764282227; \n",
      "fold: TRAIN; iteration: 420; epoch: 0; objective: 0.2756967842578888; \n",
      "fold: TRAIN; iteration: 421; epoch: 0; objective: 0.2691190838813782; \n",
      "fold: TRAIN; iteration: 422; epoch: 0; objective: 0.2911379635334015; \n",
      "fold: TRAIN; iteration: 423; epoch: 0; objective: 0.18938913941383362; \n",
      "fold: TRAIN; iteration: 424; epoch: 0; objective: 0.16801032423973083; \n",
      "fold: TRAIN; iteration: 425; epoch: 0; objective: 0.26485854387283325; \n",
      "fold: TRAIN; iteration: 426; epoch: 0; objective: 0.2327996790409088; \n",
      "fold: TRAIN; iteration: 427; epoch: 0; objective: 0.19870758056640625; \n",
      "fold: TRAIN; iteration: 428; epoch: 0; objective: 0.21755273640155792; \n",
      "fold: TRAIN; iteration: 429; epoch: 0; objective: 0.25806954503059387; \n",
      "fold: TRAIN; iteration: 430; epoch: 0; objective: 0.19747407734394073; \n",
      "fold: TRAIN; iteration: 431; epoch: 0; objective: 0.25326111912727356; \n",
      "fold: TRAIN; iteration: 432; epoch: 0; objective: 0.31392326951026917; \n",
      "fold: TRAIN; iteration: 433; epoch: 0; objective: 0.2487327754497528; \n",
      "fold: TRAIN; iteration: 434; epoch: 0; objective: 0.23849140107631683; \n",
      "fold: TRAIN; iteration: 435; epoch: 0; objective: 0.15530537068843842; \n",
      "fold: TRAIN; iteration: 436; epoch: 0; objective: 0.1950419843196869; \n",
      "fold: TRAIN; iteration: 437; epoch: 0; objective: 0.1952582150697708; \n",
      "fold: TRAIN; iteration: 438; epoch: 0; objective: 0.21605144441127777; \n",
      "fold: TRAIN; iteration: 439; epoch: 0; objective: 0.2664875388145447; \n",
      "fold: TRAIN; iteration: 440; epoch: 0; objective: 0.18463116884231567; \n",
      "fold: TRAIN; iteration: 441; epoch: 0; objective: 0.24148668348789215; \n",
      "fold: TRAIN; iteration: 442; epoch: 0; objective: 0.20758256316184998; \n",
      "fold: TRAIN; iteration: 443; epoch: 0; objective: 0.1514841467142105; \n",
      "fold: TRAIN; iteration: 444; epoch: 0; objective: 0.17998872697353363; \n",
      "fold: TRAIN; iteration: 445; epoch: 0; objective: 0.3070352077484131; \n",
      "fold: TRAIN; iteration: 446; epoch: 0; objective: 0.2224719077348709; \n",
      "fold: TRAIN; iteration: 447; epoch: 0; objective: 0.2462306171655655; \n",
      "fold: TRAIN; iteration: 448; epoch: 0; objective: 0.31477972865104675; \n",
      "fold: TRAIN; iteration: 449; epoch: 0; objective: 0.18871411681175232; \n",
      "validating model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving\n",
      "fold: VALID; iteration: 450; epoch: 0; classification/accuracy: 0.94; objective: 0.2202315921584765; \n",
      "fold: TRAIN; iteration: 450; epoch: 0; objective: 0.3427373468875885; \n",
      "fold: TRAIN; iteration: 451; epoch: 0; objective: 0.2933960258960724; \n",
      "fold: TRAIN; iteration: 452; epoch: 0; objective: 0.24070678651332855; \n",
      "fold: TRAIN; iteration: 453; epoch: 0; objective: 0.15879234671592712; \n",
      "fold: TRAIN; iteration: 454; epoch: 0; objective: 0.24718570709228516; \n",
      "fold: TRAIN; iteration: 455; epoch: 0; objective: 0.2556569576263428; \n",
      "fold: TRAIN; iteration: 456; epoch: 0; objective: 0.12138854712247849; \n",
      "fold: TRAIN; iteration: 457; epoch: 0; objective: 0.2650008499622345; \n",
      "fold: TRAIN; iteration: 458; epoch: 0; objective: 0.29882845282554626; \n",
      "fold: TRAIN; iteration: 459; epoch: 0; objective: 0.15554076433181763; \n",
      "fold: TRAIN; iteration: 460; epoch: 0; objective: 0.16984958946704865; \n",
      "fold: TRAIN; iteration: 461; epoch: 0; objective: 0.2106398046016693; \n",
      "fold: TRAIN; iteration: 462; epoch: 0; objective: 0.2985335886478424; \n",
      "fold: TRAIN; iteration: 463; epoch: 0; objective: 0.24811267852783203; \n",
      "fold: TRAIN; iteration: 464; epoch: 0; objective: 0.3276515603065491; \n",
      "fold: TRAIN; iteration: 465; epoch: 0; objective: 0.1901465803384781; \n",
      "fold: TRAIN; iteration: 466; epoch: 0; objective: 0.230638787150383; \n",
      "fold: TRAIN; iteration: 467; epoch: 0; objective: 0.13812604546546936; \n",
      "fold: TRAIN; iteration: 468; epoch: 0; objective: 0.15015307068824768; \n",
      "fold: TRAIN; iteration: 469; epoch: 0; objective: 0.27036288380622864; \n",
      "fold: TRAIN; iteration: 470; epoch: 0; objective: 0.1999765932559967; \n",
      "fold: TRAIN; iteration: 471; epoch: 0; objective: 0.22494636476039886; \n",
      "fold: TRAIN; iteration: 472; epoch: 0; objective: 0.20256225764751434; \n",
      "fold: TRAIN; iteration: 473; epoch: 0; objective: 0.2946631908416748; \n",
      "fold: TRAIN; iteration: 474; epoch: 0; objective: 0.1795780509710312; \n",
      "fold: TRAIN; iteration: 475; epoch: 0; objective: 0.17701974511146545; \n",
      "fold: TRAIN; iteration: 476; epoch: 0; objective: 0.14021989703178406; \n",
      "fold: TRAIN; iteration: 477; epoch: 0; objective: 0.16956569254398346; \n",
      "fold: TRAIN; iteration: 478; epoch: 0; objective: 0.18581807613372803; \n",
      "fold: TRAIN; iteration: 479; epoch: 0; objective: 0.22475704550743103; \n",
      "fold: TRAIN; iteration: 480; epoch: 0; objective: 0.14151117205619812; \n",
      "fold: TRAIN; iteration: 481; epoch: 0; objective: 0.19475750625133514; \n",
      "fold: TRAIN; iteration: 482; epoch: 0; objective: 0.1699545681476593; \n",
      "fold: TRAIN; iteration: 483; epoch: 0; objective: 0.17020109295845032; \n",
      "fold: TRAIN; iteration: 484; epoch: 0; objective: 0.20773467421531677; \n",
      "fold: TRAIN; iteration: 485; epoch: 0; objective: 0.19283048808574677; \n",
      "fold: TRAIN; iteration: 486; epoch: 0; objective: 0.1792152374982834; \n",
      "fold: TRAIN; iteration: 487; epoch: 0; objective: 0.27654173970222473; \n",
      "fold: TRAIN; iteration: 488; epoch: 0; objective: 0.25266751646995544; \n",
      "fold: TRAIN; iteration: 489; epoch: 0; objective: 0.18450777232646942; \n",
      "fold: TRAIN; iteration: 490; epoch: 0; objective: 0.17453807592391968; \n",
      "fold: TRAIN; iteration: 491; epoch: 0; objective: 0.3506135940551758; \n",
      "fold: TRAIN; iteration: 492; epoch: 0; objective: 0.28894445300102234; \n",
      "fold: TRAIN; iteration: 493; epoch: 0; objective: 0.17367404699325562; \n",
      "fold: TRAIN; iteration: 494; epoch: 0; objective: 0.25919800996780396; \n",
      "fold: TRAIN; iteration: 495; epoch: 0; objective: 0.240495502948761; \n",
      "fold: TRAIN; iteration: 496; epoch: 0; objective: 0.12402601540088654; \n",
      "fold: TRAIN; iteration: 497; epoch: 0; objective: 0.1922873556613922; \n",
      "fold: TRAIN; iteration: 498; epoch: 0; objective: 0.22712677717208862; \n",
      "fold: TRAIN; iteration: 499; epoch: 0; objective: 0.19210264086723328; \n",
      "validating model...\n",
      "saving\n",
      "fold: VALID; iteration: 500; epoch: 0; classification/accuracy: 0.952; objective: 0.1985008955001831; \n",
      "fold: TRAIN; iteration: 500; epoch: 0; objective: 0.34193456172943115; \n",
      "fold: TRAIN; iteration: 501; epoch: 0; objective: 0.1700141578912735; \n",
      "fold: TRAIN; iteration: 502; epoch: 0; objective: 0.22091826796531677; \n",
      "fold: TRAIN; iteration: 503; epoch: 0; objective: 0.11235649138689041; \n",
      "fold: TRAIN; iteration: 504; epoch: 0; objective: 0.23385673761367798; \n",
      "fold: TRAIN; iteration: 505; epoch: 0; objective: 0.22495973110198975; \n",
      "fold: TRAIN; iteration: 506; epoch: 0; objective: 0.1603945791721344; \n",
      "fold: TRAIN; iteration: 507; epoch: 0; objective: 0.18913617730140686; \n",
      "fold: TRAIN; iteration: 508; epoch: 0; objective: 0.1866404116153717; \n",
      "fold: TRAIN; iteration: 509; epoch: 0; objective: 0.19231143593788147; \n",
      "fold: TRAIN; iteration: 510; epoch: 0; objective: 0.3017175793647766; \n",
      "fold: TRAIN; iteration: 511; epoch: 0; objective: 0.17670468986034393; \n",
      "fold: TRAIN; iteration: 512; epoch: 0; objective: 0.13777945935726166; \n",
      "fold: TRAIN; iteration: 513; epoch: 0; objective: 0.1609065979719162; \n",
      "fold: TRAIN; iteration: 514; epoch: 0; objective: 0.2201937884092331; \n",
      "fold: TRAIN; iteration: 515; epoch: 0; objective: 0.12707413733005524; \n",
      "fold: TRAIN; iteration: 516; epoch: 0; objective: 0.2682068645954132; \n",
      "fold: TRAIN; iteration: 517; epoch: 0; objective: 0.1533145308494568; \n",
      "fold: TRAIN; iteration: 518; epoch: 0; objective: 0.17312858998775482; \n",
      "fold: TRAIN; iteration: 519; epoch: 0; objective: 0.14656074345111847; \n",
      "fold: TRAIN; iteration: 520; epoch: 0; objective: 0.13691766560077667; \n",
      "fold: TRAIN; iteration: 521; epoch: 0; objective: 0.23027002811431885; \n",
      "fold: TRAIN; iteration: 522; epoch: 0; objective: 0.21672046184539795; \n",
      "fold: TRAIN; iteration: 523; epoch: 0; objective: 0.16200271248817444; \n",
      "fold: TRAIN; iteration: 524; epoch: 0; objective: 0.2158258855342865; \n",
      "fold: TRAIN; iteration: 525; epoch: 0; objective: 0.21183525025844574; \n",
      "fold: TRAIN; iteration: 526; epoch: 0; objective: 0.2291606068611145; \n",
      "fold: TRAIN; iteration: 527; epoch: 0; objective: 0.21560673415660858; \n",
      "fold: TRAIN; iteration: 528; epoch: 0; objective: 0.15520630776882172; \n",
      "fold: TRAIN; iteration: 529; epoch: 0; objective: 0.2426547259092331; \n",
      "fold: TRAIN; iteration: 530; epoch: 0; objective: 0.1819598525762558; \n",
      "fold: TRAIN; iteration: 531; epoch: 0; objective: 0.2975311577320099; \n",
      "fold: TRAIN; iteration: 532; epoch: 0; objective: 0.23767006397247314; \n",
      "fold: TRAIN; iteration: 533; epoch: 0; objective: 0.24048259854316711; \n",
      "fold: TRAIN; iteration: 534; epoch: 0; objective: 0.2786899507045746; \n",
      "fold: TRAIN; iteration: 535; epoch: 0; objective: 0.18676641583442688; \n",
      "fold: TRAIN; iteration: 536; epoch: 0; objective: 0.19481685757637024; \n",
      "fold: TRAIN; iteration: 537; epoch: 0; objective: 0.2825712263584137; \n",
      "fold: TRAIN; iteration: 538; epoch: 0; objective: 0.1999097615480423; \n",
      "fold: TRAIN; iteration: 539; epoch: 0; objective: 0.15146929025650024; \n",
      "fold: TRAIN; iteration: 540; epoch: 0; objective: 0.2981124222278595; \n",
      "fold: TRAIN; iteration: 541; epoch: 0; objective: 0.1159762367606163; \n",
      "fold: TRAIN; iteration: 542; epoch: 0; objective: 0.1138950064778328; \n",
      "fold: TRAIN; iteration: 543; epoch: 0; objective: 0.23178477585315704; \n",
      "fold: TRAIN; iteration: 544; epoch: 0; objective: 0.11758368462324142; \n",
      "fold: TRAIN; iteration: 545; epoch: 0; objective: 0.24007628858089447; \n",
      "fold: TRAIN; iteration: 546; epoch: 0; objective: 0.211588054895401; \n",
      "fold: TRAIN; iteration: 547; epoch: 0; objective: 0.11058691143989563; \n",
      "fold: TRAIN; iteration: 548; epoch: 0; objective: 0.28114861249923706; \n",
      "fold: TRAIN; iteration: 549; epoch: 0; objective: 0.2574964165687561; \n",
      "validating model...\n",
      "saving\n",
      "fold: VALID; iteration: 550; epoch: 0; classification/accuracy: 0.952; objective: 0.1844787746667862; \n",
      "fold: TRAIN; iteration: 550; epoch: 0; objective: 0.12526275217533112; \n",
      "fold: TRAIN; iteration: 551; epoch: 0; objective: 0.21123693883419037; \n",
      "fold: TRAIN; iteration: 552; epoch: 0; objective: 0.16277724504470825; \n",
      "fold: TRAIN; iteration: 553; epoch: 0; objective: 0.1829250454902649; \n",
      "fold: TRAIN; iteration: 554; epoch: 0; objective: 0.287153035402298; \n",
      "fold: TRAIN; iteration: 555; epoch: 0; objective: 0.19057098031044006; \n",
      "fold: TRAIN; iteration: 556; epoch: 0; objective: 0.26657339930534363; \n",
      "fold: TRAIN; iteration: 557; epoch: 0; objective: 0.1144324243068695; \n",
      "fold: TRAIN; iteration: 558; epoch: 0; objective: 0.13002189993858337; \n",
      "fold: TRAIN; iteration: 559; epoch: 0; objective: 0.2280491441488266; \n",
      "fold: TRAIN; iteration: 560; epoch: 0; objective: 0.23707519471645355; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 561; epoch: 1; objective: 0.12399019300937653; \n",
      "fold: TRAIN; iteration: 562; epoch: 1; objective: 0.21294039487838745; \n",
      "fold: TRAIN; iteration: 563; epoch: 1; objective: 0.15567994117736816; \n",
      "fold: TRAIN; iteration: 564; epoch: 1; objective: 0.1355845332145691; \n",
      "fold: TRAIN; iteration: 565; epoch: 1; objective: 0.19686712324619293; \n",
      "fold: TRAIN; iteration: 566; epoch: 1; objective: 0.16636371612548828; \n",
      "fold: TRAIN; iteration: 567; epoch: 1; objective: 0.2233036458492279; \n",
      "fold: TRAIN; iteration: 568; epoch: 1; objective: 0.20250879228115082; \n",
      "fold: TRAIN; iteration: 569; epoch: 1; objective: 0.12003739178180695; \n",
      "fold: TRAIN; iteration: 570; epoch: 1; objective: 0.1673162430524826; \n",
      "fold: TRAIN; iteration: 571; epoch: 1; objective: 0.19965755939483643; \n",
      "fold: TRAIN; iteration: 572; epoch: 1; objective: 0.17470651865005493; \n",
      "fold: TRAIN; iteration: 573; epoch: 1; objective: 0.19950200617313385; \n",
      "fold: TRAIN; iteration: 574; epoch: 1; objective: 0.15453730523586273; \n",
      "fold: TRAIN; iteration: 575; epoch: 1; objective: 0.13994331657886505; \n",
      "fold: TRAIN; iteration: 576; epoch: 1; objective: 0.10436835885047913; \n",
      "fold: TRAIN; iteration: 577; epoch: 1; objective: 0.09058217704296112; \n",
      "fold: TRAIN; iteration: 578; epoch: 1; objective: 0.1710711121559143; \n",
      "fold: TRAIN; iteration: 579; epoch: 1; objective: 0.1010253056883812; \n",
      "fold: TRAIN; iteration: 580; epoch: 1; objective: 0.22838634252548218; \n",
      "fold: TRAIN; iteration: 581; epoch: 1; objective: 0.21666020154953003; \n",
      "fold: TRAIN; iteration: 582; epoch: 1; objective: 0.22986029088497162; \n",
      "fold: TRAIN; iteration: 583; epoch: 1; objective: 0.2656724154949188; \n",
      "fold: TRAIN; iteration: 584; epoch: 1; objective: 0.15698488056659698; \n",
      "fold: TRAIN; iteration: 585; epoch: 1; objective: 0.1713288426399231; \n",
      "fold: TRAIN; iteration: 586; epoch: 1; objective: 0.15792687237262726; \n",
      "fold: TRAIN; iteration: 587; epoch: 1; objective: 0.17044855654239655; \n",
      "fold: TRAIN; iteration: 588; epoch: 1; objective: 0.31011390686035156; \n",
      "fold: TRAIN; iteration: 589; epoch: 1; objective: 0.18089012801647186; \n",
      "fold: TRAIN; iteration: 590; epoch: 1; objective: 0.2670276165008545; \n",
      "fold: TRAIN; iteration: 591; epoch: 1; objective: 0.17821116745471954; \n",
      "fold: TRAIN; iteration: 592; epoch: 1; objective: 0.11717275530099869; \n",
      "fold: TRAIN; iteration: 593; epoch: 1; objective: 0.20245219767093658; \n",
      "fold: TRAIN; iteration: 594; epoch: 1; objective: 0.14395715296268463; \n",
      "fold: TRAIN; iteration: 595; epoch: 1; objective: 0.09759523719549179; \n",
      "fold: TRAIN; iteration: 596; epoch: 1; objective: 0.14336460828781128; \n",
      "fold: TRAIN; iteration: 597; epoch: 1; objective: 0.23773308098316193; \n",
      "fold: TRAIN; iteration: 598; epoch: 1; objective: 0.18447738885879517; \n",
      "fold: TRAIN; iteration: 599; epoch: 1; objective: 0.3002721965312958; \n",
      "validating model...\n",
      "saving\n",
      "fold: VALID; iteration: 600; epoch: 1; classification/accuracy: 0.952; objective: 0.17090942164262135; \n",
      "fold: TRAIN; iteration: 600; epoch: 1; objective: 0.16814328730106354; \n",
      "fold: TRAIN; iteration: 601; epoch: 1; objective: 0.24075761437416077; \n",
      "fold: TRAIN; iteration: 602; epoch: 1; objective: 0.14185957610607147; \n",
      "fold: TRAIN; iteration: 603; epoch: 1; objective: 0.12718717753887177; \n",
      "fold: TRAIN; iteration: 604; epoch: 1; objective: 0.1484767496585846; \n",
      "fold: TRAIN; iteration: 605; epoch: 1; objective: 0.1855918914079666; \n",
      "fold: TRAIN; iteration: 606; epoch: 1; objective: 0.18488657474517822; \n",
      "fold: TRAIN; iteration: 607; epoch: 1; objective: 0.11525513976812363; \n",
      "fold: TRAIN; iteration: 608; epoch: 1; objective: 0.14469148218631744; \n",
      "fold: TRAIN; iteration: 609; epoch: 1; objective: 0.11307387053966522; \n",
      "fold: TRAIN; iteration: 610; epoch: 1; objective: 0.19584351778030396; \n",
      "fold: TRAIN; iteration: 611; epoch: 1; objective: 0.2078060507774353; \n",
      "fold: TRAIN; iteration: 612; epoch: 1; objective: 0.18292857706546783; \n",
      "fold: TRAIN; iteration: 613; epoch: 1; objective: 0.10156867653131485; \n",
      "fold: TRAIN; iteration: 614; epoch: 1; objective: 0.22306835651397705; \n",
      "fold: TRAIN; iteration: 615; epoch: 1; objective: 0.26916930079460144; \n",
      "fold: TRAIN; iteration: 616; epoch: 1; objective: 0.1725030392408371; \n",
      "fold: TRAIN; iteration: 617; epoch: 1; objective: 0.14496754109859467; \n",
      "fold: TRAIN; iteration: 618; epoch: 1; objective: 0.2886291444301605; \n",
      "fold: TRAIN; iteration: 619; epoch: 1; objective: 0.22330346703529358; \n",
      "fold: TRAIN; iteration: 620; epoch: 1; objective: 0.12107887119054794; \n",
      "fold: TRAIN; iteration: 621; epoch: 1; objective: 0.1442052125930786; \n",
      "fold: TRAIN; iteration: 622; epoch: 1; objective: 0.24493035674095154; \n",
      "fold: TRAIN; iteration: 623; epoch: 1; objective: 0.18058690428733826; \n",
      "fold: TRAIN; iteration: 624; epoch: 1; objective: 0.2217552363872528; \n",
      "fold: TRAIN; iteration: 625; epoch: 1; objective: 0.21908052265644073; \n",
      "fold: TRAIN; iteration: 626; epoch: 1; objective: 0.1686801016330719; \n",
      "fold: TRAIN; iteration: 627; epoch: 1; objective: 0.21617382764816284; \n",
      "fold: TRAIN; iteration: 628; epoch: 1; objective: 0.131461039185524; \n",
      "fold: TRAIN; iteration: 629; epoch: 1; objective: 0.1254788339138031; \n",
      "fold: TRAIN; iteration: 630; epoch: 1; objective: 0.2386426329612732; \n",
      "fold: TRAIN; iteration: 631; epoch: 1; objective: 0.11069055646657944; \n",
      "fold: TRAIN; iteration: 632; epoch: 1; objective: 0.20388182997703552; \n",
      "fold: TRAIN; iteration: 633; epoch: 1; objective: 0.10843603312969208; \n",
      "fold: TRAIN; iteration: 634; epoch: 1; objective: 0.15322476625442505; \n",
      "fold: TRAIN; iteration: 635; epoch: 1; objective: 0.22984491288661957; \n",
      "fold: TRAIN; iteration: 636; epoch: 1; objective: 0.1149313822388649; \n",
      "fold: TRAIN; iteration: 637; epoch: 1; objective: 0.1657429337501526; \n",
      "fold: TRAIN; iteration: 638; epoch: 1; objective: 0.1268138438463211; \n",
      "fold: TRAIN; iteration: 639; epoch: 1; objective: 0.16061675548553467; \n",
      "fold: TRAIN; iteration: 640; epoch: 1; objective: 0.12170236557722092; \n",
      "fold: TRAIN; iteration: 641; epoch: 1; objective: 0.20137670636177063; \n",
      "fold: TRAIN; iteration: 642; epoch: 1; objective: 0.15941943228244781; \n",
      "fold: TRAIN; iteration: 643; epoch: 1; objective: 0.1538052260875702; \n",
      "fold: TRAIN; iteration: 644; epoch: 1; objective: 0.10224104672670364; \n",
      "fold: TRAIN; iteration: 645; epoch: 1; objective: 0.17638547718524933; \n",
      "fold: TRAIN; iteration: 646; epoch: 1; objective: 0.1538364291191101; \n",
      "fold: TRAIN; iteration: 647; epoch: 1; objective: 0.12539081275463104; \n",
      "fold: TRAIN; iteration: 648; epoch: 1; objective: 0.17326682806015015; \n",
      "fold: TRAIN; iteration: 649; epoch: 1; objective: 0.1999392956495285; \n",
      "validating model...\n",
      "saving\n",
      "fold: VALID; iteration: 650; epoch: 1; classification/accuracy: 0.956; objective: 0.16332482372721036; \n",
      "fold: TRAIN; iteration: 650; epoch: 1; objective: 0.22247232496738434; \n",
      "fold: TRAIN; iteration: 651; epoch: 1; objective: 0.10964414477348328; \n",
      "fold: TRAIN; iteration: 652; epoch: 1; objective: 0.1043873131275177; \n",
      "fold: TRAIN; iteration: 653; epoch: 1; objective: 0.20777395367622375; \n",
      "fold: TRAIN; iteration: 654; epoch: 1; objective: 0.21118581295013428; \n",
      "fold: TRAIN; iteration: 655; epoch: 1; objective: 0.10456282645463943; \n",
      "fold: TRAIN; iteration: 656; epoch: 1; objective: 0.16961194574832916; \n",
      "fold: TRAIN; iteration: 657; epoch: 1; objective: 0.1600629836320877; \n",
      "fold: TRAIN; iteration: 658; epoch: 1; objective: 0.1444777101278305; \n",
      "fold: TRAIN; iteration: 659; epoch: 1; objective: 0.11562364548444748; \n",
      "fold: TRAIN; iteration: 660; epoch: 1; objective: 0.1068309098482132; \n",
      "fold: TRAIN; iteration: 661; epoch: 1; objective: 0.15383276343345642; \n",
      "fold: TRAIN; iteration: 662; epoch: 1; objective: 0.08654527366161346; \n",
      "fold: TRAIN; iteration: 663; epoch: 1; objective: 0.15408316254615784; \n",
      "fold: TRAIN; iteration: 664; epoch: 1; objective: 0.2494044303894043; \n",
      "fold: TRAIN; iteration: 665; epoch: 1; objective: 0.20610448718070984; \n",
      "fold: TRAIN; iteration: 666; epoch: 1; objective: 0.219131737947464; \n",
      "fold: TRAIN; iteration: 667; epoch: 1; objective: 0.11269491910934448; \n",
      "fold: TRAIN; iteration: 668; epoch: 1; objective: 0.16706378757953644; \n",
      "fold: TRAIN; iteration: 669; epoch: 1; objective: 0.11762119084596634; \n",
      "fold: TRAIN; iteration: 670; epoch: 1; objective: 0.09928932785987854; \n",
      "fold: TRAIN; iteration: 671; epoch: 1; objective: 0.17761150002479553; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 672; epoch: 1; objective: 0.13453304767608643; \n",
      "fold: TRAIN; iteration: 673; epoch: 1; objective: 0.2706030011177063; \n",
      "fold: TRAIN; iteration: 674; epoch: 1; objective: 0.13351663947105408; \n",
      "fold: TRAIN; iteration: 675; epoch: 1; objective: 0.1459687203168869; \n",
      "fold: TRAIN; iteration: 676; epoch: 1; objective: 0.1591513752937317; \n",
      "fold: TRAIN; iteration: 677; epoch: 1; objective: 0.15807530283927917; \n",
      "fold: TRAIN; iteration: 678; epoch: 1; objective: 0.168272003531456; \n",
      "fold: TRAIN; iteration: 679; epoch: 1; objective: 0.11846507340669632; \n",
      "fold: TRAIN; iteration: 680; epoch: 1; objective: 0.11052240431308746; \n",
      "fold: TRAIN; iteration: 681; epoch: 1; objective: 0.1169259324669838; \n",
      "fold: TRAIN; iteration: 682; epoch: 1; objective: 0.3086187541484833; \n",
      "fold: TRAIN; iteration: 683; epoch: 1; objective: 0.10857883095741272; \n",
      "fold: TRAIN; iteration: 684; epoch: 1; objective: 0.09190763533115387; \n",
      "fold: TRAIN; iteration: 685; epoch: 1; objective: 0.17539700865745544; \n",
      "fold: TRAIN; iteration: 686; epoch: 1; objective: 0.2914719581604004; \n",
      "fold: TRAIN; iteration: 687; epoch: 1; objective: 0.10151812434196472; \n",
      "fold: TRAIN; iteration: 688; epoch: 1; objective: 0.15348351001739502; \n",
      "fold: TRAIN; iteration: 689; epoch: 1; objective: 0.08725801110267639; \n",
      "fold: TRAIN; iteration: 690; epoch: 1; objective: 0.19653387367725372; \n",
      "fold: TRAIN; iteration: 691; epoch: 1; objective: 0.1431339681148529; \n",
      "fold: TRAIN; iteration: 692; epoch: 1; objective: 0.25091761350631714; \n",
      "fold: TRAIN; iteration: 693; epoch: 1; objective: 0.18081603944301605; \n",
      "fold: TRAIN; iteration: 694; epoch: 1; objective: 0.176161989569664; \n",
      "fold: TRAIN; iteration: 695; epoch: 1; objective: 0.2590833008289337; \n",
      "fold: TRAIN; iteration: 696; epoch: 1; objective: 0.1436423510313034; \n",
      "fold: TRAIN; iteration: 697; epoch: 1; objective: 0.1388799250125885; \n",
      "fold: TRAIN; iteration: 698; epoch: 1; objective: 0.25090858340263367; \n",
      "fold: TRAIN; iteration: 699; epoch: 1; objective: 0.13297027349472046; \n",
      "validating model...\n",
      "saving\n",
      "fold: VALID; iteration: 700; epoch: 1; classification/accuracy: 0.96; objective: 0.1533856804172198; \n",
      "fold: TRAIN; iteration: 700; epoch: 1; objective: 0.21521113812923431; \n",
      "fold: TRAIN; iteration: 701; epoch: 1; objective: 0.08079146593809128; \n",
      "fold: TRAIN; iteration: 702; epoch: 1; objective: 0.15079374611377716; \n",
      "fold: TRAIN; iteration: 703; epoch: 1; objective: 0.15834885835647583; \n",
      "fold: TRAIN; iteration: 704; epoch: 1; objective: 0.13277390599250793; \n",
      "fold: TRAIN; iteration: 705; epoch: 1; objective: 0.26538413763046265; \n",
      "fold: TRAIN; iteration: 706; epoch: 1; objective: 0.22603566944599152; \n",
      "fold: TRAIN; iteration: 707; epoch: 1; objective: 0.19540764391422272; \n",
      "fold: TRAIN; iteration: 708; epoch: 1; objective: 0.13349147140979767; \n",
      "fold: TRAIN; iteration: 709; epoch: 1; objective: 0.09125662595033646; \n",
      "fold: TRAIN; iteration: 710; epoch: 1; objective: 0.14866578578948975; \n",
      "fold: TRAIN; iteration: 711; epoch: 1; objective: 0.11190507560968399; \n",
      "fold: TRAIN; iteration: 712; epoch: 1; objective: 0.15625233948230743; \n",
      "fold: TRAIN; iteration: 713; epoch: 1; objective: 0.09469716995954514; \n",
      "fold: TRAIN; iteration: 714; epoch: 1; objective: 0.16966089606285095; \n",
      "fold: TRAIN; iteration: 715; epoch: 1; objective: 0.13622598350048065; \n",
      "fold: TRAIN; iteration: 716; epoch: 1; objective: 0.16096177697181702; \n",
      "fold: TRAIN; iteration: 717; epoch: 1; objective: 0.17428043484687805; \n",
      "fold: TRAIN; iteration: 718; epoch: 1; objective: 0.16932491958141327; \n",
      "fold: TRAIN; iteration: 719; epoch: 1; objective: 0.13296577334403992; \n",
      "fold: TRAIN; iteration: 720; epoch: 1; objective: 0.11598207801580429; \n",
      "fold: TRAIN; iteration: 721; epoch: 1; objective: 0.06253064423799515; \n",
      "fold: TRAIN; iteration: 722; epoch: 1; objective: 0.22285959124565125; \n",
      "fold: TRAIN; iteration: 723; epoch: 1; objective: 0.1211727112531662; \n",
      "fold: TRAIN; iteration: 724; epoch: 1; objective: 0.13857011497020721; \n",
      "fold: TRAIN; iteration: 725; epoch: 1; objective: 0.22243404388427734; \n",
      "fold: TRAIN; iteration: 726; epoch: 1; objective: 0.11317699402570724; \n",
      "fold: TRAIN; iteration: 727; epoch: 1; objective: 0.19121447205543518; \n",
      "fold: TRAIN; iteration: 728; epoch: 1; objective: 0.11188942193984985; \n",
      "fold: TRAIN; iteration: 729; epoch: 1; objective: 0.2192509025335312; \n",
      "fold: TRAIN; iteration: 730; epoch: 1; objective: 0.20481014251708984; \n",
      "fold: TRAIN; iteration: 731; epoch: 1; objective: 0.13084349036216736; \n",
      "fold: TRAIN; iteration: 732; epoch: 1; objective: 0.1849420964717865; \n",
      "fold: TRAIN; iteration: 733; epoch: 1; objective: 0.09244340658187866; \n",
      "fold: TRAIN; iteration: 734; epoch: 1; objective: 0.14923883974552155; \n",
      "fold: TRAIN; iteration: 735; epoch: 1; objective: 0.10311626642942429; \n",
      "fold: TRAIN; iteration: 736; epoch: 1; objective: 0.13161496818065643; \n",
      "fold: TRAIN; iteration: 737; epoch: 1; objective: 0.14786139130592346; \n",
      "fold: TRAIN; iteration: 738; epoch: 1; objective: 0.10031076520681381; \n",
      "fold: TRAIN; iteration: 739; epoch: 1; objective: 0.19538934528827667; \n",
      "fold: TRAIN; iteration: 740; epoch: 1; objective: 0.1277523636817932; \n",
      "fold: TRAIN; iteration: 741; epoch: 1; objective: 0.2639615535736084; \n",
      "fold: TRAIN; iteration: 742; epoch: 1; objective: 0.1813918948173523; \n",
      "fold: TRAIN; iteration: 743; epoch: 1; objective: 0.08393186330795288; \n",
      "fold: TRAIN; iteration: 744; epoch: 1; objective: 0.0882650762796402; \n",
      "fold: TRAIN; iteration: 745; epoch: 1; objective: 0.1795661747455597; \n",
      "fold: TRAIN; iteration: 746; epoch: 1; objective: 0.1880778670310974; \n",
      "fold: TRAIN; iteration: 747; epoch: 1; objective: 0.18677227199077606; \n",
      "fold: TRAIN; iteration: 748; epoch: 1; objective: 0.21135473251342773; \n",
      "fold: TRAIN; iteration: 749; epoch: 1; objective: 0.10569947212934494; \n",
      "validating model...\n",
      "saving\n",
      "fold: VALID; iteration: 750; epoch: 1; classification/accuracy: 0.96; objective: 0.1456368088722229; \n",
      "fold: TRAIN; iteration: 750; epoch: 1; objective: 0.1465524137020111; \n",
      "fold: TRAIN; iteration: 751; epoch: 1; objective: 0.1704043596982956; \n",
      "fold: TRAIN; iteration: 752; epoch: 1; objective: 0.108006551861763; \n",
      "fold: TRAIN; iteration: 753; epoch: 1; objective: 0.16997341811656952; \n",
      "fold: TRAIN; iteration: 754; epoch: 1; objective: 0.13798296451568604; \n",
      "fold: TRAIN; iteration: 755; epoch: 1; objective: 0.10919704288244247; \n",
      "fold: TRAIN; iteration: 756; epoch: 1; objective: 0.18467850983142853; \n",
      "fold: TRAIN; iteration: 757; epoch: 1; objective: 0.19865308701992035; \n",
      "fold: TRAIN; iteration: 758; epoch: 1; objective: 0.15349994599819183; \n",
      "fold: TRAIN; iteration: 759; epoch: 1; objective: 0.1505618840456009; \n",
      "fold: TRAIN; iteration: 760; epoch: 1; objective: 0.20705057680606842; \n",
      "fold: TRAIN; iteration: 761; epoch: 1; objective: 0.11727693676948547; \n",
      "fold: TRAIN; iteration: 762; epoch: 1; objective: 0.2302546501159668; \n",
      "fold: TRAIN; iteration: 763; epoch: 1; objective: 0.15090195834636688; \n",
      "fold: TRAIN; iteration: 764; epoch: 1; objective: 0.2663187086582184; \n",
      "fold: TRAIN; iteration: 765; epoch: 1; objective: 0.1646449863910675; \n",
      "fold: TRAIN; iteration: 766; epoch: 1; objective: 0.21133755147457123; \n",
      "fold: TRAIN; iteration: 767; epoch: 1; objective: 0.09130086749792099; \n",
      "fold: TRAIN; iteration: 768; epoch: 1; objective: 0.1312248259782791; \n",
      "fold: TRAIN; iteration: 769; epoch: 1; objective: 0.22718927264213562; \n",
      "fold: TRAIN; iteration: 770; epoch: 1; objective: 0.20226429402828217; \n",
      "fold: TRAIN; iteration: 771; epoch: 1; objective: 0.10608243942260742; \n",
      "fold: TRAIN; iteration: 772; epoch: 1; objective: 0.2004861831665039; \n",
      "fold: TRAIN; iteration: 773; epoch: 1; objective: 0.1676432192325592; \n",
      "fold: TRAIN; iteration: 774; epoch: 1; objective: 0.08952751755714417; \n",
      "fold: TRAIN; iteration: 775; epoch: 1; objective: 0.13841034471988678; \n",
      "fold: TRAIN; iteration: 776; epoch: 1; objective: 0.0653623566031456; \n",
      "fold: TRAIN; iteration: 777; epoch: 1; objective: 0.2554415762424469; \n",
      "fold: TRAIN; iteration: 778; epoch: 1; objective: 0.16062207520008087; \n",
      "fold: TRAIN; iteration: 779; epoch: 1; objective: 0.15368907153606415; \n",
      "fold: TRAIN; iteration: 780; epoch: 1; objective: 0.2289990484714508; \n",
      "fold: TRAIN; iteration: 781; epoch: 1; objective: 0.17642588913440704; \n",
      "fold: TRAIN; iteration: 782; epoch: 1; objective: 0.16819451749324799; \n",
      "fold: TRAIN; iteration: 783; epoch: 1; objective: 0.182088240981102; \n",
      "fold: TRAIN; iteration: 784; epoch: 1; objective: 0.1962289661169052; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 785; epoch: 1; objective: 0.18785052001476288; \n",
      "fold: TRAIN; iteration: 786; epoch: 1; objective: 0.09952273219823837; \n",
      "fold: TRAIN; iteration: 787; epoch: 1; objective: 0.18721473217010498; \n",
      "fold: TRAIN; iteration: 788; epoch: 1; objective: 0.1736941933631897; \n",
      "fold: TRAIN; iteration: 789; epoch: 1; objective: 0.10788406431674957; \n",
      "fold: TRAIN; iteration: 790; epoch: 1; objective: 0.17834147810935974; \n",
      "fold: TRAIN; iteration: 791; epoch: 1; objective: 0.12719005346298218; \n",
      "fold: TRAIN; iteration: 792; epoch: 1; objective: 0.12264537811279297; \n",
      "fold: TRAIN; iteration: 793; epoch: 1; objective: 0.15268954634666443; \n",
      "fold: TRAIN; iteration: 794; epoch: 1; objective: 0.0985567644238472; \n",
      "fold: TRAIN; iteration: 795; epoch: 1; objective: 0.16299723088741302; \n",
      "fold: TRAIN; iteration: 796; epoch: 1; objective: 0.12490257620811462; \n",
      "fold: TRAIN; iteration: 797; epoch: 1; objective: 0.07185285538434982; \n",
      "fold: TRAIN; iteration: 798; epoch: 1; objective: 0.130813330411911; \n",
      "fold: TRAIN; iteration: 799; epoch: 1; objective: 0.1759350597858429; \n",
      "validating model...\n",
      "saving\n",
      "fold: VALID; iteration: 800; epoch: 1; classification/accuracy: 0.968; objective: 0.13809367045760154; \n",
      "fold: TRAIN; iteration: 800; epoch: 1; objective: 0.17513205111026764; \n",
      "fold: TRAIN; iteration: 801; epoch: 1; objective: 0.10797163844108582; \n",
      "fold: TRAIN; iteration: 802; epoch: 1; objective: 0.18647798895835876; \n",
      "fold: TRAIN; iteration: 803; epoch: 1; objective: 0.1154538094997406; \n",
      "fold: TRAIN; iteration: 804; epoch: 1; objective: 0.13613447546958923; \n",
      "fold: TRAIN; iteration: 805; epoch: 1; objective: 0.08168582618236542; \n",
      "fold: TRAIN; iteration: 806; epoch: 1; objective: 0.17545098066329956; \n",
      "fold: TRAIN; iteration: 807; epoch: 1; objective: 0.23676250874996185; \n",
      "fold: TRAIN; iteration: 808; epoch: 1; objective: 0.1942254602909088; \n",
      "fold: TRAIN; iteration: 809; epoch: 1; objective: 0.16768960654735565; \n",
      "fold: TRAIN; iteration: 810; epoch: 1; objective: 0.07119841873645782; \n",
      "fold: TRAIN; iteration: 811; epoch: 1; objective: 0.06503059715032578; \n",
      "fold: TRAIN; iteration: 812; epoch: 1; objective: 0.20121900737285614; \n",
      "fold: TRAIN; iteration: 813; epoch: 1; objective: 0.14672420918941498; \n",
      "fold: TRAIN; iteration: 814; epoch: 1; objective: 0.23256056010723114; \n",
      "fold: TRAIN; iteration: 815; epoch: 1; objective: 0.14722613990306854; \n",
      "fold: TRAIN; iteration: 816; epoch: 1; objective: 0.15859782695770264; \n",
      "fold: TRAIN; iteration: 817; epoch: 1; objective: 0.09792676568031311; \n",
      "fold: TRAIN; iteration: 818; epoch: 1; objective: 0.1335165947675705; \n",
      "fold: TRAIN; iteration: 819; epoch: 1; objective: 0.11289732903242111; \n",
      "fold: TRAIN; iteration: 820; epoch: 1; objective: 0.06836038827896118; \n",
      "fold: TRAIN; iteration: 821; epoch: 1; objective: 0.14989739656448364; \n",
      "fold: TRAIN; iteration: 822; epoch: 1; objective: 0.09006932377815247; \n",
      "fold: TRAIN; iteration: 823; epoch: 1; objective: 0.05765366181731224; \n",
      "fold: TRAIN; iteration: 824; epoch: 1; objective: 0.07625463604927063; \n",
      "fold: TRAIN; iteration: 825; epoch: 1; objective: 0.16981057822704315; \n",
      "fold: TRAIN; iteration: 826; epoch: 1; objective: 0.13899219036102295; \n",
      "fold: TRAIN; iteration: 827; epoch: 1; objective: 0.06310434639453888; \n",
      "fold: TRAIN; iteration: 828; epoch: 1; objective: 0.08352897316217422; \n",
      "fold: TRAIN; iteration: 829; epoch: 1; objective: 0.1039222776889801; \n",
      "fold: TRAIN; iteration: 830; epoch: 1; objective: 0.25488558411598206; \n",
      "fold: TRAIN; iteration: 831; epoch: 1; objective: 0.1308625042438507; \n",
      "fold: TRAIN; iteration: 832; epoch: 1; objective: 0.07773405313491821; \n",
      "fold: TRAIN; iteration: 833; epoch: 1; objective: 0.17067302763462067; \n",
      "fold: TRAIN; iteration: 834; epoch: 1; objective: 0.1981981098651886; \n",
      "fold: TRAIN; iteration: 835; epoch: 1; objective: 0.11220316588878632; \n",
      "fold: TRAIN; iteration: 836; epoch: 1; objective: 0.14889921247959137; \n",
      "fold: TRAIN; iteration: 837; epoch: 1; objective: 0.15655595064163208; \n",
      "fold: TRAIN; iteration: 838; epoch: 1; objective: 0.09441731125116348; \n",
      "fold: TRAIN; iteration: 839; epoch: 1; objective: 0.217558816075325; \n",
      "fold: TRAIN; iteration: 840; epoch: 1; objective: 0.1369691789150238; \n",
      "fold: TRAIN; iteration: 841; epoch: 1; objective: 0.1888202428817749; \n",
      "fold: TRAIN; iteration: 842; epoch: 1; objective: 0.1366887241601944; \n",
      "fold: TRAIN; iteration: 843; epoch: 1; objective: 0.15500052273273468; \n",
      "fold: TRAIN; iteration: 844; epoch: 1; objective: 0.049591682851314545; \n",
      "fold: TRAIN; iteration: 845; epoch: 1; objective: 0.10563904047012329; \n",
      "fold: TRAIN; iteration: 846; epoch: 1; objective: 0.15612873435020447; \n",
      "fold: TRAIN; iteration: 847; epoch: 1; objective: 0.05276819318532944; \n",
      "fold: TRAIN; iteration: 848; epoch: 1; objective: 0.0754772275686264; \n",
      "fold: TRAIN; iteration: 849; epoch: 1; objective: 0.08001939952373505; \n",
      "validating model...\n",
      "saving\n",
      "fold: VALID; iteration: 850; epoch: 1; classification/accuracy: 0.964; objective: 0.1323872630794843; \n",
      "fold: TRAIN; iteration: 850; epoch: 1; objective: 0.16008302569389343; \n",
      "fold: TRAIN; iteration: 851; epoch: 1; objective: 0.08026960492134094; \n",
      "fold: TRAIN; iteration: 852; epoch: 1; objective: 0.09417860209941864; \n",
      "fold: TRAIN; iteration: 853; epoch: 1; objective: 0.1697046458721161; \n",
      "fold: TRAIN; iteration: 854; epoch: 1; objective: 0.13548535108566284; \n",
      "fold: TRAIN; iteration: 855; epoch: 1; objective: 0.13325361907482147; \n",
      "fold: TRAIN; iteration: 856; epoch: 1; objective: 0.15667128562927246; \n",
      "fold: TRAIN; iteration: 857; epoch: 1; objective: 0.04937618598341942; \n",
      "fold: TRAIN; iteration: 858; epoch: 1; objective: 0.12968270480632782; \n",
      "fold: TRAIN; iteration: 859; epoch: 1; objective: 0.1340891420841217; \n",
      "fold: TRAIN; iteration: 860; epoch: 1; objective: 0.11890136450529099; \n",
      "fold: TRAIN; iteration: 861; epoch: 1; objective: 0.12534329295158386; \n",
      "fold: TRAIN; iteration: 862; epoch: 1; objective: 0.13635720312595367; \n",
      "fold: TRAIN; iteration: 863; epoch: 1; objective: 0.13097219169139862; \n",
      "fold: TRAIN; iteration: 864; epoch: 1; objective: 0.16383053362369537; \n",
      "fold: TRAIN; iteration: 865; epoch: 1; objective: 0.14271920919418335; \n",
      "fold: TRAIN; iteration: 866; epoch: 1; objective: 0.2418079972267151; \n",
      "fold: TRAIN; iteration: 867; epoch: 1; objective: 0.09282884001731873; \n",
      "fold: TRAIN; iteration: 868; epoch: 1; objective: 0.12025035917758942; \n",
      "fold: TRAIN; iteration: 869; epoch: 1; objective: 0.11198361217975616; \n",
      "fold: TRAIN; iteration: 870; epoch: 1; objective: 0.18245849013328552; \n",
      "fold: TRAIN; iteration: 871; epoch: 1; objective: 0.07193674892187119; \n",
      "fold: TRAIN; iteration: 872; epoch: 1; objective: 0.11288020759820938; \n",
      "fold: TRAIN; iteration: 873; epoch: 1; objective: 0.13121585547924042; \n",
      "fold: TRAIN; iteration: 874; epoch: 1; objective: 0.12725143134593964; \n",
      "fold: TRAIN; iteration: 875; epoch: 1; objective: 0.17043298482894897; \n",
      "fold: TRAIN; iteration: 876; epoch: 1; objective: 0.1653416007757187; \n",
      "fold: TRAIN; iteration: 877; epoch: 1; objective: 0.15116524696350098; \n",
      "fold: TRAIN; iteration: 878; epoch: 1; objective: 0.1331067532300949; \n",
      "fold: TRAIN; iteration: 879; epoch: 1; objective: 0.10675472021102905; \n",
      "fold: TRAIN; iteration: 880; epoch: 1; objective: 0.07554394006729126; \n",
      "fold: TRAIN; iteration: 881; epoch: 1; objective: 0.1530287116765976; \n",
      "fold: TRAIN; iteration: 882; epoch: 1; objective: 0.15792621672153473; \n",
      "fold: TRAIN; iteration: 883; epoch: 1; objective: 0.1593613177537918; \n",
      "fold: TRAIN; iteration: 884; epoch: 1; objective: 0.1083512008190155; \n",
      "fold: TRAIN; iteration: 885; epoch: 1; objective: 0.17296110093593597; \n",
      "fold: TRAIN; iteration: 886; epoch: 1; objective: 0.18651248514652252; \n",
      "fold: TRAIN; iteration: 887; epoch: 1; objective: 0.16863271594047546; \n",
      "fold: TRAIN; iteration: 888; epoch: 1; objective: 0.062056440860033035; \n",
      "fold: TRAIN; iteration: 889; epoch: 1; objective: 0.16550908982753754; \n",
      "fold: TRAIN; iteration: 890; epoch: 1; objective: 0.09279920905828476; \n",
      "fold: TRAIN; iteration: 891; epoch: 1; objective: 0.11538758128881454; \n",
      "fold: TRAIN; iteration: 892; epoch: 1; objective: 0.11507774144411087; \n",
      "fold: TRAIN; iteration: 893; epoch: 1; objective: 0.15674294531345367; \n",
      "fold: TRAIN; iteration: 894; epoch: 1; objective: 0.08618975430727005; \n",
      "fold: TRAIN; iteration: 895; epoch: 1; objective: 0.06423470377922058; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 896; epoch: 1; objective: 0.143004909157753; \n",
      "fold: TRAIN; iteration: 897; epoch: 1; objective: 0.17877762019634247; \n",
      "fold: TRAIN; iteration: 898; epoch: 1; objective: 0.19388040900230408; \n",
      "fold: TRAIN; iteration: 899; epoch: 1; objective: 0.057186201214790344; \n",
      "validating model...\n",
      "saving\n",
      "fold: VALID; iteration: 900; epoch: 1; classification/accuracy: 0.972; objective: 0.12656324803829194; \n",
      "fold: TRAIN; iteration: 900; epoch: 1; objective: 0.10010326653718948; \n",
      "fold: TRAIN; iteration: 901; epoch: 1; objective: 0.18034546077251434; \n",
      "fold: TRAIN; iteration: 902; epoch: 1; objective: 0.10843949019908905; \n",
      "fold: TRAIN; iteration: 903; epoch: 1; objective: 0.15338784456253052; \n",
      "fold: TRAIN; iteration: 904; epoch: 1; objective: 0.1375640332698822; \n",
      "fold: TRAIN; iteration: 905; epoch: 1; objective: 0.12990571558475494; \n",
      "fold: TRAIN; iteration: 906; epoch: 1; objective: 0.17104536294937134; \n",
      "fold: TRAIN; iteration: 907; epoch: 1; objective: 0.24392536282539368; \n",
      "fold: TRAIN; iteration: 908; epoch: 1; objective: 0.0925436019897461; \n",
      "fold: TRAIN; iteration: 909; epoch: 1; objective: 0.16295892000198364; \n",
      "fold: TRAIN; iteration: 910; epoch: 1; objective: 0.11790169030427933; \n",
      "fold: TRAIN; iteration: 911; epoch: 1; objective: 0.1311112344264984; \n",
      "fold: TRAIN; iteration: 912; epoch: 1; objective: 0.09730290621519089; \n",
      "fold: TRAIN; iteration: 913; epoch: 1; objective: 0.2351408451795578; \n",
      "fold: TRAIN; iteration: 914; epoch: 1; objective: 0.15085133910179138; \n",
      "fold: TRAIN; iteration: 915; epoch: 1; objective: 0.17743907868862152; \n",
      "fold: TRAIN; iteration: 916; epoch: 1; objective: 0.1391180455684662; \n",
      "fold: TRAIN; iteration: 917; epoch: 1; objective: 0.12238288670778275; \n",
      "fold: TRAIN; iteration: 918; epoch: 1; objective: 0.13014519214630127; \n",
      "fold: TRAIN; iteration: 919; epoch: 1; objective: 0.10197640210390091; \n",
      "fold: TRAIN; iteration: 920; epoch: 1; objective: 0.09012650698423386; \n",
      "fold: TRAIN; iteration: 921; epoch: 1; objective: 0.08779837936162949; \n",
      "fold: TRAIN; iteration: 922; epoch: 1; objective: 0.04590155929327011; \n",
      "fold: TRAIN; iteration: 923; epoch: 1; objective: 0.1755264699459076; \n",
      "fold: TRAIN; iteration: 924; epoch: 1; objective: 0.13345080614089966; \n",
      "fold: TRAIN; iteration: 925; epoch: 1; objective: 0.08567997813224792; \n",
      "fold: TRAIN; iteration: 926; epoch: 1; objective: 0.13027560710906982; \n",
      "fold: TRAIN; iteration: 927; epoch: 1; objective: 0.2445105016231537; \n",
      "fold: TRAIN; iteration: 928; epoch: 1; objective: 0.09482686966657639; \n",
      "fold: TRAIN; iteration: 929; epoch: 1; objective: 0.10422583669424057; \n",
      "fold: TRAIN; iteration: 930; epoch: 1; objective: 0.13479813933372498; \n",
      "fold: TRAIN; iteration: 931; epoch: 1; objective: 0.11373312026262283; \n",
      "fold: TRAIN; iteration: 932; epoch: 1; objective: 0.06299398094415665; \n",
      "fold: TRAIN; iteration: 933; epoch: 1; objective: 0.23980778455734253; \n",
      "fold: TRAIN; iteration: 934; epoch: 1; objective: 0.1321791708469391; \n",
      "fold: TRAIN; iteration: 935; epoch: 1; objective: 0.20099201798439026; \n",
      "fold: TRAIN; iteration: 936; epoch: 1; objective: 0.14240069687366486; \n",
      "fold: TRAIN; iteration: 937; epoch: 1; objective: 0.12840449810028076; \n",
      "fold: TRAIN; iteration: 938; epoch: 1; objective: 0.16777119040489197; \n",
      "fold: TRAIN; iteration: 939; epoch: 1; objective: 0.10214778780937195; \n",
      "fold: TRAIN; iteration: 940; epoch: 1; objective: 0.22020040452480316; \n",
      "fold: TRAIN; iteration: 941; epoch: 1; objective: 0.08849507570266724; \n",
      "fold: TRAIN; iteration: 942; epoch: 1; objective: 0.0973282903432846; \n",
      "fold: TRAIN; iteration: 943; epoch: 1; objective: 0.15507805347442627; \n",
      "fold: TRAIN; iteration: 944; epoch: 1; objective: 0.14319513738155365; \n",
      "fold: TRAIN; iteration: 945; epoch: 1; objective: 0.10854741930961609; \n",
      "fold: TRAIN; iteration: 946; epoch: 1; objective: 0.08024337887763977; \n",
      "fold: TRAIN; iteration: 947; epoch: 1; objective: 0.11280857026576996; \n",
      "fold: TRAIN; iteration: 948; epoch: 1; objective: 0.14316320419311523; \n",
      "fold: TRAIN; iteration: 949; epoch: 1; objective: 0.12171473354101181; \n",
      "validating model...\n",
      "saving\n",
      "fold: VALID; iteration: 950; epoch: 1; classification/accuracy: 0.964; objective: 0.12027560199300448; \n",
      "fold: TRAIN; iteration: 950; epoch: 1; objective: 0.07164636254310608; \n",
      "fold: TRAIN; iteration: 951; epoch: 1; objective: 0.14823925495147705; \n",
      "fold: TRAIN; iteration: 952; epoch: 1; objective: 0.2127835601568222; \n",
      "fold: TRAIN; iteration: 953; epoch: 1; objective: 0.11629101634025574; \n",
      "fold: TRAIN; iteration: 954; epoch: 1; objective: 0.07153528183698654; \n",
      "fold: TRAIN; iteration: 955; epoch: 1; objective: 0.07723500579595566; \n",
      "fold: TRAIN; iteration: 956; epoch: 1; objective: 0.13852982223033905; \n",
      "fold: TRAIN; iteration: 957; epoch: 1; objective: 0.15326480567455292; \n",
      "fold: TRAIN; iteration: 958; epoch: 1; objective: 0.11922917515039444; \n",
      "fold: TRAIN; iteration: 959; epoch: 1; objective: 0.1608286052942276; \n",
      "fold: TRAIN; iteration: 960; epoch: 1; objective: 0.16118355095386505; \n",
      "fold: TRAIN; iteration: 961; epoch: 1; objective: 0.11559095978736877; \n",
      "fold: TRAIN; iteration: 962; epoch: 1; objective: 0.13107725977897644; \n",
      "fold: TRAIN; iteration: 963; epoch: 1; objective: 0.08718966692686081; \n",
      "fold: TRAIN; iteration: 964; epoch: 1; objective: 0.18001356720924377; \n",
      "fold: TRAIN; iteration: 965; epoch: 1; objective: 0.2466842085123062; \n",
      "fold: TRAIN; iteration: 966; epoch: 1; objective: 0.18316349387168884; \n",
      "fold: TRAIN; iteration: 967; epoch: 1; objective: 0.08563064783811569; \n",
      "fold: TRAIN; iteration: 968; epoch: 1; objective: 0.07513988763093948; \n",
      "fold: TRAIN; iteration: 969; epoch: 1; objective: 0.08719716966152191; \n",
      "fold: TRAIN; iteration: 970; epoch: 1; objective: 0.12189695984125137; \n",
      "fold: TRAIN; iteration: 971; epoch: 1; objective: 0.08844667673110962; \n",
      "fold: TRAIN; iteration: 972; epoch: 1; objective: 0.1587173044681549; \n",
      "fold: TRAIN; iteration: 973; epoch: 1; objective: 0.1889744997024536; \n",
      "fold: TRAIN; iteration: 974; epoch: 1; objective: 0.1740720123052597; \n",
      "fold: TRAIN; iteration: 975; epoch: 1; objective: 0.26210740208625793; \n",
      "fold: TRAIN; iteration: 976; epoch: 1; objective: 0.13568651676177979; \n",
      "fold: TRAIN; iteration: 977; epoch: 1; objective: 0.15272945165634155; \n",
      "fold: TRAIN; iteration: 978; epoch: 1; objective: 0.0747513398528099; \n",
      "fold: TRAIN; iteration: 979; epoch: 1; objective: 0.0806150808930397; \n",
      "fold: TRAIN; iteration: 980; epoch: 1; objective: 0.13266848027706146; \n",
      "fold: TRAIN; iteration: 981; epoch: 1; objective: 0.06671343743801117; \n",
      "fold: TRAIN; iteration: 982; epoch: 1; objective: 0.12236922234296799; \n",
      "fold: TRAIN; iteration: 983; epoch: 1; objective: 0.053028736263513565; \n",
      "fold: TRAIN; iteration: 984; epoch: 1; objective: 0.039785195142030716; \n",
      "fold: TRAIN; iteration: 985; epoch: 1; objective: 0.25563302636146545; \n",
      "fold: TRAIN; iteration: 986; epoch: 1; objective: 0.07957643270492554; \n",
      "fold: TRAIN; iteration: 987; epoch: 1; objective: 0.29238536953926086; \n",
      "fold: TRAIN; iteration: 988; epoch: 1; objective: 0.1359715610742569; \n",
      "fold: TRAIN; iteration: 989; epoch: 1; objective: 0.09372492134571075; \n",
      "fold: TRAIN; iteration: 990; epoch: 1; objective: 0.06551173329353333; \n",
      "fold: TRAIN; iteration: 991; epoch: 1; objective: 0.12916812300682068; \n",
      "fold: TRAIN; iteration: 992; epoch: 1; objective: 0.14238989353179932; \n",
      "fold: TRAIN; iteration: 993; epoch: 1; objective: 0.06651347875595093; \n",
      "fold: TRAIN; iteration: 994; epoch: 1; objective: 0.1633652299642563; \n",
      "fold: TRAIN; iteration: 995; epoch: 1; objective: 0.10216112434864044; \n",
      "fold: TRAIN; iteration: 996; epoch: 1; objective: 0.09695759415626526; \n",
      "fold: TRAIN; iteration: 997; epoch: 1; objective: 0.06895221769809723; \n",
      "fold: TRAIN; iteration: 998; epoch: 1; objective: 0.1663387268781662; \n",
      "fold: TRAIN; iteration: 999; epoch: 1; objective: 0.04991752654314041; \n",
      "validating model...\n",
      "saving\n",
      "fold: VALID; iteration: 1000; epoch: 1; classification/accuracy: 0.972; objective: 0.11598934071759383; \n"
     ]
    }
   ],
   "source": [
    "docs.watch_job(jobs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d241ae46",
   "metadata": {},
   "source": [
    "Now the training has finished, we can watch the computation of model outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71e3d1cf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing chunk (1/12)\n",
      "finding documents under filter\n",
      "done.\n",
      "bulk writing...\n",
      "done.\n",
      "computing chunk (2/12)\n",
      "finding documents under filter\n",
      "done.\n",
      "bulk writing...\n",
      "done.\n",
      "computing chunk (3/12)\n",
      "finding documents under filter\n",
      "done.\n",
      "bulk writing...\n",
      "done.\n",
      "computing chunk (4/12)\n",
      "finding documents under filter\n",
      "done.\n",
      "bulk writing...\n",
      "done.\n",
      "computing chunk (5/12)\n",
      "finding documents under filter\n",
      "done.\n",
      "bulk writing...\n",
      "done.\n",
      "computing chunk (6/12)\n",
      "finding documents under filter\n",
      "done.\n",
      "bulk writing...\n",
      "done.\n",
      "computing chunk (7/12)\n",
      "finding documents under filter\n",
      "done.\n",
      "bulk writing...\n",
      "done.\n",
      "computing chunk (8/12)\n",
      "finding documents under filter\n",
      "done.\n",
      "bulk writing...\n",
      "done.\n",
      "computing chunk (9/12)\n",
      "finding documents under filter\n",
      "done.\n",
      "bulk writing...\n",
      "done.\n",
      "computing chunk (10/12)\n",
      "finding documents under filter\n",
      "done.\n",
      "bulk writing...\n",
      "done.\n",
      "computing chunk (11/12)\n",
      "finding documents under filter\n",
      "done.\n",
      "bulk writing...\n",
      "done.\n",
      "computing chunk (12/12)\n",
      "finding documents under filter\n",
      "done.\n",
      "bulk writing...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "docs.watch_job(jobs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67384028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('642aacc1e9dde2a6de1976af'),\n",
       " 'variety': 'learning_task',\n",
       " 'identifier': 'predictor',\n",
       " 'query_params': ['digits', {}],\n",
       " 'models': ['lenet', 'label'],\n",
       " 'keys': ['img', 'class'],\n",
       " 'metrics': ['accuracy'],\n",
       " 'objective': 'classification',\n",
       " 'splitter': None,\n",
       " 'validation_sets': ['classification'],\n",
       " 'keys_to_watch': ['img'],\n",
       " 'trainer_kwargs': {'n_iterations': 1000,\n",
       "  'validation_interval': 50,\n",
       "  'loader_suppress': ['_id']},\n",
       " 'trainer': 'ImputationTrainer',\n",
       " 'task_type': 'imputation',\n",
       " 'metric_values': {'classification': {'accuracy': [0.096,\n",
       "    0.48,\n",
       "    0.728,\n",
       "    0.844,\n",
       "    0.864,\n",
       "    0.896,\n",
       "    0.908,\n",
       "    0.924,\n",
       "    0.944,\n",
       "    0.94,\n",
       "    0.952,\n",
       "    0.952,\n",
       "    0.952,\n",
       "    0.956,\n",
       "    0.96,\n",
       "    0.96,\n",
       "    0.968,\n",
       "    0.964,\n",
       "    0.972,\n",
       "    0.964,\n",
       "    0.972]},\n",
       "  'objective': [2.3062571843465167,\n",
       "   2.0219791690508524,\n",
       "   1.470482877890269,\n",
       "   0.9092001179854076,\n",
       "   0.5880270600318909,\n",
       "   0.42862788736820223,\n",
       "   0.33637697498003644,\n",
       "   0.2839222768942515,\n",
       "   0.250561593969663,\n",
       "   0.2202315921584765,\n",
       "   0.1985008955001831,\n",
       "   0.1844787746667862,\n",
       "   0.17090942164262135,\n",
       "   0.16332482372721036,\n",
       "   0.1533856804172198,\n",
       "   0.1456368088722229,\n",
       "   0.13809367045760154,\n",
       "   0.1323872630794843,\n",
       "   0.12656324803829194,\n",
       "   0.12027560199300448,\n",
       "   0.11598934071759383]}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info = docs.database.get_object_info('predictor', 'learning_task')\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99a20ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16a122920>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(info['metric_values']['classification']['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99caf447",
   "metadata": {},
   "source": [
    "Accuracy is good, and we can see the outputs have been added to the documents (`_outputs.img.lenet`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7051b119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('642aacade9dde2a6de189027'),\n",
       " 'img': <PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>,\n",
       " 'class': 1,\n",
       " '_fold': 'train',\n",
       " '_outputs': {'img': {'lenet': 1}}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.find_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e41ab4c",
   "metadata": {},
   "source": [
    "After training, you'll see that a model **watcher** has been created, which keeps the `img` key up-to-date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0def946d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['predictor/img']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.list_watchers()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5c2958",
   "metadata": {},
   "source": [
    "When new data are added, the trained model kicks into action \n",
    "and it's outputs are added/ enriched to the newly added data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67f7e156",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_, jobs = docs.insert_many([{'img': x[0], 'class': x[1], 'update': True} for x in mnist_data[-1000:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f964af",
   "metadata": {},
   "source": [
    "We can watch the progress of adding this new data as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e825dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.watch_job(jobs['watcher', 'predictor'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4168e3d",
   "metadata": {},
   "source": [
    "After inserting and training the model, the model is automatically served on the SuperDuperDB model-server. If you're deployment is exposed to the internet, then these predictions are available anywhere:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c37b84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = docs.find_one({'_fold': 'valid'})['img']\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e184633",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.apply_model('lenet', im)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
