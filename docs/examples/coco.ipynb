{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "238f94f6",
   "metadata": {},
   "source": [
    "# Image retrieval, captioning and classification with CoCo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38bc025",
   "metadata": {},
   "source": [
    "This tutorial uses the [CoCo dataset \"Common objects in Context\"](https://cocodataset.org/#home) to show case some of the key-features of SuperDuperDB. In this example, you'll learn how to:\n",
    "\n",
    "- Prepare data in the best way for SuperDuperDB usage\n",
    "- Define data types\n",
    "- Upload and query data to and from the data base\n",
    "- Define multiple models on the database, including models with dependencies\n",
    "- Define a searchable semantic index based on existing models\n",
    "- Train a semantic index from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66577c0c",
   "metadata": {},
   "source": [
    "If you haven't downloaded the data already, execute the lines of bash below. We've tried to keep it clean,\n",
    "and for reasons of efficiency have resized the images using imagemagick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6232ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -o data/coco/\n",
    "!curl http://images.cocodataset.org/annotations/annotations_trainval2014.zip -o data/coco/raw.zip\n",
    "!unzip data/coco/raw.zip\n",
    "!mv data/coco/annotations/captions_train2014.json data/coco/\n",
    "!rm -rf data/coco/annotations\n",
    "!rm data/coco/raw.zip\n",
    "!curl http://images.cocodataset.org/zips/train2014.zip -o data/coco/images.zip\n",
    "!unzip data/coco/images.zip\n",
    "!rm data/coco/images.zip\n",
    "!sudo apt install imagemagick\n",
    "!mogrify -resize 224x data/coco/images/*.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b455a1c8",
   "metadata": {},
   "source": [
    "SuperDuperDB uses MongoDB for data storage. If you haven't done so already, install it using the following lines of bash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7ec394",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -qO - https://www.mongodb.org/static/pgp/server-6.0.asc | sudo apt-key add -\n",
    "!sudo apt-get install gnupg\n",
    "!wget -qO - https://www.mongodb.org/static/pgp/server-6.0.asc | sudo apt-key add -\n",
    "!echo \"deb [ arch=amd64,arm64 ] https://repo.mongodb.org/apt/ubuntu focal/mongodb-org/6.0 multiverse\" | sudo tee /etc/apt/sources.list.d/mongodb-org-6.0.list\n",
    "!sudo apt-get update\n",
    "!sudo apt-get install -y mongodb-org"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd6dc87",
   "metadata": {},
   "source": [
    "In case you haven't done so already, install the dependencies for this tutorial, including SuperDuperDB,\n",
    "which is a simple pip install."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5382d874",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install pillow\n",
    "!pip install torch\n",
    "!pip install superduperdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e1e6e1",
   "metadata": {},
   "source": [
    "SuperDuperDB can handle data in any format, including images. The documents in the database are MongoDB `bson` documents, which mix `json` with raw bytes and `ObjectId` objects. SuperDuperDB takes advantage of this by \n",
    "serializing more sophisticated objects to bytes, and reinstantiating the objects in memory, when data is queried.\n",
    "\n",
    "In order to tell SuperDuperDB what type an object has, one specifies this with a subdocument of the form:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"_content\": {\n",
    "        \"bytes\": ...,\n",
    "        \"type\": \"<my-type>\",\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "If however, the content is located on the web or the filesystem, one can specify the URLs directly:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"_content\": {\n",
    "        \"url\": \"<url-or-file>\",\n",
    "        \"type\": \"<my-type>\",\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "Let's see this now in action. We reformat the CoCo data, so that each image is associated in one document with all of the captions which describe it, and add the location of the images using the `_content` formalism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a5dc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data/coco/captions_train2014.json') as f:\n",
    "    raw = json.load(f)\n",
    "    \n",
    "raw['images'] = {x['id']: x for x in raw['images']}\n",
    "\n",
    "for im in raw['images']:\n",
    "    raw['images'][im]['captions'] = []\n",
    "    \n",
    "for a in raw['annotations']:\n",
    "    raw['images'][a['image_id']]['captions'].append(a['caption'])\n",
    "\n",
    "raw = list(raw['images'].values())\n",
    "\n",
    "for i, im in enumerate(raw):\n",
    "    # if image is already in memory, then add 'bytes': b'...' instead of 'url': '...'\n",
    "    # for content located on the web, use 'http://' or 'https://' instead of 'file://'\n",
    "    im['img'] = {\n",
    "        '_content': {'url': f'file://data/coco/images/{im[\"file_name\"]}', 'type': 'image'}\n",
    "    }\n",
    "    raw[i] = {'captions': im['captions'], 'img': im['img']}\n",
    "\n",
    "with open('data/coco/data.json', 'w') as f:\n",
    "    json.dump(raw, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a45f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "\n",
    "sys.path.append('../../')\n",
    "\n",
    "from superduperdb.client import the_client\n",
    "from IPython.display import display, clear_output\n",
    "import torch\n",
    "\n",
    "docs = the_client.coco_example.documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17b03ae",
   "metadata": {},
   "source": [
    "We'll load the data and add most of it to the database. We'll hold back some data so that we can see how to update \n",
    "the database later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bf022c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open('data/coco/data.json') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "docs.insert_many(data[:-1000]), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1433f7c0",
   "metadata": {},
   "source": [
    "We previously added the type `image` to the `_content` subrecords earlier.\n",
    "So that we can load the data using this type, we need to add this type to the database.\n",
    "You can see in `examples/types.py` how the class encodes and decodes data. Suffice to say at this point, \n",
    "that each type has an `encode` and `decode` method, which convert to and from `bytes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2728cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.types import FloatTensor, Image\n",
    "\n",
    "docs.create_type('float_tensor', FloatTensor())\n",
    "docs.create_type('image', Image())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70298808",
   "metadata": {},
   "source": [
    "In the first AI task which we implement for the `docs` collection, we'll be setting up a model to retrieve relevant images using provided text. For this data, that means the `captions` field being used to retrieve the `img` field. In order to be able to keep an objective record of performance, we can set up an immutable validation dataset from the collection. We use a **splitter** to define how we'd like to test retrieval. This splits the documents into query and retrieved document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8565389",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "docs.create_validation_set(\n",
    "    'text2image_retrieval', \n",
    "    filter={},\n",
    "    splitter=lambda x: ({'img': x['img']}, {'captions': [x['captions'][0]]}),\n",
    "    sample_size=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126c91f7",
   "metadata": {},
   "source": [
    "We can see what the data points in the validation set look like by querying:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c171e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs['_validation_sets'].find_one({'_validation_set': 'text2image_retrieval'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd2550b",
   "metadata": {},
   "source": [
    "You can see that the sample \"query\" is split into the `_other` field. This is important when evaluating semantic indexes.\n",
    "\n",
    "Now let's start adding a model to the collection.\n",
    "A nice open source model to test text-2-image retrieval is [CLIP](https://openai.com/blog/clip/) which understands images and texts and embeds these in a common vector space.\n",
    "\n",
    "Note that we are specifying the type of the model output, so that the collection knows how to store the results, as well as \"activating\" the model with `active=True`. That means, whenever we add data which fall under the `filter`, then these will get processed by the model, and the outputs will be added to the collection documents.\n",
    "\n",
    "The `key` argument specifies which part of the document the model should act. If `key=\"_base\"` then the model takes the whole document as input. Since we'll be encoding documents as images, then we'll chose `key=\"img`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfee9613",
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.models import CLIP\n",
    "\n",
    "docs.create_model(\n",
    "    name='clip',\n",
    "    object=CLIP('RN50'),\n",
    "    filter={},\n",
    "    type='float_tensor',\n",
    "    key='img',\n",
    "    verbose=True,\n",
    "    active=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861db6a0",
   "metadata": {},
   "source": [
    "We'll create a companion model which uses the same underlying object as the previous model. That's specified by adding the name instead of the object in the `object` argument. In this case the model is not `active`, since we'll only be using it for querying the collection. We don't need to specify a `type` since that was done in the last step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b925d707",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.create_model(\n",
    "    name='clip_text',\n",
    "    object='clip',\n",
    "    key='captions',\n",
    "    active=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c908e762",
   "metadata": {},
   "source": [
    "We'll also create a measure which tests how similar to each other two outputs might be. Since CLIP was trained with cosine-similarity we'll use that here too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6cd6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.measures import css\n",
    "\n",
    "docs.create_measure('css', css)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda8af6c",
   "metadata": {},
   "source": [
    "In order to be able to measure performance on the validation set, we'll add a **metric**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66911bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.metrics import PatK\n",
    "\n",
    "docs.create_metric('p_at_10', PatK(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d34b2f",
   "metadata": {},
   "source": [
    "Now we're ready to go to add a **semantic index**. This is a tuple of models, one of which is activated in order to populate the collection with vectors. The idea is that any of the models in the **semantic index** can be used to query the collection using nearest neighbour lookup based on the **measure** chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd71ce6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from examples.models import CLIP\n",
    "\n",
    "docs.create_semantic_index(\n",
    "    'clip',\n",
    "    models=['clip', 'clip_text'],\n",
    "    measure='css',\n",
    "    metrics=['p_at_10'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a38189",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bson import ObjectId\n",
    "from IPython.display import display\n",
    "\n",
    "docs.semantic_index = 'clip'\n",
    "for r in docs.find({'$like': {'document': {'_id': ObjectId('63d27372745cc274ef3518f2')}, 'n': 10}}):\n",
    "    display(r['img'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76310241",
   "metadata": {},
   "source": [
    "Let's now evaluate the quality of this semantic index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aff23c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.validate_semantic_index('clip', ['text2image_retrieval'], ['p_at_10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bdb5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs['_semantic_indexes'].find_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac54e49",
   "metadata": {},
   "source": [
    "We can see that we can get nice meaningful retrievals using the CLIP model from short descriptive pieces of text.\n",
    "This is very useful, since the model is now deployed to the database, listening for incoming queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193a26a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.list_semantic_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4e0e73",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "docs.semantic_index = 'clip'\n",
    "for r in docs.find({'$like': {'document': {'captions': ['Dog catches a frisbee']}, 'n': 5}}):\n",
    "    display(r['img'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407f2c87",
   "metadata": {},
   "source": [
    "In the next section of this example, let us train our own model from scratch. The model will be much simpler than the clip model, but will yield faster retrievals. It will be interesting to see how this compares to CLIP, and show-case SuperDuperDB as a framework for easily integrating and benchmarking AI models, in particular for retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d9293c",
   "metadata": {},
   "source": [
    "First we will implement a simpler sentence embedding, using a simple word-embedding approach based around Glove.\n",
    "Please look at the model in `examples.models.AverageOfGloves`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df44c5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl https://nlp.stanford.edu/data/glove.6B.zip -o data/glove.6B.zip\n",
    "!unzip data/glove.6B.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbb979e",
   "metadata": {},
   "source": [
    "We may register this model to the collection in the same way we did for the textual part of CLIP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625813aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import torch\n",
    "from examples.models import AverageOfGloves\n",
    "\n",
    "with open('data/glove.6B/glove.6B.50d.txt') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "    \n",
    "lines = [x.split(' ') for x in lines[:-1]]\n",
    "index = [x[0] for x in lines]\n",
    "vectors = [[float(y) for y in x[1:]] for x in lines]\n",
    "vectors = numpy.array(vectors)\n",
    "\n",
    "glove = AverageOfGloves(torch.from_numpy(vectors).type(torch.float), index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527f2aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.create_model(\n",
    "    'average_glove',\n",
    "    object=glove,\n",
    "    key='captions',\n",
    "    active=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4d4c37",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "docs.create_model(\n",
    "    'clip_projection',\n",
    "    object=torch.nn.Linear(1024, 50),\n",
    "    active=True,\n",
    "    key='img',\n",
    "    type='float_tensor',\n",
    "    features={'img': 'clip'},\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ecddf4",
   "metadata": {},
   "source": [
    "Let's also create a loss function, in order to be able to perform the learning task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aebdd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.losses import ranking_loss\n",
    "\n",
    "docs.create_loss('ranking_loss', ranking_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a44467",
   "metadata": {},
   "source": [
    "A semantic index training requires:\n",
    "\n",
    "- 1 or more models\n",
    "- A measure function to measure similarity between model outputs\n",
    "- A loss function\n",
    "- One or more validation sets\n",
    "- One or more metrics to measure performance\n",
    "\n",
    "We now have all of these things ready and registered with the database, so we can start the training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddf5276",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "docs.create_semantic_index(\n",
    "    'simple_image_search',\n",
    "    models=['clip_projection', 'average_glove'],\n",
    "    loss='ranking_loss',\n",
    "    filter={},\n",
    "    projection={'image': 0, '_like': 0},\n",
    "    metrics=['p_at_10'],\n",
    "    measure='css',\n",
    "    validation_sets=['text2image_retrieval'],\n",
    "    batch_size=250,\n",
    "    num_workers=0,\n",
    "    n_epochs=20,\n",
    "    lr=0.001,\n",
    "    log_weights=True,\n",
    "    download=True,\n",
    "    validation_interval=50,\n",
    "    no_improve_then_stop=5,\n",
    "    n_iterations=5000,\n",
    "    use_grads={'clip_projection': True, 'average_glove': False},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0041c4c",
   "metadata": {},
   "source": [
    "We now can see that we've set and trained our own semantic index. Let's take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12e0022",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.list_semantic_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6771a45",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "info = docs['_semantic_indexes'].find_one({'name': 'simple_image_search'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18871e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in info['metric_values']:\n",
    "    if k == 'loss':\n",
    "        print(info['metric_values'][k])\n",
    "        plt.figure()\n",
    "        plt.title('loss')\n",
    "        plt.plot(info['metric_values'][k])\n",
    "        continue\n",
    "    for result in info['metric_values'][k]:\n",
    "        plt.figure()\n",
    "        plt.title(f'{k}/{result}')\n",
    "        plt.plot(info['metric_values'][k][result])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374cf054",
   "metadata": {},
   "outputs": [],
   "source": [
    "for parameter in info['weights']:\n",
    "    plt.figure()\n",
    "    plt.title(parameter)\n",
    "    plt.plot(info['weights'][parameter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc334d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e43c4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.refresh_model('clip_projection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b1bf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "docs.semantic_index = 'simple_image_search'\n",
    "for r in docs.find({'$like': {'document': {'captions': ['Dog catches frisbee']}, 'n': 5}}):\n",
    "    display(r['img'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3ff23d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from examples.models import NounWords\n",
    "docs.create_model('noun_words', NounWords(), verbose=True, key='captions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1aebe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.create_validation_set('attribute_prediction', sample_size=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289d515e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import tqdm\n",
    "all_nouns = []\n",
    "for r in tqdm.tqdm(docs.find({'_fold': 'train'}, {'_outputs.captions.noun_words': 1}), total=docs.count_documents({})):\n",
    "    all_nouns.extend(r['_outputs']['captions']['noun_words'])\n",
    "    \n",
    "counts = dict(collections.Counter(all_nouns))\n",
    "all_nouns = [w for w in counts if counts[w] > 30]\n",
    "total = docs.count_documents({})\n",
    "pos_weights = [counts[w] / total for w in all_nouns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386dc8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.models import FewHot, TopK\n",
    "from examples.metrics import jacquard_index\n",
    "\n",
    "docs.create_model('nouns_to_few_hot', FewHot(all_nouns))\n",
    "docs.create_postprocessor('top_5', TopK(all_nouns, 5))\n",
    "docs.create_forward('attribute_predictor', torch.nn.Linear(1024, len(all_nouns)))\n",
    "docs.create_loss('nouns_loss', torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor(pos_weights)))\n",
    "docs.create_metric('jacquard_index', jacquard_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a444d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.models import FewHot\n",
    "docs.create_model('nouns_to_few_hot', FewHot(post.tokens), active=False,\n",
    "                 key='_outputs.captions.noun_words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60be2dbb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "docs.create_model('attribute_predictor', forward='attribute_predictor', postprocessor='top_5',\n",
    "                  key='img', features={'img': 'clip'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d80959",
   "metadata": {},
   "source": [
    "Let's test the model, using the `apply_model` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06695727",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.apply_model('attribute_predictor', docs.find_one())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e45e59",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "docs.create_imputation(\n",
    "    'noun_prediction',\n",
    "    model='attribute_predictor',\n",
    "    target='nouns_to_few_hot',\n",
    "    loss='nouns_loss',\n",
    "    metrics=['jacquard_index'],\n",
    "    validation_sets=['attribute_prediction'],\n",
    "    lr=0.001,\n",
    "    validation_interval=10,\n",
    "    n_iterations=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30dc496",
   "metadata": {},
   "source": [
    "We can view the results of learning (metrics, loss etc.) by looking in the `_imputations` subcollection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbfcd145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "\n",
    "sys.path.append('../../')\n",
    "\n",
    "from superduperdb.client import the_client\n",
    "from IPython.display import display, clear_output\n",
    "import torch\n",
    "\n",
    "docs = the_client.coco_example.documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4166411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.023638010025024414,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 48,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 78560,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e03e334a40974c089d5dff0defcad04f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/78560 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tqdm \n",
    "\n",
    "all_captions = []\n",
    "n = docs.count_documents({'_fold': 'train'})\n",
    "for r in tqdm.tqdm_notebook(docs.find({'_fold': 'train'}, {'captions': 1, '_id': 0}), total=n):\n",
    "    all_captions.extend(r['captions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6a4472f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import re\n",
    "all_captions = [re.sub('[^a-z ]', '', x.lower()).strip() for x in all_captions]\n",
    "words = ' '.join(all_captions).split(' ')\n",
    "counts = dict(collections.Counter(words))\n",
    "vocab = sorted([w for w in counts if counts[w] > 5 and w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d71d299",
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.models import ConditionalLM, SimpleTokenizer\n",
    "tokenizer = SimpleTokenizer(vocab)\n",
    "m = ConditionalLM(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a4cd4be",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "docs.create_model('conditional_lm', object=m, active=False, features={'img': 'clip'}, key='_base')\n",
    "docs.create_model('captioning_tokenizer', tokenizer, key='caption', active=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "432e3bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are about to delete these models: [ObjectId('63ebdc062c13085e82d849ce')], are you sure? [y/N]: y\n",
      "unsetting output field _outputs._base.conditional_lm\n",
      "You are about to delete these models: [ObjectId('63ebdc062c13085e82d84a6d')], are you sure? [y/N]: y\n",
      "unsetting output field _outputs.caption.captioning_tokenizer\n"
     ]
    }
   ],
   "source": [
    "docs.delete_model('conditional_lm', force=True)\n",
    "docs.delete_model('captioning_tokenizer', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e501979",
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.losses import auto_regressive_loss\n",
    "docs.create_loss('autoregressive_loss', auto_regressive_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bce3f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs['_validation_sets'].find_one({'_validation_set': 'attribute_prediction'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2902496f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.splitters import captioning_splitter\n",
    "\n",
    "docs.create_splitter('captioning_splitter', captioning_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020d38e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "captioning_splitter(docs.find_one())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10344946",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "docs.create_validation_set('captioning', splitter=docs.splitters['captioning_splitter'],\n",
    "                           sample_size=500, chunk_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb18cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs['_validation_sets'].find_one({'_validation_set': 'captioning'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aa5079",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading ids for {'_fold': 'train'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 78560/78560 [00:00<00:00, 212987.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading records for {'_fold': 'valid'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4223/4223 [00:00<00:00, 10464.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: VALID; iteration: 0; epoch: 0; loss: 9.006699079625747; \n",
      "fold: TRAIN; iteration: 0; epoch: 0; loss: 9.007852554321289; \n",
      "fold: TRAIN; iteration: 1; epoch: 0; loss: 8.673001289367676; \n",
      "fold: TRAIN; iteration: 2; epoch: 0; loss: 8.33862590789795; \n",
      "fold: TRAIN; iteration: 3; epoch: 0; loss: 7.989694118499756; \n",
      "fold: TRAIN; iteration: 4; epoch: 0; loss: 7.5262064933776855; \n",
      "fold: TRAIN; iteration: 5; epoch: 0; loss: 7.103574752807617; \n",
      "fold: TRAIN; iteration: 6; epoch: 0; loss: 6.254573822021484; \n",
      "fold: TRAIN; iteration: 7; epoch: 0; loss: 5.6371636390686035; \n",
      "fold: TRAIN; iteration: 8; epoch: 0; loss: 5.411647319793701; \n",
      "fold: TRAIN; iteration: 9; epoch: 0; loss: 4.917050838470459; \n",
      "fold: TRAIN; iteration: 10; epoch: 0; loss: 5.1513471603393555; \n",
      "fold: TRAIN; iteration: 11; epoch: 0; loss: 5.066558361053467; \n",
      "fold: TRAIN; iteration: 12; epoch: 0; loss: 4.722397804260254; \n",
      "fold: TRAIN; iteration: 13; epoch: 0; loss: 5.1696906089782715; \n",
      "fold: TRAIN; iteration: 14; epoch: 0; loss: 5.103100299835205; \n",
      "fold: TRAIN; iteration: 15; epoch: 0; loss: 4.834744930267334; \n",
      "fold: TRAIN; iteration: 16; epoch: 0; loss: 4.827073574066162; \n",
      "fold: TRAIN; iteration: 17; epoch: 0; loss: 4.576658248901367; \n",
      "fold: TRAIN; iteration: 18; epoch: 0; loss: 4.938275337219238; \n",
      "fold: TRAIN; iteration: 19; epoch: 0; loss: 4.860889434814453; \n",
      "fold: TRAIN; iteration: 20; epoch: 0; loss: 4.667354583740234; \n",
      "fold: TRAIN; iteration: 21; epoch: 0; loss: 4.722173690795898; \n",
      "fold: TRAIN; iteration: 22; epoch: 0; loss: 4.846364974975586; \n",
      "fold: TRAIN; iteration: 23; epoch: 0; loss: 4.549621105194092; \n",
      "fold: TRAIN; iteration: 24; epoch: 0; loss: 4.646560192108154; \n",
      "fold: TRAIN; iteration: 25; epoch: 0; loss: 4.70808219909668; \n",
      "fold: TRAIN; iteration: 26; epoch: 0; loss: 4.786731243133545; \n",
      "fold: TRAIN; iteration: 27; epoch: 0; loss: 4.613207817077637; \n",
      "fold: TRAIN; iteration: 28; epoch: 0; loss: 4.605914115905762; \n",
      "fold: TRAIN; iteration: 29; epoch: 0; loss: 4.535373687744141; \n",
      "fold: TRAIN; iteration: 30; epoch: 0; loss: 4.5979838371276855; \n",
      "fold: TRAIN; iteration: 31; epoch: 0; loss: 4.587547779083252; \n",
      "fold: TRAIN; iteration: 32; epoch: 0; loss: 4.640610694885254; \n",
      "fold: TRAIN; iteration: 33; epoch: 0; loss: 4.550013065338135; \n",
      "fold: TRAIN; iteration: 34; epoch: 0; loss: 4.661821365356445; \n",
      "fold: TRAIN; iteration: 35; epoch: 0; loss: 4.370927333831787; \n",
      "fold: TRAIN; iteration: 36; epoch: 0; loss: 4.676568031311035; \n",
      "fold: TRAIN; iteration: 37; epoch: 0; loss: 4.427049160003662; \n",
      "fold: TRAIN; iteration: 38; epoch: 0; loss: 4.3530707359313965; \n",
      "fold: TRAIN; iteration: 39; epoch: 0; loss: 4.347004413604736; \n",
      "fold: TRAIN; iteration: 40; epoch: 0; loss: 4.503622531890869; \n",
      "fold: TRAIN; iteration: 41; epoch: 0; loss: 4.251798152923584; \n",
      "fold: TRAIN; iteration: 42; epoch: 0; loss: 4.346681594848633; \n",
      "fold: TRAIN; iteration: 43; epoch: 0; loss: 4.155911445617676; \n",
      "fold: TRAIN; iteration: 44; epoch: 0; loss: 4.429801940917969; \n",
      "fold: TRAIN; iteration: 45; epoch: 0; loss: 4.1940999031066895; \n",
      "fold: TRAIN; iteration: 46; epoch: 0; loss: 4.3298468589782715; \n",
      "fold: TRAIN; iteration: 47; epoch: 0; loss: 4.296901702880859; \n",
      "fold: TRAIN; iteration: 48; epoch: 0; loss: 4.325868129730225; \n",
      "fold: TRAIN; iteration: 49; epoch: 0; loss: 4.217217922210693; \n",
      "fold: TRAIN; iteration: 50; epoch: 0; loss: 4.159416675567627; \n",
      "fold: TRAIN; iteration: 51; epoch: 0; loss: 4.451361179351807; \n",
      "fold: TRAIN; iteration: 52; epoch: 0; loss: 4.148470878601074; \n",
      "fold: TRAIN; iteration: 53; epoch: 0; loss: 4.263782501220703; \n",
      "fold: TRAIN; iteration: 54; epoch: 0; loss: 4.032332420349121; \n",
      "fold: TRAIN; iteration: 55; epoch: 0; loss: 4.251324653625488; \n",
      "fold: TRAIN; iteration: 56; epoch: 0; loss: 4.304043769836426; \n",
      "fold: TRAIN; iteration: 57; epoch: 0; loss: 3.947641611099243; \n",
      "fold: TRAIN; iteration: 58; epoch: 0; loss: 4.244446277618408; \n",
      "fold: TRAIN; iteration: 59; epoch: 0; loss: 4.495344161987305; \n",
      "fold: TRAIN; iteration: 60; epoch: 0; loss: 4.022599220275879; \n",
      "fold: TRAIN; iteration: 61; epoch: 0; loss: 4.389049530029297; \n",
      "fold: TRAIN; iteration: 62; epoch: 0; loss: 4.078886985778809; \n",
      "fold: TRAIN; iteration: 63; epoch: 0; loss: 3.9792778491973877; \n",
      "fold: TRAIN; iteration: 64; epoch: 0; loss: 4.021294116973877; \n",
      "fold: TRAIN; iteration: 65; epoch: 0; loss: 3.9582605361938477; \n",
      "fold: TRAIN; iteration: 66; epoch: 0; loss: 4.102292537689209; \n",
      "fold: TRAIN; iteration: 67; epoch: 0; loss: 3.939516544342041; \n",
      "fold: TRAIN; iteration: 68; epoch: 0; loss: 3.9574620723724365; \n",
      "fold: TRAIN; iteration: 69; epoch: 0; loss: 3.925955295562744; \n",
      "fold: TRAIN; iteration: 70; epoch: 0; loss: 4.157577991485596; \n",
      "fold: TRAIN; iteration: 71; epoch: 0; loss: 4.058897018432617; \n",
      "fold: TRAIN; iteration: 72; epoch: 0; loss: 4.028336524963379; \n",
      "fold: TRAIN; iteration: 73; epoch: 0; loss: 3.8876116275787354; \n",
      "fold: TRAIN; iteration: 74; epoch: 0; loss: 3.9872000217437744; \n",
      "fold: TRAIN; iteration: 75; epoch: 0; loss: 4.100535869598389; \n",
      "fold: TRAIN; iteration: 76; epoch: 0; loss: 3.8436288833618164; \n",
      "fold: TRAIN; iteration: 77; epoch: 0; loss: 3.7029154300689697; \n",
      "fold: TRAIN; iteration: 78; epoch: 0; loss: 3.9667932987213135; \n",
      "fold: TRAIN; iteration: 79; epoch: 0; loss: 3.8965511322021484; \n",
      "fold: TRAIN; iteration: 80; epoch: 0; loss: 3.5442147254943848; \n",
      "fold: TRAIN; iteration: 81; epoch: 0; loss: 4.069461822509766; \n",
      "fold: TRAIN; iteration: 82; epoch: 0; loss: 4.03965425491333; \n",
      "fold: TRAIN; iteration: 83; epoch: 0; loss: 3.741915702819824; \n",
      "fold: TRAIN; iteration: 84; epoch: 0; loss: 3.931758165359497; \n",
      "fold: TRAIN; iteration: 85; epoch: 0; loss: 3.778116464614868; \n",
      "fold: TRAIN; iteration: 86; epoch: 0; loss: 4.0618815422058105; \n",
      "fold: TRAIN; iteration: 87; epoch: 0; loss: 3.7486090660095215; \n",
      "fold: TRAIN; iteration: 88; epoch: 0; loss: 4.130152702331543; \n",
      "fold: TRAIN; iteration: 89; epoch: 0; loss: 4.001167297363281; \n",
      "fold: TRAIN; iteration: 90; epoch: 0; loss: 3.927802085876465; \n",
      "fold: TRAIN; iteration: 91; epoch: 0; loss: 3.8266284465789795; \n",
      "fold: TRAIN; iteration: 92; epoch: 0; loss: 3.9150302410125732; \n",
      "fold: TRAIN; iteration: 93; epoch: 0; loss: 3.748394250869751; \n",
      "fold: TRAIN; iteration: 94; epoch: 0; loss: 3.8056435585021973; \n",
      "fold: TRAIN; iteration: 95; epoch: 0; loss: 3.8320257663726807; \n",
      "fold: TRAIN; iteration: 96; epoch: 0; loss: 3.8467791080474854; \n",
      "fold: TRAIN; iteration: 97; epoch: 0; loss: 3.671478509902954; \n",
      "fold: TRAIN; iteration: 98; epoch: 0; loss: 3.4679765701293945; \n",
      "fold: TRAIN; iteration: 99; epoch: 0; loss: 3.8666701316833496; \n",
      "fold: TRAIN; iteration: 100; epoch: 0; loss: 3.9230356216430664; \n",
      "fold: TRAIN; iteration: 101; epoch: 0; loss: 3.925760507583618; \n",
      "fold: TRAIN; iteration: 102; epoch: 0; loss: 3.7969348430633545; \n",
      "fold: TRAIN; iteration: 103; epoch: 0; loss: 3.6442272663116455; \n",
      "fold: TRAIN; iteration: 104; epoch: 0; loss: 3.603660821914673; \n",
      "fold: TRAIN; iteration: 105; epoch: 0; loss: 3.7598986625671387; \n",
      "fold: TRAIN; iteration: 106; epoch: 0; loss: 3.5569276809692383; \n",
      "fold: TRAIN; iteration: 107; epoch: 0; loss: 3.7621591091156006; \n",
      "fold: TRAIN; iteration: 108; epoch: 0; loss: 3.6095776557922363; \n",
      "fold: TRAIN; iteration: 109; epoch: 0; loss: 3.771341562271118; \n",
      "fold: TRAIN; iteration: 110; epoch: 0; loss: 3.793370008468628; \n",
      "fold: TRAIN; iteration: 111; epoch: 0; loss: 3.9256746768951416; \n",
      "fold: TRAIN; iteration: 112; epoch: 0; loss: 4.0801591873168945; \n",
      "fold: TRAIN; iteration: 113; epoch: 0; loss: 3.699575901031494; \n",
      "fold: TRAIN; iteration: 114; epoch: 0; loss: 3.979522943496704; \n",
      "fold: TRAIN; iteration: 115; epoch: 0; loss: 3.4239232540130615; \n",
      "fold: TRAIN; iteration: 116; epoch: 0; loss: 3.6540825366973877; \n",
      "fold: TRAIN; iteration: 117; epoch: 0; loss: 3.451775550842285; \n",
      "fold: TRAIN; iteration: 118; epoch: 0; loss: 3.758643865585327; \n",
      "fold: TRAIN; iteration: 119; epoch: 0; loss: 4.1185832023620605; \n",
      "fold: TRAIN; iteration: 120; epoch: 0; loss: 3.557082176208496; \n",
      "fold: TRAIN; iteration: 121; epoch: 0; loss: 3.7577505111694336; \n",
      "fold: TRAIN; iteration: 122; epoch: 0; loss: 3.774523973464966; \n",
      "fold: TRAIN; iteration: 123; epoch: 0; loss: 3.831472396850586; \n",
      "fold: TRAIN; iteration: 124; epoch: 0; loss: 3.555569648742676; \n",
      "fold: TRAIN; iteration: 125; epoch: 0; loss: 3.806027412414551; \n",
      "fold: TRAIN; iteration: 126; epoch: 0; loss: 3.5688202381134033; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 127; epoch: 0; loss: 3.5306012630462646; \n",
      "fold: TRAIN; iteration: 128; epoch: 0; loss: 3.6273486614227295; \n",
      "fold: TRAIN; iteration: 129; epoch: 0; loss: 3.5704855918884277; \n",
      "fold: TRAIN; iteration: 130; epoch: 0; loss: 3.7388901710510254; \n",
      "fold: TRAIN; iteration: 131; epoch: 0; loss: 3.783998489379883; \n",
      "fold: TRAIN; iteration: 132; epoch: 0; loss: 3.8043880462646484; \n",
      "fold: TRAIN; iteration: 133; epoch: 0; loss: 3.586892604827881; \n",
      "fold: TRAIN; iteration: 134; epoch: 0; loss: 3.533267021179199; \n",
      "fold: TRAIN; iteration: 135; epoch: 0; loss: 3.4774672985076904; \n",
      "fold: TRAIN; iteration: 136; epoch: 0; loss: 3.8149490356445312; \n",
      "fold: TRAIN; iteration: 137; epoch: 0; loss: 3.6567680835723877; \n",
      "fold: TRAIN; iteration: 138; epoch: 0; loss: 3.540497064590454; \n",
      "fold: TRAIN; iteration: 139; epoch: 0; loss: 3.6971683502197266; \n",
      "fold: TRAIN; iteration: 140; epoch: 0; loss: 3.3800716400146484; \n",
      "fold: TRAIN; iteration: 141; epoch: 0; loss: 3.6187169551849365; \n",
      "fold: TRAIN; iteration: 142; epoch: 0; loss: 3.551632881164551; \n",
      "fold: TRAIN; iteration: 143; epoch: 0; loss: 3.291236639022827; \n",
      "fold: TRAIN; iteration: 144; epoch: 0; loss: 3.663015127182007; \n",
      "fold: TRAIN; iteration: 145; epoch: 0; loss: 3.8557894229888916; \n",
      "fold: TRAIN; iteration: 146; epoch: 0; loss: 3.4615650177001953; \n",
      "fold: TRAIN; iteration: 147; epoch: 0; loss: 3.7670724391937256; \n",
      "fold: TRAIN; iteration: 148; epoch: 0; loss: 3.482963800430298; \n",
      "fold: TRAIN; iteration: 149; epoch: 0; loss: 3.340230941772461; \n",
      "fold: TRAIN; iteration: 150; epoch: 0; loss: 3.7450997829437256; \n",
      "fold: TRAIN; iteration: 151; epoch: 0; loss: 3.669975519180298; \n",
      "fold: TRAIN; iteration: 152; epoch: 0; loss: 3.5001587867736816; \n",
      "fold: TRAIN; iteration: 153; epoch: 0; loss: 3.5711593627929688; \n",
      "fold: TRAIN; iteration: 154; epoch: 0; loss: 3.5531411170959473; \n",
      "fold: TRAIN; iteration: 155; epoch: 0; loss: 3.620663642883301; \n",
      "fold: TRAIN; iteration: 156; epoch: 0; loss: 3.4200799465179443; \n",
      "fold: TRAIN; iteration: 157; epoch: 0; loss: 3.633669376373291; \n",
      "fold: TRAIN; iteration: 158; epoch: 0; loss: 3.4867827892303467; \n",
      "fold: TRAIN; iteration: 159; epoch: 0; loss: 3.782421350479126; \n",
      "fold: TRAIN; iteration: 160; epoch: 0; loss: 3.496744394302368; \n",
      "fold: TRAIN; iteration: 161; epoch: 0; loss: 3.4125466346740723; \n",
      "fold: TRAIN; iteration: 162; epoch: 0; loss: 3.5232954025268555; \n",
      "fold: TRAIN; iteration: 163; epoch: 0; loss: 3.6959242820739746; \n",
      "fold: TRAIN; iteration: 164; epoch: 0; loss: 3.5129406452178955; \n",
      "fold: TRAIN; iteration: 165; epoch: 0; loss: 3.5954675674438477; \n",
      "fold: TRAIN; iteration: 166; epoch: 0; loss: 3.410062551498413; \n",
      "fold: TRAIN; iteration: 167; epoch: 0; loss: 3.4081478118896484; \n",
      "fold: TRAIN; iteration: 168; epoch: 0; loss: 3.475332260131836; \n",
      "fold: TRAIN; iteration: 169; epoch: 0; loss: 3.0898325443267822; \n",
      "fold: TRAIN; iteration: 170; epoch: 0; loss: 3.320897102355957; \n",
      "fold: TRAIN; iteration: 171; epoch: 0; loss: 3.4838805198669434; \n",
      "fold: TRAIN; iteration: 172; epoch: 0; loss: 3.1956217288970947; \n",
      "fold: TRAIN; iteration: 173; epoch: 0; loss: 3.6510815620422363; \n",
      "fold: TRAIN; iteration: 174; epoch: 0; loss: 3.1765682697296143; \n",
      "fold: TRAIN; iteration: 175; epoch: 0; loss: 3.583092451095581; \n",
      "fold: TRAIN; iteration: 176; epoch: 0; loss: 3.471517324447632; \n",
      "fold: TRAIN; iteration: 177; epoch: 0; loss: 3.3353161811828613; \n",
      "fold: TRAIN; iteration: 178; epoch: 0; loss: 3.4640347957611084; \n",
      "fold: TRAIN; iteration: 179; epoch: 0; loss: 3.324106454849243; \n",
      "fold: TRAIN; iteration: 180; epoch: 0; loss: 3.3619558811187744; \n",
      "fold: TRAIN; iteration: 181; epoch: 0; loss: 3.3870551586151123; \n",
      "fold: TRAIN; iteration: 182; epoch: 0; loss: 3.22784423828125; \n",
      "fold: TRAIN; iteration: 183; epoch: 0; loss: 3.504518985748291; \n",
      "fold: TRAIN; iteration: 184; epoch: 0; loss: 3.492806911468506; \n",
      "fold: TRAIN; iteration: 185; epoch: 0; loss: 3.4797279834747314; \n",
      "fold: TRAIN; iteration: 186; epoch: 0; loss: 3.250498056411743; \n",
      "fold: TRAIN; iteration: 187; epoch: 0; loss: 3.408121347427368; \n",
      "fold: TRAIN; iteration: 188; epoch: 0; loss: 3.55886173248291; \n",
      "fold: TRAIN; iteration: 189; epoch: 0; loss: 3.195962905883789; \n",
      "fold: TRAIN; iteration: 190; epoch: 0; loss: 3.1489336490631104; \n",
      "fold: TRAIN; iteration: 191; epoch: 0; loss: 3.358579635620117; \n",
      "fold: TRAIN; iteration: 192; epoch: 0; loss: 3.2808806896209717; \n",
      "fold: TRAIN; iteration: 193; epoch: 0; loss: 3.7336883544921875; \n",
      "fold: TRAIN; iteration: 194; epoch: 0; loss: 3.422701358795166; \n",
      "fold: TRAIN; iteration: 195; epoch: 0; loss: 3.395514726638794; \n",
      "fold: TRAIN; iteration: 196; epoch: 0; loss: 3.4912712574005127; \n",
      "fold: TRAIN; iteration: 197; epoch: 0; loss: 3.3250863552093506; \n",
      "fold: TRAIN; iteration: 198; epoch: 0; loss: 3.3540866374969482; \n",
      "fold: TRAIN; iteration: 199; epoch: 0; loss: 3.1147475242614746; \n",
      "fold: TRAIN; iteration: 200; epoch: 0; loss: 3.4029300212860107; \n",
      "fold: TRAIN; iteration: 201; epoch: 0; loss: 3.406467914581299; \n",
      "fold: TRAIN; iteration: 202; epoch: 0; loss: 3.4123826026916504; \n",
      "fold: TRAIN; iteration: 203; epoch: 0; loss: 3.6713857650756836; \n",
      "fold: TRAIN; iteration: 204; epoch: 0; loss: 3.0763063430786133; \n",
      "fold: TRAIN; iteration: 205; epoch: 0; loss: 3.392836332321167; \n",
      "fold: TRAIN; iteration: 206; epoch: 0; loss: 3.583984136581421; \n",
      "fold: TRAIN; iteration: 207; epoch: 0; loss: 3.333904504776001; \n",
      "fold: TRAIN; iteration: 208; epoch: 0; loss: 3.3013336658477783; \n",
      "fold: TRAIN; iteration: 209; epoch: 0; loss: 3.5215747356414795; \n",
      "fold: TRAIN; iteration: 210; epoch: 0; loss: 3.2404592037200928; \n",
      "fold: TRAIN; iteration: 211; epoch: 0; loss: 3.255436420440674; \n",
      "fold: TRAIN; iteration: 212; epoch: 0; loss: 3.2725019454956055; \n",
      "fold: TRAIN; iteration: 213; epoch: 0; loss: 3.3593060970306396; \n",
      "fold: TRAIN; iteration: 214; epoch: 0; loss: 3.6328423023223877; \n",
      "fold: TRAIN; iteration: 215; epoch: 0; loss: 3.2981879711151123; \n",
      "fold: TRAIN; iteration: 216; epoch: 0; loss: 3.5155608654022217; \n",
      "fold: TRAIN; iteration: 217; epoch: 0; loss: 3.1483547687530518; \n",
      "fold: TRAIN; iteration: 218; epoch: 0; loss: 3.045273780822754; \n",
      "fold: TRAIN; iteration: 219; epoch: 0; loss: 3.4656543731689453; \n",
      "fold: TRAIN; iteration: 220; epoch: 0; loss: 3.695491313934326; \n",
      "fold: TRAIN; iteration: 221; epoch: 0; loss: 3.2615106105804443; \n",
      "fold: TRAIN; iteration: 222; epoch: 0; loss: 3.508835792541504; \n",
      "fold: TRAIN; iteration: 223; epoch: 0; loss: 3.4295732975006104; \n",
      "fold: TRAIN; iteration: 224; epoch: 0; loss: 3.0853912830352783; \n",
      "fold: TRAIN; iteration: 225; epoch: 0; loss: 3.3468499183654785; \n",
      "fold: TRAIN; iteration: 226; epoch: 0; loss: 3.3289012908935547; \n",
      "fold: TRAIN; iteration: 227; epoch: 0; loss: 3.258671522140503; \n",
      "fold: TRAIN; iteration: 228; epoch: 0; loss: 3.2057623863220215; \n",
      "fold: TRAIN; iteration: 229; epoch: 0; loss: 3.2702019214630127; \n",
      "fold: TRAIN; iteration: 230; epoch: 0; loss: 3.5638184547424316; \n",
      "fold: TRAIN; iteration: 231; epoch: 0; loss: 3.1088924407958984; \n",
      "fold: TRAIN; iteration: 232; epoch: 0; loss: 3.0358920097351074; \n",
      "fold: TRAIN; iteration: 233; epoch: 0; loss: 3.048330783843994; \n",
      "fold: TRAIN; iteration: 234; epoch: 0; loss: 3.0823006629943848; \n",
      "fold: TRAIN; iteration: 235; epoch: 0; loss: 3.138690233230591; \n",
      "fold: TRAIN; iteration: 236; epoch: 0; loss: 3.1777849197387695; \n",
      "fold: TRAIN; iteration: 237; epoch: 0; loss: 3.469883680343628; \n",
      "fold: TRAIN; iteration: 238; epoch: 0; loss: 3.263773202896118; \n",
      "fold: TRAIN; iteration: 239; epoch: 0; loss: 3.0564796924591064; \n",
      "fold: TRAIN; iteration: 240; epoch: 0; loss: 3.1021413803100586; \n",
      "fold: TRAIN; iteration: 241; epoch: 0; loss: 3.1371145248413086; \n",
      "fold: TRAIN; iteration: 242; epoch: 0; loss: 3.386603593826294; \n",
      "fold: TRAIN; iteration: 243; epoch: 0; loss: 3.386960744857788; \n",
      "fold: TRAIN; iteration: 244; epoch: 0; loss: 3.2363228797912598; \n",
      "fold: TRAIN; iteration: 245; epoch: 0; loss: 3.2397420406341553; \n",
      "fold: TRAIN; iteration: 246; epoch: 0; loss: 3.2081432342529297; \n",
      "fold: TRAIN; iteration: 247; epoch: 0; loss: 3.1418206691741943; \n",
      "fold: TRAIN; iteration: 248; epoch: 0; loss: 3.4188013076782227; \n",
      "fold: TRAIN; iteration: 249; epoch: 0; loss: 3.026237726211548; \n",
      "fold: TRAIN; iteration: 250; epoch: 0; loss: 3.1278412342071533; \n",
      "fold: TRAIN; iteration: 251; epoch: 0; loss: 3.110719919204712; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 252; epoch: 0; loss: 3.3025548458099365; \n",
      "fold: TRAIN; iteration: 253; epoch: 0; loss: 3.535299062728882; \n",
      "fold: TRAIN; iteration: 254; epoch: 0; loss: 3.289707660675049; \n",
      "fold: TRAIN; iteration: 255; epoch: 0; loss: 3.169229745864868; \n",
      "fold: TRAIN; iteration: 256; epoch: 0; loss: 3.169198989868164; \n",
      "fold: TRAIN; iteration: 257; epoch: 0; loss: 3.2280631065368652; \n",
      "fold: TRAIN; iteration: 258; epoch: 0; loss: 3.478644609451294; \n",
      "fold: TRAIN; iteration: 259; epoch: 0; loss: 3.0874063968658447; \n",
      "fold: TRAIN; iteration: 260; epoch: 0; loss: 3.3499557971954346; \n",
      "fold: TRAIN; iteration: 261; epoch: 0; loss: 3.0331878662109375; \n",
      "fold: TRAIN; iteration: 262; epoch: 0; loss: 3.3936567306518555; \n",
      "fold: TRAIN; iteration: 263; epoch: 0; loss: 3.163952112197876; \n",
      "fold: TRAIN; iteration: 264; epoch: 0; loss: 3.4539365768432617; \n",
      "fold: TRAIN; iteration: 265; epoch: 0; loss: 3.309785842895508; \n",
      "fold: TRAIN; iteration: 266; epoch: 0; loss: 3.36650013923645; \n",
      "fold: TRAIN; iteration: 267; epoch: 0; loss: 2.8618059158325195; \n",
      "fold: TRAIN; iteration: 268; epoch: 0; loss: 2.9877712726593018; \n",
      "fold: TRAIN; iteration: 269; epoch: 0; loss: 3.112192153930664; \n",
      "fold: TRAIN; iteration: 270; epoch: 0; loss: 3.2944159507751465; \n",
      "fold: TRAIN; iteration: 271; epoch: 0; loss: 3.4614999294281006; \n",
      "fold: TRAIN; iteration: 272; epoch: 0; loss: 3.2636590003967285; \n",
      "fold: TRAIN; iteration: 273; epoch: 0; loss: 3.595339059829712; \n",
      "fold: TRAIN; iteration: 274; epoch: 0; loss: 3.3500630855560303; \n",
      "fold: TRAIN; iteration: 275; epoch: 0; loss: 3.242354154586792; \n",
      "fold: TRAIN; iteration: 276; epoch: 0; loss: 2.958685874938965; \n",
      "fold: TRAIN; iteration: 277; epoch: 0; loss: 3.0883560180664062; \n",
      "fold: TRAIN; iteration: 278; epoch: 0; loss: 3.1140737533569336; \n",
      "fold: TRAIN; iteration: 279; epoch: 0; loss: 3.1660280227661133; \n",
      "fold: TRAIN; iteration: 280; epoch: 0; loss: 3.089578151702881; \n",
      "fold: TRAIN; iteration: 281; epoch: 0; loss: 3.1045172214508057; \n",
      "fold: TRAIN; iteration: 282; epoch: 0; loss: 3.075601816177368; \n",
      "fold: TRAIN; iteration: 283; epoch: 0; loss: 3.382180690765381; \n",
      "fold: TRAIN; iteration: 284; epoch: 0; loss: 3.284579277038574; \n",
      "fold: TRAIN; iteration: 285; epoch: 0; loss: 3.143136501312256; \n",
      "fold: TRAIN; iteration: 286; epoch: 0; loss: 3.239067316055298; \n",
      "fold: TRAIN; iteration: 287; epoch: 0; loss: 3.2735390663146973; \n",
      "fold: TRAIN; iteration: 288; epoch: 0; loss: 3.0578932762145996; \n",
      "fold: TRAIN; iteration: 289; epoch: 0; loss: 3.1727983951568604; \n",
      "fold: TRAIN; iteration: 290; epoch: 0; loss: 3.1762313842773438; \n",
      "fold: TRAIN; iteration: 291; epoch: 0; loss: 2.9467270374298096; \n",
      "fold: TRAIN; iteration: 292; epoch: 0; loss: 3.041605234146118; \n",
      "fold: TRAIN; iteration: 293; epoch: 0; loss: 3.0707290172576904; \n",
      "fold: TRAIN; iteration: 294; epoch: 0; loss: 3.134747266769409; \n",
      "fold: TRAIN; iteration: 295; epoch: 0; loss: 2.9679903984069824; \n",
      "fold: TRAIN; iteration: 296; epoch: 0; loss: 3.267932176589966; \n",
      "fold: TRAIN; iteration: 297; epoch: 0; loss: 2.973182439804077; \n",
      "fold: TRAIN; iteration: 298; epoch: 0; loss: 3.0244107246398926; \n",
      "fold: TRAIN; iteration: 299; epoch: 0; loss: 3.1046741008758545; \n",
      "fold: TRAIN; iteration: 300; epoch: 0; loss: 3.2824769020080566; \n",
      "fold: TRAIN; iteration: 301; epoch: 0; loss: 3.1787893772125244; \n",
      "fold: TRAIN; iteration: 302; epoch: 0; loss: 3.5729455947875977; \n",
      "fold: TRAIN; iteration: 303; epoch: 0; loss: 3.0927536487579346; \n",
      "fold: TRAIN; iteration: 304; epoch: 0; loss: 3.139904499053955; \n",
      "fold: TRAIN; iteration: 305; epoch: 0; loss: 3.1767966747283936; \n",
      "fold: TRAIN; iteration: 306; epoch: 0; loss: 3.1017849445343018; \n",
      "fold: TRAIN; iteration: 307; epoch: 0; loss: 3.1879565715789795; \n",
      "fold: TRAIN; iteration: 308; epoch: 0; loss: 3.4529852867126465; \n",
      "fold: TRAIN; iteration: 309; epoch: 0; loss: 2.970893144607544; \n",
      "fold: TRAIN; iteration: 310; epoch: 0; loss: 3.183610439300537; \n",
      "fold: TRAIN; iteration: 311; epoch: 0; loss: 3.1520721912384033; \n",
      "fold: TRAIN; iteration: 312; epoch: 0; loss: 3.049558162689209; \n",
      "fold: TRAIN; iteration: 313; epoch: 0; loss: 2.9771454334259033; \n",
      "fold: TRAIN; iteration: 314; epoch: 0; loss: 3.176023483276367; \n",
      "fold: TRAIN; iteration: 315; epoch: 0; loss: 2.969179630279541; \n",
      "fold: TRAIN; iteration: 316; epoch: 0; loss: 2.9714910984039307; \n",
      "fold: TRAIN; iteration: 317; epoch: 0; loss: 3.0143442153930664; \n",
      "fold: TRAIN; iteration: 318; epoch: 0; loss: 3.021792411804199; \n",
      "fold: TRAIN; iteration: 319; epoch: 0; loss: 2.9952569007873535; \n",
      "fold: TRAIN; iteration: 320; epoch: 0; loss: 3.117124557495117; \n",
      "fold: TRAIN; iteration: 321; epoch: 0; loss: 3.03178071975708; \n",
      "fold: TRAIN; iteration: 322; epoch: 0; loss: 3.2907238006591797; \n",
      "fold: TRAIN; iteration: 323; epoch: 0; loss: 3.18552827835083; \n",
      "fold: TRAIN; iteration: 324; epoch: 0; loss: 3.260120153427124; \n",
      "fold: TRAIN; iteration: 325; epoch: 0; loss: 3.2933928966522217; \n",
      "fold: TRAIN; iteration: 326; epoch: 0; loss: 2.950054407119751; \n",
      "fold: TRAIN; iteration: 327; epoch: 0; loss: 3.0043082237243652; \n",
      "fold: TRAIN; iteration: 328; epoch: 0; loss: 3.152083158493042; \n",
      "fold: TRAIN; iteration: 329; epoch: 0; loss: 3.1110074520111084; \n",
      "fold: TRAIN; iteration: 330; epoch: 0; loss: 2.9992153644561768; \n",
      "fold: TRAIN; iteration: 331; epoch: 0; loss: 3.331404447555542; \n",
      "fold: TRAIN; iteration: 332; epoch: 0; loss: 3.0406932830810547; \n",
      "fold: TRAIN; iteration: 333; epoch: 0; loss: 2.999629020690918; \n",
      "fold: TRAIN; iteration: 334; epoch: 0; loss: 2.999025344848633; \n",
      "fold: TRAIN; iteration: 335; epoch: 0; loss: 2.984625816345215; \n",
      "fold: TRAIN; iteration: 336; epoch: 0; loss: 3.1496224403381348; \n",
      "fold: TRAIN; iteration: 337; epoch: 0; loss: 3.0794386863708496; \n",
      "fold: TRAIN; iteration: 338; epoch: 0; loss: 3.2601757049560547; \n",
      "fold: TRAIN; iteration: 339; epoch: 0; loss: 2.889033794403076; \n",
      "fold: TRAIN; iteration: 340; epoch: 0; loss: 3.0241527557373047; \n",
      "fold: TRAIN; iteration: 341; epoch: 0; loss: 2.6621930599212646; \n",
      "fold: TRAIN; iteration: 342; epoch: 0; loss: 3.345130681991577; \n",
      "fold: TRAIN; iteration: 343; epoch: 0; loss: 3.0384464263916016; \n",
      "fold: TRAIN; iteration: 344; epoch: 0; loss: 2.987353801727295; \n",
      "fold: TRAIN; iteration: 345; epoch: 0; loss: 3.123507022857666; \n",
      "fold: TRAIN; iteration: 346; epoch: 0; loss: 3.1209139823913574; \n",
      "fold: TRAIN; iteration: 347; epoch: 0; loss: 2.996480703353882; \n",
      "fold: TRAIN; iteration: 348; epoch: 0; loss: 3.240313768386841; \n",
      "fold: TRAIN; iteration: 349; epoch: 0; loss: 3.2115721702575684; \n",
      "fold: TRAIN; iteration: 350; epoch: 0; loss: 3.291577100753784; \n",
      "fold: TRAIN; iteration: 351; epoch: 0; loss: 3.0328283309936523; \n",
      "fold: TRAIN; iteration: 352; epoch: 0; loss: 3.2710886001586914; \n",
      "fold: TRAIN; iteration: 353; epoch: 0; loss: 3.200105667114258; \n",
      "fold: TRAIN; iteration: 354; epoch: 0; loss: 2.6653738021850586; \n",
      "fold: TRAIN; iteration: 355; epoch: 0; loss: 2.957247257232666; \n",
      "fold: TRAIN; iteration: 356; epoch: 0; loss: 2.987295627593994; \n",
      "fold: TRAIN; iteration: 357; epoch: 0; loss: 3.2229268550872803; \n",
      "fold: TRAIN; iteration: 358; epoch: 0; loss: 2.985217809677124; \n",
      "fold: TRAIN; iteration: 359; epoch: 0; loss: 2.9857141971588135; \n",
      "fold: TRAIN; iteration: 360; epoch: 0; loss: 3.030320167541504; \n",
      "fold: TRAIN; iteration: 361; epoch: 0; loss: 3.207733392715454; \n",
      "fold: TRAIN; iteration: 362; epoch: 0; loss: 3.162870168685913; \n",
      "fold: TRAIN; iteration: 363; epoch: 0; loss: 3.204557180404663; \n",
      "fold: TRAIN; iteration: 364; epoch: 0; loss: 3.114304304122925; \n",
      "fold: TRAIN; iteration: 365; epoch: 0; loss: 3.145496129989624; \n",
      "fold: TRAIN; iteration: 366; epoch: 0; loss: 3.290928363800049; \n",
      "fold: TRAIN; iteration: 367; epoch: 0; loss: 3.077003240585327; \n",
      "fold: TRAIN; iteration: 368; epoch: 0; loss: 3.0428009033203125; \n",
      "fold: TRAIN; iteration: 369; epoch: 0; loss: 3.1231887340545654; \n",
      "fold: TRAIN; iteration: 370; epoch: 0; loss: 2.9294300079345703; \n",
      "fold: TRAIN; iteration: 371; epoch: 0; loss: 2.656351327896118; \n",
      "fold: TRAIN; iteration: 372; epoch: 0; loss: 2.908705234527588; \n",
      "fold: TRAIN; iteration: 373; epoch: 0; loss: 2.922724962234497; \n",
      "fold: TRAIN; iteration: 374; epoch: 0; loss: 3.0040371417999268; \n",
      "fold: TRAIN; iteration: 375; epoch: 0; loss: 3.091740608215332; \n",
      "fold: TRAIN; iteration: 376; epoch: 0; loss: 2.749598979949951; \n",
      "fold: TRAIN; iteration: 377; epoch: 0; loss: 2.8807942867279053; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 378; epoch: 0; loss: 2.9617910385131836; \n",
      "fold: TRAIN; iteration: 379; epoch: 0; loss: 3.3599393367767334; \n",
      "fold: TRAIN; iteration: 380; epoch: 0; loss: 3.192246437072754; \n",
      "fold: TRAIN; iteration: 381; epoch: 0; loss: 3.0519165992736816; \n",
      "fold: TRAIN; iteration: 382; epoch: 0; loss: 3.0035552978515625; \n",
      "fold: TRAIN; iteration: 383; epoch: 0; loss: 3.407025098800659; \n",
      "fold: TRAIN; iteration: 384; epoch: 0; loss: 2.8631045818328857; \n",
      "fold: TRAIN; iteration: 385; epoch: 0; loss: 3.192976951599121; \n",
      "fold: TRAIN; iteration: 386; epoch: 0; loss: 3.0421454906463623; \n",
      "fold: TRAIN; iteration: 387; epoch: 0; loss: 3.187725782394409; \n",
      "fold: TRAIN; iteration: 388; epoch: 0; loss: 3.026165246963501; \n",
      "fold: TRAIN; iteration: 389; epoch: 0; loss: 2.954634428024292; \n",
      "fold: TRAIN; iteration: 390; epoch: 0; loss: 3.0811407566070557; \n",
      "fold: TRAIN; iteration: 391; epoch: 0; loss: 2.926492214202881; \n",
      "fold: TRAIN; iteration: 392; epoch: 0; loss: 2.8851635456085205; \n",
      "fold: TRAIN; iteration: 393; epoch: 0; loss: 3.1618947982788086; \n",
      "fold: TRAIN; iteration: 394; epoch: 0; loss: 3.1420865058898926; \n",
      "fold: TRAIN; iteration: 395; epoch: 0; loss: 3.048318386077881; \n",
      "fold: TRAIN; iteration: 396; epoch: 0; loss: 2.9260036945343018; \n",
      "fold: TRAIN; iteration: 397; epoch: 0; loss: 3.2609097957611084; \n",
      "fold: TRAIN; iteration: 398; epoch: 0; loss: 3.1718125343322754; \n",
      "fold: TRAIN; iteration: 399; epoch: 0; loss: 2.980458974838257; \n",
      "fold: TRAIN; iteration: 400; epoch: 0; loss: 3.248028039932251; \n",
      "fold: TRAIN; iteration: 401; epoch: 0; loss: 2.9906580448150635; \n",
      "fold: TRAIN; iteration: 402; epoch: 0; loss: 2.8951380252838135; \n",
      "fold: TRAIN; iteration: 403; epoch: 0; loss: 3.1282575130462646; \n",
      "fold: TRAIN; iteration: 404; epoch: 0; loss: 2.750626564025879; \n",
      "fold: TRAIN; iteration: 405; epoch: 0; loss: 2.887253999710083; \n",
      "fold: TRAIN; iteration: 406; epoch: 0; loss: 2.802579879760742; \n",
      "fold: TRAIN; iteration: 407; epoch: 0; loss: 2.803961992263794; \n",
      "fold: TRAIN; iteration: 408; epoch: 0; loss: 2.878387689590454; \n",
      "fold: TRAIN; iteration: 409; epoch: 0; loss: 2.7408127784729004; \n",
      "fold: TRAIN; iteration: 410; epoch: 0; loss: 3.0997345447540283; \n",
      "fold: TRAIN; iteration: 411; epoch: 0; loss: 2.911766767501831; \n",
      "fold: TRAIN; iteration: 412; epoch: 0; loss: 2.9773385524749756; \n",
      "fold: TRAIN; iteration: 413; epoch: 0; loss: 3.020796298980713; \n",
      "fold: TRAIN; iteration: 414; epoch: 0; loss: 3.0575287342071533; \n",
      "fold: TRAIN; iteration: 415; epoch: 0; loss: 2.855576276779175; \n",
      "fold: TRAIN; iteration: 416; epoch: 0; loss: 3.0471935272216797; \n",
      "fold: TRAIN; iteration: 417; epoch: 0; loss: 2.8683414459228516; \n",
      "fold: TRAIN; iteration: 418; epoch: 0; loss: 2.981510877609253; \n",
      "fold: TRAIN; iteration: 419; epoch: 0; loss: 2.9789137840270996; \n",
      "fold: TRAIN; iteration: 420; epoch: 0; loss: 2.94477915763855; \n",
      "fold: TRAIN; iteration: 421; epoch: 0; loss: 2.9124679565429688; \n",
      "fold: TRAIN; iteration: 422; epoch: 0; loss: 2.9992141723632812; \n",
      "fold: TRAIN; iteration: 423; epoch: 0; loss: 3.1814980506896973; \n",
      "fold: TRAIN; iteration: 424; epoch: 0; loss: 2.9409966468811035; \n",
      "fold: TRAIN; iteration: 425; epoch: 0; loss: 2.940403699874878; \n",
      "fold: TRAIN; iteration: 426; epoch: 0; loss: 2.823882818222046; \n",
      "fold: TRAIN; iteration: 427; epoch: 0; loss: 2.9408962726593018; \n",
      "fold: TRAIN; iteration: 428; epoch: 0; loss: 2.988441228866577; \n",
      "fold: TRAIN; iteration: 429; epoch: 0; loss: 3.1144301891326904; \n",
      "fold: TRAIN; iteration: 430; epoch: 0; loss: 2.8320398330688477; \n",
      "fold: TRAIN; iteration: 431; epoch: 0; loss: 2.866450786590576; \n",
      "fold: TRAIN; iteration: 432; epoch: 0; loss: 3.075026035308838; \n",
      "fold: TRAIN; iteration: 433; epoch: 0; loss: 3.055495262145996; \n",
      "fold: TRAIN; iteration: 434; epoch: 0; loss: 3.022711753845215; \n",
      "fold: TRAIN; iteration: 435; epoch: 0; loss: 2.9101812839508057; \n",
      "fold: TRAIN; iteration: 436; epoch: 0; loss: 3.0546562671661377; \n",
      "fold: TRAIN; iteration: 437; epoch: 0; loss: 2.9209463596343994; \n",
      "fold: TRAIN; iteration: 438; epoch: 0; loss: 3.0502426624298096; \n",
      "fold: TRAIN; iteration: 439; epoch: 0; loss: 3.1587796211242676; \n",
      "fold: TRAIN; iteration: 440; epoch: 0; loss: 3.0214171409606934; \n",
      "fold: TRAIN; iteration: 441; epoch: 0; loss: 3.0881640911102295; \n",
      "fold: TRAIN; iteration: 442; epoch: 0; loss: 2.9830987453460693; \n",
      "fold: TRAIN; iteration: 443; epoch: 0; loss: 3.0740597248077393; \n",
      "fold: TRAIN; iteration: 444; epoch: 0; loss: 2.8764123916625977; \n",
      "fold: TRAIN; iteration: 445; epoch: 0; loss: 2.810213088989258; \n",
      "fold: TRAIN; iteration: 446; epoch: 0; loss: 3.1693451404571533; \n",
      "fold: TRAIN; iteration: 447; epoch: 0; loss: 2.6946260929107666; \n",
      "fold: TRAIN; iteration: 448; epoch: 0; loss: 2.857151508331299; \n",
      "fold: TRAIN; iteration: 449; epoch: 0; loss: 3.005307674407959; \n",
      "fold: TRAIN; iteration: 450; epoch: 0; loss: 2.7633185386657715; \n",
      "fold: TRAIN; iteration: 451; epoch: 0; loss: 2.9270944595336914; \n",
      "fold: TRAIN; iteration: 452; epoch: 0; loss: 2.960477828979492; \n",
      "fold: TRAIN; iteration: 453; epoch: 0; loss: 2.775965690612793; \n",
      "fold: TRAIN; iteration: 454; epoch: 0; loss: 2.8711130619049072; \n",
      "fold: TRAIN; iteration: 455; epoch: 0; loss: 2.85819149017334; \n",
      "fold: TRAIN; iteration: 456; epoch: 0; loss: 2.9520790576934814; \n",
      "fold: TRAIN; iteration: 457; epoch: 0; loss: 2.9307079315185547; \n",
      "fold: TRAIN; iteration: 458; epoch: 0; loss: 2.740816354751587; \n",
      "fold: TRAIN; iteration: 459; epoch: 0; loss: 2.8982315063476562; \n",
      "fold: TRAIN; iteration: 460; epoch: 0; loss: 3.050835609436035; \n",
      "fold: TRAIN; iteration: 461; epoch: 0; loss: 2.7904584407806396; \n",
      "fold: TRAIN; iteration: 462; epoch: 0; loss: 2.74990177154541; \n",
      "fold: TRAIN; iteration: 463; epoch: 0; loss: 2.8537633419036865; \n",
      "fold: TRAIN; iteration: 464; epoch: 0; loss: 3.090743064880371; \n",
      "fold: TRAIN; iteration: 465; epoch: 0; loss: 2.8355677127838135; \n",
      "fold: TRAIN; iteration: 466; epoch: 0; loss: 2.4388821125030518; \n",
      "fold: TRAIN; iteration: 467; epoch: 0; loss: 3.101309299468994; \n",
      "fold: TRAIN; iteration: 468; epoch: 0; loss: 3.0006484985351562; \n",
      "fold: TRAIN; iteration: 469; epoch: 0; loss: 2.953411817550659; \n",
      "fold: TRAIN; iteration: 470; epoch: 0; loss: 3.1003429889678955; \n",
      "fold: TRAIN; iteration: 471; epoch: 0; loss: 2.7678287029266357; \n",
      "fold: TRAIN; iteration: 472; epoch: 0; loss: 2.744582176208496; \n",
      "fold: TRAIN; iteration: 473; epoch: 0; loss: 2.7280755043029785; \n",
      "fold: TRAIN; iteration: 474; epoch: 0; loss: 2.8051321506500244; \n",
      "fold: TRAIN; iteration: 475; epoch: 0; loss: 2.8871870040893555; \n",
      "fold: TRAIN; iteration: 476; epoch: 0; loss: 2.698543071746826; \n",
      "fold: TRAIN; iteration: 477; epoch: 0; loss: 2.802990674972534; \n",
      "fold: TRAIN; iteration: 478; epoch: 0; loss: 2.810572862625122; \n",
      "fold: TRAIN; iteration: 479; epoch: 0; loss: 2.8700079917907715; \n",
      "fold: TRAIN; iteration: 480; epoch: 0; loss: 2.987287998199463; \n",
      "fold: TRAIN; iteration: 481; epoch: 0; loss: 2.976418972015381; \n",
      "fold: TRAIN; iteration: 482; epoch: 0; loss: 3.0024595260620117; \n",
      "fold: TRAIN; iteration: 483; epoch: 0; loss: 2.934731960296631; \n",
      "fold: TRAIN; iteration: 484; epoch: 0; loss: 2.8850903511047363; \n",
      "fold: TRAIN; iteration: 485; epoch: 0; loss: 2.8647501468658447; \n",
      "fold: TRAIN; iteration: 486; epoch: 0; loss: 2.963709831237793; \n",
      "fold: TRAIN; iteration: 487; epoch: 0; loss: 3.1256167888641357; \n",
      "fold: TRAIN; iteration: 488; epoch: 0; loss: 2.7137603759765625; \n",
      "fold: TRAIN; iteration: 489; epoch: 0; loss: 2.919045925140381; \n",
      "fold: TRAIN; iteration: 490; epoch: 0; loss: 3.0113959312438965; \n",
      "fold: TRAIN; iteration: 491; epoch: 0; loss: 2.9202163219451904; \n",
      "fold: TRAIN; iteration: 492; epoch: 0; loss: 2.8722925186157227; \n",
      "fold: TRAIN; iteration: 493; epoch: 0; loss: 2.8646633625030518; \n",
      "fold: TRAIN; iteration: 494; epoch: 0; loss: 2.782219648361206; \n",
      "fold: TRAIN; iteration: 495; epoch: 0; loss: 2.795400381088257; \n",
      "fold: TRAIN; iteration: 496; epoch: 0; loss: 3.0030181407928467; \n",
      "fold: TRAIN; iteration: 497; epoch: 0; loss: 2.8328402042388916; \n",
      "fold: TRAIN; iteration: 498; epoch: 0; loss: 2.704064130783081; \n",
      "fold: TRAIN; iteration: 499; epoch: 0; loss: 2.991032123565674; \n",
      "fold: TRAIN; iteration: 500; epoch: 0; loss: 2.930567979812622; \n",
      "fold: TRAIN; iteration: 501; epoch: 0; loss: 3.0762317180633545; \n",
      "fold: TRAIN; iteration: 502; epoch: 0; loss: 2.822732925415039; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 503; epoch: 0; loss: 2.9005985260009766; \n",
      "fold: TRAIN; iteration: 504; epoch: 0; loss: 2.792280912399292; \n",
      "fold: TRAIN; iteration: 505; epoch: 0; loss: 2.7791597843170166; \n",
      "fold: TRAIN; iteration: 506; epoch: 0; loss: 3.109731674194336; \n",
      "fold: TRAIN; iteration: 507; epoch: 0; loss: 2.72694730758667; \n",
      "fold: TRAIN; iteration: 508; epoch: 0; loss: 2.8179495334625244; \n",
      "fold: TRAIN; iteration: 509; epoch: 0; loss: 2.9594364166259766; \n",
      "fold: TRAIN; iteration: 510; epoch: 0; loss: 2.9932236671447754; \n",
      "fold: TRAIN; iteration: 511; epoch: 0; loss: 3.022176742553711; \n",
      "fold: TRAIN; iteration: 512; epoch: 0; loss: 3.0908923149108887; \n",
      "fold: TRAIN; iteration: 513; epoch: 0; loss: 2.791015863418579; \n",
      "fold: TRAIN; iteration: 514; epoch: 0; loss: 2.4571845531463623; \n",
      "fold: TRAIN; iteration: 515; epoch: 0; loss: 2.690831184387207; \n",
      "fold: TRAIN; iteration: 516; epoch: 0; loss: 3.0511081218719482; \n",
      "fold: TRAIN; iteration: 517; epoch: 0; loss: 3.0473947525024414; \n",
      "fold: TRAIN; iteration: 518; epoch: 0; loss: 2.8468642234802246; \n",
      "fold: TRAIN; iteration: 519; epoch: 0; loss: 3.1171112060546875; \n",
      "fold: TRAIN; iteration: 520; epoch: 0; loss: 2.8445611000061035; \n",
      "fold: TRAIN; iteration: 521; epoch: 0; loss: 2.636645555496216; \n",
      "fold: TRAIN; iteration: 522; epoch: 0; loss: 3.1085431575775146; \n",
      "fold: TRAIN; iteration: 523; epoch: 0; loss: 2.671221971511841; \n",
      "fold: TRAIN; iteration: 524; epoch: 0; loss: 3.151890516281128; \n",
      "fold: TRAIN; iteration: 525; epoch: 0; loss: 2.8282275199890137; \n",
      "fold: TRAIN; iteration: 526; epoch: 0; loss: 2.7504098415374756; \n",
      "fold: TRAIN; iteration: 527; epoch: 0; loss: 3.0615346431732178; \n",
      "fold: TRAIN; iteration: 528; epoch: 0; loss: 2.977583885192871; \n",
      "fold: TRAIN; iteration: 529; epoch: 0; loss: 3.0220885276794434; \n",
      "fold: TRAIN; iteration: 530; epoch: 0; loss: 2.507452964782715; \n",
      "fold: TRAIN; iteration: 531; epoch: 0; loss: 2.875429153442383; \n",
      "fold: TRAIN; iteration: 532; epoch: 0; loss: 2.8646087646484375; \n",
      "fold: TRAIN; iteration: 533; epoch: 0; loss: 2.7998878955841064; \n",
      "fold: TRAIN; iteration: 534; epoch: 0; loss: 2.9141767024993896; \n",
      "fold: TRAIN; iteration: 535; epoch: 0; loss: 3.078590154647827; \n",
      "fold: TRAIN; iteration: 536; epoch: 0; loss: 2.9753551483154297; \n",
      "fold: TRAIN; iteration: 537; epoch: 0; loss: 2.9425835609436035; \n",
      "fold: TRAIN; iteration: 538; epoch: 0; loss: 2.868607759475708; \n",
      "fold: TRAIN; iteration: 539; epoch: 0; loss: 2.9288437366485596; \n",
      "fold: TRAIN; iteration: 540; epoch: 0; loss: 2.9170491695404053; \n",
      "fold: TRAIN; iteration: 541; epoch: 0; loss: 2.908219814300537; \n",
      "fold: TRAIN; iteration: 542; epoch: 0; loss: 3.004171371459961; \n",
      "fold: TRAIN; iteration: 543; epoch: 0; loss: 2.972569465637207; \n",
      "fold: TRAIN; iteration: 544; epoch: 0; loss: 2.8715198040008545; \n",
      "fold: TRAIN; iteration: 545; epoch: 0; loss: 3.0662293434143066; \n",
      "fold: TRAIN; iteration: 546; epoch: 0; loss: 3.0036752223968506; \n",
      "fold: TRAIN; iteration: 547; epoch: 0; loss: 2.934185743331909; \n",
      "fold: TRAIN; iteration: 548; epoch: 0; loss: 2.9610109329223633; \n",
      "fold: TRAIN; iteration: 549; epoch: 0; loss: 2.6657111644744873; \n",
      "fold: TRAIN; iteration: 550; epoch: 0; loss: 2.8553662300109863; \n",
      "fold: TRAIN; iteration: 551; epoch: 0; loss: 2.799487590789795; \n",
      "fold: TRAIN; iteration: 552; epoch: 0; loss: 2.7624011039733887; \n",
      "fold: TRAIN; iteration: 553; epoch: 0; loss: 2.6318416595458984; \n",
      "fold: TRAIN; iteration: 554; epoch: 0; loss: 2.723593235015869; \n",
      "fold: TRAIN; iteration: 555; epoch: 0; loss: 2.97233510017395; \n",
      "fold: TRAIN; iteration: 556; epoch: 0; loss: 2.7331042289733887; \n",
      "fold: TRAIN; iteration: 557; epoch: 0; loss: 2.775960683822632; \n",
      "fold: TRAIN; iteration: 558; epoch: 0; loss: 2.770638942718506; \n",
      "fold: TRAIN; iteration: 559; epoch: 0; loss: 2.7173094749450684; \n",
      "fold: TRAIN; iteration: 560; epoch: 0; loss: 2.7748284339904785; \n",
      "fold: TRAIN; iteration: 561; epoch: 0; loss: 2.8260130882263184; \n",
      "fold: TRAIN; iteration: 562; epoch: 0; loss: 2.8786730766296387; \n",
      "fold: TRAIN; iteration: 563; epoch: 0; loss: 2.865812063217163; \n",
      "fold: TRAIN; iteration: 564; epoch: 0; loss: 2.808688163757324; \n",
      "fold: TRAIN; iteration: 565; epoch: 0; loss: 2.855173110961914; \n",
      "fold: TRAIN; iteration: 566; epoch: 0; loss: 2.8833818435668945; \n",
      "fold: TRAIN; iteration: 567; epoch: 0; loss: 2.811038017272949; \n",
      "fold: TRAIN; iteration: 568; epoch: 0; loss: 2.7483911514282227; \n",
      "fold: TRAIN; iteration: 569; epoch: 0; loss: 2.6578433513641357; \n",
      "fold: TRAIN; iteration: 570; epoch: 0; loss: 3.008643865585327; \n",
      "fold: TRAIN; iteration: 571; epoch: 0; loss: 2.726424217224121; \n",
      "fold: TRAIN; iteration: 572; epoch: 0; loss: 2.717381000518799; \n",
      "fold: TRAIN; iteration: 573; epoch: 0; loss: 2.8686623573303223; \n",
      "fold: TRAIN; iteration: 574; epoch: 0; loss: 2.8056516647338867; \n",
      "fold: TRAIN; iteration: 575; epoch: 0; loss: 3.2352511882781982; \n",
      "fold: TRAIN; iteration: 576; epoch: 0; loss: 3.0642969608306885; \n",
      "fold: TRAIN; iteration: 577; epoch: 0; loss: 2.8620903491973877; \n",
      "fold: TRAIN; iteration: 578; epoch: 0; loss: 2.7717971801757812; \n",
      "fold: TRAIN; iteration: 579; epoch: 0; loss: 3.2307233810424805; \n",
      "fold: TRAIN; iteration: 580; epoch: 0; loss: 2.6291887760162354; \n",
      "fold: TRAIN; iteration: 581; epoch: 0; loss: 2.709104537963867; \n",
      "fold: TRAIN; iteration: 582; epoch: 0; loss: 3.1640145778656006; \n",
      "fold: TRAIN; iteration: 583; epoch: 0; loss: 2.9266481399536133; \n",
      "fold: TRAIN; iteration: 584; epoch: 0; loss: 3.138010263442993; \n",
      "fold: TRAIN; iteration: 585; epoch: 0; loss: 2.9583497047424316; \n",
      "fold: TRAIN; iteration: 586; epoch: 0; loss: 2.7581615447998047; \n",
      "fold: TRAIN; iteration: 587; epoch: 0; loss: 2.7518346309661865; \n",
      "fold: TRAIN; iteration: 588; epoch: 0; loss: 2.8355941772460938; \n",
      "fold: TRAIN; iteration: 589; epoch: 0; loss: 2.7541894912719727; \n",
      "fold: TRAIN; iteration: 590; epoch: 0; loss: 2.626969575881958; \n",
      "fold: TRAIN; iteration: 591; epoch: 0; loss: 2.789259910583496; \n",
      "fold: TRAIN; iteration: 592; epoch: 0; loss: 2.898104667663574; \n",
      "fold: TRAIN; iteration: 593; epoch: 0; loss: 2.7824645042419434; \n",
      "fold: TRAIN; iteration: 594; epoch: 0; loss: 2.948838233947754; \n",
      "fold: TRAIN; iteration: 595; epoch: 0; loss: 2.857983350753784; \n",
      "fold: TRAIN; iteration: 596; epoch: 0; loss: 2.8583312034606934; \n",
      "fold: TRAIN; iteration: 597; epoch: 0; loss: 3.0028412342071533; \n",
      "fold: TRAIN; iteration: 598; epoch: 0; loss: 3.0702264308929443; \n",
      "fold: TRAIN; iteration: 599; epoch: 0; loss: 2.6042261123657227; \n",
      "fold: TRAIN; iteration: 600; epoch: 0; loss: 2.8129355907440186; \n",
      "fold: TRAIN; iteration: 601; epoch: 0; loss: 2.745619773864746; \n",
      "fold: TRAIN; iteration: 602; epoch: 0; loss: 2.728710889816284; \n",
      "fold: TRAIN; iteration: 603; epoch: 0; loss: 2.6454946994781494; \n",
      "fold: TRAIN; iteration: 604; epoch: 0; loss: 2.817203998565674; \n",
      "fold: TRAIN; iteration: 605; epoch: 0; loss: 2.9191832542419434; \n",
      "fold: TRAIN; iteration: 606; epoch: 0; loss: 3.1086313724517822; \n",
      "fold: TRAIN; iteration: 607; epoch: 0; loss: 3.102593183517456; \n",
      "fold: TRAIN; iteration: 608; epoch: 0; loss: 2.69423770904541; \n",
      "fold: TRAIN; iteration: 609; epoch: 0; loss: 2.7373976707458496; \n",
      "fold: TRAIN; iteration: 610; epoch: 0; loss: 3.0659308433532715; \n",
      "fold: TRAIN; iteration: 611; epoch: 0; loss: 3.019984245300293; \n",
      "fold: TRAIN; iteration: 612; epoch: 0; loss: 2.7964730262756348; \n",
      "fold: TRAIN; iteration: 613; epoch: 0; loss: 2.552481174468994; \n",
      "fold: TRAIN; iteration: 614; epoch: 0; loss: 2.7192461490631104; \n",
      "fold: TRAIN; iteration: 615; epoch: 0; loss: 2.7807135581970215; \n",
      "fold: TRAIN; iteration: 616; epoch: 0; loss: 2.6248745918273926; \n",
      "fold: TRAIN; iteration: 617; epoch: 0; loss: 3.107696533203125; \n",
      "fold: TRAIN; iteration: 618; epoch: 0; loss: 2.9115991592407227; \n",
      "fold: TRAIN; iteration: 619; epoch: 0; loss: 2.7137818336486816; \n",
      "fold: TRAIN; iteration: 620; epoch: 0; loss: 2.9578163623809814; \n",
      "fold: TRAIN; iteration: 621; epoch: 0; loss: 3.0173885822296143; \n",
      "fold: TRAIN; iteration: 622; epoch: 0; loss: 2.867344379425049; \n",
      "fold: TRAIN; iteration: 623; epoch: 0; loss: 2.830045223236084; \n",
      "fold: TRAIN; iteration: 624; epoch: 0; loss: 2.577939033508301; \n",
      "fold: TRAIN; iteration: 625; epoch: 0; loss: 2.715745449066162; \n",
      "fold: TRAIN; iteration: 626; epoch: 0; loss: 2.7091569900512695; \n",
      "fold: TRAIN; iteration: 627; epoch: 0; loss: 2.7316248416900635; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 628; epoch: 0; loss: 2.8850176334381104; \n",
      "fold: TRAIN; iteration: 629; epoch: 0; loss: 2.538836717605591; \n",
      "fold: TRAIN; iteration: 630; epoch: 0; loss: 2.8520495891571045; \n",
      "fold: TRAIN; iteration: 631; epoch: 0; loss: 2.7184340953826904; \n",
      "fold: TRAIN; iteration: 632; epoch: 0; loss: 2.6422183513641357; \n",
      "fold: TRAIN; iteration: 633; epoch: 0; loss: 2.8021395206451416; \n",
      "fold: TRAIN; iteration: 634; epoch: 0; loss: 2.8662140369415283; \n",
      "fold: TRAIN; iteration: 635; epoch: 0; loss: 2.8247854709625244; \n",
      "fold: TRAIN; iteration: 636; epoch: 0; loss: 2.7300586700439453; \n",
      "fold: TRAIN; iteration: 637; epoch: 0; loss: 2.8297805786132812; \n",
      "fold: TRAIN; iteration: 638; epoch: 0; loss: 3.039525032043457; \n",
      "fold: TRAIN; iteration: 639; epoch: 0; loss: 2.8390111923217773; \n",
      "fold: TRAIN; iteration: 640; epoch: 0; loss: 2.8150501251220703; \n",
      "fold: TRAIN; iteration: 641; epoch: 0; loss: 2.850726842880249; \n",
      "fold: TRAIN; iteration: 642; epoch: 0; loss: 2.741708993911743; \n",
      "fold: TRAIN; iteration: 643; epoch: 0; loss: 2.477132558822632; \n",
      "fold: TRAIN; iteration: 644; epoch: 0; loss: 2.676833391189575; \n",
      "fold: TRAIN; iteration: 645; epoch: 0; loss: 2.5825514793395996; \n",
      "fold: TRAIN; iteration: 646; epoch: 0; loss: 2.833803653717041; \n",
      "fold: TRAIN; iteration: 647; epoch: 0; loss: 2.7886857986450195; \n",
      "fold: TRAIN; iteration: 648; epoch: 0; loss: 2.670051336288452; \n",
      "fold: TRAIN; iteration: 649; epoch: 0; loss: 2.7185752391815186; \n",
      "fold: TRAIN; iteration: 650; epoch: 0; loss: 2.7877864837646484; \n",
      "fold: TRAIN; iteration: 651; epoch: 0; loss: 2.8652853965759277; \n",
      "fold: TRAIN; iteration: 652; epoch: 0; loss: 2.7110652923583984; \n",
      "fold: TRAIN; iteration: 653; epoch: 0; loss: 2.6343472003936768; \n",
      "fold: TRAIN; iteration: 654; epoch: 0; loss: 2.947169542312622; \n",
      "fold: TRAIN; iteration: 655; epoch: 0; loss: 2.8633980751037598; \n",
      "fold: TRAIN; iteration: 656; epoch: 0; loss: 2.9624526500701904; \n",
      "fold: TRAIN; iteration: 657; epoch: 0; loss: 3.035273551940918; \n",
      "fold: TRAIN; iteration: 658; epoch: 0; loss: 2.913848638534546; \n",
      "fold: TRAIN; iteration: 659; epoch: 0; loss: 2.904496669769287; \n",
      "fold: TRAIN; iteration: 660; epoch: 0; loss: 2.8361434936523438; \n",
      "fold: TRAIN; iteration: 661; epoch: 0; loss: 2.729444980621338; \n",
      "fold: TRAIN; iteration: 662; epoch: 0; loss: 2.6766912937164307; \n",
      "fold: TRAIN; iteration: 663; epoch: 0; loss: 2.960658073425293; \n",
      "fold: TRAIN; iteration: 664; epoch: 0; loss: 2.677699327468872; \n",
      "fold: TRAIN; iteration: 665; epoch: 0; loss: 2.927041530609131; \n",
      "fold: TRAIN; iteration: 666; epoch: 0; loss: 2.861499547958374; \n",
      "fold: TRAIN; iteration: 667; epoch: 0; loss: 2.874244451522827; \n",
      "fold: TRAIN; iteration: 668; epoch: 0; loss: 2.6039011478424072; \n",
      "fold: TRAIN; iteration: 669; epoch: 0; loss: 3.0307297706604004; \n",
      "fold: TRAIN; iteration: 670; epoch: 0; loss: 2.9215686321258545; \n",
      "fold: TRAIN; iteration: 671; epoch: 0; loss: 2.6915860176086426; \n",
      "fold: TRAIN; iteration: 672; epoch: 0; loss: 2.789454460144043; \n",
      "fold: TRAIN; iteration: 673; epoch: 0; loss: 2.925640821456909; \n",
      "fold: TRAIN; iteration: 674; epoch: 0; loss: 2.7674643993377686; \n",
      "fold: TRAIN; iteration: 675; epoch: 0; loss: 3.0605697631835938; \n",
      "fold: TRAIN; iteration: 676; epoch: 0; loss: 2.8281326293945312; \n",
      "fold: TRAIN; iteration: 677; epoch: 0; loss: 2.9670333862304688; \n",
      "fold: TRAIN; iteration: 678; epoch: 0; loss: 2.5543911457061768; \n",
      "fold: TRAIN; iteration: 679; epoch: 0; loss: 2.811373233795166; \n",
      "fold: TRAIN; iteration: 680; epoch: 0; loss: 2.518404960632324; \n",
      "fold: TRAIN; iteration: 681; epoch: 0; loss: 2.7362046241760254; \n",
      "fold: TRAIN; iteration: 682; epoch: 0; loss: 2.5902459621429443; \n",
      "fold: TRAIN; iteration: 683; epoch: 0; loss: 2.718125104904175; \n",
      "fold: TRAIN; iteration: 684; epoch: 0; loss: 2.9290854930877686; \n",
      "fold: TRAIN; iteration: 685; epoch: 0; loss: 2.8354992866516113; \n",
      "fold: TRAIN; iteration: 686; epoch: 0; loss: 2.812993049621582; \n",
      "fold: TRAIN; iteration: 687; epoch: 0; loss: 2.941882371902466; \n",
      "fold: TRAIN; iteration: 688; epoch: 0; loss: 2.7920961380004883; \n",
      "fold: TRAIN; iteration: 689; epoch: 0; loss: 2.8347158432006836; \n",
      "fold: TRAIN; iteration: 690; epoch: 0; loss: 2.6057868003845215; \n",
      "fold: TRAIN; iteration: 691; epoch: 0; loss: 2.6254396438598633; \n",
      "fold: TRAIN; iteration: 692; epoch: 0; loss: 2.624361038208008; \n",
      "fold: TRAIN; iteration: 693; epoch: 0; loss: 2.8849947452545166; \n",
      "fold: TRAIN; iteration: 694; epoch: 0; loss: 2.8796658515930176; \n",
      "fold: TRAIN; iteration: 695; epoch: 0; loss: 2.6916027069091797; \n",
      "fold: TRAIN; iteration: 696; epoch: 0; loss: 2.8183395862579346; \n",
      "fold: TRAIN; iteration: 697; epoch: 0; loss: 2.8872973918914795; \n",
      "fold: TRAIN; iteration: 698; epoch: 0; loss: 2.5912389755249023; \n",
      "fold: TRAIN; iteration: 699; epoch: 0; loss: 2.9453823566436768; \n",
      "fold: TRAIN; iteration: 700; epoch: 0; loss: 2.853085517883301; \n",
      "fold: TRAIN; iteration: 701; epoch: 0; loss: 3.1479275226593018; \n",
      "fold: TRAIN; iteration: 702; epoch: 0; loss: 3.079505205154419; \n",
      "fold: TRAIN; iteration: 703; epoch: 0; loss: 2.5409679412841797; \n",
      "fold: TRAIN; iteration: 704; epoch: 0; loss: 2.8821892738342285; \n",
      "fold: TRAIN; iteration: 705; epoch: 0; loss: 2.935366153717041; \n",
      "fold: TRAIN; iteration: 706; epoch: 0; loss: 3.106696367263794; \n",
      "fold: TRAIN; iteration: 707; epoch: 0; loss: 2.891493797302246; \n",
      "fold: TRAIN; iteration: 708; epoch: 0; loss: 2.5329601764678955; \n",
      "fold: TRAIN; iteration: 709; epoch: 0; loss: 3.131204128265381; \n",
      "fold: TRAIN; iteration: 710; epoch: 0; loss: 2.6565260887145996; \n",
      "fold: TRAIN; iteration: 711; epoch: 0; loss: 2.5688717365264893; \n",
      "fold: TRAIN; iteration: 712; epoch: 0; loss: 2.6753852367401123; \n",
      "fold: TRAIN; iteration: 713; epoch: 0; loss: 2.818812370300293; \n",
      "fold: TRAIN; iteration: 714; epoch: 0; loss: 2.6697182655334473; \n",
      "fold: TRAIN; iteration: 715; epoch: 0; loss: 2.7238452434539795; \n",
      "fold: TRAIN; iteration: 716; epoch: 0; loss: 2.720684289932251; \n",
      "fold: TRAIN; iteration: 717; epoch: 0; loss: 2.7933437824249268; \n",
      "fold: TRAIN; iteration: 718; epoch: 0; loss: 3.0369231700897217; \n",
      "fold: TRAIN; iteration: 719; epoch: 0; loss: 2.3816285133361816; \n",
      "fold: TRAIN; iteration: 720; epoch: 0; loss: 2.806337833404541; \n",
      "fold: TRAIN; iteration: 721; epoch: 0; loss: 2.727806806564331; \n",
      "fold: TRAIN; iteration: 722; epoch: 0; loss: 2.730123996734619; \n",
      "fold: TRAIN; iteration: 723; epoch: 0; loss: 2.6935906410217285; \n",
      "fold: TRAIN; iteration: 724; epoch: 0; loss: 2.637277603149414; \n",
      "fold: TRAIN; iteration: 725; epoch: 0; loss: 2.673764944076538; \n",
      "fold: TRAIN; iteration: 726; epoch: 0; loss: 2.365448474884033; \n",
      "fold: TRAIN; iteration: 727; epoch: 0; loss: 2.9492461681365967; \n",
      "fold: TRAIN; iteration: 728; epoch: 0; loss: 3.0825371742248535; \n",
      "fold: TRAIN; iteration: 729; epoch: 0; loss: 2.682650566101074; \n",
      "fold: TRAIN; iteration: 730; epoch: 0; loss: 2.775437593460083; \n",
      "fold: TRAIN; iteration: 731; epoch: 0; loss: 2.727659225463867; \n",
      "fold: TRAIN; iteration: 732; epoch: 0; loss: 2.6080963611602783; \n",
      "fold: TRAIN; iteration: 733; epoch: 0; loss: 2.8394479751586914; \n",
      "fold: TRAIN; iteration: 734; epoch: 0; loss: 2.5325493812561035; \n",
      "fold: TRAIN; iteration: 735; epoch: 0; loss: 2.8253355026245117; \n",
      "fold: TRAIN; iteration: 736; epoch: 0; loss: 2.5704665184020996; \n",
      "fold: TRAIN; iteration: 737; epoch: 0; loss: 2.7345151901245117; \n",
      "fold: TRAIN; iteration: 738; epoch: 0; loss: 2.5537962913513184; \n",
      "fold: TRAIN; iteration: 739; epoch: 0; loss: 2.722593069076538; \n",
      "fold: TRAIN; iteration: 740; epoch: 0; loss: 2.731555461883545; \n",
      "fold: TRAIN; iteration: 741; epoch: 0; loss: 2.6657800674438477; \n",
      "fold: TRAIN; iteration: 742; epoch: 0; loss: 2.8236467838287354; \n",
      "fold: TRAIN; iteration: 743; epoch: 0; loss: 2.6748201847076416; \n",
      "fold: TRAIN; iteration: 744; epoch: 0; loss: 2.6760261058807373; \n",
      "fold: TRAIN; iteration: 745; epoch: 0; loss: 3.0301036834716797; \n",
      "fold: TRAIN; iteration: 746; epoch: 0; loss: 2.660280704498291; \n",
      "fold: TRAIN; iteration: 747; epoch: 0; loss: 2.807790517807007; \n",
      "fold: TRAIN; iteration: 748; epoch: 0; loss: 2.9361870288848877; \n",
      "fold: TRAIN; iteration: 749; epoch: 0; loss: 2.759756565093994; \n",
      "fold: TRAIN; iteration: 750; epoch: 0; loss: 2.7873687744140625; \n",
      "fold: TRAIN; iteration: 751; epoch: 0; loss: 2.641918897628784; \n",
      "fold: TRAIN; iteration: 752; epoch: 0; loss: 2.5817322731018066; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 753; epoch: 0; loss: 2.556485652923584; \n",
      "fold: TRAIN; iteration: 754; epoch: 0; loss: 2.7180206775665283; \n",
      "fold: TRAIN; iteration: 755; epoch: 0; loss: 2.825225830078125; \n",
      "fold: TRAIN; iteration: 756; epoch: 0; loss: 2.8048806190490723; \n",
      "fold: TRAIN; iteration: 757; epoch: 0; loss: 2.607280969619751; \n",
      "fold: TRAIN; iteration: 758; epoch: 0; loss: 2.7191579341888428; \n",
      "fold: TRAIN; iteration: 759; epoch: 0; loss: 2.667433500289917; \n",
      "fold: TRAIN; iteration: 760; epoch: 0; loss: 2.933004379272461; \n",
      "fold: TRAIN; iteration: 761; epoch: 0; loss: 2.731727361679077; \n",
      "fold: TRAIN; iteration: 762; epoch: 0; loss: 2.9065933227539062; \n",
      "fold: TRAIN; iteration: 763; epoch: 0; loss: 2.6850898265838623; \n",
      "fold: TRAIN; iteration: 764; epoch: 0; loss: 2.6501200199127197; \n",
      "fold: TRAIN; iteration: 765; epoch: 0; loss: 2.733642578125; \n",
      "fold: TRAIN; iteration: 766; epoch: 0; loss: 2.5715367794036865; \n",
      "fold: TRAIN; iteration: 767; epoch: 0; loss: 2.641545057296753; \n",
      "fold: TRAIN; iteration: 768; epoch: 0; loss: 2.6191158294677734; \n",
      "fold: TRAIN; iteration: 769; epoch: 0; loss: 2.5916988849639893; \n",
      "fold: TRAIN; iteration: 770; epoch: 0; loss: 2.65106201171875; \n",
      "fold: TRAIN; iteration: 771; epoch: 0; loss: 2.8770337104797363; \n",
      "fold: TRAIN; iteration: 772; epoch: 0; loss: 2.8338804244995117; \n",
      "fold: TRAIN; iteration: 773; epoch: 0; loss: 2.64732027053833; \n",
      "fold: TRAIN; iteration: 774; epoch: 0; loss: 2.872274398803711; \n",
      "fold: TRAIN; iteration: 775; epoch: 0; loss: 2.718613624572754; \n",
      "fold: TRAIN; iteration: 776; epoch: 0; loss: 2.827008008956909; \n",
      "fold: TRAIN; iteration: 777; epoch: 0; loss: 3.0120668411254883; \n",
      "fold: TRAIN; iteration: 778; epoch: 0; loss: 2.7337799072265625; \n",
      "fold: TRAIN; iteration: 779; epoch: 0; loss: 2.7181015014648438; \n",
      "fold: TRAIN; iteration: 780; epoch: 0; loss: 2.6050782203674316; \n",
      "fold: TRAIN; iteration: 781; epoch: 0; loss: 2.7479708194732666; \n",
      "fold: TRAIN; iteration: 782; epoch: 0; loss: 2.790440082550049; \n",
      "fold: TRAIN; iteration: 783; epoch: 0; loss: 2.8810617923736572; \n",
      "fold: TRAIN; iteration: 784; epoch: 0; loss: 2.604696750640869; \n",
      "fold: TRAIN; iteration: 785; epoch: 0; loss: 2.8016388416290283; \n",
      "fold: TRAIN; iteration: 786; epoch: 0; loss: 2.468217372894287; \n",
      "fold: TRAIN; iteration: 787; epoch: 0; loss: 2.689432382583618; \n",
      "fold: TRAIN; iteration: 788; epoch: 0; loss: 2.812481641769409; \n",
      "fold: TRAIN; iteration: 789; epoch: 0; loss: 2.5475058555603027; \n",
      "fold: TRAIN; iteration: 790; epoch: 0; loss: 2.7733075618743896; \n",
      "fold: TRAIN; iteration: 791; epoch: 0; loss: 2.8736464977264404; \n",
      "fold: TRAIN; iteration: 792; epoch: 0; loss: 2.8234353065490723; \n",
      "fold: TRAIN; iteration: 793; epoch: 0; loss: 2.7806055545806885; \n",
      "fold: TRAIN; iteration: 794; epoch: 0; loss: 2.572744131088257; \n",
      "fold: TRAIN; iteration: 795; epoch: 0; loss: 2.9304864406585693; \n",
      "fold: TRAIN; iteration: 796; epoch: 0; loss: 2.648449182510376; \n",
      "fold: TRAIN; iteration: 797; epoch: 0; loss: 2.8593502044677734; \n",
      "fold: TRAIN; iteration: 798; epoch: 0; loss: 2.949439764022827; \n",
      "fold: TRAIN; iteration: 799; epoch: 0; loss: 2.7231431007385254; \n",
      "fold: TRAIN; iteration: 800; epoch: 0; loss: 2.742363214492798; \n",
      "fold: TRAIN; iteration: 801; epoch: 0; loss: 3.1742806434631348; \n",
      "fold: TRAIN; iteration: 802; epoch: 0; loss: 2.6078503131866455; \n",
      "fold: TRAIN; iteration: 803; epoch: 0; loss: 2.8953802585601807; \n",
      "fold: TRAIN; iteration: 804; epoch: 0; loss: 2.8188414573669434; \n",
      "fold: TRAIN; iteration: 805; epoch: 0; loss: 2.551607608795166; \n",
      "fold: TRAIN; iteration: 806; epoch: 0; loss: 2.5836474895477295; \n",
      "fold: TRAIN; iteration: 807; epoch: 0; loss: 2.972836971282959; \n",
      "fold: TRAIN; iteration: 808; epoch: 0; loss: 2.4579668045043945; \n",
      "fold: TRAIN; iteration: 809; epoch: 0; loss: 2.7027904987335205; \n",
      "fold: TRAIN; iteration: 810; epoch: 0; loss: 2.6399872303009033; \n",
      "fold: TRAIN; iteration: 811; epoch: 0; loss: 2.7561776638031006; \n",
      "fold: TRAIN; iteration: 812; epoch: 0; loss: 2.610006093978882; \n",
      "fold: TRAIN; iteration: 813; epoch: 0; loss: 2.5192904472351074; \n",
      "fold: TRAIN; iteration: 814; epoch: 0; loss: 2.7433114051818848; \n",
      "fold: TRAIN; iteration: 815; epoch: 0; loss: 2.770432472229004; \n",
      "fold: TRAIN; iteration: 816; epoch: 0; loss: 2.851745843887329; \n",
      "fold: TRAIN; iteration: 817; epoch: 0; loss: 2.513117790222168; \n",
      "fold: TRAIN; iteration: 818; epoch: 0; loss: 2.8558032512664795; \n",
      "fold: TRAIN; iteration: 819; epoch: 0; loss: 2.6679465770721436; \n",
      "fold: TRAIN; iteration: 820; epoch: 0; loss: 2.7603235244750977; \n",
      "fold: TRAIN; iteration: 821; epoch: 0; loss: 2.836923599243164; \n",
      "fold: TRAIN; iteration: 822; epoch: 0; loss: 2.7671890258789062; \n",
      "fold: TRAIN; iteration: 823; epoch: 0; loss: 2.8052361011505127; \n",
      "fold: TRAIN; iteration: 824; epoch: 0; loss: 2.797090530395508; \n",
      "fold: TRAIN; iteration: 825; epoch: 0; loss: 2.886526584625244; \n",
      "fold: TRAIN; iteration: 826; epoch: 0; loss: 2.8149523735046387; \n",
      "fold: TRAIN; iteration: 827; epoch: 0; loss: 2.6879634857177734; \n",
      "fold: TRAIN; iteration: 828; epoch: 0; loss: 2.791377067565918; \n",
      "fold: TRAIN; iteration: 829; epoch: 0; loss: 2.6553359031677246; \n",
      "fold: TRAIN; iteration: 830; epoch: 0; loss: 2.5315191745758057; \n",
      "fold: TRAIN; iteration: 831; epoch: 0; loss: 2.6577653884887695; \n",
      "fold: TRAIN; iteration: 832; epoch: 0; loss: 2.921748161315918; \n",
      "fold: TRAIN; iteration: 833; epoch: 0; loss: 2.5253958702087402; \n",
      "fold: TRAIN; iteration: 834; epoch: 0; loss: 2.6157402992248535; \n",
      "fold: TRAIN; iteration: 835; epoch: 0; loss: 2.746760845184326; \n",
      "fold: TRAIN; iteration: 836; epoch: 0; loss: 2.6861939430236816; \n",
      "fold: TRAIN; iteration: 837; epoch: 0; loss: 2.9037346839904785; \n",
      "fold: TRAIN; iteration: 838; epoch: 0; loss: 2.757627248764038; \n",
      "fold: TRAIN; iteration: 839; epoch: 0; loss: 2.916410446166992; \n",
      "fold: TRAIN; iteration: 840; epoch: 0; loss: 2.8384125232696533; \n",
      "fold: TRAIN; iteration: 841; epoch: 0; loss: 2.708142042160034; \n",
      "fold: TRAIN; iteration: 842; epoch: 0; loss: 2.976487159729004; \n",
      "fold: TRAIN; iteration: 843; epoch: 0; loss: 2.6318984031677246; \n",
      "fold: TRAIN; iteration: 844; epoch: 0; loss: 2.6036083698272705; \n",
      "fold: TRAIN; iteration: 845; epoch: 0; loss: 2.5508546829223633; \n",
      "fold: TRAIN; iteration: 846; epoch: 0; loss: 2.9513461589813232; \n",
      "fold: TRAIN; iteration: 847; epoch: 0; loss: 2.7202465534210205; \n",
      "fold: TRAIN; iteration: 848; epoch: 0; loss: 2.5785422325134277; \n",
      "fold: TRAIN; iteration: 849; epoch: 0; loss: 2.8230602741241455; \n",
      "fold: TRAIN; iteration: 850; epoch: 0; loss: 2.6334428787231445; \n",
      "fold: TRAIN; iteration: 851; epoch: 0; loss: 2.5740714073181152; \n",
      "fold: TRAIN; iteration: 852; epoch: 0; loss: 2.8406314849853516; \n",
      "fold: TRAIN; iteration: 853; epoch: 0; loss: 2.470198392868042; \n",
      "fold: TRAIN; iteration: 854; epoch: 0; loss: 2.638547420501709; \n",
      "fold: TRAIN; iteration: 855; epoch: 0; loss: 2.865718364715576; \n",
      "fold: TRAIN; iteration: 856; epoch: 0; loss: 2.699293851852417; \n",
      "fold: TRAIN; iteration: 857; epoch: 0; loss: 2.783663749694824; \n",
      "fold: TRAIN; iteration: 858; epoch: 0; loss: 2.6400339603424072; \n",
      "fold: TRAIN; iteration: 859; epoch: 0; loss: 2.8822438716888428; \n",
      "fold: TRAIN; iteration: 860; epoch: 0; loss: 2.682373046875; \n",
      "fold: TRAIN; iteration: 861; epoch: 0; loss: 2.5573458671569824; \n",
      "fold: TRAIN; iteration: 862; epoch: 0; loss: 2.601060152053833; \n",
      "fold: TRAIN; iteration: 863; epoch: 0; loss: 2.9437012672424316; \n",
      "fold: TRAIN; iteration: 864; epoch: 0; loss: 2.9096994400024414; \n",
      "fold: TRAIN; iteration: 865; epoch: 0; loss: 2.530251979827881; \n",
      "fold: TRAIN; iteration: 866; epoch: 0; loss: 2.465313673019409; \n",
      "fold: TRAIN; iteration: 867; epoch: 0; loss: 2.6546530723571777; \n",
      "fold: TRAIN; iteration: 868; epoch: 0; loss: 2.7749969959259033; \n",
      "fold: TRAIN; iteration: 869; epoch: 0; loss: 2.8717658519744873; \n",
      "fold: TRAIN; iteration: 870; epoch: 0; loss: 2.6869874000549316; \n",
      "fold: TRAIN; iteration: 871; epoch: 0; loss: 2.7783780097961426; \n",
      "fold: TRAIN; iteration: 872; epoch: 0; loss: 2.628000497817993; \n",
      "fold: TRAIN; iteration: 873; epoch: 0; loss: 2.6102471351623535; \n",
      "fold: TRAIN; iteration: 874; epoch: 0; loss: 2.9134576320648193; \n",
      "fold: TRAIN; iteration: 875; epoch: 0; loss: 2.524829626083374; \n",
      "fold: TRAIN; iteration: 876; epoch: 0; loss: 2.6766862869262695; \n",
      "fold: TRAIN; iteration: 877; epoch: 0; loss: 2.400871753692627; \n",
      "fold: TRAIN; iteration: 878; epoch: 0; loss: 2.5784146785736084; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 879; epoch: 0; loss: 2.67195987701416; \n",
      "fold: TRAIN; iteration: 880; epoch: 0; loss: 2.7776598930358887; \n",
      "fold: TRAIN; iteration: 881; epoch: 0; loss: 2.5185816287994385; \n",
      "fold: TRAIN; iteration: 882; epoch: 0; loss: 2.5120575428009033; \n",
      "fold: TRAIN; iteration: 883; epoch: 0; loss: 2.7521328926086426; \n",
      "fold: TRAIN; iteration: 884; epoch: 0; loss: 2.820573329925537; \n",
      "fold: TRAIN; iteration: 885; epoch: 0; loss: 2.378431797027588; \n",
      "fold: TRAIN; iteration: 886; epoch: 0; loss: 2.635345220565796; \n",
      "fold: TRAIN; iteration: 887; epoch: 0; loss: 2.7695062160491943; \n",
      "fold: TRAIN; iteration: 888; epoch: 0; loss: 2.5698647499084473; \n",
      "fold: TRAIN; iteration: 889; epoch: 0; loss: 2.7513577938079834; \n",
      "fold: TRAIN; iteration: 890; epoch: 0; loss: 3.0883607864379883; \n",
      "fold: TRAIN; iteration: 891; epoch: 0; loss: 2.547504186630249; \n",
      "fold: TRAIN; iteration: 892; epoch: 0; loss: 2.7954490184783936; \n",
      "fold: TRAIN; iteration: 893; epoch: 0; loss: 2.5654633045196533; \n",
      "fold: TRAIN; iteration: 894; epoch: 0; loss: 2.4786391258239746; \n",
      "fold: TRAIN; iteration: 895; epoch: 0; loss: 3.2439186573028564; \n",
      "fold: TRAIN; iteration: 896; epoch: 0; loss: 2.6658692359924316; \n",
      "fold: TRAIN; iteration: 897; epoch: 0; loss: 2.62448787689209; \n",
      "fold: TRAIN; iteration: 898; epoch: 0; loss: 2.5884854793548584; \n",
      "fold: TRAIN; iteration: 899; epoch: 0; loss: 2.617394208908081; \n",
      "fold: TRAIN; iteration: 900; epoch: 0; loss: 2.865527391433716; \n",
      "fold: TRAIN; iteration: 901; epoch: 0; loss: 2.433497667312622; \n",
      "fold: TRAIN; iteration: 902; epoch: 0; loss: 2.5825674533843994; \n",
      "fold: TRAIN; iteration: 903; epoch: 0; loss: 2.7477312088012695; \n",
      "fold: TRAIN; iteration: 904; epoch: 0; loss: 2.6507554054260254; \n",
      "fold: TRAIN; iteration: 905; epoch: 0; loss: 2.633800983428955; \n",
      "fold: TRAIN; iteration: 906; epoch: 0; loss: 2.8696067333221436; \n",
      "fold: TRAIN; iteration: 907; epoch: 0; loss: 2.9139513969421387; \n",
      "fold: TRAIN; iteration: 908; epoch: 0; loss: 2.718334674835205; \n",
      "fold: TRAIN; iteration: 909; epoch: 0; loss: 2.575479030609131; \n",
      "fold: TRAIN; iteration: 910; epoch: 0; loss: 2.637768030166626; \n",
      "fold: TRAIN; iteration: 911; epoch: 0; loss: 2.561379909515381; \n",
      "fold: TRAIN; iteration: 912; epoch: 0; loss: 3.0773956775665283; \n",
      "fold: TRAIN; iteration: 913; epoch: 0; loss: 2.8030526638031006; \n",
      "fold: TRAIN; iteration: 914; epoch: 0; loss: 2.478818416595459; \n",
      "fold: TRAIN; iteration: 915; epoch: 0; loss: 2.5011203289031982; \n",
      "fold: TRAIN; iteration: 916; epoch: 0; loss: 2.6613593101501465; \n",
      "fold: TRAIN; iteration: 917; epoch: 0; loss: 2.5673913955688477; \n",
      "fold: TRAIN; iteration: 918; epoch: 0; loss: 2.705145835876465; \n",
      "fold: TRAIN; iteration: 919; epoch: 0; loss: 2.7598628997802734; \n",
      "fold: TRAIN; iteration: 920; epoch: 0; loss: 2.3824245929718018; \n",
      "fold: TRAIN; iteration: 921; epoch: 0; loss: 2.6373374462127686; \n",
      "fold: TRAIN; iteration: 922; epoch: 0; loss: 2.407641887664795; \n",
      "fold: TRAIN; iteration: 923; epoch: 0; loss: 2.7111053466796875; \n",
      "fold: TRAIN; iteration: 924; epoch: 0; loss: 2.306716203689575; \n",
      "fold: TRAIN; iteration: 925; epoch: 0; loss: 2.4478933811187744; \n",
      "fold: TRAIN; iteration: 926; epoch: 0; loss: 2.933558940887451; \n",
      "fold: TRAIN; iteration: 927; epoch: 0; loss: 2.9152181148529053; \n",
      "fold: TRAIN; iteration: 928; epoch: 0; loss: 3.0327203273773193; \n",
      "fold: TRAIN; iteration: 929; epoch: 0; loss: 2.5789361000061035; \n",
      "fold: TRAIN; iteration: 930; epoch: 0; loss: 2.6795544624328613; \n",
      "fold: TRAIN; iteration: 931; epoch: 0; loss: 2.6721739768981934; \n",
      "fold: TRAIN; iteration: 932; epoch: 0; loss: 2.8512206077575684; \n",
      "fold: TRAIN; iteration: 933; epoch: 0; loss: 2.702948808670044; \n",
      "fold: TRAIN; iteration: 934; epoch: 0; loss: 2.759444236755371; \n",
      "fold: TRAIN; iteration: 935; epoch: 0; loss: 2.7142879962921143; \n",
      "fold: TRAIN; iteration: 936; epoch: 0; loss: 2.6831815242767334; \n",
      "fold: TRAIN; iteration: 937; epoch: 0; loss: 2.4094083309173584; \n",
      "fold: TRAIN; iteration: 938; epoch: 0; loss: 2.935845136642456; \n",
      "fold: TRAIN; iteration: 939; epoch: 0; loss: 2.6077563762664795; \n",
      "fold: TRAIN; iteration: 940; epoch: 0; loss: 2.7900283336639404; \n",
      "fold: TRAIN; iteration: 941; epoch: 0; loss: 2.776707172393799; \n",
      "fold: TRAIN; iteration: 942; epoch: 0; loss: 2.645298480987549; \n",
      "fold: TRAIN; iteration: 943; epoch: 0; loss: 2.7287285327911377; \n",
      "fold: TRAIN; iteration: 944; epoch: 0; loss: 2.571718692779541; \n",
      "fold: TRAIN; iteration: 945; epoch: 0; loss: 2.467817544937134; \n",
      "fold: TRAIN; iteration: 946; epoch: 0; loss: 2.81350040435791; \n",
      "fold: TRAIN; iteration: 947; epoch: 0; loss: 2.490464925765991; \n",
      "fold: TRAIN; iteration: 948; epoch: 0; loss: 2.7187769412994385; \n",
      "fold: TRAIN; iteration: 949; epoch: 0; loss: 2.9962124824523926; \n",
      "fold: TRAIN; iteration: 950; epoch: 0; loss: 2.681469202041626; \n",
      "fold: TRAIN; iteration: 951; epoch: 0; loss: 2.87839412689209; \n",
      "fold: TRAIN; iteration: 952; epoch: 0; loss: 2.5753161907196045; \n",
      "fold: TRAIN; iteration: 953; epoch: 0; loss: 2.9210104942321777; \n",
      "fold: TRAIN; iteration: 954; epoch: 0; loss: 2.685662031173706; \n",
      "fold: TRAIN; iteration: 955; epoch: 0; loss: 2.7336208820343018; \n",
      "fold: TRAIN; iteration: 956; epoch: 0; loss: 2.714215040206909; \n",
      "fold: TRAIN; iteration: 957; epoch: 0; loss: 2.5784807205200195; \n",
      "fold: TRAIN; iteration: 958; epoch: 0; loss: 2.5965476036071777; \n",
      "fold: TRAIN; iteration: 959; epoch: 0; loss: 2.9452884197235107; \n",
      "fold: TRAIN; iteration: 960; epoch: 0; loss: 2.6931395530700684; \n",
      "fold: TRAIN; iteration: 961; epoch: 0; loss: 2.676892042160034; \n",
      "fold: TRAIN; iteration: 962; epoch: 0; loss: 2.548351526260376; \n",
      "fold: TRAIN; iteration: 963; epoch: 0; loss: 2.468325614929199; \n",
      "fold: TRAIN; iteration: 964; epoch: 0; loss: 2.48724365234375; \n",
      "fold: TRAIN; iteration: 965; epoch: 0; loss: 2.749708890914917; \n",
      "fold: TRAIN; iteration: 966; epoch: 0; loss: 2.4917986392974854; \n",
      "fold: TRAIN; iteration: 967; epoch: 0; loss: 2.615121841430664; \n",
      "fold: TRAIN; iteration: 968; epoch: 0; loss: 2.472708225250244; \n",
      "fold: TRAIN; iteration: 969; epoch: 0; loss: 2.6911377906799316; \n",
      "fold: TRAIN; iteration: 970; epoch: 0; loss: 2.5617682933807373; \n",
      "fold: TRAIN; iteration: 971; epoch: 0; loss: 2.6076860427856445; \n",
      "fold: TRAIN; iteration: 972; epoch: 0; loss: 2.6834888458251953; \n",
      "fold: TRAIN; iteration: 973; epoch: 0; loss: 2.8148691654205322; \n",
      "fold: TRAIN; iteration: 974; epoch: 0; loss: 2.543574810028076; \n",
      "fold: TRAIN; iteration: 975; epoch: 0; loss: 2.789660692214966; \n",
      "fold: TRAIN; iteration: 976; epoch: 0; loss: 2.7118377685546875; \n",
      "fold: TRAIN; iteration: 977; epoch: 0; loss: 2.938525676727295; \n",
      "fold: TRAIN; iteration: 978; epoch: 0; loss: 2.5130808353424072; \n",
      "fold: TRAIN; iteration: 979; epoch: 0; loss: 2.729074716567993; \n",
      "fold: TRAIN; iteration: 980; epoch: 0; loss: 2.593832015991211; \n",
      "fold: TRAIN; iteration: 981; epoch: 0; loss: 2.552114248275757; \n",
      "fold: TRAIN; iteration: 982; epoch: 0; loss: 2.606109619140625; \n",
      "fold: TRAIN; iteration: 983; epoch: 0; loss: 2.7257094383239746; \n",
      "fold: TRAIN; iteration: 984; epoch: 0; loss: 2.6450960636138916; \n",
      "fold: TRAIN; iteration: 985; epoch: 0; loss: 2.390019416809082; \n",
      "fold: TRAIN; iteration: 986; epoch: 0; loss: 2.691237688064575; \n",
      "fold: TRAIN; iteration: 987; epoch: 0; loss: 2.7394661903381348; \n",
      "fold: TRAIN; iteration: 988; epoch: 0; loss: 2.588371515274048; \n",
      "fold: TRAIN; iteration: 989; epoch: 0; loss: 2.623289108276367; \n",
      "fold: TRAIN; iteration: 990; epoch: 0; loss: 2.7955615520477295; \n",
      "fold: TRAIN; iteration: 991; epoch: 0; loss: 2.298780918121338; \n",
      "fold: TRAIN; iteration: 992; epoch: 0; loss: 2.647289991378784; \n",
      "fold: TRAIN; iteration: 993; epoch: 0; loss: 2.576556921005249; \n",
      "fold: TRAIN; iteration: 994; epoch: 0; loss: 2.4797780513763428; \n",
      "fold: TRAIN; iteration: 995; epoch: 0; loss: 2.6120986938476562; \n",
      "fold: TRAIN; iteration: 996; epoch: 0; loss: 2.430633544921875; \n",
      "fold: TRAIN; iteration: 997; epoch: 0; loss: 2.641723871231079; \n",
      "fold: TRAIN; iteration: 998; epoch: 0; loss: 2.603832721710205; \n",
      "fold: TRAIN; iteration: 999; epoch: 0; loss: 2.4522409439086914; \n",
      "validating model...\n",
      "saving\n",
      "fold: VALID; iteration: 1000; epoch: 0; loss: 2.68211191962747; \n",
      "fold: TRAIN; iteration: 1000; epoch: 0; loss: 2.851592779159546; \n",
      "fold: TRAIN; iteration: 1001; epoch: 0; loss: 2.7845406532287598; \n",
      "fold: TRAIN; iteration: 1002; epoch: 0; loss: 2.8671798706054688; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 1003; epoch: 0; loss: 2.877822160720825; \n",
      "fold: TRAIN; iteration: 1004; epoch: 0; loss: 2.605705976486206; \n",
      "fold: TRAIN; iteration: 1005; epoch: 0; loss: 2.8300440311431885; \n",
      "fold: TRAIN; iteration: 1006; epoch: 0; loss: 2.609776496887207; \n",
      "fold: TRAIN; iteration: 1007; epoch: 0; loss: 2.6012802124023438; \n",
      "fold: TRAIN; iteration: 1008; epoch: 0; loss: 2.5395407676696777; \n",
      "fold: TRAIN; iteration: 1009; epoch: 0; loss: 2.8148586750030518; \n",
      "fold: TRAIN; iteration: 1010; epoch: 0; loss: 2.4991273880004883; \n",
      "fold: TRAIN; iteration: 1011; epoch: 0; loss: 3.006856679916382; \n",
      "fold: TRAIN; iteration: 1012; epoch: 0; loss: 2.685232639312744; \n",
      "fold: TRAIN; iteration: 1013; epoch: 0; loss: 2.8271491527557373; \n",
      "fold: TRAIN; iteration: 1014; epoch: 0; loss: 2.6740007400512695; \n",
      "fold: TRAIN; iteration: 1015; epoch: 0; loss: 2.6696279048919678; \n",
      "fold: TRAIN; iteration: 1016; epoch: 0; loss: 2.699922561645508; \n",
      "fold: TRAIN; iteration: 1017; epoch: 0; loss: 2.6639654636383057; \n",
      "fold: TRAIN; iteration: 1018; epoch: 0; loss: 2.467621088027954; \n",
      "fold: TRAIN; iteration: 1019; epoch: 0; loss: 2.8479318618774414; \n",
      "fold: TRAIN; iteration: 1020; epoch: 0; loss: 2.802269220352173; \n",
      "fold: TRAIN; iteration: 1021; epoch: 0; loss: 2.4405293464660645; \n",
      "fold: TRAIN; iteration: 1022; epoch: 0; loss: 2.5888822078704834; \n",
      "fold: TRAIN; iteration: 1023; epoch: 0; loss: 2.5564897060394287; \n",
      "fold: TRAIN; iteration: 1024; epoch: 0; loss: 2.5920705795288086; \n",
      "fold: TRAIN; iteration: 1025; epoch: 0; loss: 2.5083870887756348; \n",
      "fold: TRAIN; iteration: 1026; epoch: 0; loss: 2.740703821182251; \n",
      "fold: TRAIN; iteration: 1027; epoch: 0; loss: 2.3824586868286133; \n",
      "fold: TRAIN; iteration: 1028; epoch: 0; loss: 2.7177035808563232; \n",
      "fold: TRAIN; iteration: 1029; epoch: 0; loss: 2.786233425140381; \n",
      "fold: TRAIN; iteration: 1030; epoch: 0; loss: 2.9147467613220215; \n",
      "fold: TRAIN; iteration: 1031; epoch: 0; loss: 2.6045827865600586; \n",
      "fold: TRAIN; iteration: 1032; epoch: 0; loss: 2.7967095375061035; \n",
      "fold: TRAIN; iteration: 1033; epoch: 0; loss: 2.7647275924682617; \n",
      "fold: TRAIN; iteration: 1034; epoch: 0; loss: 2.7743988037109375; \n",
      "fold: TRAIN; iteration: 1035; epoch: 0; loss: 2.8311331272125244; \n",
      "fold: TRAIN; iteration: 1036; epoch: 0; loss: 2.5586700439453125; \n",
      "fold: TRAIN; iteration: 1037; epoch: 0; loss: 2.742648124694824; \n",
      "fold: TRAIN; iteration: 1038; epoch: 0; loss: 2.606931209564209; \n",
      "fold: TRAIN; iteration: 1039; epoch: 0; loss: 2.582862615585327; \n",
      "fold: TRAIN; iteration: 1040; epoch: 0; loss: 2.4540817737579346; \n",
      "fold: TRAIN; iteration: 1041; epoch: 0; loss: 2.4332451820373535; \n",
      "fold: TRAIN; iteration: 1042; epoch: 0; loss: 2.7438595294952393; \n",
      "fold: TRAIN; iteration: 1043; epoch: 0; loss: 2.5294928550720215; \n",
      "fold: TRAIN; iteration: 1044; epoch: 0; loss: 2.637907028198242; \n",
      "fold: TRAIN; iteration: 1045; epoch: 0; loss: 2.832705020904541; \n",
      "fold: TRAIN; iteration: 1046; epoch: 0; loss: 2.7528645992279053; \n",
      "fold: TRAIN; iteration: 1047; epoch: 0; loss: 2.5287861824035645; \n",
      "fold: TRAIN; iteration: 1048; epoch: 0; loss: 2.8122856616973877; \n",
      "fold: TRAIN; iteration: 1049; epoch: 0; loss: 2.588505268096924; \n",
      "fold: TRAIN; iteration: 1050; epoch: 0; loss: 2.9457383155822754; \n",
      "fold: TRAIN; iteration: 1051; epoch: 0; loss: 2.592276096343994; \n",
      "fold: TRAIN; iteration: 1052; epoch: 0; loss: 2.653754949569702; \n",
      "fold: TRAIN; iteration: 1053; epoch: 0; loss: 2.7418394088745117; \n",
      "fold: TRAIN; iteration: 1054; epoch: 0; loss: 2.4958629608154297; \n",
      "fold: TRAIN; iteration: 1055; epoch: 0; loss: 2.500986337661743; \n",
      "fold: TRAIN; iteration: 1056; epoch: 0; loss: 2.671030282974243; \n",
      "fold: TRAIN; iteration: 1057; epoch: 0; loss: 2.675523042678833; \n",
      "fold: TRAIN; iteration: 1058; epoch: 0; loss: 2.3183188438415527; \n",
      "fold: TRAIN; iteration: 1059; epoch: 0; loss: 2.6866750717163086; \n",
      "fold: TRAIN; iteration: 1060; epoch: 0; loss: 2.9347023963928223; \n",
      "fold: TRAIN; iteration: 1061; epoch: 0; loss: 2.527489423751831; \n",
      "fold: TRAIN; iteration: 1062; epoch: 0; loss: 2.8518173694610596; \n",
      "fold: TRAIN; iteration: 1063; epoch: 0; loss: 2.431535005569458; \n",
      "fold: TRAIN; iteration: 1064; epoch: 0; loss: 2.6097517013549805; \n",
      "fold: TRAIN; iteration: 1065; epoch: 0; loss: 2.5600099563598633; \n",
      "fold: TRAIN; iteration: 1066; epoch: 0; loss: 2.6620373725891113; \n",
      "fold: TRAIN; iteration: 1067; epoch: 0; loss: 2.6337289810180664; \n",
      "fold: TRAIN; iteration: 1068; epoch: 0; loss: 2.6206579208374023; \n",
      "fold: TRAIN; iteration: 1069; epoch: 0; loss: 2.370706558227539; \n",
      "fold: TRAIN; iteration: 1070; epoch: 0; loss: 2.567110061645508; \n",
      "fold: TRAIN; iteration: 1071; epoch: 0; loss: 2.7632246017456055; \n",
      "fold: TRAIN; iteration: 1072; epoch: 0; loss: 2.6846773624420166; \n",
      "fold: TRAIN; iteration: 1073; epoch: 0; loss: 2.76200008392334; \n",
      "fold: TRAIN; iteration: 1074; epoch: 0; loss: 2.5839831829071045; \n",
      "fold: TRAIN; iteration: 1075; epoch: 0; loss: 2.7759599685668945; \n",
      "fold: TRAIN; iteration: 1076; epoch: 0; loss: 2.8041350841522217; \n",
      "fold: TRAIN; iteration: 1077; epoch: 0; loss: 2.45806884765625; \n",
      "fold: TRAIN; iteration: 1078; epoch: 0; loss: 2.5693891048431396; \n",
      "fold: TRAIN; iteration: 1079; epoch: 0; loss: 2.412616491317749; \n",
      "fold: TRAIN; iteration: 1080; epoch: 0; loss: 2.4572505950927734; \n",
      "fold: TRAIN; iteration: 1081; epoch: 0; loss: 2.4600493907928467; \n",
      "fold: TRAIN; iteration: 1082; epoch: 0; loss: 2.693540334701538; \n",
      "fold: TRAIN; iteration: 1083; epoch: 0; loss: 2.4811911582946777; \n",
      "fold: TRAIN; iteration: 1084; epoch: 0; loss: 2.9177029132843018; \n",
      "fold: TRAIN; iteration: 1085; epoch: 0; loss: 2.610295057296753; \n",
      "fold: TRAIN; iteration: 1086; epoch: 0; loss: 2.406852960586548; \n",
      "fold: TRAIN; iteration: 1087; epoch: 0; loss: 2.5261101722717285; \n",
      "fold: TRAIN; iteration: 1088; epoch: 0; loss: 2.7399981021881104; \n",
      "fold: TRAIN; iteration: 1089; epoch: 0; loss: 2.7987871170043945; \n",
      "fold: TRAIN; iteration: 1090; epoch: 0; loss: 2.9205641746520996; \n",
      "fold: TRAIN; iteration: 1091; epoch: 0; loss: 2.6221697330474854; \n",
      "fold: TRAIN; iteration: 1092; epoch: 0; loss: 2.6613714694976807; \n",
      "fold: TRAIN; iteration: 1093; epoch: 0; loss: 2.564211130142212; \n",
      "fold: TRAIN; iteration: 1094; epoch: 0; loss: 2.6963589191436768; \n",
      "fold: TRAIN; iteration: 1095; epoch: 0; loss: 2.6721384525299072; \n",
      "fold: TRAIN; iteration: 1096; epoch: 0; loss: 2.6228277683258057; \n",
      "fold: TRAIN; iteration: 1097; epoch: 0; loss: 2.7903177738189697; \n",
      "fold: TRAIN; iteration: 1098; epoch: 0; loss: 3.085406541824341; \n",
      "fold: TRAIN; iteration: 1099; epoch: 0; loss: 2.7327747344970703; \n",
      "fold: TRAIN; iteration: 1100; epoch: 0; loss: 2.6417856216430664; \n",
      "fold: TRAIN; iteration: 1101; epoch: 0; loss: 2.6408376693725586; \n",
      "fold: TRAIN; iteration: 1102; epoch: 0; loss: 2.7011330127716064; \n",
      "fold: TRAIN; iteration: 1103; epoch: 0; loss: 2.6743292808532715; \n",
      "fold: TRAIN; iteration: 1104; epoch: 0; loss: 2.8264858722686768; \n",
      "fold: TRAIN; iteration: 1105; epoch: 0; loss: 2.60296630859375; \n",
      "fold: TRAIN; iteration: 1106; epoch: 0; loss: 2.470339059829712; \n",
      "fold: TRAIN; iteration: 1107; epoch: 0; loss: 2.6695117950439453; \n",
      "fold: TRAIN; iteration: 1108; epoch: 0; loss: 2.633380651473999; \n",
      "fold: TRAIN; iteration: 1109; epoch: 0; loss: 2.5608086585998535; \n",
      "fold: TRAIN; iteration: 1110; epoch: 0; loss: 2.617347002029419; \n",
      "fold: TRAIN; iteration: 1111; epoch: 0; loss: 2.751185894012451; \n",
      "fold: TRAIN; iteration: 1112; epoch: 0; loss: 2.6662662029266357; \n",
      "fold: TRAIN; iteration: 1113; epoch: 0; loss: 2.489380121231079; \n",
      "fold: TRAIN; iteration: 1114; epoch: 0; loss: 2.6309802532196045; \n",
      "fold: TRAIN; iteration: 1115; epoch: 0; loss: 2.688632011413574; \n",
      "fold: TRAIN; iteration: 1116; epoch: 0; loss: 2.7807998657226562; \n",
      "fold: TRAIN; iteration: 1117; epoch: 0; loss: 2.5891592502593994; \n",
      "fold: TRAIN; iteration: 1118; epoch: 0; loss: 2.6624138355255127; \n",
      "fold: TRAIN; iteration: 1119; epoch: 0; loss: 2.693819046020508; \n",
      "fold: TRAIN; iteration: 1120; epoch: 0; loss: 2.5968379974365234; \n",
      "fold: TRAIN; iteration: 1121; epoch: 0; loss: 2.6786413192749023; \n",
      "fold: TRAIN; iteration: 1122; epoch: 0; loss: 2.5245938301086426; \n",
      "fold: TRAIN; iteration: 1123; epoch: 0; loss: 2.5821588039398193; \n",
      "fold: TRAIN; iteration: 1124; epoch: 0; loss: 2.5104594230651855; \n",
      "fold: TRAIN; iteration: 1125; epoch: 0; loss: 2.581209421157837; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 1126; epoch: 0; loss: 2.488957166671753; \n",
      "fold: TRAIN; iteration: 1127; epoch: 0; loss: 2.5194103717803955; \n",
      "fold: TRAIN; iteration: 1128; epoch: 0; loss: 2.8163888454437256; \n",
      "fold: TRAIN; iteration: 1129; epoch: 0; loss: 2.6604177951812744; \n",
      "fold: TRAIN; iteration: 1130; epoch: 0; loss: 2.5556087493896484; \n",
      "fold: TRAIN; iteration: 1131; epoch: 0; loss: 3.0062875747680664; \n",
      "fold: TRAIN; iteration: 1132; epoch: 0; loss: 2.5002715587615967; \n",
      "fold: TRAIN; iteration: 1133; epoch: 0; loss: 2.718641996383667; \n",
      "fold: TRAIN; iteration: 1134; epoch: 0; loss: 2.6851882934570312; \n",
      "fold: TRAIN; iteration: 1135; epoch: 0; loss: 2.4910478591918945; \n",
      "fold: TRAIN; iteration: 1136; epoch: 0; loss: 2.540102005004883; \n",
      "fold: TRAIN; iteration: 1137; epoch: 0; loss: 2.5340747833251953; \n",
      "fold: TRAIN; iteration: 1138; epoch: 0; loss: 2.7450945377349854; \n",
      "fold: TRAIN; iteration: 1139; epoch: 0; loss: 2.6043612957000732; \n",
      "fold: TRAIN; iteration: 1140; epoch: 0; loss: 2.7741329669952393; \n",
      "fold: TRAIN; iteration: 1141; epoch: 0; loss: 2.5100579261779785; \n",
      "fold: TRAIN; iteration: 1142; epoch: 0; loss: 2.5815603733062744; \n",
      "fold: TRAIN; iteration: 1143; epoch: 0; loss: 2.5219128131866455; \n",
      "fold: TRAIN; iteration: 1144; epoch: 0; loss: 2.8003649711608887; \n",
      "fold: TRAIN; iteration: 1145; epoch: 0; loss: 2.705218553543091; \n",
      "fold: TRAIN; iteration: 1146; epoch: 0; loss: 2.4210879802703857; \n",
      "fold: TRAIN; iteration: 1147; epoch: 0; loss: 2.7728121280670166; \n",
      "fold: TRAIN; iteration: 1148; epoch: 0; loss: 2.602194309234619; \n",
      "fold: TRAIN; iteration: 1149; epoch: 0; loss: 2.8749237060546875; \n",
      "fold: TRAIN; iteration: 1150; epoch: 0; loss: 2.479595184326172; \n",
      "fold: TRAIN; iteration: 1151; epoch: 0; loss: 2.806809902191162; \n",
      "fold: TRAIN; iteration: 1152; epoch: 0; loss: 2.6514644622802734; \n",
      "fold: TRAIN; iteration: 1153; epoch: 0; loss: 2.762519598007202; \n",
      "fold: TRAIN; iteration: 1154; epoch: 0; loss: 2.6705641746520996; \n",
      "fold: TRAIN; iteration: 1155; epoch: 0; loss: 2.6548197269439697; \n",
      "fold: TRAIN; iteration: 1156; epoch: 0; loss: 2.581022262573242; \n",
      "fold: TRAIN; iteration: 1157; epoch: 0; loss: 2.6574883460998535; \n",
      "fold: TRAIN; iteration: 1158; epoch: 0; loss: 2.563154697418213; \n",
      "fold: TRAIN; iteration: 1159; epoch: 0; loss: 2.789583683013916; \n",
      "fold: TRAIN; iteration: 1160; epoch: 0; loss: 2.6312127113342285; \n",
      "fold: TRAIN; iteration: 1161; epoch: 0; loss: 2.8411922454833984; \n",
      "fold: TRAIN; iteration: 1162; epoch: 0; loss: 2.7641820907592773; \n",
      "fold: TRAIN; iteration: 1163; epoch: 0; loss: 2.431248903274536; \n",
      "fold: TRAIN; iteration: 1164; epoch: 0; loss: 2.589373826980591; \n",
      "fold: TRAIN; iteration: 1165; epoch: 0; loss: 2.7461888790130615; \n",
      "fold: TRAIN; iteration: 1166; epoch: 0; loss: 2.472496271133423; \n",
      "fold: TRAIN; iteration: 1167; epoch: 0; loss: 2.446352481842041; \n",
      "fold: TRAIN; iteration: 1168; epoch: 0; loss: 2.3184654712677; \n",
      "fold: TRAIN; iteration: 1169; epoch: 0; loss: 2.8753418922424316; \n",
      "fold: TRAIN; iteration: 1170; epoch: 0; loss: 2.476752281188965; \n",
      "fold: TRAIN; iteration: 1171; epoch: 0; loss: 2.8866126537323; \n",
      "fold: TRAIN; iteration: 1172; epoch: 0; loss: 2.571335792541504; \n",
      "fold: TRAIN; iteration: 1173; epoch: 0; loss: 2.623537540435791; \n",
      "fold: TRAIN; iteration: 1174; epoch: 0; loss: 3.0171475410461426; \n",
      "fold: TRAIN; iteration: 1175; epoch: 0; loss: 2.6511950492858887; \n",
      "fold: TRAIN; iteration: 1176; epoch: 0; loss: 2.649085283279419; \n",
      "fold: TRAIN; iteration: 1177; epoch: 0; loss: 2.785956382751465; \n",
      "fold: TRAIN; iteration: 1178; epoch: 0; loss: 2.441679000854492; \n",
      "fold: TRAIN; iteration: 1179; epoch: 0; loss: 2.5800716876983643; \n",
      "fold: TRAIN; iteration: 1180; epoch: 0; loss: 2.7492992877960205; \n",
      "fold: TRAIN; iteration: 1181; epoch: 0; loss: 2.7491936683654785; \n",
      "fold: TRAIN; iteration: 1182; epoch: 0; loss: 2.7466561794281006; \n",
      "fold: TRAIN; iteration: 1183; epoch: 0; loss: 2.7312514781951904; \n",
      "fold: TRAIN; iteration: 1184; epoch: 0; loss: 2.674764394760132; \n",
      "fold: TRAIN; iteration: 1185; epoch: 0; loss: 2.574317216873169; \n",
      "fold: TRAIN; iteration: 1186; epoch: 0; loss: 2.5940279960632324; \n",
      "fold: TRAIN; iteration: 1187; epoch: 0; loss: 2.4368879795074463; \n",
      "fold: TRAIN; iteration: 1188; epoch: 0; loss: 2.6469192504882812; \n",
      "fold: TRAIN; iteration: 1189; epoch: 0; loss: 2.6147208213806152; \n",
      "fold: TRAIN; iteration: 1190; epoch: 0; loss: 2.6732451915740967; \n",
      "fold: TRAIN; iteration: 1191; epoch: 0; loss: 2.65889048576355; \n",
      "fold: TRAIN; iteration: 1192; epoch: 0; loss: 2.4838578701019287; \n",
      "fold: TRAIN; iteration: 1193; epoch: 0; loss: 2.5172972679138184; \n",
      "fold: TRAIN; iteration: 1194; epoch: 0; loss: 2.8641350269317627; \n",
      "fold: TRAIN; iteration: 1195; epoch: 0; loss: 2.959982395172119; \n",
      "fold: TRAIN; iteration: 1196; epoch: 0; loss: 2.684631109237671; \n",
      "fold: TRAIN; iteration: 1197; epoch: 0; loss: 2.685347318649292; \n",
      "fold: TRAIN; iteration: 1198; epoch: 0; loss: 2.535367965698242; \n",
      "fold: TRAIN; iteration: 1199; epoch: 0; loss: 2.22853422164917; \n",
      "fold: TRAIN; iteration: 1200; epoch: 0; loss: 2.6635353565216064; \n",
      "fold: TRAIN; iteration: 1201; epoch: 0; loss: 2.7317538261413574; \n",
      "fold: TRAIN; iteration: 1202; epoch: 0; loss: 2.4619007110595703; \n",
      "fold: TRAIN; iteration: 1203; epoch: 0; loss: 2.7019126415252686; \n",
      "fold: TRAIN; iteration: 1204; epoch: 0; loss: 2.6424295902252197; \n",
      "fold: TRAIN; iteration: 1205; epoch: 0; loss: 2.689732551574707; \n",
      "fold: TRAIN; iteration: 1206; epoch: 0; loss: 2.43873929977417; \n",
      "fold: TRAIN; iteration: 1207; epoch: 0; loss: 2.6738171577453613; \n",
      "fold: TRAIN; iteration: 1208; epoch: 0; loss: 2.656341314315796; \n",
      "fold: TRAIN; iteration: 1209; epoch: 0; loss: 2.703761100769043; \n",
      "fold: TRAIN; iteration: 1210; epoch: 0; loss: 2.557964563369751; \n",
      "fold: TRAIN; iteration: 1211; epoch: 0; loss: 2.792102575302124; \n",
      "fold: TRAIN; iteration: 1212; epoch: 0; loss: 2.6274290084838867; \n",
      "fold: TRAIN; iteration: 1213; epoch: 0; loss: 2.6711182594299316; \n",
      "fold: TRAIN; iteration: 1214; epoch: 0; loss: 2.4363512992858887; \n",
      "fold: TRAIN; iteration: 1215; epoch: 0; loss: 2.574824333190918; \n",
      "fold: TRAIN; iteration: 1216; epoch: 0; loss: 2.6661736965179443; \n",
      "fold: TRAIN; iteration: 1217; epoch: 0; loss: 2.843639612197876; \n",
      "fold: TRAIN; iteration: 1218; epoch: 0; loss: 2.527122974395752; \n",
      "fold: TRAIN; iteration: 1219; epoch: 0; loss: 2.4297497272491455; \n",
      "fold: TRAIN; iteration: 1220; epoch: 0; loss: 2.6732308864593506; \n",
      "fold: TRAIN; iteration: 1221; epoch: 0; loss: 2.6645421981811523; \n",
      "fold: TRAIN; iteration: 1222; epoch: 0; loss: 2.768995761871338; \n",
      "fold: TRAIN; iteration: 1223; epoch: 0; loss: 2.3491437435150146; \n",
      "fold: TRAIN; iteration: 1224; epoch: 0; loss: 2.8387796878814697; \n",
      "fold: TRAIN; iteration: 1225; epoch: 0; loss: 2.5641889572143555; \n",
      "fold: TRAIN; iteration: 1226; epoch: 0; loss: 2.336167335510254; \n",
      "fold: TRAIN; iteration: 1227; epoch: 0; loss: 2.5047483444213867; \n",
      "fold: TRAIN; iteration: 1228; epoch: 0; loss: 2.2771294116973877; \n",
      "fold: TRAIN; iteration: 1229; epoch: 0; loss: 2.7114737033843994; \n",
      "fold: TRAIN; iteration: 1230; epoch: 0; loss: 2.905984401702881; \n",
      "fold: TRAIN; iteration: 1231; epoch: 0; loss: 2.589520215988159; \n",
      "fold: TRAIN; iteration: 1232; epoch: 0; loss: 2.5024096965789795; \n",
      "fold: TRAIN; iteration: 1233; epoch: 0; loss: 2.414116859436035; \n",
      "fold: TRAIN; iteration: 1234; epoch: 0; loss: 2.788820743560791; \n",
      "fold: TRAIN; iteration: 1235; epoch: 0; loss: 2.646883487701416; \n",
      "fold: TRAIN; iteration: 1236; epoch: 0; loss: 2.689833402633667; \n",
      "fold: TRAIN; iteration: 1237; epoch: 0; loss: 2.3917527198791504; \n",
      "fold: TRAIN; iteration: 1238; epoch: 0; loss: 2.389373540878296; \n",
      "fold: TRAIN; iteration: 1239; epoch: 0; loss: 2.4295079708099365; \n",
      "fold: TRAIN; iteration: 1240; epoch: 0; loss: 2.7996044158935547; \n",
      "fold: TRAIN; iteration: 1241; epoch: 0; loss: 2.6467254161834717; \n",
      "fold: TRAIN; iteration: 1242; epoch: 0; loss: 2.347383737564087; \n",
      "fold: TRAIN; iteration: 1243; epoch: 0; loss: 2.5682687759399414; \n",
      "fold: TRAIN; iteration: 1244; epoch: 0; loss: 2.517411708831787; \n",
      "fold: TRAIN; iteration: 1245; epoch: 0; loss: 2.6609432697296143; \n",
      "fold: TRAIN; iteration: 1246; epoch: 0; loss: 2.418489933013916; \n",
      "fold: TRAIN; iteration: 1247; epoch: 0; loss: 2.719935894012451; \n",
      "fold: TRAIN; iteration: 1248; epoch: 0; loss: 2.6579761505126953; \n",
      "fold: TRAIN; iteration: 1249; epoch: 0; loss: 2.444023370742798; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 1250; epoch: 0; loss: 2.6041488647460938; \n",
      "fold: TRAIN; iteration: 1251; epoch: 0; loss: 2.5522241592407227; \n",
      "fold: TRAIN; iteration: 1252; epoch: 0; loss: 2.4567761421203613; \n",
      "fold: TRAIN; iteration: 1253; epoch: 0; loss: 2.3785057067871094; \n",
      "fold: TRAIN; iteration: 1254; epoch: 0; loss: 2.580000638961792; \n",
      "fold: TRAIN; iteration: 1255; epoch: 0; loss: 2.4596662521362305; \n",
      "fold: TRAIN; iteration: 1256; epoch: 0; loss: 2.6239397525787354; \n",
      "fold: TRAIN; iteration: 1257; epoch: 0; loss: 2.5650362968444824; \n",
      "fold: TRAIN; iteration: 1258; epoch: 0; loss: 2.923020839691162; \n",
      "fold: TRAIN; iteration: 1259; epoch: 0; loss: 2.434727668762207; \n",
      "fold: TRAIN; iteration: 1260; epoch: 0; loss: 2.292541027069092; \n",
      "fold: TRAIN; iteration: 1261; epoch: 0; loss: 2.371037721633911; \n",
      "fold: TRAIN; iteration: 1262; epoch: 0; loss: 2.726065158843994; \n",
      "fold: TRAIN; iteration: 1263; epoch: 0; loss: 2.5731890201568604; \n",
      "fold: TRAIN; iteration: 1264; epoch: 0; loss: 2.7455894947052; \n",
      "fold: TRAIN; iteration: 1265; epoch: 0; loss: 2.7802464962005615; \n",
      "fold: TRAIN; iteration: 1266; epoch: 0; loss: 2.5711963176727295; \n",
      "fold: TRAIN; iteration: 1267; epoch: 0; loss: 2.6110639572143555; \n",
      "fold: TRAIN; iteration: 1268; epoch: 0; loss: 2.3745009899139404; \n",
      "fold: TRAIN; iteration: 1269; epoch: 0; loss: 2.752927780151367; \n",
      "fold: TRAIN; iteration: 1270; epoch: 0; loss: 2.4985408782958984; \n",
      "fold: TRAIN; iteration: 1271; epoch: 0; loss: 2.589742660522461; \n",
      "fold: TRAIN; iteration: 1272; epoch: 0; loss: 2.634819984436035; \n",
      "fold: TRAIN; iteration: 1273; epoch: 0; loss: 2.7499091625213623; \n",
      "fold: TRAIN; iteration: 1274; epoch: 0; loss: 2.6566383838653564; \n",
      "fold: TRAIN; iteration: 1275; epoch: 0; loss: 2.2489168643951416; \n",
      "fold: TRAIN; iteration: 1276; epoch: 0; loss: 2.7879672050476074; \n",
      "fold: TRAIN; iteration: 1277; epoch: 0; loss: 2.3488099575042725; \n",
      "fold: TRAIN; iteration: 1278; epoch: 0; loss: 2.520340919494629; \n",
      "fold: TRAIN; iteration: 1279; epoch: 0; loss: 2.505824089050293; \n",
      "fold: TRAIN; iteration: 1280; epoch: 0; loss: 2.6736977100372314; \n",
      "fold: TRAIN; iteration: 1281; epoch: 0; loss: 2.3715481758117676; \n",
      "fold: TRAIN; iteration: 1282; epoch: 0; loss: 2.6385719776153564; \n",
      "fold: TRAIN; iteration: 1283; epoch: 0; loss: 2.584031105041504; \n",
      "fold: TRAIN; iteration: 1284; epoch: 0; loss: 2.8189640045166016; \n",
      "fold: TRAIN; iteration: 1285; epoch: 0; loss: 2.6055102348327637; \n",
      "fold: TRAIN; iteration: 1286; epoch: 0; loss: 2.4317522048950195; \n",
      "fold: TRAIN; iteration: 1287; epoch: 0; loss: 2.6236276626586914; \n",
      "fold: TRAIN; iteration: 1288; epoch: 0; loss: 2.548858404159546; \n",
      "fold: TRAIN; iteration: 1289; epoch: 0; loss: 2.703568696975708; \n",
      "fold: TRAIN; iteration: 1290; epoch: 0; loss: 2.6275670528411865; \n",
      "fold: TRAIN; iteration: 1291; epoch: 0; loss: 2.8750405311584473; \n",
      "fold: TRAIN; iteration: 1292; epoch: 0; loss: 2.836423397064209; \n",
      "fold: TRAIN; iteration: 1293; epoch: 0; loss: 2.73335337638855; \n",
      "fold: TRAIN; iteration: 1294; epoch: 0; loss: 2.5590696334838867; \n",
      "fold: TRAIN; iteration: 1295; epoch: 0; loss: 2.655029535293579; \n",
      "fold: TRAIN; iteration: 1296; epoch: 0; loss: 2.4434726238250732; \n",
      "fold: TRAIN; iteration: 1297; epoch: 0; loss: 2.586648941040039; \n",
      "fold: TRAIN; iteration: 1298; epoch: 0; loss: 2.532033920288086; \n",
      "fold: TRAIN; iteration: 1299; epoch: 0; loss: 2.596245050430298; \n",
      "fold: TRAIN; iteration: 1300; epoch: 0; loss: 2.651297092437744; \n",
      "fold: TRAIN; iteration: 1301; epoch: 0; loss: 2.672135829925537; \n",
      "fold: TRAIN; iteration: 1302; epoch: 0; loss: 2.763021469116211; \n",
      "fold: TRAIN; iteration: 1303; epoch: 0; loss: 2.378915309906006; \n",
      "fold: TRAIN; iteration: 1304; epoch: 0; loss: 2.6915459632873535; \n",
      "fold: TRAIN; iteration: 1305; epoch: 0; loss: 2.805511474609375; \n",
      "fold: TRAIN; iteration: 1306; epoch: 0; loss: 2.4114344120025635; \n",
      "fold: TRAIN; iteration: 1307; epoch: 0; loss: 2.5901153087615967; \n",
      "fold: TRAIN; iteration: 1308; epoch: 0; loss: 2.489614725112915; \n",
      "fold: TRAIN; iteration: 1309; epoch: 0; loss: 2.5433247089385986; \n",
      "fold: TRAIN; iteration: 1310; epoch: 0; loss: 2.6025936603546143; \n",
      "fold: TRAIN; iteration: 1311; epoch: 0; loss: 2.563356399536133; \n",
      "fold: TRAIN; iteration: 1312; epoch: 0; loss: 2.6098368167877197; \n",
      "fold: TRAIN; iteration: 1313; epoch: 0; loss: 2.711592435836792; \n",
      "fold: TRAIN; iteration: 1314; epoch: 0; loss: 2.435858726501465; \n",
      "fold: TRAIN; iteration: 1315; epoch: 0; loss: 2.6194612979888916; \n",
      "fold: TRAIN; iteration: 1316; epoch: 0; loss: 2.550342082977295; \n",
      "fold: TRAIN; iteration: 1317; epoch: 0; loss: 2.556642532348633; \n",
      "fold: TRAIN; iteration: 1318; epoch: 0; loss: 2.598895788192749; \n",
      "fold: TRAIN; iteration: 1319; epoch: 0; loss: 2.668361186981201; \n",
      "fold: TRAIN; iteration: 1320; epoch: 0; loss: 2.360426425933838; \n",
      "fold: TRAIN; iteration: 1321; epoch: 0; loss: 2.5489721298217773; \n",
      "fold: TRAIN; iteration: 1322; epoch: 0; loss: 2.4688048362731934; \n",
      "fold: TRAIN; iteration: 1323; epoch: 0; loss: 2.8647143840789795; \n",
      "fold: TRAIN; iteration: 1324; epoch: 0; loss: 2.899378776550293; \n",
      "fold: TRAIN; iteration: 1325; epoch: 0; loss: 2.5254321098327637; \n",
      "fold: TRAIN; iteration: 1326; epoch: 0; loss: 2.696786403656006; \n",
      "fold: TRAIN; iteration: 1327; epoch: 0; loss: 2.43985652923584; \n",
      "fold: TRAIN; iteration: 1328; epoch: 0; loss: 2.4374427795410156; \n",
      "fold: TRAIN; iteration: 1329; epoch: 0; loss: 2.5572495460510254; \n",
      "fold: TRAIN; iteration: 1330; epoch: 0; loss: 2.6763253211975098; \n",
      "fold: TRAIN; iteration: 1331; epoch: 0; loss: 2.704555034637451; \n",
      "fold: TRAIN; iteration: 1332; epoch: 0; loss: 2.7101657390594482; \n",
      "fold: TRAIN; iteration: 1333; epoch: 0; loss: 2.308781623840332; \n",
      "fold: TRAIN; iteration: 1334; epoch: 0; loss: 2.7218270301818848; \n",
      "fold: TRAIN; iteration: 1335; epoch: 0; loss: 2.3647964000701904; \n",
      "fold: TRAIN; iteration: 1336; epoch: 0; loss: 2.856199026107788; \n",
      "fold: TRAIN; iteration: 1337; epoch: 0; loss: 2.481623411178589; \n",
      "fold: TRAIN; iteration: 1338; epoch: 0; loss: 2.4442973136901855; \n",
      "fold: TRAIN; iteration: 1339; epoch: 0; loss: 2.3634836673736572; \n",
      "fold: TRAIN; iteration: 1340; epoch: 0; loss: 2.7720513343811035; \n",
      "fold: TRAIN; iteration: 1341; epoch: 0; loss: 2.8187062740325928; \n",
      "fold: TRAIN; iteration: 1342; epoch: 0; loss: 2.553892135620117; \n",
      "fold: TRAIN; iteration: 1343; epoch: 0; loss: 2.5860652923583984; \n",
      "fold: TRAIN; iteration: 1344; epoch: 0; loss: 2.511558771133423; \n",
      "fold: TRAIN; iteration: 1345; epoch: 0; loss: 2.6817498207092285; \n",
      "fold: TRAIN; iteration: 1346; epoch: 0; loss: 2.5610573291778564; \n",
      "fold: TRAIN; iteration: 1347; epoch: 0; loss: 2.4967293739318848; \n",
      "fold: TRAIN; iteration: 1348; epoch: 0; loss: 2.5567922592163086; \n",
      "fold: TRAIN; iteration: 1349; epoch: 0; loss: 2.765692710876465; \n",
      "fold: TRAIN; iteration: 1350; epoch: 0; loss: 2.745258092880249; \n",
      "fold: TRAIN; iteration: 1351; epoch: 0; loss: 2.4824371337890625; \n",
      "fold: TRAIN; iteration: 1352; epoch: 0; loss: 2.652514696121216; \n",
      "fold: TRAIN; iteration: 1353; epoch: 0; loss: 2.587925910949707; \n",
      "fold: TRAIN; iteration: 1354; epoch: 0; loss: 2.5704517364501953; \n",
      "fold: TRAIN; iteration: 1355; epoch: 0; loss: 2.5897533893585205; \n",
      "fold: TRAIN; iteration: 1356; epoch: 0; loss: 2.455392599105835; \n",
      "fold: TRAIN; iteration: 1357; epoch: 0; loss: 2.6418018341064453; \n",
      "fold: TRAIN; iteration: 1358; epoch: 0; loss: 2.7181997299194336; \n",
      "fold: TRAIN; iteration: 1359; epoch: 0; loss: 2.529461145401001; \n",
      "fold: TRAIN; iteration: 1360; epoch: 0; loss: 2.666738510131836; \n",
      "fold: TRAIN; iteration: 1361; epoch: 0; loss: 2.5175347328186035; \n",
      "fold: TRAIN; iteration: 1362; epoch: 0; loss: 2.3882646560668945; \n",
      "fold: TRAIN; iteration: 1363; epoch: 0; loss: 2.4136741161346436; \n",
      "fold: TRAIN; iteration: 1364; epoch: 0; loss: 2.764382839202881; \n",
      "fold: TRAIN; iteration: 1365; epoch: 0; loss: 2.583667516708374; \n",
      "fold: TRAIN; iteration: 1366; epoch: 0; loss: 2.446059465408325; \n",
      "fold: TRAIN; iteration: 1367; epoch: 0; loss: 2.6389660835266113; \n",
      "fold: TRAIN; iteration: 1368; epoch: 0; loss: 2.3445677757263184; \n",
      "fold: TRAIN; iteration: 1369; epoch: 0; loss: 2.5617880821228027; \n",
      "fold: TRAIN; iteration: 1370; epoch: 0; loss: 2.7810513973236084; \n",
      "fold: TRAIN; iteration: 1371; epoch: 0; loss: 2.6370770931243896; \n",
      "fold: TRAIN; iteration: 1372; epoch: 0; loss: 2.5684702396392822; \n",
      "fold: TRAIN; iteration: 1373; epoch: 0; loss: 2.5394346714019775; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 1374; epoch: 0; loss: 2.788285493850708; \n",
      "fold: TRAIN; iteration: 1375; epoch: 0; loss: 2.343899726867676; \n",
      "fold: TRAIN; iteration: 1376; epoch: 0; loss: 2.720607042312622; \n",
      "fold: TRAIN; iteration: 1377; epoch: 0; loss: 2.4855294227600098; \n",
      "fold: TRAIN; iteration: 1378; epoch: 0; loss: 2.481715202331543; \n",
      "fold: TRAIN; iteration: 1379; epoch: 0; loss: 2.684149742126465; \n",
      "fold: TRAIN; iteration: 1380; epoch: 0; loss: 2.6578660011291504; \n",
      "fold: TRAIN; iteration: 1381; epoch: 0; loss: 2.3734023571014404; \n",
      "fold: TRAIN; iteration: 1382; epoch: 0; loss: 2.4031758308410645; \n",
      "fold: TRAIN; iteration: 1383; epoch: 0; loss: 2.5284225940704346; \n",
      "fold: TRAIN; iteration: 1384; epoch: 0; loss: 2.4784650802612305; \n",
      "fold: TRAIN; iteration: 1385; epoch: 0; loss: 2.4060518741607666; \n",
      "fold: TRAIN; iteration: 1386; epoch: 0; loss: 2.5390126705169678; \n",
      "fold: TRAIN; iteration: 1387; epoch: 0; loss: 2.5069053173065186; \n",
      "fold: TRAIN; iteration: 1388; epoch: 0; loss: 2.815866708755493; \n",
      "fold: TRAIN; iteration: 1389; epoch: 0; loss: 2.2908754348754883; \n",
      "fold: TRAIN; iteration: 1390; epoch: 0; loss: 2.4887640476226807; \n",
      "fold: TRAIN; iteration: 1391; epoch: 0; loss: 2.580386161804199; \n",
      "fold: TRAIN; iteration: 1392; epoch: 0; loss: 2.587822198867798; \n",
      "fold: TRAIN; iteration: 1393; epoch: 0; loss: 2.7816948890686035; \n",
      "fold: TRAIN; iteration: 1394; epoch: 0; loss: 2.645376682281494; \n",
      "fold: TRAIN; iteration: 1395; epoch: 0; loss: 2.438711404800415; \n",
      "fold: TRAIN; iteration: 1396; epoch: 0; loss: 2.4515345096588135; \n",
      "fold: TRAIN; iteration: 1397; epoch: 0; loss: 2.3105106353759766; \n",
      "fold: TRAIN; iteration: 1398; epoch: 0; loss: 2.531118869781494; \n",
      "fold: TRAIN; iteration: 1399; epoch: 0; loss: 2.416604995727539; \n",
      "fold: TRAIN; iteration: 1400; epoch: 0; loss: 2.740441083908081; \n",
      "fold: TRAIN; iteration: 1401; epoch: 0; loss: 2.723939895629883; \n",
      "fold: TRAIN; iteration: 1402; epoch: 0; loss: 2.4744956493377686; \n",
      "fold: TRAIN; iteration: 1403; epoch: 0; loss: 2.770925283432007; \n",
      "fold: TRAIN; iteration: 1404; epoch: 0; loss: 2.529510021209717; \n",
      "fold: TRAIN; iteration: 1405; epoch: 0; loss: 2.678358793258667; \n",
      "fold: TRAIN; iteration: 1406; epoch: 0; loss: 2.6832175254821777; \n",
      "fold: TRAIN; iteration: 1407; epoch: 0; loss: 2.3860013484954834; \n",
      "fold: TRAIN; iteration: 1408; epoch: 0; loss: 2.5885565280914307; \n",
      "fold: TRAIN; iteration: 1409; epoch: 0; loss: 2.5892345905303955; \n",
      "fold: TRAIN; iteration: 1410; epoch: 0; loss: 2.2937026023864746; \n",
      "fold: TRAIN; iteration: 1411; epoch: 0; loss: 2.3061323165893555; \n",
      "fold: TRAIN; iteration: 1412; epoch: 0; loss: 2.6155591011047363; \n",
      "fold: TRAIN; iteration: 1413; epoch: 0; loss: 2.6187849044799805; \n",
      "fold: TRAIN; iteration: 1414; epoch: 0; loss: 2.442561626434326; \n",
      "fold: TRAIN; iteration: 1415; epoch: 0; loss: 2.5719776153564453; \n",
      "fold: TRAIN; iteration: 1416; epoch: 0; loss: 2.4789493083953857; \n",
      "fold: TRAIN; iteration: 1417; epoch: 0; loss: 2.3704826831817627; \n",
      "fold: TRAIN; iteration: 1418; epoch: 0; loss: 2.449036121368408; \n",
      "fold: TRAIN; iteration: 1419; epoch: 0; loss: 2.509392738342285; \n",
      "fold: TRAIN; iteration: 1420; epoch: 0; loss: 2.468827247619629; \n",
      "fold: TRAIN; iteration: 1421; epoch: 0; loss: 2.747074604034424; \n",
      "fold: TRAIN; iteration: 1422; epoch: 0; loss: 2.6491968631744385; \n",
      "fold: TRAIN; iteration: 1423; epoch: 0; loss: 2.6745331287384033; \n",
      "fold: TRAIN; iteration: 1424; epoch: 0; loss: 2.8422698974609375; \n",
      "fold: TRAIN; iteration: 1425; epoch: 0; loss: 2.6584577560424805; \n",
      "fold: TRAIN; iteration: 1426; epoch: 0; loss: 2.9169390201568604; \n",
      "fold: TRAIN; iteration: 1427; epoch: 0; loss: 2.775369167327881; \n",
      "fold: TRAIN; iteration: 1428; epoch: 0; loss: 2.616079807281494; \n",
      "fold: TRAIN; iteration: 1429; epoch: 0; loss: 2.3798515796661377; \n",
      "fold: TRAIN; iteration: 1430; epoch: 0; loss: 2.5331718921661377; \n",
      "fold: TRAIN; iteration: 1431; epoch: 0; loss: 2.9547107219696045; \n",
      "fold: TRAIN; iteration: 1432; epoch: 0; loss: 2.602282762527466; \n",
      "fold: TRAIN; iteration: 1433; epoch: 0; loss: 2.4521291255950928; \n",
      "fold: TRAIN; iteration: 1434; epoch: 0; loss: 2.556710958480835; \n",
      "fold: TRAIN; iteration: 1435; epoch: 0; loss: 2.619173049926758; \n",
      "fold: TRAIN; iteration: 1436; epoch: 0; loss: 2.6911444664001465; \n",
      "fold: TRAIN; iteration: 1437; epoch: 0; loss: 2.5240068435668945; \n",
      "fold: TRAIN; iteration: 1438; epoch: 0; loss: 2.4948434829711914; \n",
      "fold: TRAIN; iteration: 1439; epoch: 0; loss: 2.5280046463012695; \n",
      "fold: TRAIN; iteration: 1440; epoch: 0; loss: 2.3985280990600586; \n",
      "fold: TRAIN; iteration: 1441; epoch: 0; loss: 2.609226703643799; \n",
      "fold: TRAIN; iteration: 1442; epoch: 0; loss: 2.5126259326934814; \n",
      "fold: TRAIN; iteration: 1443; epoch: 0; loss: 2.623091697692871; \n",
      "fold: TRAIN; iteration: 1444; epoch: 0; loss: 2.5096378326416016; \n",
      "fold: TRAIN; iteration: 1445; epoch: 0; loss: 2.840325117111206; \n",
      "fold: TRAIN; iteration: 1446; epoch: 0; loss: 2.492788076400757; \n",
      "fold: TRAIN; iteration: 1447; epoch: 0; loss: 2.764481782913208; \n",
      "fold: TRAIN; iteration: 1448; epoch: 0; loss: 2.4273428916931152; \n",
      "fold: TRAIN; iteration: 1449; epoch: 0; loss: 2.7186877727508545; \n",
      "fold: TRAIN; iteration: 1450; epoch: 0; loss: 2.464149236679077; \n",
      "fold: TRAIN; iteration: 1451; epoch: 0; loss: 2.7924001216888428; \n",
      "fold: TRAIN; iteration: 1452; epoch: 0; loss: 2.3513023853302; \n",
      "fold: TRAIN; iteration: 1453; epoch: 0; loss: 2.4341745376586914; \n",
      "fold: TRAIN; iteration: 1454; epoch: 0; loss: 2.641155958175659; \n",
      "fold: TRAIN; iteration: 1455; epoch: 0; loss: 2.8221514225006104; \n",
      "fold: TRAIN; iteration: 1456; epoch: 0; loss: 2.341433048248291; \n",
      "fold: TRAIN; iteration: 1457; epoch: 0; loss: 2.724574327468872; \n",
      "fold: TRAIN; iteration: 1458; epoch: 0; loss: 2.432154893875122; \n",
      "fold: TRAIN; iteration: 1459; epoch: 0; loss: 2.5607104301452637; \n",
      "fold: TRAIN; iteration: 1460; epoch: 0; loss: 2.6216659545898438; \n",
      "fold: TRAIN; iteration: 1461; epoch: 0; loss: 2.454423189163208; \n",
      "fold: TRAIN; iteration: 1462; epoch: 0; loss: 2.6946020126342773; \n",
      "fold: TRAIN; iteration: 1463; epoch: 0; loss: 2.6211774349212646; \n",
      "fold: TRAIN; iteration: 1464; epoch: 0; loss: 2.6479668617248535; \n",
      "fold: TRAIN; iteration: 1465; epoch: 0; loss: 2.426024913787842; \n",
      "fold: TRAIN; iteration: 1466; epoch: 0; loss: 2.672816753387451; \n",
      "fold: TRAIN; iteration: 1467; epoch: 0; loss: 2.433957576751709; \n",
      "fold: TRAIN; iteration: 1468; epoch: 0; loss: 2.5736305713653564; \n",
      "fold: TRAIN; iteration: 1469; epoch: 0; loss: 2.4369771480560303; \n",
      "fold: TRAIN; iteration: 1470; epoch: 0; loss: 2.2470502853393555; \n",
      "fold: TRAIN; iteration: 1471; epoch: 0; loss: 2.6199746131896973; \n",
      "fold: TRAIN; iteration: 1472; epoch: 0; loss: 2.475162982940674; \n",
      "fold: TRAIN; iteration: 1473; epoch: 0; loss: 2.520908832550049; \n",
      "fold: TRAIN; iteration: 1474; epoch: 0; loss: 2.709113836288452; \n",
      "fold: TRAIN; iteration: 1475; epoch: 0; loss: 2.616652250289917; \n",
      "fold: TRAIN; iteration: 1476; epoch: 0; loss: 2.7888097763061523; \n",
      "fold: TRAIN; iteration: 1477; epoch: 0; loss: 2.623339891433716; \n",
      "fold: TRAIN; iteration: 1478; epoch: 0; loss: 2.510434150695801; \n",
      "fold: TRAIN; iteration: 1479; epoch: 0; loss: 2.6649696826934814; \n",
      "fold: TRAIN; iteration: 1480; epoch: 0; loss: 2.7396559715270996; \n",
      "fold: TRAIN; iteration: 1481; epoch: 0; loss: 2.5733635425567627; \n",
      "fold: TRAIN; iteration: 1482; epoch: 0; loss: 2.5884292125701904; \n",
      "fold: TRAIN; iteration: 1483; epoch: 0; loss: 2.3950002193450928; \n",
      "fold: TRAIN; iteration: 1484; epoch: 0; loss: 2.7695271968841553; \n",
      "fold: TRAIN; iteration: 1485; epoch: 0; loss: 2.831531286239624; \n",
      "fold: TRAIN; iteration: 1486; epoch: 0; loss: 2.5396010875701904; \n",
      "fold: TRAIN; iteration: 1487; epoch: 0; loss: 2.31978440284729; \n",
      "fold: TRAIN; iteration: 1488; epoch: 0; loss: 2.3482906818389893; \n",
      "fold: TRAIN; iteration: 1489; epoch: 0; loss: 2.8133771419525146; \n",
      "fold: TRAIN; iteration: 1490; epoch: 0; loss: 2.729346513748169; \n",
      "fold: TRAIN; iteration: 1491; epoch: 0; loss: 2.595273733139038; \n",
      "fold: TRAIN; iteration: 1492; epoch: 0; loss: 2.647279739379883; \n",
      "fold: TRAIN; iteration: 1493; epoch: 0; loss: 2.780132532119751; \n",
      "fold: TRAIN; iteration: 1494; epoch: 0; loss: 2.7255499362945557; \n",
      "fold: TRAIN; iteration: 1495; epoch: 0; loss: 2.5805885791778564; \n",
      "fold: TRAIN; iteration: 1496; epoch: 0; loss: 2.446798801422119; \n",
      "fold: TRAIN; iteration: 1497; epoch: 0; loss: 2.562844753265381; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 1498; epoch: 0; loss: 2.361706495285034; \n",
      "fold: TRAIN; iteration: 1499; epoch: 0; loss: 2.488914728164673; \n",
      "fold: TRAIN; iteration: 1500; epoch: 0; loss: 2.4358909130096436; \n",
      "fold: TRAIN; iteration: 1501; epoch: 0; loss: 2.7047629356384277; \n",
      "fold: TRAIN; iteration: 1502; epoch: 0; loss: 2.397745132446289; \n",
      "fold: TRAIN; iteration: 1503; epoch: 0; loss: 2.657252311706543; \n",
      "fold: TRAIN; iteration: 1504; epoch: 0; loss: 2.4919698238372803; \n",
      "fold: TRAIN; iteration: 1505; epoch: 0; loss: 2.556795597076416; \n",
      "fold: TRAIN; iteration: 1506; epoch: 0; loss: 2.324160099029541; \n",
      "fold: TRAIN; iteration: 1507; epoch: 0; loss: 2.6054062843322754; \n",
      "fold: TRAIN; iteration: 1508; epoch: 0; loss: 2.6462619304656982; \n",
      "fold: TRAIN; iteration: 1509; epoch: 0; loss: 2.5789740085601807; \n",
      "fold: TRAIN; iteration: 1510; epoch: 0; loss: 2.5357823371887207; \n",
      "fold: TRAIN; iteration: 1511; epoch: 0; loss: 2.683260202407837; \n",
      "fold: TRAIN; iteration: 1512; epoch: 0; loss: 2.606450080871582; \n",
      "fold: TRAIN; iteration: 1513; epoch: 0; loss: 2.6857800483703613; \n",
      "fold: TRAIN; iteration: 1514; epoch: 0; loss: 2.374462366104126; \n",
      "fold: TRAIN; iteration: 1515; epoch: 0; loss: 2.6793041229248047; \n",
      "fold: TRAIN; iteration: 1516; epoch: 0; loss: 2.704094171524048; \n",
      "fold: TRAIN; iteration: 1517; epoch: 0; loss: 2.2788994312286377; \n",
      "fold: TRAIN; iteration: 1518; epoch: 0; loss: 2.7580339908599854; \n",
      "fold: TRAIN; iteration: 1519; epoch: 0; loss: 2.778787136077881; \n",
      "fold: TRAIN; iteration: 1520; epoch: 0; loss: 2.482302665710449; \n",
      "fold: TRAIN; iteration: 1521; epoch: 0; loss: 2.604667901992798; \n",
      "fold: TRAIN; iteration: 1522; epoch: 0; loss: 2.469595432281494; \n",
      "fold: TRAIN; iteration: 1523; epoch: 0; loss: 2.5027925968170166; \n",
      "fold: TRAIN; iteration: 1524; epoch: 0; loss: 2.57293701171875; \n",
      "fold: TRAIN; iteration: 1525; epoch: 0; loss: 2.7016358375549316; \n",
      "fold: TRAIN; iteration: 1526; epoch: 0; loss: 2.6465206146240234; \n",
      "fold: TRAIN; iteration: 1527; epoch: 0; loss: 2.3737146854400635; \n",
      "fold: TRAIN; iteration: 1528; epoch: 0; loss: 2.669651985168457; \n",
      "fold: TRAIN; iteration: 1529; epoch: 0; loss: 2.8178322315216064; \n",
      "fold: TRAIN; iteration: 1530; epoch: 0; loss: 2.626171827316284; \n",
      "fold: TRAIN; iteration: 1531; epoch: 0; loss: 2.3919994831085205; \n",
      "fold: TRAIN; iteration: 1532; epoch: 0; loss: 2.722926616668701; \n",
      "fold: TRAIN; iteration: 1533; epoch: 0; loss: 2.6344430446624756; \n",
      "fold: TRAIN; iteration: 1534; epoch: 0; loss: 2.6682686805725098; \n",
      "fold: TRAIN; iteration: 1535; epoch: 0; loss: 2.53408145904541; \n",
      "fold: TRAIN; iteration: 1536; epoch: 0; loss: 2.477046251296997; \n",
      "fold: TRAIN; iteration: 1537; epoch: 0; loss: 2.732513427734375; \n",
      "fold: TRAIN; iteration: 1538; epoch: 0; loss: 2.4027626514434814; \n",
      "fold: TRAIN; iteration: 1539; epoch: 0; loss: 2.5047836303710938; \n",
      "fold: TRAIN; iteration: 1540; epoch: 0; loss: 2.7538998126983643; \n",
      "fold: TRAIN; iteration: 1541; epoch: 0; loss: 2.5129892826080322; \n",
      "fold: TRAIN; iteration: 1542; epoch: 0; loss: 2.6036624908447266; \n",
      "fold: TRAIN; iteration: 1543; epoch: 0; loss: 2.5977272987365723; \n",
      "fold: TRAIN; iteration: 1544; epoch: 0; loss: 2.5994560718536377; \n",
      "fold: TRAIN; iteration: 1545; epoch: 0; loss: 2.30151104927063; \n",
      "fold: TRAIN; iteration: 1546; epoch: 0; loss: 2.3352832794189453; \n",
      "fold: TRAIN; iteration: 1547; epoch: 0; loss: 2.7121126651763916; \n",
      "fold: TRAIN; iteration: 1548; epoch: 0; loss: 2.5902175903320312; \n",
      "fold: TRAIN; iteration: 1549; epoch: 0; loss: 2.578817129135132; \n",
      "fold: TRAIN; iteration: 1550; epoch: 0; loss: 2.5523788928985596; \n",
      "fold: TRAIN; iteration: 1551; epoch: 0; loss: 2.5005364418029785; \n",
      "fold: TRAIN; iteration: 1552; epoch: 0; loss: 2.5533270835876465; \n",
      "fold: TRAIN; iteration: 1553; epoch: 0; loss: 2.604416847229004; \n",
      "fold: TRAIN; iteration: 1554; epoch: 0; loss: 2.4898650646209717; \n",
      "fold: TRAIN; iteration: 1555; epoch: 0; loss: 2.567117929458618; \n",
      "fold: TRAIN; iteration: 1556; epoch: 0; loss: 2.7320873737335205; \n",
      "fold: TRAIN; iteration: 1557; epoch: 0; loss: 2.5832953453063965; \n",
      "fold: TRAIN; iteration: 1558; epoch: 0; loss: 2.4646997451782227; \n",
      "fold: TRAIN; iteration: 1559; epoch: 0; loss: 2.3401997089385986; \n",
      "fold: TRAIN; iteration: 1560; epoch: 0; loss: 2.603605270385742; \n",
      "fold: TRAIN; iteration: 1561; epoch: 0; loss: 2.511929988861084; \n",
      "fold: TRAIN; iteration: 1562; epoch: 0; loss: 2.4477059841156006; \n",
      "fold: TRAIN; iteration: 1563; epoch: 0; loss: 2.5486602783203125; \n",
      "fold: TRAIN; iteration: 1564; epoch: 0; loss: 2.4354660511016846; \n",
      "fold: TRAIN; iteration: 1565; epoch: 0; loss: 2.634190559387207; \n",
      "fold: TRAIN; iteration: 1566; epoch: 0; loss: 2.5384280681610107; \n",
      "fold: TRAIN; iteration: 1567; epoch: 0; loss: 2.4611361026763916; \n",
      "fold: TRAIN; iteration: 1568; epoch: 0; loss: 2.480363368988037; \n",
      "fold: TRAIN; iteration: 1569; epoch: 0; loss: 2.366795778274536; \n",
      "fold: TRAIN; iteration: 1570; epoch: 0; loss: 2.5019829273223877; \n",
      "fold: TRAIN; iteration: 1571; epoch: 0; loss: 2.7223832607269287; \n",
      "fold: TRAIN; iteration: 1572; epoch: 1; loss: 2.6341354846954346; \n",
      "fold: TRAIN; iteration: 1573; epoch: 1; loss: 2.4000160694122314; \n",
      "fold: TRAIN; iteration: 1574; epoch: 1; loss: 2.548074722290039; \n",
      "fold: TRAIN; iteration: 1575; epoch: 1; loss: 2.5275423526763916; \n",
      "fold: TRAIN; iteration: 1576; epoch: 1; loss: 2.439016342163086; \n",
      "fold: TRAIN; iteration: 1577; epoch: 1; loss: 2.440793037414551; \n",
      "fold: TRAIN; iteration: 1578; epoch: 1; loss: 2.4017302989959717; \n",
      "fold: TRAIN; iteration: 1579; epoch: 1; loss: 2.4645614624023438; \n",
      "fold: TRAIN; iteration: 1580; epoch: 1; loss: 2.33254337310791; \n",
      "fold: TRAIN; iteration: 1581; epoch: 1; loss: 2.3171463012695312; \n",
      "fold: TRAIN; iteration: 1582; epoch: 1; loss: 2.5665249824523926; \n",
      "fold: TRAIN; iteration: 1583; epoch: 1; loss: 2.3978607654571533; \n",
      "fold: TRAIN; iteration: 1584; epoch: 1; loss: 2.4192354679107666; \n",
      "fold: TRAIN; iteration: 1585; epoch: 1; loss: 2.306229591369629; \n",
      "fold: TRAIN; iteration: 1586; epoch: 1; loss: 2.6860263347625732; \n",
      "fold: TRAIN; iteration: 1587; epoch: 1; loss: 2.8054370880126953; \n",
      "fold: TRAIN; iteration: 1588; epoch: 1; loss: 2.509079694747925; \n",
      "fold: TRAIN; iteration: 1589; epoch: 1; loss: 2.446986436843872; \n",
      "fold: TRAIN; iteration: 1590; epoch: 1; loss: 2.4235587120056152; \n",
      "fold: TRAIN; iteration: 1591; epoch: 1; loss: 2.5085289478302; \n",
      "fold: TRAIN; iteration: 1592; epoch: 1; loss: 2.5476465225219727; \n",
      "fold: TRAIN; iteration: 1593; epoch: 1; loss: 2.450437068939209; \n",
      "fold: TRAIN; iteration: 1594; epoch: 1; loss: 2.4742770195007324; \n",
      "fold: TRAIN; iteration: 1595; epoch: 1; loss: 2.6291933059692383; \n",
      "fold: TRAIN; iteration: 1596; epoch: 1; loss: 2.486750841140747; \n",
      "fold: TRAIN; iteration: 1597; epoch: 1; loss: 2.4800686836242676; \n",
      "fold: TRAIN; iteration: 1598; epoch: 1; loss: 2.5393669605255127; \n",
      "fold: TRAIN; iteration: 1599; epoch: 1; loss: 2.3431715965270996; \n",
      "fold: TRAIN; iteration: 1600; epoch: 1; loss: 2.4493465423583984; \n",
      "fold: TRAIN; iteration: 1601; epoch: 1; loss: 2.3490171432495117; \n",
      "fold: TRAIN; iteration: 1602; epoch: 1; loss: 2.520233392715454; \n",
      "fold: TRAIN; iteration: 1603; epoch: 1; loss: 2.568521022796631; \n",
      "fold: TRAIN; iteration: 1604; epoch: 1; loss: 2.4456048011779785; \n",
      "fold: TRAIN; iteration: 1605; epoch: 1; loss: 2.4167373180389404; \n",
      "fold: TRAIN; iteration: 1606; epoch: 1; loss: 2.5516321659088135; \n",
      "fold: TRAIN; iteration: 1607; epoch: 1; loss: 2.4796645641326904; \n",
      "fold: TRAIN; iteration: 1608; epoch: 1; loss: 2.5380795001983643; \n",
      "fold: TRAIN; iteration: 1609; epoch: 1; loss: 2.3390746116638184; \n",
      "fold: TRAIN; iteration: 1610; epoch: 1; loss: 2.4384796619415283; \n",
      "fold: TRAIN; iteration: 1611; epoch: 1; loss: 2.6280393600463867; \n",
      "fold: TRAIN; iteration: 1612; epoch: 1; loss: 2.4792683124542236; \n",
      "fold: TRAIN; iteration: 1613; epoch: 1; loss: 2.6349363327026367; \n",
      "fold: TRAIN; iteration: 1614; epoch: 1; loss: 2.6316866874694824; \n",
      "fold: TRAIN; iteration: 1615; epoch: 1; loss: 2.2493016719818115; \n",
      "fold: TRAIN; iteration: 1616; epoch: 1; loss: 2.402636766433716; \n",
      "fold: TRAIN; iteration: 1617; epoch: 1; loss: 2.4805872440338135; \n",
      "fold: TRAIN; iteration: 1618; epoch: 1; loss: 2.660510301589966; \n",
      "fold: TRAIN; iteration: 1619; epoch: 1; loss: 2.3830814361572266; \n",
      "fold: TRAIN; iteration: 1620; epoch: 1; loss: 2.6843178272247314; \n",
      "fold: TRAIN; iteration: 1621; epoch: 1; loss: 2.2535908222198486; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 1622; epoch: 1; loss: 2.7048211097717285; \n",
      "fold: TRAIN; iteration: 1623; epoch: 1; loss: 2.5125374794006348; \n",
      "fold: TRAIN; iteration: 1624; epoch: 1; loss: 2.6775717735290527; \n",
      "fold: TRAIN; iteration: 1625; epoch: 1; loss: 2.4630537033081055; \n",
      "fold: TRAIN; iteration: 1626; epoch: 1; loss: 2.3929429054260254; \n",
      "fold: TRAIN; iteration: 1627; epoch: 1; loss: 2.301651954650879; \n",
      "fold: TRAIN; iteration: 1628; epoch: 1; loss: 2.5890960693359375; \n",
      "fold: TRAIN; iteration: 1629; epoch: 1; loss: 2.814729690551758; \n",
      "fold: TRAIN; iteration: 1630; epoch: 1; loss: 2.6884024143218994; \n",
      "fold: TRAIN; iteration: 1631; epoch: 1; loss: 2.673366069793701; \n",
      "fold: TRAIN; iteration: 1632; epoch: 1; loss: 2.42689847946167; \n",
      "fold: TRAIN; iteration: 1633; epoch: 1; loss: 2.507333993911743; \n",
      "fold: TRAIN; iteration: 1634; epoch: 1; loss: 2.3849804401397705; \n",
      "fold: TRAIN; iteration: 1635; epoch: 1; loss: 2.5466790199279785; \n",
      "fold: TRAIN; iteration: 1636; epoch: 1; loss: 2.558736801147461; \n",
      "fold: TRAIN; iteration: 1637; epoch: 1; loss: 2.6473474502563477; \n",
      "fold: TRAIN; iteration: 1638; epoch: 1; loss: 2.6923840045928955; \n",
      "fold: TRAIN; iteration: 1639; epoch: 1; loss: 2.5028486251831055; \n",
      "fold: TRAIN; iteration: 1640; epoch: 1; loss: 2.443678379058838; \n",
      "fold: TRAIN; iteration: 1641; epoch: 1; loss: 2.4226317405700684; \n",
      "fold: TRAIN; iteration: 1642; epoch: 1; loss: 2.748516321182251; \n",
      "fold: TRAIN; iteration: 1643; epoch: 1; loss: 2.4999735355377197; \n",
      "fold: TRAIN; iteration: 1644; epoch: 1; loss: 2.4792373180389404; \n",
      "fold: TRAIN; iteration: 1645; epoch: 1; loss: 2.5652434825897217; \n",
      "fold: TRAIN; iteration: 1646; epoch: 1; loss: 2.5492770671844482; \n",
      "fold: TRAIN; iteration: 1647; epoch: 1; loss: 2.2624950408935547; \n",
      "fold: TRAIN; iteration: 1648; epoch: 1; loss: 2.4352779388427734; \n",
      "fold: TRAIN; iteration: 1649; epoch: 1; loss: 2.5529541969299316; \n",
      "fold: TRAIN; iteration: 1650; epoch: 1; loss: 2.428215742111206; \n",
      "fold: TRAIN; iteration: 1651; epoch: 1; loss: 2.4542548656463623; \n",
      "fold: TRAIN; iteration: 1652; epoch: 1; loss: 2.458916425704956; \n",
      "fold: TRAIN; iteration: 1653; epoch: 1; loss: 2.316202402114868; \n",
      "fold: TRAIN; iteration: 1654; epoch: 1; loss: 2.4215009212493896; \n",
      "fold: TRAIN; iteration: 1655; epoch: 1; loss: 2.257253646850586; \n",
      "fold: TRAIN; iteration: 1656; epoch: 1; loss: 2.4160959720611572; \n",
      "fold: TRAIN; iteration: 1657; epoch: 1; loss: 2.474231481552124; \n",
      "fold: TRAIN; iteration: 1658; epoch: 1; loss: 2.6610913276672363; \n",
      "fold: TRAIN; iteration: 1659; epoch: 1; loss: 2.369870185852051; \n",
      "fold: TRAIN; iteration: 1660; epoch: 1; loss: 2.5031020641326904; \n",
      "fold: TRAIN; iteration: 1661; epoch: 1; loss: 2.7438242435455322; \n",
      "fold: TRAIN; iteration: 1662; epoch: 1; loss: 2.3537943363189697; \n",
      "fold: TRAIN; iteration: 1663; epoch: 1; loss: 2.673297643661499; \n",
      "fold: TRAIN; iteration: 1664; epoch: 1; loss: 2.553483247756958; \n",
      "fold: TRAIN; iteration: 1665; epoch: 1; loss: 2.5163190364837646; \n",
      "fold: TRAIN; iteration: 1666; epoch: 1; loss: 2.5825934410095215; \n",
      "fold: TRAIN; iteration: 1667; epoch: 1; loss: 2.32565975189209; \n",
      "fold: TRAIN; iteration: 1668; epoch: 1; loss: 2.5679852962493896; \n",
      "fold: TRAIN; iteration: 1669; epoch: 1; loss: 2.434063673019409; \n",
      "fold: TRAIN; iteration: 1670; epoch: 1; loss: 2.5636610984802246; \n",
      "fold: TRAIN; iteration: 1671; epoch: 1; loss: 2.7572710514068604; \n",
      "fold: TRAIN; iteration: 1672; epoch: 1; loss: 2.458400011062622; \n",
      "fold: TRAIN; iteration: 1673; epoch: 1; loss: 2.3835885524749756; \n",
      "fold: TRAIN; iteration: 1674; epoch: 1; loss: 2.184178113937378; \n",
      "fold: TRAIN; iteration: 1675; epoch: 1; loss: 2.332857847213745; \n",
      "fold: TRAIN; iteration: 1676; epoch: 1; loss: 2.379728078842163; \n",
      "fold: TRAIN; iteration: 1677; epoch: 1; loss: 2.432032346725464; \n",
      "fold: TRAIN; iteration: 1678; epoch: 1; loss: 2.260377883911133; \n",
      "fold: TRAIN; iteration: 1679; epoch: 1; loss: 2.7309446334838867; \n",
      "fold: TRAIN; iteration: 1680; epoch: 1; loss: 2.4763007164001465; \n",
      "fold: TRAIN; iteration: 1681; epoch: 1; loss: 2.388684034347534; \n",
      "fold: TRAIN; iteration: 1682; epoch: 1; loss: 2.555633783340454; \n",
      "fold: TRAIN; iteration: 1683; epoch: 1; loss: 2.481043815612793; \n",
      "fold: TRAIN; iteration: 1684; epoch: 1; loss: 2.7143752574920654; \n",
      "fold: TRAIN; iteration: 1685; epoch: 1; loss: 2.3287973403930664; \n",
      "fold: TRAIN; iteration: 1686; epoch: 1; loss: 2.337639808654785; \n",
      "fold: TRAIN; iteration: 1687; epoch: 1; loss: 2.4522364139556885; \n",
      "fold: TRAIN; iteration: 1688; epoch: 1; loss: 2.42429256439209; \n",
      "fold: TRAIN; iteration: 1689; epoch: 1; loss: 2.5940515995025635; \n",
      "fold: TRAIN; iteration: 1690; epoch: 1; loss: 2.587639808654785; \n",
      "fold: TRAIN; iteration: 1691; epoch: 1; loss: 2.6132442951202393; \n",
      "fold: TRAIN; iteration: 1692; epoch: 1; loss: 2.3804214000701904; \n",
      "fold: TRAIN; iteration: 1693; epoch: 1; loss: 2.454557180404663; \n",
      "fold: TRAIN; iteration: 1694; epoch: 1; loss: 2.337071180343628; \n",
      "fold: TRAIN; iteration: 1695; epoch: 1; loss: 2.3535404205322266; \n",
      "fold: TRAIN; iteration: 1696; epoch: 1; loss: 2.5797924995422363; \n",
      "fold: TRAIN; iteration: 1697; epoch: 1; loss: 2.633296251296997; \n",
      "fold: TRAIN; iteration: 1698; epoch: 1; loss: 2.5494649410247803; \n",
      "fold: TRAIN; iteration: 1699; epoch: 1; loss: 2.4186959266662598; \n",
      "fold: TRAIN; iteration: 1700; epoch: 1; loss: 2.4362051486968994; \n",
      "fold: TRAIN; iteration: 1701; epoch: 1; loss: 2.488494634628296; \n",
      "fold: TRAIN; iteration: 1702; epoch: 1; loss: 2.644521713256836; \n",
      "fold: TRAIN; iteration: 1703; epoch: 1; loss: 2.624049663543701; \n",
      "fold: TRAIN; iteration: 1704; epoch: 1; loss: 2.4835164546966553; \n",
      "fold: TRAIN; iteration: 1705; epoch: 1; loss: 2.444617509841919; \n",
      "fold: TRAIN; iteration: 1706; epoch: 1; loss: 2.379157066345215; \n",
      "fold: TRAIN; iteration: 1707; epoch: 1; loss: 2.307438850402832; \n",
      "fold: TRAIN; iteration: 1708; epoch: 1; loss: 2.464672803878784; \n",
      "fold: TRAIN; iteration: 1709; epoch: 1; loss: 2.4040377140045166; \n",
      "fold: TRAIN; iteration: 1710; epoch: 1; loss: 2.61130952835083; \n",
      "fold: TRAIN; iteration: 1711; epoch: 1; loss: 2.5692763328552246; \n",
      "fold: TRAIN; iteration: 1712; epoch: 1; loss: 2.6913583278656006; \n",
      "fold: TRAIN; iteration: 1713; epoch: 1; loss: 2.385317325592041; \n",
      "fold: TRAIN; iteration: 1714; epoch: 1; loss: 2.530094861984253; \n",
      "fold: TRAIN; iteration: 1715; epoch: 1; loss: 2.6013011932373047; \n",
      "fold: TRAIN; iteration: 1716; epoch: 1; loss: 2.620145559310913; \n",
      "fold: TRAIN; iteration: 1717; epoch: 1; loss: 2.429173707962036; \n",
      "fold: TRAIN; iteration: 1718; epoch: 1; loss: 2.256286859512329; \n",
      "fold: TRAIN; iteration: 1719; epoch: 1; loss: 2.2231245040893555; \n",
      "fold: TRAIN; iteration: 1720; epoch: 1; loss: 2.4637351036071777; \n",
      "fold: TRAIN; iteration: 1721; epoch: 1; loss: 2.6829237937927246; \n",
      "fold: TRAIN; iteration: 1722; epoch: 1; loss: 2.6095364093780518; \n",
      "fold: TRAIN; iteration: 1723; epoch: 1; loss: 2.42848539352417; \n",
      "fold: TRAIN; iteration: 1724; epoch: 1; loss: 2.5720839500427246; \n",
      "fold: TRAIN; iteration: 1725; epoch: 1; loss: 2.441028118133545; \n",
      "fold: TRAIN; iteration: 1726; epoch: 1; loss: 2.543116569519043; \n",
      "fold: TRAIN; iteration: 1727; epoch: 1; loss: 2.348604440689087; \n",
      "fold: TRAIN; iteration: 1728; epoch: 1; loss: 2.416689395904541; \n",
      "fold: TRAIN; iteration: 1729; epoch: 1; loss: 2.6001524925231934; \n",
      "fold: TRAIN; iteration: 1730; epoch: 1; loss: 2.405378818511963; \n",
      "fold: TRAIN; iteration: 1731; epoch: 1; loss: 2.3624727725982666; \n",
      "fold: TRAIN; iteration: 1732; epoch: 1; loss: 2.239996910095215; \n",
      "fold: TRAIN; iteration: 1733; epoch: 1; loss: 2.4875876903533936; \n",
      "fold: TRAIN; iteration: 1734; epoch: 1; loss: 2.6393203735351562; \n",
      "fold: TRAIN; iteration: 1735; epoch: 1; loss: 2.549201726913452; \n",
      "fold: TRAIN; iteration: 1736; epoch: 1; loss: 2.5212907791137695; \n",
      "fold: TRAIN; iteration: 1737; epoch: 1; loss: 2.40629243850708; \n",
      "fold: TRAIN; iteration: 1738; epoch: 1; loss: 2.269892692565918; \n",
      "fold: TRAIN; iteration: 1739; epoch: 1; loss: 2.2462565898895264; \n",
      "fold: TRAIN; iteration: 1740; epoch: 1; loss: 2.495323657989502; \n",
      "fold: TRAIN; iteration: 1741; epoch: 1; loss: 2.2971394062042236; \n",
      "fold: TRAIN; iteration: 1742; epoch: 1; loss: 2.456920862197876; \n",
      "fold: TRAIN; iteration: 1743; epoch: 1; loss: 2.201829671859741; \n",
      "fold: TRAIN; iteration: 1744; epoch: 1; loss: 2.421402931213379; \n",
      "fold: TRAIN; iteration: 1745; epoch: 1; loss: 2.7016894817352295; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 1746; epoch: 1; loss: 2.234729051589966; \n",
      "fold: TRAIN; iteration: 1747; epoch: 1; loss: 2.5599820613861084; \n",
      "fold: TRAIN; iteration: 1748; epoch: 1; loss: 2.5608720779418945; \n",
      "fold: TRAIN; iteration: 1749; epoch: 1; loss: 2.5231847763061523; \n",
      "fold: TRAIN; iteration: 1750; epoch: 1; loss: 2.2424564361572266; \n",
      "fold: TRAIN; iteration: 1751; epoch: 1; loss: 2.5227789878845215; \n",
      "fold: TRAIN; iteration: 1752; epoch: 1; loss: 2.4477481842041016; \n",
      "fold: TRAIN; iteration: 1753; epoch: 1; loss: 2.654062509536743; \n",
      "fold: TRAIN; iteration: 1754; epoch: 1; loss: 2.473684787750244; \n",
      "fold: TRAIN; iteration: 1755; epoch: 1; loss: 2.329988479614258; \n",
      "fold: TRAIN; iteration: 1756; epoch: 1; loss: 2.304197311401367; \n",
      "fold: TRAIN; iteration: 1757; epoch: 1; loss: 2.380648136138916; \n",
      "fold: TRAIN; iteration: 1758; epoch: 1; loss: 2.558554172515869; \n",
      "fold: TRAIN; iteration: 1759; epoch: 1; loss: 2.3047544956207275; \n",
      "fold: TRAIN; iteration: 1760; epoch: 1; loss: 2.6073427200317383; \n",
      "fold: TRAIN; iteration: 1761; epoch: 1; loss: 2.5294971466064453; \n",
      "fold: TRAIN; iteration: 1762; epoch: 1; loss: 2.393737316131592; \n",
      "fold: TRAIN; iteration: 1763; epoch: 1; loss: 2.240144729614258; \n",
      "fold: TRAIN; iteration: 1764; epoch: 1; loss: 2.3000173568725586; \n",
      "fold: TRAIN; iteration: 1765; epoch: 1; loss: 2.584183692932129; \n",
      "fold: TRAIN; iteration: 1766; epoch: 1; loss: 2.4103755950927734; \n",
      "fold: TRAIN; iteration: 1767; epoch: 1; loss: 2.561164617538452; \n",
      "fold: TRAIN; iteration: 1768; epoch: 1; loss: 2.7374067306518555; \n",
      "fold: TRAIN; iteration: 1769; epoch: 1; loss: 2.731649160385132; \n",
      "fold: TRAIN; iteration: 1770; epoch: 1; loss: 2.441896915435791; \n",
      "fold: TRAIN; iteration: 1771; epoch: 1; loss: 2.4427623748779297; \n",
      "fold: TRAIN; iteration: 1772; epoch: 1; loss: 2.5902483463287354; \n",
      "fold: TRAIN; iteration: 1773; epoch: 1; loss: 2.6370151042938232; \n",
      "fold: TRAIN; iteration: 1774; epoch: 1; loss: 2.556964159011841; \n",
      "fold: TRAIN; iteration: 1775; epoch: 1; loss: 2.404022693634033; \n",
      "fold: TRAIN; iteration: 1776; epoch: 1; loss: 2.497316598892212; \n",
      "fold: TRAIN; iteration: 1777; epoch: 1; loss: 2.513132333755493; \n",
      "fold: TRAIN; iteration: 1778; epoch: 1; loss: 2.316074848175049; \n",
      "fold: TRAIN; iteration: 1779; epoch: 1; loss: 2.5096328258514404; \n",
      "fold: TRAIN; iteration: 1780; epoch: 1; loss: 2.434086561203003; \n",
      "fold: TRAIN; iteration: 1781; epoch: 1; loss: 2.335106134414673; \n",
      "fold: TRAIN; iteration: 1782; epoch: 1; loss: 2.7596306800842285; \n",
      "fold: TRAIN; iteration: 1783; epoch: 1; loss: 2.62709379196167; \n",
      "fold: TRAIN; iteration: 1784; epoch: 1; loss: 2.394336462020874; \n",
      "fold: TRAIN; iteration: 1785; epoch: 1; loss: 2.2403719425201416; \n",
      "fold: TRAIN; iteration: 1786; epoch: 1; loss: 2.5740621089935303; \n",
      "fold: TRAIN; iteration: 1787; epoch: 1; loss: 2.7163209915161133; \n",
      "fold: TRAIN; iteration: 1788; epoch: 1; loss: 2.7129201889038086; \n",
      "fold: TRAIN; iteration: 1789; epoch: 1; loss: 2.386941432952881; \n",
      "fold: TRAIN; iteration: 1790; epoch: 1; loss: 2.5724282264709473; \n",
      "fold: TRAIN; iteration: 1791; epoch: 1; loss: 2.4625649452209473; \n",
      "fold: TRAIN; iteration: 1792; epoch: 1; loss: 2.3270628452301025; \n",
      "fold: TRAIN; iteration: 1793; epoch: 1; loss: 2.2891554832458496; \n",
      "fold: TRAIN; iteration: 1794; epoch: 1; loss: 2.605555772781372; \n",
      "fold: TRAIN; iteration: 1795; epoch: 1; loss: 2.6502561569213867; \n",
      "fold: TRAIN; iteration: 1796; epoch: 1; loss: 2.5700366497039795; \n",
      "fold: TRAIN; iteration: 1797; epoch: 1; loss: 2.459929943084717; \n",
      "fold: TRAIN; iteration: 1798; epoch: 1; loss: 2.4945788383483887; \n",
      "fold: TRAIN; iteration: 1799; epoch: 1; loss: 2.6707375049591064; \n",
      "fold: TRAIN; iteration: 1800; epoch: 1; loss: 2.5450737476348877; \n",
      "fold: TRAIN; iteration: 1801; epoch: 1; loss: 2.378401517868042; \n",
      "fold: TRAIN; iteration: 1802; epoch: 1; loss: 2.3859264850616455; \n",
      "fold: TRAIN; iteration: 1803; epoch: 1; loss: 2.474543809890747; \n",
      "fold: TRAIN; iteration: 1804; epoch: 1; loss: 2.5488879680633545; \n",
      "fold: TRAIN; iteration: 1805; epoch: 1; loss: 2.662221670150757; \n",
      "fold: TRAIN; iteration: 1806; epoch: 1; loss: 2.418393135070801; \n",
      "fold: TRAIN; iteration: 1807; epoch: 1; loss: 2.430373430252075; \n",
      "fold: TRAIN; iteration: 1808; epoch: 1; loss: 2.534261465072632; \n",
      "fold: TRAIN; iteration: 1809; epoch: 1; loss: 2.432492733001709; \n",
      "fold: TRAIN; iteration: 1810; epoch: 1; loss: 2.4671151638031006; \n",
      "fold: TRAIN; iteration: 1811; epoch: 1; loss: 2.6990914344787598; \n",
      "fold: TRAIN; iteration: 1812; epoch: 1; loss: 2.535764694213867; \n",
      "fold: TRAIN; iteration: 1813; epoch: 1; loss: 2.3381879329681396; \n",
      "fold: TRAIN; iteration: 1814; epoch: 1; loss: 2.746945858001709; \n",
      "fold: TRAIN; iteration: 1815; epoch: 1; loss: 2.4983856678009033; \n",
      "fold: TRAIN; iteration: 1816; epoch: 1; loss: 2.3939507007598877; \n",
      "fold: TRAIN; iteration: 1817; epoch: 1; loss: 2.535834312438965; \n",
      "fold: TRAIN; iteration: 1818; epoch: 1; loss: 2.6638107299804688; \n",
      "fold: TRAIN; iteration: 1819; epoch: 1; loss: 2.5204660892486572; \n",
      "fold: TRAIN; iteration: 1820; epoch: 1; loss: 2.243823766708374; \n",
      "fold: TRAIN; iteration: 1821; epoch: 1; loss: 2.520402431488037; \n",
      "fold: TRAIN; iteration: 1822; epoch: 1; loss: 2.282028913497925; \n",
      "fold: TRAIN; iteration: 1823; epoch: 1; loss: 2.401186227798462; \n",
      "fold: TRAIN; iteration: 1824; epoch: 1; loss: 2.472428321838379; \n",
      "fold: TRAIN; iteration: 1825; epoch: 1; loss: 2.2424604892730713; \n",
      "fold: TRAIN; iteration: 1826; epoch: 1; loss: 2.257395029067993; \n",
      "fold: TRAIN; iteration: 1827; epoch: 1; loss: 2.4588584899902344; \n",
      "fold: TRAIN; iteration: 1828; epoch: 1; loss: 2.473310708999634; \n",
      "fold: TRAIN; iteration: 1829; epoch: 1; loss: 2.483410358428955; \n",
      "fold: TRAIN; iteration: 1830; epoch: 1; loss: 2.4728667736053467; \n",
      "fold: TRAIN; iteration: 1831; epoch: 1; loss: 2.383653163909912; \n",
      "fold: TRAIN; iteration: 1832; epoch: 1; loss: 2.3518643379211426; \n",
      "fold: TRAIN; iteration: 1833; epoch: 1; loss: 2.538560390472412; \n",
      "fold: TRAIN; iteration: 1834; epoch: 1; loss: 2.5182247161865234; \n",
      "fold: TRAIN; iteration: 1835; epoch: 1; loss: 2.5664567947387695; \n",
      "fold: TRAIN; iteration: 1836; epoch: 1; loss: 2.6393237113952637; \n",
      "fold: TRAIN; iteration: 1837; epoch: 1; loss: 2.460109233856201; \n",
      "fold: TRAIN; iteration: 1838; epoch: 1; loss: 2.311638593673706; \n",
      "fold: TRAIN; iteration: 1839; epoch: 1; loss: 2.3426389694213867; \n",
      "fold: TRAIN; iteration: 1840; epoch: 1; loss: 2.648449420928955; \n",
      "fold: TRAIN; iteration: 1841; epoch: 1; loss: 2.495070457458496; \n",
      "fold: TRAIN; iteration: 1842; epoch: 1; loss: 2.5598256587982178; \n",
      "fold: TRAIN; iteration: 1843; epoch: 1; loss: 2.516394853591919; \n",
      "fold: TRAIN; iteration: 1844; epoch: 1; loss: 2.378089666366577; \n",
      "fold: TRAIN; iteration: 1845; epoch: 1; loss: 2.6689648628234863; \n",
      "fold: TRAIN; iteration: 1846; epoch: 1; loss: 2.4606218338012695; \n",
      "fold: TRAIN; iteration: 1847; epoch: 1; loss: 2.6111679077148438; \n",
      "fold: TRAIN; iteration: 1848; epoch: 1; loss: 2.418123245239258; \n",
      "fold: TRAIN; iteration: 1849; epoch: 1; loss: 2.4000139236450195; \n",
      "fold: TRAIN; iteration: 1850; epoch: 1; loss: 2.3679018020629883; \n",
      "fold: TRAIN; iteration: 1851; epoch: 1; loss: 2.340534210205078; \n",
      "fold: TRAIN; iteration: 1852; epoch: 1; loss: 2.1958751678466797; \n",
      "fold: TRAIN; iteration: 1853; epoch: 1; loss: 2.3576819896698; \n",
      "fold: TRAIN; iteration: 1854; epoch: 1; loss: 2.4576950073242188; \n",
      "fold: TRAIN; iteration: 1855; epoch: 1; loss: 2.527190923690796; \n",
      "fold: TRAIN; iteration: 1856; epoch: 1; loss: 2.594528913497925; \n",
      "fold: TRAIN; iteration: 1857; epoch: 1; loss: 2.4001376628875732; \n",
      "fold: TRAIN; iteration: 1858; epoch: 1; loss: 2.5004284381866455; \n",
      "fold: TRAIN; iteration: 1859; epoch: 1; loss: 2.5960159301757812; \n",
      "fold: TRAIN; iteration: 1860; epoch: 1; loss: 2.429938793182373; \n",
      "fold: TRAIN; iteration: 1861; epoch: 1; loss: 2.397886037826538; \n",
      "fold: TRAIN; iteration: 1862; epoch: 1; loss: 2.280442714691162; \n",
      "fold: TRAIN; iteration: 1863; epoch: 1; loss: 2.3174943923950195; \n",
      "fold: TRAIN; iteration: 1864; epoch: 1; loss: 2.4418675899505615; \n",
      "fold: TRAIN; iteration: 1865; epoch: 1; loss: 2.1887760162353516; \n",
      "fold: TRAIN; iteration: 1866; epoch: 1; loss: 2.64080810546875; \n",
      "fold: TRAIN; iteration: 1867; epoch: 1; loss: 2.2331418991088867; \n",
      "fold: TRAIN; iteration: 1868; epoch: 1; loss: 2.269412040710449; \n",
      "fold: TRAIN; iteration: 1869; epoch: 1; loss: 2.9229214191436768; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 1870; epoch: 1; loss: 2.447986364364624; \n",
      "fold: TRAIN; iteration: 1871; epoch: 1; loss: 2.6272149085998535; \n",
      "fold: TRAIN; iteration: 1872; epoch: 1; loss: 2.604793071746826; \n",
      "fold: TRAIN; iteration: 1873; epoch: 1; loss: 2.361370325088501; \n",
      "fold: TRAIN; iteration: 1874; epoch: 1; loss: 2.5238938331604004; \n",
      "fold: TRAIN; iteration: 1875; epoch: 1; loss: 2.4279096126556396; \n",
      "fold: TRAIN; iteration: 1876; epoch: 1; loss: 2.6186635494232178; \n",
      "fold: TRAIN; iteration: 1877; epoch: 1; loss: 2.6969974040985107; \n",
      "fold: TRAIN; iteration: 1878; epoch: 1; loss: 2.3604860305786133; \n",
      "fold: TRAIN; iteration: 1879; epoch: 1; loss: 2.4698829650878906; \n",
      "fold: TRAIN; iteration: 1880; epoch: 1; loss: 2.4826223850250244; \n",
      "fold: TRAIN; iteration: 1881; epoch: 1; loss: 2.3901610374450684; \n",
      "fold: TRAIN; iteration: 1882; epoch: 1; loss: 2.3833465576171875; \n",
      "fold: TRAIN; iteration: 1883; epoch: 1; loss: 2.4806642532348633; \n",
      "fold: TRAIN; iteration: 1884; epoch: 1; loss: 2.330108880996704; \n",
      "fold: TRAIN; iteration: 1885; epoch: 1; loss: 2.537667989730835; \n",
      "fold: TRAIN; iteration: 1886; epoch: 1; loss: 2.521517038345337; \n",
      "fold: TRAIN; iteration: 1887; epoch: 1; loss: 2.401801109313965; \n",
      "fold: TRAIN; iteration: 1888; epoch: 1; loss: 2.4573545455932617; \n",
      "fold: TRAIN; iteration: 1889; epoch: 1; loss: 2.3321611881256104; \n",
      "fold: TRAIN; iteration: 1890; epoch: 1; loss: 2.582456350326538; \n",
      "fold: TRAIN; iteration: 1891; epoch: 1; loss: 2.3575685024261475; \n",
      "fold: TRAIN; iteration: 1892; epoch: 1; loss: 2.456326484680176; \n",
      "fold: TRAIN; iteration: 1893; epoch: 1; loss: 2.3694345951080322; \n",
      "fold: TRAIN; iteration: 1894; epoch: 1; loss: 2.5269899368286133; \n",
      "fold: TRAIN; iteration: 1895; epoch: 1; loss: 2.297915458679199; \n",
      "fold: TRAIN; iteration: 1896; epoch: 1; loss: 2.659886360168457; \n",
      "fold: TRAIN; iteration: 1897; epoch: 1; loss: 2.2495858669281006; \n",
      "fold: TRAIN; iteration: 1898; epoch: 1; loss: 2.522491455078125; \n",
      "fold: TRAIN; iteration: 1899; epoch: 1; loss: 3.01155161857605; \n",
      "fold: TRAIN; iteration: 1900; epoch: 1; loss: 2.2978615760803223; \n",
      "fold: TRAIN; iteration: 1901; epoch: 1; loss: 2.3361120223999023; \n",
      "fold: TRAIN; iteration: 1902; epoch: 1; loss: 2.370150327682495; \n",
      "fold: TRAIN; iteration: 1903; epoch: 1; loss: 2.5399887561798096; \n",
      "fold: TRAIN; iteration: 1904; epoch: 1; loss: 2.455836296081543; \n",
      "fold: TRAIN; iteration: 1905; epoch: 1; loss: 2.376180410385132; \n",
      "fold: TRAIN; iteration: 1906; epoch: 1; loss: 2.484619379043579; \n",
      "fold: TRAIN; iteration: 1907; epoch: 1; loss: 2.28513765335083; \n",
      "fold: TRAIN; iteration: 1908; epoch: 1; loss: 2.7786669731140137; \n",
      "fold: TRAIN; iteration: 1909; epoch: 1; loss: 2.5585358142852783; \n",
      "fold: TRAIN; iteration: 1910; epoch: 1; loss: 2.532479763031006; \n",
      "fold: TRAIN; iteration: 1911; epoch: 1; loss: 2.4464468955993652; \n",
      "fold: TRAIN; iteration: 1912; epoch: 1; loss: 2.5706071853637695; \n",
      "fold: TRAIN; iteration: 1913; epoch: 1; loss: 2.5124926567077637; \n",
      "fold: TRAIN; iteration: 1914; epoch: 1; loss: 2.4607605934143066; \n",
      "fold: TRAIN; iteration: 1915; epoch: 1; loss: 2.3508291244506836; \n",
      "fold: TRAIN; iteration: 1916; epoch: 1; loss: 2.3093268871307373; \n",
      "fold: TRAIN; iteration: 1917; epoch: 1; loss: 2.5540771484375; \n",
      "fold: TRAIN; iteration: 1918; epoch: 1; loss: 2.3896775245666504; \n",
      "fold: TRAIN; iteration: 1919; epoch: 1; loss: 2.4116103649139404; \n",
      "fold: TRAIN; iteration: 1920; epoch: 1; loss: 2.2686610221862793; \n",
      "fold: TRAIN; iteration: 1921; epoch: 1; loss: 2.3847460746765137; \n",
      "fold: TRAIN; iteration: 1922; epoch: 1; loss: 2.644782781600952; \n",
      "fold: TRAIN; iteration: 1923; epoch: 1; loss: 2.2995729446411133; \n",
      "fold: TRAIN; iteration: 1924; epoch: 1; loss: 2.6564443111419678; \n",
      "fold: TRAIN; iteration: 1925; epoch: 1; loss: 2.6295318603515625; \n",
      "fold: TRAIN; iteration: 1926; epoch: 1; loss: 2.3417301177978516; \n",
      "fold: TRAIN; iteration: 1927; epoch: 1; loss: 2.312147617340088; \n",
      "fold: TRAIN; iteration: 1928; epoch: 1; loss: 2.6093666553497314; \n",
      "fold: TRAIN; iteration: 1929; epoch: 1; loss: 2.454702138900757; \n",
      "fold: TRAIN; iteration: 1930; epoch: 1; loss: 2.4277946949005127; \n",
      "fold: TRAIN; iteration: 1931; epoch: 1; loss: 2.656890869140625; \n",
      "fold: TRAIN; iteration: 1932; epoch: 1; loss: 2.212700843811035; \n",
      "fold: TRAIN; iteration: 1933; epoch: 1; loss: 2.426515579223633; \n",
      "fold: TRAIN; iteration: 1934; epoch: 1; loss: 2.385549783706665; \n",
      "fold: TRAIN; iteration: 1935; epoch: 1; loss: 2.4676618576049805; \n",
      "fold: TRAIN; iteration: 1936; epoch: 1; loss: 2.4893856048583984; \n",
      "fold: TRAIN; iteration: 1937; epoch: 1; loss: 2.555656671524048; \n",
      "fold: TRAIN; iteration: 1938; epoch: 1; loss: 2.5321216583251953; \n",
      "fold: TRAIN; iteration: 1939; epoch: 1; loss: 2.3587968349456787; \n",
      "fold: TRAIN; iteration: 1940; epoch: 1; loss: 2.518113136291504; \n",
      "fold: TRAIN; iteration: 1941; epoch: 1; loss: 2.5941321849823; \n",
      "fold: TRAIN; iteration: 1942; epoch: 1; loss: 2.507079839706421; \n",
      "fold: TRAIN; iteration: 1943; epoch: 1; loss: 2.5931262969970703; \n",
      "fold: TRAIN; iteration: 1944; epoch: 1; loss: 2.5961475372314453; \n",
      "fold: TRAIN; iteration: 1945; epoch: 1; loss: 2.587886333465576; \n",
      "fold: TRAIN; iteration: 1946; epoch: 1; loss: 2.3806285858154297; \n",
      "fold: TRAIN; iteration: 1947; epoch: 1; loss: 2.712207555770874; \n",
      "fold: TRAIN; iteration: 1948; epoch: 1; loss: 2.5460402965545654; \n",
      "fold: TRAIN; iteration: 1949; epoch: 1; loss: 2.51659893989563; \n",
      "fold: TRAIN; iteration: 1950; epoch: 1; loss: 2.5928304195404053; \n",
      "fold: TRAIN; iteration: 1951; epoch: 1; loss: 2.804145574569702; \n",
      "fold: TRAIN; iteration: 1952; epoch: 1; loss: 2.719315528869629; \n",
      "fold: TRAIN; iteration: 1953; epoch: 1; loss: 2.341279983520508; \n",
      "fold: TRAIN; iteration: 1954; epoch: 1; loss: 2.4248015880584717; \n",
      "fold: TRAIN; iteration: 1955; epoch: 1; loss: 2.672792434692383; \n",
      "fold: TRAIN; iteration: 1956; epoch: 1; loss: 2.423168897628784; \n",
      "fold: TRAIN; iteration: 1957; epoch: 1; loss: 2.833343744277954; \n",
      "fold: TRAIN; iteration: 1958; epoch: 1; loss: 2.5418317317962646; \n",
      "fold: TRAIN; iteration: 1959; epoch: 1; loss: 2.6582956314086914; \n",
      "fold: TRAIN; iteration: 1960; epoch: 1; loss: 2.5213241577148438; \n",
      "fold: TRAIN; iteration: 1961; epoch: 1; loss: 2.3881278038024902; \n",
      "fold: TRAIN; iteration: 1962; epoch: 1; loss: 2.2583303451538086; \n",
      "fold: TRAIN; iteration: 1963; epoch: 1; loss: 2.1914923191070557; \n",
      "fold: TRAIN; iteration: 1964; epoch: 1; loss: 2.4443352222442627; \n",
      "fold: TRAIN; iteration: 1965; epoch: 1; loss: 2.510188341140747; \n",
      "fold: TRAIN; iteration: 1966; epoch: 1; loss: 2.5438244342803955; \n",
      "fold: TRAIN; iteration: 1967; epoch: 1; loss: 2.209869861602783; \n",
      "fold: TRAIN; iteration: 1968; epoch: 1; loss: 2.512077569961548; \n",
      "fold: TRAIN; iteration: 1969; epoch: 1; loss: 2.5012598037719727; \n",
      "fold: TRAIN; iteration: 1970; epoch: 1; loss: 2.4924476146698; \n",
      "fold: TRAIN; iteration: 1971; epoch: 1; loss: 2.4109742641448975; \n",
      "fold: TRAIN; iteration: 1972; epoch: 1; loss: 2.4814281463623047; \n",
      "fold: TRAIN; iteration: 1973; epoch: 1; loss: 2.4592275619506836; \n",
      "fold: TRAIN; iteration: 1974; epoch: 1; loss: 2.107607841491699; \n",
      "fold: TRAIN; iteration: 1975; epoch: 1; loss: 2.429927349090576; \n",
      "fold: TRAIN; iteration: 1976; epoch: 1; loss: 2.557218074798584; \n",
      "fold: TRAIN; iteration: 1977; epoch: 1; loss: 2.4058263301849365; \n",
      "fold: TRAIN; iteration: 1978; epoch: 1; loss: 2.6011600494384766; \n",
      "fold: TRAIN; iteration: 1979; epoch: 1; loss: 2.1319377422332764; \n",
      "fold: TRAIN; iteration: 1980; epoch: 1; loss: 2.7189862728118896; \n",
      "fold: TRAIN; iteration: 1981; epoch: 1; loss: 2.5542023181915283; \n",
      "fold: TRAIN; iteration: 1982; epoch: 1; loss: 2.570333242416382; \n",
      "fold: TRAIN; iteration: 1983; epoch: 1; loss: 2.5669283866882324; \n",
      "fold: TRAIN; iteration: 1984; epoch: 1; loss: 2.4749979972839355; \n",
      "fold: TRAIN; iteration: 1985; epoch: 1; loss: 2.5099916458129883; \n",
      "fold: TRAIN; iteration: 1986; epoch: 1; loss: 2.6341662406921387; \n",
      "fold: TRAIN; iteration: 1987; epoch: 1; loss: 2.298614740371704; \n",
      "fold: TRAIN; iteration: 1988; epoch: 1; loss: 2.7601637840270996; \n",
      "fold: TRAIN; iteration: 1989; epoch: 1; loss: 2.3197214603424072; \n",
      "fold: TRAIN; iteration: 1990; epoch: 1; loss: 2.6423633098602295; \n",
      "fold: TRAIN; iteration: 1991; epoch: 1; loss: 2.4590210914611816; \n",
      "fold: TRAIN; iteration: 1992; epoch: 1; loss: 2.3282713890075684; \n",
      "fold: TRAIN; iteration: 1993; epoch: 1; loss: 2.385684013366699; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 1994; epoch: 1; loss: 2.700587749481201; \n",
      "fold: TRAIN; iteration: 1995; epoch: 1; loss: 2.309718132019043; \n",
      "fold: TRAIN; iteration: 1996; epoch: 1; loss: 2.57183837890625; \n",
      "fold: TRAIN; iteration: 1997; epoch: 1; loss: 2.552568197250366; \n",
      "fold: TRAIN; iteration: 1998; epoch: 1; loss: 2.6586339473724365; \n",
      "fold: TRAIN; iteration: 1999; epoch: 1; loss: 2.48745059967041; \n",
      "validating model...\n",
      "saving\n",
      "fold: VALID; iteration: 2000; epoch: 1; loss: 2.4759505973142737; \n",
      "fold: TRAIN; iteration: 2000; epoch: 1; loss: 2.566033363342285; \n",
      "fold: TRAIN; iteration: 2001; epoch: 1; loss: 2.4644358158111572; \n",
      "fold: TRAIN; iteration: 2002; epoch: 1; loss: 2.3275296688079834; \n",
      "fold: TRAIN; iteration: 2003; epoch: 1; loss: 2.6421327590942383; \n",
      "fold: TRAIN; iteration: 2004; epoch: 1; loss: 2.4324495792388916; \n",
      "fold: TRAIN; iteration: 2005; epoch: 1; loss: 2.4249155521392822; \n",
      "fold: TRAIN; iteration: 2006; epoch: 1; loss: 2.3565542697906494; \n",
      "fold: TRAIN; iteration: 2007; epoch: 1; loss: 2.5645196437835693; \n",
      "fold: TRAIN; iteration: 2008; epoch: 1; loss: 2.637833595275879; \n",
      "fold: TRAIN; iteration: 2009; epoch: 1; loss: 2.5186967849731445; \n",
      "fold: TRAIN; iteration: 2010; epoch: 1; loss: 2.401421546936035; \n",
      "fold: TRAIN; iteration: 2011; epoch: 1; loss: 2.527714252471924; \n",
      "fold: TRAIN; iteration: 2012; epoch: 1; loss: 2.478469133377075; \n",
      "fold: TRAIN; iteration: 2013; epoch: 1; loss: 2.511256456375122; \n",
      "fold: TRAIN; iteration: 2014; epoch: 1; loss: 2.342780828475952; \n",
      "fold: TRAIN; iteration: 2015; epoch: 1; loss: 2.2162015438079834; \n",
      "fold: TRAIN; iteration: 2016; epoch: 1; loss: 2.416729688644409; \n",
      "fold: TRAIN; iteration: 2017; epoch: 1; loss: 2.7055230140686035; \n",
      "fold: TRAIN; iteration: 2018; epoch: 1; loss: 2.393284559249878; \n",
      "fold: TRAIN; iteration: 2019; epoch: 1; loss: 2.4972689151763916; \n",
      "fold: TRAIN; iteration: 2020; epoch: 1; loss: 2.48136830329895; \n",
      "fold: TRAIN; iteration: 2021; epoch: 1; loss: 2.4082999229431152; \n",
      "fold: TRAIN; iteration: 2022; epoch: 1; loss: 2.484360456466675; \n",
      "fold: TRAIN; iteration: 2023; epoch: 1; loss: 2.2787787914276123; \n",
      "fold: TRAIN; iteration: 2024; epoch: 1; loss: 2.3253281116485596; \n",
      "fold: TRAIN; iteration: 2025; epoch: 1; loss: 2.420550584793091; \n",
      "fold: TRAIN; iteration: 2026; epoch: 1; loss: 2.1409823894500732; \n",
      "fold: TRAIN; iteration: 2027; epoch: 1; loss: 2.4110443592071533; \n",
      "fold: TRAIN; iteration: 2028; epoch: 1; loss: 2.515846014022827; \n",
      "fold: TRAIN; iteration: 2029; epoch: 1; loss: 2.4654037952423096; \n",
      "fold: TRAIN; iteration: 2030; epoch: 1; loss: 2.580275058746338; \n",
      "fold: TRAIN; iteration: 2031; epoch: 1; loss: 2.7136640548706055; \n",
      "fold: TRAIN; iteration: 2032; epoch: 1; loss: 2.3601555824279785; \n",
      "fold: TRAIN; iteration: 2033; epoch: 1; loss: 2.5674424171447754; \n",
      "fold: TRAIN; iteration: 2034; epoch: 1; loss: 2.5947561264038086; \n",
      "fold: TRAIN; iteration: 2035; epoch: 1; loss: 2.4731688499450684; \n",
      "fold: TRAIN; iteration: 2036; epoch: 1; loss: 2.265589714050293; \n",
      "fold: TRAIN; iteration: 2037; epoch: 1; loss: 2.6008081436157227; \n",
      "fold: TRAIN; iteration: 2038; epoch: 1; loss: 2.4813809394836426; \n",
      "fold: TRAIN; iteration: 2039; epoch: 1; loss: 2.5632901191711426; \n",
      "fold: TRAIN; iteration: 2040; epoch: 1; loss: 2.529156446456909; \n",
      "fold: TRAIN; iteration: 2041; epoch: 1; loss: 2.422360420227051; \n",
      "fold: TRAIN; iteration: 2042; epoch: 1; loss: 2.656517267227173; \n",
      "fold: TRAIN; iteration: 2043; epoch: 1; loss: 2.427220344543457; \n",
      "fold: TRAIN; iteration: 2044; epoch: 1; loss: 2.3990771770477295; \n",
      "fold: TRAIN; iteration: 2045; epoch: 1; loss: 2.641324520111084; \n",
      "fold: TRAIN; iteration: 2046; epoch: 1; loss: 2.3391034603118896; \n",
      "fold: TRAIN; iteration: 2047; epoch: 1; loss: 2.5298290252685547; \n",
      "fold: TRAIN; iteration: 2048; epoch: 1; loss: 2.6207773685455322; \n",
      "fold: TRAIN; iteration: 2049; epoch: 1; loss: 2.330657482147217; \n",
      "fold: TRAIN; iteration: 2050; epoch: 1; loss: 2.5066583156585693; \n",
      "fold: TRAIN; iteration: 2051; epoch: 1; loss: 2.616964340209961; \n",
      "fold: TRAIN; iteration: 2052; epoch: 1; loss: 2.257850408554077; \n",
      "fold: TRAIN; iteration: 2053; epoch: 1; loss: 2.613959312438965; \n",
      "fold: TRAIN; iteration: 2054; epoch: 1; loss: 2.270561695098877; \n",
      "fold: TRAIN; iteration: 2055; epoch: 1; loss: 2.6410019397735596; \n",
      "fold: TRAIN; iteration: 2056; epoch: 1; loss: 2.4540553092956543; \n",
      "fold: TRAIN; iteration: 2057; epoch: 1; loss: 2.757006883621216; \n",
      "fold: TRAIN; iteration: 2058; epoch: 1; loss: 2.5164926052093506; \n",
      "fold: TRAIN; iteration: 2059; epoch: 1; loss: 2.526775598526001; \n",
      "fold: TRAIN; iteration: 2060; epoch: 1; loss: 2.2888224124908447; \n",
      "fold: TRAIN; iteration: 2061; epoch: 1; loss: 2.259251117706299; \n",
      "fold: TRAIN; iteration: 2062; epoch: 1; loss: 2.4124724864959717; \n",
      "fold: TRAIN; iteration: 2063; epoch: 1; loss: 2.5070369243621826; \n",
      "fold: TRAIN; iteration: 2064; epoch: 1; loss: 2.5275166034698486; \n",
      "fold: TRAIN; iteration: 2065; epoch: 1; loss: 2.499108076095581; \n",
      "fold: TRAIN; iteration: 2066; epoch: 1; loss: 2.353391647338867; \n",
      "fold: TRAIN; iteration: 2067; epoch: 1; loss: 2.2656168937683105; \n",
      "fold: TRAIN; iteration: 2068; epoch: 1; loss: 2.2494454383850098; \n",
      "fold: TRAIN; iteration: 2069; epoch: 1; loss: 2.23103404045105; \n",
      "fold: TRAIN; iteration: 2070; epoch: 1; loss: 2.446030855178833; \n",
      "fold: TRAIN; iteration: 2071; epoch: 1; loss: 2.6138195991516113; \n",
      "fold: TRAIN; iteration: 2072; epoch: 1; loss: 2.3211402893066406; \n",
      "fold: TRAIN; iteration: 2073; epoch: 1; loss: 2.3539986610412598; \n",
      "fold: TRAIN; iteration: 2074; epoch: 1; loss: 2.351201057434082; \n",
      "fold: TRAIN; iteration: 2075; epoch: 1; loss: 2.3506827354431152; \n",
      "fold: TRAIN; iteration: 2076; epoch: 1; loss: 2.4229836463928223; \n",
      "fold: TRAIN; iteration: 2077; epoch: 1; loss: 2.5097362995147705; \n",
      "fold: TRAIN; iteration: 2078; epoch: 1; loss: 2.5499346256256104; \n",
      "fold: TRAIN; iteration: 2079; epoch: 1; loss: 2.4738123416900635; \n",
      "fold: TRAIN; iteration: 2080; epoch: 1; loss: 2.255197048187256; \n",
      "fold: TRAIN; iteration: 2081; epoch: 1; loss: 2.296870708465576; \n",
      "fold: TRAIN; iteration: 2082; epoch: 1; loss: 2.607307195663452; \n",
      "fold: TRAIN; iteration: 2083; epoch: 1; loss: 2.526764154434204; \n",
      "fold: TRAIN; iteration: 2084; epoch: 1; loss: 2.360088586807251; \n",
      "fold: TRAIN; iteration: 2085; epoch: 1; loss: 2.3523006439208984; \n",
      "fold: TRAIN; iteration: 2086; epoch: 1; loss: 2.43869686126709; \n",
      "fold: TRAIN; iteration: 2087; epoch: 1; loss: 2.3126299381256104; \n",
      "fold: TRAIN; iteration: 2088; epoch: 1; loss: 2.235365867614746; \n",
      "fold: TRAIN; iteration: 2089; epoch: 1; loss: 2.49662709236145; \n",
      "fold: TRAIN; iteration: 2090; epoch: 1; loss: 2.069838047027588; \n",
      "fold: TRAIN; iteration: 2091; epoch: 1; loss: 2.534773826599121; \n",
      "fold: TRAIN; iteration: 2092; epoch: 1; loss: 2.595752000808716; \n",
      "fold: TRAIN; iteration: 2093; epoch: 1; loss: 2.5651679039001465; \n",
      "fold: TRAIN; iteration: 2094; epoch: 1; loss: 2.281235456466675; \n",
      "fold: TRAIN; iteration: 2095; epoch: 1; loss: 2.476516008377075; \n",
      "fold: TRAIN; iteration: 2096; epoch: 1; loss: 2.658262014389038; \n",
      "fold: TRAIN; iteration: 2097; epoch: 1; loss: 2.311077833175659; \n",
      "fold: TRAIN; iteration: 2098; epoch: 1; loss: 2.5388519763946533; \n",
      "fold: TRAIN; iteration: 2099; epoch: 1; loss: 2.474578380584717; \n",
      "fold: TRAIN; iteration: 2100; epoch: 1; loss: 2.4014406204223633; \n",
      "fold: TRAIN; iteration: 2101; epoch: 1; loss: 2.412623405456543; \n",
      "fold: TRAIN; iteration: 2102; epoch: 1; loss: 2.4163565635681152; \n",
      "fold: TRAIN; iteration: 2103; epoch: 1; loss: 2.2445573806762695; \n",
      "fold: TRAIN; iteration: 2104; epoch: 1; loss: 2.3714797496795654; \n",
      "fold: TRAIN; iteration: 2105; epoch: 1; loss: 2.6044013500213623; \n",
      "fold: TRAIN; iteration: 2106; epoch: 1; loss: 2.6677188873291016; \n",
      "fold: TRAIN; iteration: 2107; epoch: 1; loss: 2.6200804710388184; \n",
      "fold: TRAIN; iteration: 2108; epoch: 1; loss: 2.402703285217285; \n",
      "fold: TRAIN; iteration: 2109; epoch: 1; loss: 2.3391969203948975; \n",
      "fold: TRAIN; iteration: 2110; epoch: 1; loss: 2.4567127227783203; \n",
      "fold: TRAIN; iteration: 2111; epoch: 1; loss: 2.6275861263275146; \n",
      "fold: TRAIN; iteration: 2112; epoch: 1; loss: 2.4154160022735596; \n",
      "fold: TRAIN; iteration: 2113; epoch: 1; loss: 2.4009509086608887; \n",
      "fold: TRAIN; iteration: 2114; epoch: 1; loss: 2.5026187896728516; \n",
      "fold: TRAIN; iteration: 2115; epoch: 1; loss: 2.4891490936279297; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 2116; epoch: 1; loss: 2.2404022216796875; \n",
      "fold: TRAIN; iteration: 2117; epoch: 1; loss: 2.525148868560791; \n",
      "fold: TRAIN; iteration: 2118; epoch: 1; loss: 2.3131613731384277; \n",
      "fold: TRAIN; iteration: 2119; epoch: 1; loss: 2.6463046073913574; \n",
      "fold: TRAIN; iteration: 2120; epoch: 1; loss: 2.3872175216674805; \n",
      "fold: TRAIN; iteration: 2121; epoch: 1; loss: 2.500378370285034; \n",
      "fold: TRAIN; iteration: 2122; epoch: 1; loss: 2.4558022022247314; \n",
      "fold: TRAIN; iteration: 2123; epoch: 1; loss: 2.392667531967163; \n",
      "fold: TRAIN; iteration: 2124; epoch: 1; loss: 2.591515302658081; \n",
      "fold: TRAIN; iteration: 2125; epoch: 1; loss: 2.7657077312469482; \n",
      "fold: TRAIN; iteration: 2126; epoch: 1; loss: 2.850219488143921; \n",
      "fold: TRAIN; iteration: 2127; epoch: 1; loss: 2.470404624938965; \n",
      "fold: TRAIN; iteration: 2128; epoch: 1; loss: 2.6574959754943848; \n",
      "fold: TRAIN; iteration: 2129; epoch: 1; loss: 2.5255913734436035; \n",
      "fold: TRAIN; iteration: 2130; epoch: 1; loss: 2.5335071086883545; \n",
      "fold: TRAIN; iteration: 2131; epoch: 1; loss: 2.4432992935180664; \n",
      "fold: TRAIN; iteration: 2132; epoch: 1; loss: 2.596961736679077; \n",
      "fold: TRAIN; iteration: 2133; epoch: 1; loss: 2.6914267539978027; \n",
      "fold: TRAIN; iteration: 2134; epoch: 1; loss: 2.3503808975219727; \n",
      "fold: TRAIN; iteration: 2135; epoch: 1; loss: 2.4703283309936523; \n",
      "fold: TRAIN; iteration: 2136; epoch: 1; loss: 2.580059766769409; \n",
      "fold: TRAIN; iteration: 2137; epoch: 1; loss: 2.452023983001709; \n",
      "fold: TRAIN; iteration: 2138; epoch: 1; loss: 2.7878196239471436; \n",
      "fold: TRAIN; iteration: 2139; epoch: 1; loss: 2.227931022644043; \n",
      "fold: TRAIN; iteration: 2140; epoch: 1; loss: 2.5138587951660156; \n",
      "fold: TRAIN; iteration: 2141; epoch: 1; loss: 2.501749277114868; \n",
      "fold: TRAIN; iteration: 2142; epoch: 1; loss: 2.2965197563171387; \n",
      "fold: TRAIN; iteration: 2143; epoch: 1; loss: 2.3472888469696045; \n",
      "fold: TRAIN; iteration: 2144; epoch: 1; loss: 2.1491713523864746; \n",
      "fold: TRAIN; iteration: 2145; epoch: 1; loss: 2.344902753829956; \n",
      "fold: TRAIN; iteration: 2146; epoch: 1; loss: 2.461986780166626; \n",
      "fold: TRAIN; iteration: 2147; epoch: 1; loss: 2.290131092071533; \n",
      "fold: TRAIN; iteration: 2148; epoch: 1; loss: 2.5842676162719727; \n",
      "fold: TRAIN; iteration: 2149; epoch: 1; loss: 2.3880908489227295; \n",
      "fold: TRAIN; iteration: 2150; epoch: 1; loss: 2.4955718517303467; \n",
      "fold: TRAIN; iteration: 2151; epoch: 1; loss: 2.487694025039673; \n",
      "fold: TRAIN; iteration: 2152; epoch: 1; loss: 2.4450693130493164; \n",
      "fold: TRAIN; iteration: 2153; epoch: 1; loss: 2.3396058082580566; \n",
      "fold: TRAIN; iteration: 2154; epoch: 1; loss: 2.3112192153930664; \n",
      "fold: TRAIN; iteration: 2155; epoch: 1; loss: 2.4292690753936768; \n",
      "fold: TRAIN; iteration: 2156; epoch: 1; loss: 2.373699426651001; \n",
      "fold: TRAIN; iteration: 2157; epoch: 1; loss: 2.4178431034088135; \n",
      "fold: TRAIN; iteration: 2158; epoch: 1; loss: 2.5353102684020996; \n",
      "fold: TRAIN; iteration: 2159; epoch: 1; loss: 2.466372013092041; \n",
      "fold: TRAIN; iteration: 2160; epoch: 1; loss: 2.5389840602874756; \n",
      "fold: TRAIN; iteration: 2161; epoch: 1; loss: 2.7154457569122314; \n",
      "fold: TRAIN; iteration: 2162; epoch: 1; loss: 2.367676258087158; \n",
      "fold: TRAIN; iteration: 2163; epoch: 1; loss: 2.3143908977508545; \n",
      "fold: TRAIN; iteration: 2164; epoch: 1; loss: 2.2233567237854004; \n",
      "fold: TRAIN; iteration: 2165; epoch: 1; loss: 2.3566596508026123; \n",
      "fold: TRAIN; iteration: 2166; epoch: 1; loss: 2.330681800842285; \n",
      "fold: TRAIN; iteration: 2167; epoch: 1; loss: 2.708962917327881; \n",
      "fold: TRAIN; iteration: 2168; epoch: 1; loss: 2.4014947414398193; \n",
      "fold: TRAIN; iteration: 2169; epoch: 1; loss: 2.624069929122925; \n",
      "fold: TRAIN; iteration: 2170; epoch: 1; loss: 2.398815631866455; \n",
      "fold: TRAIN; iteration: 2171; epoch: 1; loss: 2.438995599746704; \n",
      "fold: TRAIN; iteration: 2172; epoch: 1; loss: 2.193880558013916; \n",
      "fold: TRAIN; iteration: 2173; epoch: 1; loss: 2.543689489364624; \n",
      "fold: TRAIN; iteration: 2174; epoch: 1; loss: 2.6518521308898926; \n",
      "fold: TRAIN; iteration: 2175; epoch: 1; loss: 2.4973955154418945; \n",
      "fold: TRAIN; iteration: 2176; epoch: 1; loss: 2.533139705657959; \n",
      "fold: TRAIN; iteration: 2177; epoch: 1; loss: 2.163731336593628; \n",
      "fold: TRAIN; iteration: 2178; epoch: 1; loss: 2.578038215637207; \n",
      "fold: TRAIN; iteration: 2179; epoch: 1; loss: 2.737448215484619; \n",
      "fold: TRAIN; iteration: 2180; epoch: 1; loss: 2.359950065612793; \n",
      "fold: TRAIN; iteration: 2181; epoch: 1; loss: 2.323986053466797; \n",
      "fold: TRAIN; iteration: 2182; epoch: 1; loss: 2.404845952987671; \n",
      "fold: TRAIN; iteration: 2183; epoch: 1; loss: 2.392659902572632; \n",
      "fold: TRAIN; iteration: 2184; epoch: 1; loss: 2.5444154739379883; \n",
      "fold: TRAIN; iteration: 2185; epoch: 1; loss: 2.422051429748535; \n",
      "fold: TRAIN; iteration: 2186; epoch: 1; loss: 2.4440255165100098; \n",
      "fold: TRAIN; iteration: 2187; epoch: 1; loss: 2.5013763904571533; \n",
      "fold: TRAIN; iteration: 2188; epoch: 1; loss: 2.3976023197174072; \n",
      "fold: TRAIN; iteration: 2189; epoch: 1; loss: 2.3800344467163086; \n",
      "fold: TRAIN; iteration: 2190; epoch: 1; loss: 2.2478506565093994; \n",
      "fold: TRAIN; iteration: 2191; epoch: 1; loss: 2.3456156253814697; \n",
      "fold: TRAIN; iteration: 2192; epoch: 1; loss: 2.510300874710083; \n",
      "fold: TRAIN; iteration: 2193; epoch: 1; loss: 2.379981279373169; \n",
      "fold: TRAIN; iteration: 2194; epoch: 1; loss: 2.5072014331817627; \n",
      "fold: TRAIN; iteration: 2195; epoch: 1; loss: 2.313511848449707; \n",
      "fold: TRAIN; iteration: 2196; epoch: 1; loss: 2.385876417160034; \n",
      "fold: TRAIN; iteration: 2197; epoch: 1; loss: 2.494201421737671; \n",
      "fold: TRAIN; iteration: 2198; epoch: 1; loss: 2.7016375064849854; \n",
      "fold: TRAIN; iteration: 2199; epoch: 1; loss: 2.261892318725586; \n",
      "fold: TRAIN; iteration: 2200; epoch: 1; loss: 2.363542079925537; \n",
      "fold: TRAIN; iteration: 2201; epoch: 1; loss: 2.45615291595459; \n",
      "fold: TRAIN; iteration: 2202; epoch: 1; loss: 2.3165953159332275; \n",
      "fold: TRAIN; iteration: 2203; epoch: 1; loss: 2.4366562366485596; \n",
      "fold: TRAIN; iteration: 2204; epoch: 1; loss: 2.3601226806640625; \n",
      "fold: TRAIN; iteration: 2205; epoch: 1; loss: 2.3680248260498047; \n",
      "fold: TRAIN; iteration: 2206; epoch: 1; loss: 2.2575972080230713; \n",
      "fold: TRAIN; iteration: 2207; epoch: 1; loss: 2.481222152709961; \n",
      "fold: TRAIN; iteration: 2208; epoch: 1; loss: 2.326266050338745; \n",
      "fold: TRAIN; iteration: 2209; epoch: 1; loss: 2.4012527465820312; \n",
      "fold: TRAIN; iteration: 2210; epoch: 1; loss: 2.2335453033447266; \n",
      "fold: TRAIN; iteration: 2211; epoch: 1; loss: 2.3673791885375977; \n",
      "fold: TRAIN; iteration: 2212; epoch: 1; loss: 2.3885042667388916; \n",
      "fold: TRAIN; iteration: 2213; epoch: 1; loss: 2.2768890857696533; \n",
      "fold: TRAIN; iteration: 2214; epoch: 1; loss: 2.350398063659668; \n",
      "fold: TRAIN; iteration: 2215; epoch: 1; loss: 2.5472350120544434; \n",
      "fold: TRAIN; iteration: 2216; epoch: 1; loss: 2.4195919036865234; \n",
      "fold: TRAIN; iteration: 2217; epoch: 1; loss: 2.4803543090820312; \n",
      "fold: TRAIN; iteration: 2218; epoch: 1; loss: 2.6490182876586914; \n",
      "fold: TRAIN; iteration: 2219; epoch: 1; loss: 2.394177198410034; \n",
      "fold: TRAIN; iteration: 2220; epoch: 1; loss: 2.540774345397949; \n",
      "fold: TRAIN; iteration: 2221; epoch: 1; loss: 2.463935375213623; \n",
      "fold: TRAIN; iteration: 2222; epoch: 1; loss: 2.65195369720459; \n",
      "fold: TRAIN; iteration: 2223; epoch: 1; loss: 2.2006287574768066; \n",
      "fold: TRAIN; iteration: 2224; epoch: 1; loss: 2.6701595783233643; \n",
      "fold: TRAIN; iteration: 2225; epoch: 1; loss: 2.4054982662200928; \n",
      "fold: TRAIN; iteration: 2226; epoch: 1; loss: 2.430239677429199; \n",
      "fold: TRAIN; iteration: 2227; epoch: 1; loss: 2.4596943855285645; \n",
      "fold: TRAIN; iteration: 2228; epoch: 1; loss: 2.359543800354004; \n",
      "fold: TRAIN; iteration: 2229; epoch: 1; loss: 2.2984824180603027; \n",
      "fold: TRAIN; iteration: 2230; epoch: 1; loss: 2.4092812538146973; \n",
      "fold: TRAIN; iteration: 2231; epoch: 1; loss: 2.355618476867676; \n",
      "fold: TRAIN; iteration: 2232; epoch: 1; loss: 2.3752167224884033; \n",
      "fold: TRAIN; iteration: 2233; epoch: 1; loss: 2.3669636249542236; \n",
      "fold: TRAIN; iteration: 2234; epoch: 1; loss: 2.4612059593200684; \n",
      "fold: TRAIN; iteration: 2235; epoch: 1; loss: 2.459318161010742; \n",
      "fold: TRAIN; iteration: 2236; epoch: 1; loss: 2.252641439437866; \n",
      "fold: TRAIN; iteration: 2237; epoch: 1; loss: 2.3052682876586914; \n",
      "fold: TRAIN; iteration: 2238; epoch: 1; loss: 2.3793318271636963; \n",
      "fold: TRAIN; iteration: 2239; epoch: 1; loss: 2.372544050216675; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 2240; epoch: 1; loss: 2.48702335357666; \n",
      "fold: TRAIN; iteration: 2241; epoch: 1; loss: 2.3235936164855957; \n",
      "fold: TRAIN; iteration: 2242; epoch: 1; loss: 2.184774398803711; \n",
      "fold: TRAIN; iteration: 2243; epoch: 1; loss: 2.6297848224639893; \n",
      "fold: TRAIN; iteration: 2244; epoch: 1; loss: 2.3361589908599854; \n",
      "fold: TRAIN; iteration: 2245; epoch: 1; loss: 2.3945186138153076; \n",
      "fold: TRAIN; iteration: 2246; epoch: 1; loss: 2.389545202255249; \n",
      "fold: TRAIN; iteration: 2247; epoch: 1; loss: 2.3591177463531494; \n",
      "fold: TRAIN; iteration: 2248; epoch: 1; loss: 2.5071210861206055; \n",
      "fold: TRAIN; iteration: 2249; epoch: 1; loss: 2.4234812259674072; \n",
      "fold: TRAIN; iteration: 2250; epoch: 1; loss: 2.2056353092193604; \n",
      "fold: TRAIN; iteration: 2251; epoch: 1; loss: 2.385352849960327; \n",
      "fold: TRAIN; iteration: 2252; epoch: 1; loss: 2.1716980934143066; \n",
      "fold: TRAIN; iteration: 2253; epoch: 1; loss: 2.4637115001678467; \n",
      "fold: TRAIN; iteration: 2254; epoch: 1; loss: 2.3113911151885986; \n",
      "fold: TRAIN; iteration: 2255; epoch: 1; loss: 2.319965362548828; \n",
      "fold: TRAIN; iteration: 2256; epoch: 1; loss: 2.4690346717834473; \n",
      "fold: TRAIN; iteration: 2257; epoch: 1; loss: 2.4276440143585205; \n",
      "fold: TRAIN; iteration: 2258; epoch: 1; loss: 2.503420114517212; \n",
      "fold: TRAIN; iteration: 2259; epoch: 1; loss: 2.450432062149048; \n",
      "fold: TRAIN; iteration: 2260; epoch: 1; loss: 2.352388858795166; \n",
      "fold: TRAIN; iteration: 2261; epoch: 1; loss: 2.714674472808838; \n",
      "fold: TRAIN; iteration: 2262; epoch: 1; loss: 2.7119245529174805; \n",
      "fold: TRAIN; iteration: 2263; epoch: 1; loss: 2.5160698890686035; \n",
      "fold: TRAIN; iteration: 2264; epoch: 1; loss: 2.3709609508514404; \n",
      "fold: TRAIN; iteration: 2265; epoch: 1; loss: 2.523540735244751; \n",
      "fold: TRAIN; iteration: 2266; epoch: 1; loss: 2.3089373111724854; \n",
      "fold: TRAIN; iteration: 2267; epoch: 1; loss: 2.352085828781128; \n",
      "fold: TRAIN; iteration: 2268; epoch: 1; loss: 2.484575033187866; \n",
      "fold: TRAIN; iteration: 2269; epoch: 1; loss: 2.6166696548461914; \n",
      "fold: TRAIN; iteration: 2270; epoch: 1; loss: 2.2979695796966553; \n",
      "fold: TRAIN; iteration: 2271; epoch: 1; loss: 2.2359704971313477; \n",
      "fold: TRAIN; iteration: 2272; epoch: 1; loss: 2.526979446411133; \n",
      "fold: TRAIN; iteration: 2273; epoch: 1; loss: 2.520038604736328; \n",
      "fold: TRAIN; iteration: 2274; epoch: 1; loss: 2.237539768218994; \n",
      "fold: TRAIN; iteration: 2275; epoch: 1; loss: 2.3653295040130615; \n",
      "fold: TRAIN; iteration: 2276; epoch: 1; loss: 2.5283541679382324; \n",
      "fold: TRAIN; iteration: 2277; epoch: 1; loss: 2.4487650394439697; \n",
      "fold: TRAIN; iteration: 2278; epoch: 1; loss: 2.264253854751587; \n",
      "fold: TRAIN; iteration: 2279; epoch: 1; loss: 2.1501357555389404; \n",
      "fold: TRAIN; iteration: 2280; epoch: 1; loss: 2.6647281646728516; \n",
      "fold: TRAIN; iteration: 2281; epoch: 1; loss: 2.444591760635376; \n",
      "fold: TRAIN; iteration: 2282; epoch: 1; loss: 2.179131269454956; \n",
      "fold: TRAIN; iteration: 2283; epoch: 1; loss: 2.5196969509124756; \n",
      "fold: TRAIN; iteration: 2284; epoch: 1; loss: 2.41934871673584; \n",
      "fold: TRAIN; iteration: 2285; epoch: 1; loss: 2.4999382495880127; \n",
      "fold: TRAIN; iteration: 2286; epoch: 1; loss: 2.4108901023864746; \n",
      "fold: TRAIN; iteration: 2287; epoch: 1; loss: 2.3380069732666016; \n",
      "fold: TRAIN; iteration: 2288; epoch: 1; loss: 2.3692991733551025; \n",
      "fold: TRAIN; iteration: 2289; epoch: 1; loss: 2.425349712371826; \n",
      "fold: TRAIN; iteration: 2290; epoch: 1; loss: 2.5505454540252686; \n",
      "fold: TRAIN; iteration: 2291; epoch: 1; loss: 2.309537410736084; \n",
      "fold: TRAIN; iteration: 2292; epoch: 1; loss: 2.4509477615356445; \n",
      "fold: TRAIN; iteration: 2293; epoch: 1; loss: 2.249495029449463; \n",
      "fold: TRAIN; iteration: 2294; epoch: 1; loss: 2.546776533126831; \n",
      "fold: TRAIN; iteration: 2295; epoch: 1; loss: 2.6429266929626465; \n",
      "fold: TRAIN; iteration: 2296; epoch: 1; loss: 2.5236856937408447; \n",
      "fold: TRAIN; iteration: 2297; epoch: 1; loss: 2.578465461730957; \n",
      "fold: TRAIN; iteration: 2298; epoch: 1; loss: 2.3759727478027344; \n",
      "fold: TRAIN; iteration: 2299; epoch: 1; loss: 2.3756966590881348; \n",
      "fold: TRAIN; iteration: 2300; epoch: 1; loss: 2.5442001819610596; \n",
      "fold: TRAIN; iteration: 2301; epoch: 1; loss: 2.5052435398101807; \n",
      "fold: TRAIN; iteration: 2302; epoch: 1; loss: 2.4351272583007812; \n",
      "fold: TRAIN; iteration: 2303; epoch: 1; loss: 2.4719207286834717; \n",
      "fold: TRAIN; iteration: 2304; epoch: 1; loss: 2.6468191146850586; \n",
      "fold: TRAIN; iteration: 2305; epoch: 1; loss: 2.3722739219665527; \n",
      "fold: TRAIN; iteration: 2306; epoch: 1; loss: 2.3944718837738037; \n",
      "fold: TRAIN; iteration: 2307; epoch: 1; loss: 2.349818468093872; \n",
      "fold: TRAIN; iteration: 2308; epoch: 1; loss: 2.309138298034668; \n",
      "fold: TRAIN; iteration: 2309; epoch: 1; loss: 2.3293280601501465; \n",
      "fold: TRAIN; iteration: 2310; epoch: 1; loss: 2.1809582710266113; \n",
      "fold: TRAIN; iteration: 2311; epoch: 1; loss: 2.2196452617645264; \n",
      "fold: TRAIN; iteration: 2312; epoch: 1; loss: 2.3970048427581787; \n",
      "fold: TRAIN; iteration: 2313; epoch: 1; loss: 2.175859212875366; \n",
      "fold: TRAIN; iteration: 2314; epoch: 1; loss: 2.5271897315979004; \n",
      "fold: TRAIN; iteration: 2315; epoch: 1; loss: 2.4580514430999756; \n",
      "fold: TRAIN; iteration: 2316; epoch: 1; loss: 2.591851234436035; \n",
      "fold: TRAIN; iteration: 2317; epoch: 1; loss: 2.5234110355377197; \n",
      "fold: TRAIN; iteration: 2318; epoch: 1; loss: 2.5209903717041016; \n",
      "fold: TRAIN; iteration: 2319; epoch: 1; loss: 2.682305335998535; \n",
      "fold: TRAIN; iteration: 2320; epoch: 1; loss: 2.638646125793457; \n",
      "fold: TRAIN; iteration: 2321; epoch: 1; loss: 2.458622455596924; \n",
      "fold: TRAIN; iteration: 2322; epoch: 1; loss: 2.1753897666931152; \n",
      "fold: TRAIN; iteration: 2323; epoch: 1; loss: 2.5405406951904297; \n",
      "fold: TRAIN; iteration: 2324; epoch: 1; loss: 2.581130027770996; \n",
      "fold: TRAIN; iteration: 2325; epoch: 1; loss: 2.42238187789917; \n",
      "fold: TRAIN; iteration: 2326; epoch: 1; loss: 2.4232895374298096; \n",
      "fold: TRAIN; iteration: 2327; epoch: 1; loss: 2.740297555923462; \n",
      "fold: TRAIN; iteration: 2328; epoch: 1; loss: 2.391796588897705; \n",
      "fold: TRAIN; iteration: 2329; epoch: 1; loss: 2.5601885318756104; \n",
      "fold: TRAIN; iteration: 2330; epoch: 1; loss: 2.5819756984710693; \n",
      "fold: TRAIN; iteration: 2331; epoch: 1; loss: 2.439185380935669; \n",
      "fold: TRAIN; iteration: 2332; epoch: 1; loss: 2.7142040729522705; \n",
      "fold: TRAIN; iteration: 2333; epoch: 1; loss: 2.510514497756958; \n",
      "fold: TRAIN; iteration: 2334; epoch: 1; loss: 2.393068790435791; \n",
      "fold: TRAIN; iteration: 2335; epoch: 1; loss: 2.388690233230591; \n",
      "fold: TRAIN; iteration: 2336; epoch: 1; loss: 2.5847415924072266; \n",
      "fold: TRAIN; iteration: 2337; epoch: 1; loss: 2.452152729034424; \n",
      "fold: TRAIN; iteration: 2338; epoch: 1; loss: 2.3091368675231934; \n",
      "fold: TRAIN; iteration: 2339; epoch: 1; loss: 2.426973581314087; \n",
      "fold: TRAIN; iteration: 2340; epoch: 1; loss: 2.293288230895996; \n",
      "fold: TRAIN; iteration: 2341; epoch: 1; loss: 2.3837740421295166; \n",
      "fold: TRAIN; iteration: 2342; epoch: 1; loss: 2.3218793869018555; \n",
      "fold: TRAIN; iteration: 2343; epoch: 1; loss: 2.5439443588256836; \n",
      "fold: TRAIN; iteration: 2344; epoch: 1; loss: 2.5644190311431885; \n",
      "fold: TRAIN; iteration: 2345; epoch: 1; loss: 2.5083837509155273; \n",
      "fold: TRAIN; iteration: 2346; epoch: 1; loss: 2.2210159301757812; \n",
      "fold: TRAIN; iteration: 2347; epoch: 1; loss: 2.501486301422119; \n",
      "fold: TRAIN; iteration: 2348; epoch: 1; loss: 2.304492235183716; \n",
      "fold: TRAIN; iteration: 2349; epoch: 1; loss: 2.357020378112793; \n",
      "fold: TRAIN; iteration: 2350; epoch: 1; loss: 2.4644174575805664; \n",
      "fold: TRAIN; iteration: 2351; epoch: 1; loss: 2.4904656410217285; \n",
      "fold: TRAIN; iteration: 2352; epoch: 1; loss: 2.219210147857666; \n",
      "fold: TRAIN; iteration: 2353; epoch: 1; loss: 2.4573819637298584; \n",
      "fold: TRAIN; iteration: 2354; epoch: 1; loss: 2.4634995460510254; \n",
      "fold: TRAIN; iteration: 2355; epoch: 1; loss: 2.595019578933716; \n",
      "fold: TRAIN; iteration: 2356; epoch: 1; loss: 2.3536899089813232; \n",
      "fold: TRAIN; iteration: 2357; epoch: 1; loss: 2.5659492015838623; \n",
      "fold: TRAIN; iteration: 2358; epoch: 1; loss: 2.5247347354888916; \n",
      "fold: TRAIN; iteration: 2359; epoch: 1; loss: 2.4099550247192383; \n",
      "fold: TRAIN; iteration: 2360; epoch: 1; loss: 2.2769532203674316; \n",
      "fold: TRAIN; iteration: 2361; epoch: 1; loss: 2.60960054397583; \n",
      "fold: TRAIN; iteration: 2362; epoch: 1; loss: 2.4105329513549805; \n",
      "fold: TRAIN; iteration: 2363; epoch: 1; loss: 2.4992096424102783; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 2364; epoch: 1; loss: 2.3698060512542725; \n",
      "fold: TRAIN; iteration: 2365; epoch: 1; loss: 2.539613723754883; \n",
      "fold: TRAIN; iteration: 2366; epoch: 1; loss: 2.4435575008392334; \n",
      "fold: TRAIN; iteration: 2367; epoch: 1; loss: 2.5007028579711914; \n",
      "fold: TRAIN; iteration: 2368; epoch: 1; loss: 2.3346948623657227; \n",
      "fold: TRAIN; iteration: 2369; epoch: 1; loss: 2.360222816467285; \n",
      "fold: TRAIN; iteration: 2370; epoch: 1; loss: 2.074448347091675; \n",
      "fold: TRAIN; iteration: 2371; epoch: 1; loss: 2.571413993835449; \n",
      "fold: TRAIN; iteration: 2372; epoch: 1; loss: 2.557152032852173; \n",
      "fold: TRAIN; iteration: 2373; epoch: 1; loss: 2.4336202144622803; \n",
      "fold: TRAIN; iteration: 2374; epoch: 1; loss: 2.4284305572509766; \n",
      "fold: TRAIN; iteration: 2375; epoch: 1; loss: 2.431291103363037; \n",
      "fold: TRAIN; iteration: 2376; epoch: 1; loss: 2.720761775970459; \n",
      "fold: TRAIN; iteration: 2377; epoch: 1; loss: 2.2670812606811523; \n",
      "fold: TRAIN; iteration: 2378; epoch: 1; loss: 2.384995937347412; \n",
      "fold: TRAIN; iteration: 2379; epoch: 1; loss: 2.2102811336517334; \n",
      "fold: TRAIN; iteration: 2380; epoch: 1; loss: 2.6159098148345947; \n",
      "fold: TRAIN; iteration: 2381; epoch: 1; loss: 2.561108350753784; \n",
      "fold: TRAIN; iteration: 2382; epoch: 1; loss: 2.4901463985443115; \n",
      "fold: TRAIN; iteration: 2383; epoch: 1; loss: 2.15673828125; \n",
      "fold: TRAIN; iteration: 2384; epoch: 1; loss: 2.3417389392852783; \n",
      "fold: TRAIN; iteration: 2385; epoch: 1; loss: 2.437429904937744; \n",
      "fold: TRAIN; iteration: 2386; epoch: 1; loss: 2.4555275440216064; \n",
      "fold: TRAIN; iteration: 2387; epoch: 1; loss: 2.46108078956604; \n",
      "fold: TRAIN; iteration: 2388; epoch: 1; loss: 2.3096935749053955; \n",
      "fold: TRAIN; iteration: 2389; epoch: 1; loss: 2.172703742980957; \n",
      "fold: TRAIN; iteration: 2390; epoch: 1; loss: 2.345545768737793; \n",
      "fold: TRAIN; iteration: 2391; epoch: 1; loss: 2.5923821926116943; \n",
      "fold: TRAIN; iteration: 2392; epoch: 1; loss: 2.520779609680176; \n",
      "fold: TRAIN; iteration: 2393; epoch: 1; loss: 2.4057466983795166; \n",
      "fold: TRAIN; iteration: 2394; epoch: 1; loss: 2.37589430809021; \n",
      "fold: TRAIN; iteration: 2395; epoch: 1; loss: 2.4408528804779053; \n",
      "fold: TRAIN; iteration: 2396; epoch: 1; loss: 2.480116128921509; \n",
      "fold: TRAIN; iteration: 2397; epoch: 1; loss: 2.434340238571167; \n",
      "fold: TRAIN; iteration: 2398; epoch: 1; loss: 2.343310832977295; \n",
      "fold: TRAIN; iteration: 2399; epoch: 1; loss: 2.338770866394043; \n",
      "fold: TRAIN; iteration: 2400; epoch: 1; loss: 2.3640451431274414; \n",
      "fold: TRAIN; iteration: 2401; epoch: 1; loss: 2.3245275020599365; \n",
      "fold: TRAIN; iteration: 2402; epoch: 1; loss: 2.3185818195343018; \n",
      "fold: TRAIN; iteration: 2403; epoch: 1; loss: 2.662713050842285; \n",
      "fold: TRAIN; iteration: 2404; epoch: 1; loss: 2.484311103820801; \n",
      "fold: TRAIN; iteration: 2405; epoch: 1; loss: 2.238776445388794; \n",
      "fold: TRAIN; iteration: 2406; epoch: 1; loss: 2.466527223587036; \n",
      "fold: TRAIN; iteration: 2407; epoch: 1; loss: 2.3513755798339844; \n",
      "fold: TRAIN; iteration: 2408; epoch: 1; loss: 2.6181159019470215; \n",
      "fold: TRAIN; iteration: 2409; epoch: 1; loss: 2.4013922214508057; \n",
      "fold: TRAIN; iteration: 2410; epoch: 1; loss: 2.658557653427124; \n",
      "fold: TRAIN; iteration: 2411; epoch: 1; loss: 2.4661359786987305; \n",
      "fold: TRAIN; iteration: 2412; epoch: 1; loss: 2.365732192993164; \n",
      "fold: TRAIN; iteration: 2413; epoch: 1; loss: 2.446486711502075; \n",
      "fold: TRAIN; iteration: 2414; epoch: 1; loss: 2.373788833618164; \n",
      "fold: TRAIN; iteration: 2415; epoch: 1; loss: 2.219160556793213; \n",
      "fold: TRAIN; iteration: 2416; epoch: 1; loss: 2.4232735633850098; \n",
      "fold: TRAIN; iteration: 2417; epoch: 1; loss: 2.5466184616088867; \n",
      "fold: TRAIN; iteration: 2418; epoch: 1; loss: 2.7698583602905273; \n",
      "fold: TRAIN; iteration: 2419; epoch: 1; loss: 2.2377753257751465; \n",
      "fold: TRAIN; iteration: 2420; epoch: 1; loss: 2.5652527809143066; \n",
      "fold: TRAIN; iteration: 2421; epoch: 1; loss: 2.5311636924743652; \n",
      "fold: TRAIN; iteration: 2422; epoch: 1; loss: 2.298914909362793; \n",
      "fold: TRAIN; iteration: 2423; epoch: 1; loss: 2.5695390701293945; \n",
      "fold: TRAIN; iteration: 2424; epoch: 1; loss: 2.3762853145599365; \n",
      "fold: TRAIN; iteration: 2425; epoch: 1; loss: 2.2494077682495117; \n",
      "fold: TRAIN; iteration: 2426; epoch: 1; loss: 2.5195043087005615; \n",
      "fold: TRAIN; iteration: 2427; epoch: 1; loss: 2.4856836795806885; \n",
      "fold: TRAIN; iteration: 2428; epoch: 1; loss: 2.3365447521209717; \n",
      "fold: TRAIN; iteration: 2429; epoch: 1; loss: 2.465416193008423; \n",
      "fold: TRAIN; iteration: 2430; epoch: 1; loss: 2.420060396194458; \n",
      "fold: TRAIN; iteration: 2431; epoch: 1; loss: 2.338446617126465; \n",
      "fold: TRAIN; iteration: 2432; epoch: 1; loss: 2.43937611579895; \n",
      "fold: TRAIN; iteration: 2433; epoch: 1; loss: 2.331263303756714; \n",
      "fold: TRAIN; iteration: 2434; epoch: 1; loss: 2.631657600402832; \n",
      "fold: TRAIN; iteration: 2435; epoch: 1; loss: 2.2508487701416016; \n",
      "fold: TRAIN; iteration: 2436; epoch: 1; loss: 2.6682751178741455; \n",
      "fold: TRAIN; iteration: 2437; epoch: 1; loss: 2.391960382461548; \n",
      "fold: TRAIN; iteration: 2438; epoch: 1; loss: 2.5778753757476807; \n",
      "fold: TRAIN; iteration: 2439; epoch: 1; loss: 2.3772802352905273; \n",
      "fold: TRAIN; iteration: 2440; epoch: 1; loss: 2.4499340057373047; \n",
      "fold: TRAIN; iteration: 2441; epoch: 1; loss: 2.4333930015563965; \n",
      "fold: TRAIN; iteration: 2442; epoch: 1; loss: 2.336052417755127; \n",
      "fold: TRAIN; iteration: 2443; epoch: 1; loss: 2.4695401191711426; \n",
      "fold: TRAIN; iteration: 2444; epoch: 1; loss: 2.461387872695923; \n",
      "fold: TRAIN; iteration: 2445; epoch: 1; loss: 2.069448947906494; \n",
      "fold: TRAIN; iteration: 2446; epoch: 1; loss: 2.3740715980529785; \n",
      "fold: TRAIN; iteration: 2447; epoch: 1; loss: 2.5461418628692627; \n",
      "fold: TRAIN; iteration: 2448; epoch: 1; loss: 2.578108787536621; \n",
      "fold: TRAIN; iteration: 2449; epoch: 1; loss: 2.5557093620300293; \n",
      "fold: TRAIN; iteration: 2450; epoch: 1; loss: 2.4088294506073; \n",
      "fold: TRAIN; iteration: 2451; epoch: 1; loss: 2.1696414947509766; \n",
      "fold: TRAIN; iteration: 2452; epoch: 1; loss: 2.2332706451416016; \n",
      "fold: TRAIN; iteration: 2453; epoch: 1; loss: 2.3053653240203857; \n",
      "fold: TRAIN; iteration: 2454; epoch: 1; loss: 2.233915090560913; \n",
      "fold: TRAIN; iteration: 2455; epoch: 1; loss: 2.4565584659576416; \n",
      "fold: TRAIN; iteration: 2456; epoch: 1; loss: 2.3426597118377686; \n",
      "fold: TRAIN; iteration: 2457; epoch: 1; loss: 2.4151830673217773; \n",
      "fold: TRAIN; iteration: 2458; epoch: 1; loss: 2.517836809158325; \n",
      "fold: TRAIN; iteration: 2459; epoch: 1; loss: 2.526552677154541; \n",
      "fold: TRAIN; iteration: 2460; epoch: 1; loss: 2.5687851905822754; \n",
      "fold: TRAIN; iteration: 2461; epoch: 1; loss: 2.1507678031921387; \n",
      "fold: TRAIN; iteration: 2462; epoch: 1; loss: 2.6273553371429443; \n",
      "fold: TRAIN; iteration: 2463; epoch: 1; loss: 2.6596362590789795; \n",
      "fold: TRAIN; iteration: 2464; epoch: 1; loss: 2.2784249782562256; \n",
      "fold: TRAIN; iteration: 2465; epoch: 1; loss: 2.186302900314331; \n",
      "fold: TRAIN; iteration: 2466; epoch: 1; loss: 2.292186975479126; \n",
      "fold: TRAIN; iteration: 2467; epoch: 1; loss: 2.5159316062927246; \n",
      "fold: TRAIN; iteration: 2468; epoch: 1; loss: 2.369602918624878; \n",
      "fold: TRAIN; iteration: 2469; epoch: 1; loss: 2.3839914798736572; \n",
      "fold: TRAIN; iteration: 2470; epoch: 1; loss: 2.337014675140381; \n",
      "fold: TRAIN; iteration: 2471; epoch: 1; loss: 2.120706558227539; \n",
      "fold: TRAIN; iteration: 2472; epoch: 1; loss: 2.403165817260742; \n",
      "fold: TRAIN; iteration: 2473; epoch: 1; loss: 2.5320982933044434; \n",
      "fold: TRAIN; iteration: 2474; epoch: 1; loss: 2.5002529621124268; \n",
      "fold: TRAIN; iteration: 2475; epoch: 1; loss: 2.372469425201416; \n",
      "fold: TRAIN; iteration: 2476; epoch: 1; loss: 2.487318515777588; \n",
      "fold: TRAIN; iteration: 2477; epoch: 1; loss: 2.2237796783447266; \n",
      "fold: TRAIN; iteration: 2478; epoch: 1; loss: 2.5642337799072266; \n",
      "fold: TRAIN; iteration: 2479; epoch: 1; loss: 2.580113172531128; \n",
      "fold: TRAIN; iteration: 2480; epoch: 1; loss: 2.4331085681915283; \n",
      "fold: TRAIN; iteration: 2481; epoch: 1; loss: 2.58956241607666; \n",
      "fold: TRAIN; iteration: 2482; epoch: 1; loss: 2.4024269580841064; \n",
      "fold: TRAIN; iteration: 2483; epoch: 1; loss: 2.7804839611053467; \n",
      "fold: TRAIN; iteration: 2484; epoch: 1; loss: 2.5348379611968994; \n",
      "fold: TRAIN; iteration: 2485; epoch: 1; loss: 2.398174524307251; \n",
      "fold: TRAIN; iteration: 2486; epoch: 1; loss: 2.3886775970458984; \n",
      "fold: TRAIN; iteration: 2487; epoch: 1; loss: 2.4035866260528564; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 2488; epoch: 1; loss: 2.4484734535217285; \n",
      "fold: TRAIN; iteration: 2489; epoch: 1; loss: 2.487853765487671; \n",
      "fold: TRAIN; iteration: 2490; epoch: 1; loss: 2.5731444358825684; \n",
      "fold: TRAIN; iteration: 2491; epoch: 1; loss: 2.417546510696411; \n",
      "fold: TRAIN; iteration: 2492; epoch: 1; loss: 2.030080556869507; \n",
      "fold: TRAIN; iteration: 2493; epoch: 1; loss: 2.2683169841766357; \n",
      "fold: TRAIN; iteration: 2494; epoch: 1; loss: 2.3287642002105713; \n",
      "fold: TRAIN; iteration: 2495; epoch: 1; loss: 2.523843288421631; \n",
      "fold: TRAIN; iteration: 2496; epoch: 1; loss: 2.588747501373291; \n",
      "fold: TRAIN; iteration: 2497; epoch: 1; loss: 2.4271388053894043; \n",
      "fold: TRAIN; iteration: 2498; epoch: 1; loss: 2.286080837249756; \n",
      "fold: TRAIN; iteration: 2499; epoch: 1; loss: 2.378056526184082; \n",
      "fold: TRAIN; iteration: 2500; epoch: 1; loss: 2.402325391769409; \n",
      "fold: TRAIN; iteration: 2501; epoch: 1; loss: 2.4669559001922607; \n",
      "fold: TRAIN; iteration: 2502; epoch: 1; loss: 2.1668386459350586; \n",
      "fold: TRAIN; iteration: 2503; epoch: 1; loss: 2.3853256702423096; \n",
      "fold: TRAIN; iteration: 2504; epoch: 1; loss: 2.4581308364868164; \n",
      "fold: TRAIN; iteration: 2505; epoch: 1; loss: 2.4420604705810547; \n",
      "fold: TRAIN; iteration: 2506; epoch: 1; loss: 2.4791903495788574; \n",
      "fold: TRAIN; iteration: 2507; epoch: 1; loss: 2.405867099761963; \n",
      "fold: TRAIN; iteration: 2508; epoch: 1; loss: 2.7474067211151123; \n",
      "fold: TRAIN; iteration: 2509; epoch: 1; loss: 2.4296462535858154; \n",
      "fold: TRAIN; iteration: 2510; epoch: 1; loss: 2.5242419242858887; \n",
      "fold: TRAIN; iteration: 2511; epoch: 1; loss: 2.4357950687408447; \n",
      "fold: TRAIN; iteration: 2512; epoch: 1; loss: 2.293123245239258; \n",
      "fold: TRAIN; iteration: 2513; epoch: 1; loss: 2.5037384033203125; \n",
      "fold: TRAIN; iteration: 2514; epoch: 1; loss: 2.2154600620269775; \n",
      "fold: TRAIN; iteration: 2515; epoch: 1; loss: 2.3698084354400635; \n",
      "fold: TRAIN; iteration: 2516; epoch: 1; loss: 2.4838883876800537; \n",
      "fold: TRAIN; iteration: 2517; epoch: 1; loss: 2.286630630493164; \n",
      "fold: TRAIN; iteration: 2518; epoch: 1; loss: 2.4564898014068604; \n",
      "fold: TRAIN; iteration: 2519; epoch: 1; loss: 2.3457932472229004; \n",
      "fold: TRAIN; iteration: 2520; epoch: 1; loss: 2.5036067962646484; \n",
      "fold: TRAIN; iteration: 2521; epoch: 1; loss: 2.5392603874206543; \n",
      "fold: TRAIN; iteration: 2522; epoch: 1; loss: 2.322645664215088; \n",
      "fold: TRAIN; iteration: 2523; epoch: 1; loss: 2.1766600608825684; \n",
      "fold: TRAIN; iteration: 2524; epoch: 1; loss: 2.5346977710723877; \n",
      "fold: TRAIN; iteration: 2525; epoch: 1; loss: 2.445467472076416; \n",
      "fold: TRAIN; iteration: 2526; epoch: 1; loss: 2.610060930252075; \n",
      "fold: TRAIN; iteration: 2527; epoch: 1; loss: 2.254070281982422; \n",
      "fold: TRAIN; iteration: 2528; epoch: 1; loss: 2.730588674545288; \n",
      "fold: TRAIN; iteration: 2529; epoch: 1; loss: 2.452420711517334; \n",
      "fold: TRAIN; iteration: 2530; epoch: 1; loss: 2.334669589996338; \n",
      "fold: TRAIN; iteration: 2531; epoch: 1; loss: 2.5493106842041016; \n",
      "fold: TRAIN; iteration: 2532; epoch: 1; loss: 2.216871976852417; \n",
      "fold: TRAIN; iteration: 2533; epoch: 1; loss: 2.2577145099639893; \n",
      "fold: TRAIN; iteration: 2534; epoch: 1; loss: 2.2874133586883545; \n",
      "fold: TRAIN; iteration: 2535; epoch: 1; loss: 2.5631158351898193; \n",
      "fold: TRAIN; iteration: 2536; epoch: 1; loss: 2.3719120025634766; \n",
      "fold: TRAIN; iteration: 2537; epoch: 1; loss: 2.35233473777771; \n",
      "fold: TRAIN; iteration: 2538; epoch: 1; loss: 2.509061813354492; \n",
      "fold: TRAIN; iteration: 2539; epoch: 1; loss: 2.245798110961914; \n",
      "fold: TRAIN; iteration: 2540; epoch: 1; loss: 2.2458951473236084; \n",
      "fold: TRAIN; iteration: 2541; epoch: 1; loss: 2.4987595081329346; \n",
      "fold: TRAIN; iteration: 2542; epoch: 1; loss: 2.375821113586426; \n",
      "fold: TRAIN; iteration: 2543; epoch: 1; loss: 2.362774610519409; \n",
      "fold: TRAIN; iteration: 2544; epoch: 1; loss: 2.337801933288574; \n",
      "fold: TRAIN; iteration: 2545; epoch: 1; loss: 2.4055585861206055; \n",
      "fold: TRAIN; iteration: 2546; epoch: 1; loss: 2.5244195461273193; \n",
      "fold: TRAIN; iteration: 2547; epoch: 1; loss: 2.3333959579467773; \n",
      "fold: TRAIN; iteration: 2548; epoch: 1; loss: 2.284837245941162; \n",
      "fold: TRAIN; iteration: 2549; epoch: 1; loss: 2.301163911819458; \n",
      "fold: TRAIN; iteration: 2550; epoch: 1; loss: 2.3604724407196045; \n",
      "fold: TRAIN; iteration: 2551; epoch: 1; loss: 2.368790626525879; \n",
      "fold: TRAIN; iteration: 2552; epoch: 1; loss: 2.199066638946533; \n",
      "fold: TRAIN; iteration: 2553; epoch: 1; loss: 2.5425314903259277; \n",
      "fold: TRAIN; iteration: 2554; epoch: 1; loss: 2.46836519241333; \n",
      "fold: TRAIN; iteration: 2555; epoch: 1; loss: 2.3919425010681152; \n",
      "fold: TRAIN; iteration: 2556; epoch: 1; loss: 2.5980749130249023; \n",
      "fold: TRAIN; iteration: 2557; epoch: 1; loss: 2.518702745437622; \n",
      "fold: TRAIN; iteration: 2558; epoch: 1; loss: 2.5005125999450684; \n",
      "fold: TRAIN; iteration: 2559; epoch: 1; loss: 2.6902811527252197; \n",
      "fold: TRAIN; iteration: 2560; epoch: 1; loss: 2.5364978313446045; \n",
      "fold: TRAIN; iteration: 2561; epoch: 1; loss: 2.5228304862976074; \n",
      "fold: TRAIN; iteration: 2562; epoch: 1; loss: 2.4524383544921875; \n",
      "fold: TRAIN; iteration: 2563; epoch: 1; loss: 2.2820632457733154; \n",
      "fold: TRAIN; iteration: 2564; epoch: 1; loss: 2.3650858402252197; \n",
      "fold: TRAIN; iteration: 2565; epoch: 1; loss: 2.4469149112701416; \n",
      "fold: TRAIN; iteration: 2566; epoch: 1; loss: 2.43048357963562; \n",
      "fold: TRAIN; iteration: 2567; epoch: 1; loss: 2.369288444519043; \n",
      "fold: TRAIN; iteration: 2568; epoch: 1; loss: 2.3600122928619385; \n",
      "fold: TRAIN; iteration: 2569; epoch: 1; loss: 2.419907569885254; \n",
      "fold: TRAIN; iteration: 2570; epoch: 1; loss: 2.4468486309051514; \n",
      "fold: TRAIN; iteration: 2571; epoch: 1; loss: 2.4044077396392822; \n",
      "fold: TRAIN; iteration: 2572; epoch: 1; loss: 2.3040175437927246; \n",
      "fold: TRAIN; iteration: 2573; epoch: 1; loss: 2.348992347717285; \n",
      "fold: TRAIN; iteration: 2574; epoch: 1; loss: 2.17752742767334; \n",
      "fold: TRAIN; iteration: 2575; epoch: 1; loss: 2.3391311168670654; \n",
      "fold: TRAIN; iteration: 2576; epoch: 1; loss: 2.0836076736450195; \n",
      "fold: TRAIN; iteration: 2577; epoch: 1; loss: 2.4542102813720703; \n",
      "fold: TRAIN; iteration: 2578; epoch: 1; loss: 2.6279191970825195; \n",
      "fold: TRAIN; iteration: 2579; epoch: 1; loss: 2.3520216941833496; \n",
      "fold: TRAIN; iteration: 2580; epoch: 1; loss: 2.2207369804382324; \n",
      "fold: TRAIN; iteration: 2581; epoch: 1; loss: 2.1641173362731934; \n",
      "fold: TRAIN; iteration: 2582; epoch: 1; loss: 2.4254283905029297; \n",
      "fold: TRAIN; iteration: 2583; epoch: 1; loss: 2.5294830799102783; \n",
      "fold: TRAIN; iteration: 2584; epoch: 1; loss: 2.1870248317718506; \n",
      "fold: TRAIN; iteration: 2585; epoch: 1; loss: 2.4469878673553467; \n",
      "fold: TRAIN; iteration: 2586; epoch: 1; loss: 2.4966118335723877; \n",
      "fold: TRAIN; iteration: 2587; epoch: 1; loss: 2.5083608627319336; \n",
      "fold: TRAIN; iteration: 2588; epoch: 1; loss: 2.401210069656372; \n",
      "fold: TRAIN; iteration: 2589; epoch: 1; loss: 2.637801170349121; \n",
      "fold: TRAIN; iteration: 2590; epoch: 1; loss: 2.1809794902801514; \n",
      "fold: TRAIN; iteration: 2591; epoch: 1; loss: 2.292562961578369; \n",
      "fold: TRAIN; iteration: 2592; epoch: 1; loss: 2.433682918548584; \n",
      "fold: TRAIN; iteration: 2593; epoch: 1; loss: 2.165153741836548; \n",
      "fold: TRAIN; iteration: 2594; epoch: 1; loss: 2.6760146617889404; \n",
      "fold: TRAIN; iteration: 2595; epoch: 1; loss: 2.365534782409668; \n",
      "fold: TRAIN; iteration: 2596; epoch: 1; loss: 2.430662155151367; \n",
      "fold: TRAIN; iteration: 2597; epoch: 1; loss: 2.346911907196045; \n",
      "fold: TRAIN; iteration: 2598; epoch: 1; loss: 2.3161497116088867; \n",
      "fold: TRAIN; iteration: 2599; epoch: 1; loss: 2.6199707984924316; \n",
      "fold: TRAIN; iteration: 2600; epoch: 1; loss: 2.390795946121216; \n",
      "fold: TRAIN; iteration: 2601; epoch: 1; loss: 2.2942135334014893; \n",
      "fold: TRAIN; iteration: 2602; epoch: 1; loss: 2.3250577449798584; \n",
      "fold: TRAIN; iteration: 2603; epoch: 1; loss: 2.37024188041687; \n",
      "fold: TRAIN; iteration: 2604; epoch: 1; loss: 2.5250589847564697; \n",
      "fold: TRAIN; iteration: 2605; epoch: 1; loss: 2.325086832046509; \n",
      "fold: TRAIN; iteration: 2606; epoch: 1; loss: 2.335923194885254; \n",
      "fold: TRAIN; iteration: 2607; epoch: 1; loss: 2.368443489074707; \n",
      "fold: TRAIN; iteration: 2608; epoch: 1; loss: 2.1734158992767334; \n",
      "fold: TRAIN; iteration: 2609; epoch: 1; loss: 2.605584144592285; \n",
      "fold: TRAIN; iteration: 2610; epoch: 1; loss: 2.410308361053467; \n",
      "fold: TRAIN; iteration: 2611; epoch: 1; loss: 2.6808180809020996; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 2612; epoch: 1; loss: 2.6211419105529785; \n",
      "fold: TRAIN; iteration: 2613; epoch: 1; loss: 2.604886531829834; \n",
      "fold: TRAIN; iteration: 2614; epoch: 1; loss: 2.189863920211792; \n",
      "fold: TRAIN; iteration: 2615; epoch: 1; loss: 2.472050428390503; \n",
      "fold: TRAIN; iteration: 2616; epoch: 1; loss: 2.4250009059906006; \n",
      "fold: TRAIN; iteration: 2617; epoch: 1; loss: 2.408233880996704; \n",
      "fold: TRAIN; iteration: 2618; epoch: 1; loss: 2.1827216148376465; \n",
      "fold: TRAIN; iteration: 2619; epoch: 1; loss: 2.215000629425049; \n",
      "fold: TRAIN; iteration: 2620; epoch: 1; loss: 2.526629686355591; \n",
      "fold: TRAIN; iteration: 2621; epoch: 1; loss: 2.320277452468872; \n",
      "fold: TRAIN; iteration: 2622; epoch: 1; loss: 2.2806272506713867; \n",
      "fold: TRAIN; iteration: 2623; epoch: 1; loss: 2.364243745803833; \n",
      "fold: TRAIN; iteration: 2624; epoch: 1; loss: 2.4537882804870605; \n",
      "fold: TRAIN; iteration: 2625; epoch: 1; loss: 2.4785425662994385; \n",
      "fold: TRAIN; iteration: 2626; epoch: 1; loss: 2.618562698364258; \n",
      "fold: TRAIN; iteration: 2627; epoch: 1; loss: 2.1028833389282227; \n",
      "fold: TRAIN; iteration: 2628; epoch: 1; loss: 2.453735589981079; \n",
      "fold: TRAIN; iteration: 2629; epoch: 1; loss: 2.728461980819702; \n",
      "fold: TRAIN; iteration: 2630; epoch: 1; loss: 2.344655990600586; \n",
      "fold: TRAIN; iteration: 2631; epoch: 1; loss: 2.4385757446289062; \n",
      "fold: TRAIN; iteration: 2632; epoch: 1; loss: 2.5387959480285645; \n",
      "fold: TRAIN; iteration: 2633; epoch: 1; loss: 2.2522552013397217; \n",
      "fold: TRAIN; iteration: 2634; epoch: 1; loss: 2.4177277088165283; \n",
      "fold: TRAIN; iteration: 2635; epoch: 1; loss: 2.3635482788085938; \n",
      "fold: TRAIN; iteration: 2636; epoch: 1; loss: 2.445449113845825; \n",
      "fold: TRAIN; iteration: 2637; epoch: 1; loss: 2.171220541000366; \n",
      "fold: TRAIN; iteration: 2638; epoch: 1; loss: 2.4725096225738525; \n",
      "fold: TRAIN; iteration: 2639; epoch: 1; loss: 2.4227633476257324; \n",
      "fold: TRAIN; iteration: 2640; epoch: 1; loss: 2.513819932937622; \n",
      "fold: TRAIN; iteration: 2641; epoch: 1; loss: 2.336482286453247; \n",
      "fold: TRAIN; iteration: 2642; epoch: 1; loss: 2.449307680130005; \n",
      "fold: TRAIN; iteration: 2643; epoch: 1; loss: 2.3644208908081055; \n",
      "fold: TRAIN; iteration: 2644; epoch: 1; loss: 2.4457263946533203; \n",
      "fold: TRAIN; iteration: 2645; epoch: 1; loss: 2.6848549842834473; \n",
      "fold: TRAIN; iteration: 2646; epoch: 1; loss: 2.3257339000701904; \n",
      "fold: TRAIN; iteration: 2647; epoch: 1; loss: 2.337350368499756; \n",
      "fold: TRAIN; iteration: 2648; epoch: 1; loss: 2.2924396991729736; \n",
      "fold: TRAIN; iteration: 2649; epoch: 1; loss: 2.391953945159912; \n",
      "fold: TRAIN; iteration: 2650; epoch: 1; loss: 2.314847469329834; \n",
      "fold: TRAIN; iteration: 2651; epoch: 1; loss: 2.5648560523986816; \n",
      "fold: TRAIN; iteration: 2652; epoch: 1; loss: 2.291590452194214; \n",
      "fold: TRAIN; iteration: 2653; epoch: 1; loss: 2.1905858516693115; \n",
      "fold: TRAIN; iteration: 2654; epoch: 1; loss: 2.5539779663085938; \n",
      "fold: TRAIN; iteration: 2655; epoch: 1; loss: 2.516510248184204; \n",
      "fold: TRAIN; iteration: 2656; epoch: 1; loss: 2.5500426292419434; \n",
      "fold: TRAIN; iteration: 2657; epoch: 1; loss: 2.424945831298828; \n",
      "fold: TRAIN; iteration: 2658; epoch: 1; loss: 2.5100655555725098; \n",
      "fold: TRAIN; iteration: 2659; epoch: 1; loss: 2.3405539989471436; \n",
      "fold: TRAIN; iteration: 2660; epoch: 1; loss: 2.6257686614990234; \n",
      "fold: TRAIN; iteration: 2661; epoch: 1; loss: 2.2500405311584473; \n",
      "fold: TRAIN; iteration: 2662; epoch: 1; loss: 2.291975498199463; \n",
      "fold: TRAIN; iteration: 2663; epoch: 1; loss: 2.323035478591919; \n",
      "fold: TRAIN; iteration: 2664; epoch: 1; loss: 2.512129306793213; \n",
      "fold: TRAIN; iteration: 2665; epoch: 1; loss: 2.501417875289917; \n",
      "fold: TRAIN; iteration: 2666; epoch: 1; loss: 2.7360260486602783; \n",
      "fold: TRAIN; iteration: 2667; epoch: 1; loss: 2.695216655731201; \n",
      "fold: TRAIN; iteration: 2668; epoch: 1; loss: 2.4906558990478516; \n",
      "fold: TRAIN; iteration: 2669; epoch: 1; loss: 2.3131864070892334; \n",
      "fold: TRAIN; iteration: 2670; epoch: 1; loss: 2.3651928901672363; \n",
      "fold: TRAIN; iteration: 2671; epoch: 1; loss: 1.9873428344726562; \n",
      "fold: TRAIN; iteration: 2672; epoch: 1; loss: 2.2394461631774902; \n",
      "fold: TRAIN; iteration: 2673; epoch: 1; loss: 2.3885114192962646; \n",
      "fold: TRAIN; iteration: 2674; epoch: 1; loss: 2.720463752746582; \n",
      "fold: TRAIN; iteration: 2675; epoch: 1; loss: 2.2868645191192627; \n",
      "fold: TRAIN; iteration: 2676; epoch: 1; loss: 2.5185413360595703; \n",
      "fold: TRAIN; iteration: 2677; epoch: 1; loss: 2.4758481979370117; \n",
      "fold: TRAIN; iteration: 2678; epoch: 1; loss: 2.550638198852539; \n",
      "fold: TRAIN; iteration: 2679; epoch: 1; loss: 2.33675479888916; \n",
      "fold: TRAIN; iteration: 2680; epoch: 1; loss: 2.2291064262390137; \n",
      "fold: TRAIN; iteration: 2681; epoch: 1; loss: 2.495842695236206; \n",
      "fold: TRAIN; iteration: 2682; epoch: 1; loss: 2.2871177196502686; \n",
      "fold: TRAIN; iteration: 2683; epoch: 1; loss: 2.395632028579712; \n",
      "fold: TRAIN; iteration: 2684; epoch: 1; loss: 2.207347869873047; \n",
      "fold: TRAIN; iteration: 2685; epoch: 1; loss: 2.177874803543091; \n",
      "fold: TRAIN; iteration: 2686; epoch: 1; loss: 2.4213263988494873; \n",
      "fold: TRAIN; iteration: 2687; epoch: 1; loss: 2.2462618350982666; \n",
      "fold: TRAIN; iteration: 2688; epoch: 1; loss: 2.4119930267333984; \n",
      "fold: TRAIN; iteration: 2689; epoch: 1; loss: 2.148595094680786; \n",
      "fold: TRAIN; iteration: 2690; epoch: 1; loss: 2.3488962650299072; \n",
      "fold: TRAIN; iteration: 2691; epoch: 1; loss: 2.432772159576416; \n",
      "fold: TRAIN; iteration: 2692; epoch: 1; loss: 2.351126194000244; \n",
      "fold: TRAIN; iteration: 2693; epoch: 1; loss: 2.340005874633789; \n",
      "fold: TRAIN; iteration: 2694; epoch: 1; loss: 2.3608710765838623; \n",
      "fold: TRAIN; iteration: 2695; epoch: 1; loss: 2.4413058757781982; \n",
      "fold: TRAIN; iteration: 2696; epoch: 1; loss: 2.4802615642547607; \n",
      "fold: TRAIN; iteration: 2697; epoch: 1; loss: 2.406008720397949; \n",
      "fold: TRAIN; iteration: 2698; epoch: 1; loss: 2.368941307067871; \n",
      "fold: TRAIN; iteration: 2699; epoch: 1; loss: 2.469827890396118; \n",
      "fold: TRAIN; iteration: 2700; epoch: 1; loss: 2.423776865005493; \n",
      "fold: TRAIN; iteration: 2701; epoch: 1; loss: 2.3535702228546143; \n",
      "fold: TRAIN; iteration: 2702; epoch: 1; loss: 2.257444143295288; \n",
      "fold: TRAIN; iteration: 2703; epoch: 1; loss: 2.661746025085449; \n",
      "fold: TRAIN; iteration: 2704; epoch: 1; loss: 2.400322675704956; \n",
      "fold: TRAIN; iteration: 2705; epoch: 1; loss: 2.231449604034424; \n",
      "fold: TRAIN; iteration: 2706; epoch: 1; loss: 2.508500337600708; \n",
      "fold: TRAIN; iteration: 2707; epoch: 1; loss: 2.0668141841888428; \n",
      "fold: TRAIN; iteration: 2708; epoch: 1; loss: 2.374363899230957; \n",
      "fold: TRAIN; iteration: 2709; epoch: 1; loss: 2.456176519393921; \n",
      "fold: TRAIN; iteration: 2710; epoch: 1; loss: 2.8223953247070312; \n",
      "fold: TRAIN; iteration: 2711; epoch: 1; loss: 2.4434163570404053; \n",
      "fold: TRAIN; iteration: 2712; epoch: 1; loss: 2.5140509605407715; \n",
      "fold: TRAIN; iteration: 2713; epoch: 1; loss: 2.4394304752349854; \n",
      "fold: TRAIN; iteration: 2714; epoch: 1; loss: 2.375251531600952; \n",
      "fold: TRAIN; iteration: 2715; epoch: 1; loss: 2.240124225616455; \n",
      "fold: TRAIN; iteration: 2716; epoch: 1; loss: 2.517033100128174; \n",
      "fold: TRAIN; iteration: 2717; epoch: 1; loss: 2.304246425628662; \n",
      "fold: TRAIN; iteration: 2718; epoch: 1; loss: 2.3544912338256836; \n",
      "fold: TRAIN; iteration: 2719; epoch: 1; loss: 2.5265085697174072; \n",
      "fold: TRAIN; iteration: 2720; epoch: 1; loss: 2.548989772796631; \n",
      "fold: TRAIN; iteration: 2721; epoch: 1; loss: 2.268395185470581; \n",
      "fold: TRAIN; iteration: 2722; epoch: 1; loss: 2.2683398723602295; \n",
      "fold: TRAIN; iteration: 2723; epoch: 1; loss: 2.5623252391815186; \n",
      "fold: TRAIN; iteration: 2724; epoch: 1; loss: 2.2845635414123535; \n",
      "fold: TRAIN; iteration: 2725; epoch: 1; loss: 2.346616744995117; \n",
      "fold: TRAIN; iteration: 2726; epoch: 1; loss: 2.2055463790893555; \n",
      "fold: TRAIN; iteration: 2727; epoch: 1; loss: 2.339229106903076; \n",
      "fold: TRAIN; iteration: 2728; epoch: 1; loss: 2.703906297683716; \n",
      "fold: TRAIN; iteration: 2729; epoch: 1; loss: 2.2755165100097656; \n",
      "fold: TRAIN; iteration: 2730; epoch: 1; loss: 2.350318670272827; \n",
      "fold: TRAIN; iteration: 2731; epoch: 1; loss: 2.398639440536499; \n",
      "fold: TRAIN; iteration: 2732; epoch: 1; loss: 2.214557647705078; \n",
      "fold: TRAIN; iteration: 2733; epoch: 1; loss: 2.3295798301696777; \n",
      "fold: TRAIN; iteration: 2734; epoch: 1; loss: 2.419611692428589; \n",
      "fold: TRAIN; iteration: 2735; epoch: 1; loss: 2.4707183837890625; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 2736; epoch: 1; loss: 2.7433321475982666; \n",
      "fold: TRAIN; iteration: 2737; epoch: 1; loss: 2.457016944885254; \n",
      "fold: TRAIN; iteration: 2738; epoch: 1; loss: 2.237992286682129; \n",
      "fold: TRAIN; iteration: 2739; epoch: 1; loss: 2.3882761001586914; \n",
      "fold: TRAIN; iteration: 2740; epoch: 1; loss: 2.6013660430908203; \n",
      "fold: TRAIN; iteration: 2741; epoch: 1; loss: 2.4650397300720215; \n",
      "fold: TRAIN; iteration: 2742; epoch: 1; loss: 2.457409143447876; \n",
      "fold: TRAIN; iteration: 2743; epoch: 1; loss: 2.4466707706451416; \n",
      "fold: TRAIN; iteration: 2744; epoch: 1; loss: 2.3684072494506836; \n",
      "fold: TRAIN; iteration: 2745; epoch: 1; loss: 2.444045066833496; \n",
      "fold: TRAIN; iteration: 2746; epoch: 1; loss: 2.1663899421691895; \n",
      "fold: TRAIN; iteration: 2747; epoch: 1; loss: 2.3856351375579834; \n",
      "fold: TRAIN; iteration: 2748; epoch: 1; loss: 2.3175997734069824; \n",
      "fold: TRAIN; iteration: 2749; epoch: 1; loss: 2.3899290561676025; \n",
      "fold: TRAIN; iteration: 2750; epoch: 1; loss: 2.4103851318359375; \n",
      "fold: TRAIN; iteration: 2751; epoch: 1; loss: 2.5119566917419434; \n",
      "fold: TRAIN; iteration: 2752; epoch: 1; loss: 2.416337013244629; \n",
      "fold: TRAIN; iteration: 2753; epoch: 1; loss: 2.4460341930389404; \n",
      "fold: TRAIN; iteration: 2754; epoch: 1; loss: 2.218541145324707; \n",
      "fold: TRAIN; iteration: 2755; epoch: 1; loss: 2.5582170486450195; \n",
      "fold: TRAIN; iteration: 2756; epoch: 1; loss: 2.3393337726593018; \n",
      "fold: TRAIN; iteration: 2757; epoch: 1; loss: 2.503499984741211; \n",
      "fold: TRAIN; iteration: 2758; epoch: 1; loss: 2.2151033878326416; \n",
      "fold: TRAIN; iteration: 2759; epoch: 1; loss: 2.3621528148651123; \n",
      "fold: TRAIN; iteration: 2760; epoch: 1; loss: 2.302222967147827; \n",
      "fold: TRAIN; iteration: 2761; epoch: 1; loss: 2.530590295791626; \n",
      "fold: TRAIN; iteration: 2762; epoch: 1; loss: 2.403620958328247; \n",
      "fold: TRAIN; iteration: 2763; epoch: 1; loss: 2.390031337738037; \n",
      "fold: TRAIN; iteration: 2764; epoch: 1; loss: 2.4466278553009033; \n",
      "fold: TRAIN; iteration: 2765; epoch: 1; loss: 2.595564365386963; \n",
      "fold: TRAIN; iteration: 2766; epoch: 1; loss: 2.335256338119507; \n",
      "fold: TRAIN; iteration: 2767; epoch: 1; loss: 2.629484176635742; \n",
      "fold: TRAIN; iteration: 2768; epoch: 1; loss: 2.385737657546997; \n",
      "fold: TRAIN; iteration: 2769; epoch: 1; loss: 2.262369394302368; \n",
      "fold: TRAIN; iteration: 2770; epoch: 1; loss: 2.6434860229492188; \n",
      "fold: TRAIN; iteration: 2771; epoch: 1; loss: 2.461038112640381; \n",
      "fold: TRAIN; iteration: 2772; epoch: 1; loss: 2.405839443206787; \n",
      "fold: TRAIN; iteration: 2773; epoch: 1; loss: 2.445058822631836; \n",
      "fold: TRAIN; iteration: 2774; epoch: 1; loss: 2.7172183990478516; \n",
      "fold: TRAIN; iteration: 2775; epoch: 1; loss: 2.616564989089966; \n",
      "fold: TRAIN; iteration: 2776; epoch: 1; loss: 2.522894859313965; \n",
      "fold: TRAIN; iteration: 2777; epoch: 1; loss: 2.4723503589630127; \n",
      "fold: TRAIN; iteration: 2778; epoch: 1; loss: 2.2894201278686523; \n",
      "fold: TRAIN; iteration: 2779; epoch: 1; loss: 2.442613363265991; \n",
      "fold: TRAIN; iteration: 2780; epoch: 1; loss: 2.5121495723724365; \n",
      "fold: TRAIN; iteration: 2781; epoch: 1; loss: 2.406376838684082; \n",
      "fold: TRAIN; iteration: 2782; epoch: 1; loss: 2.2748613357543945; \n",
      "fold: TRAIN; iteration: 2783; epoch: 1; loss: 2.1888954639434814; \n",
      "fold: TRAIN; iteration: 2784; epoch: 1; loss: 2.389798164367676; \n",
      "fold: TRAIN; iteration: 2785; epoch: 1; loss: 2.441148519515991; \n",
      "fold: TRAIN; iteration: 2786; epoch: 1; loss: 2.122292995452881; \n",
      "fold: TRAIN; iteration: 2787; epoch: 1; loss: 2.3183562755584717; \n",
      "fold: TRAIN; iteration: 2788; epoch: 1; loss: 2.327359676361084; \n",
      "fold: TRAIN; iteration: 2789; epoch: 1; loss: 2.241464138031006; \n",
      "fold: TRAIN; iteration: 2790; epoch: 1; loss: 2.2985730171203613; \n",
      "fold: TRAIN; iteration: 2791; epoch: 1; loss: 2.480799913406372; \n",
      "fold: TRAIN; iteration: 2792; epoch: 1; loss: 2.7210912704467773; \n",
      "fold: TRAIN; iteration: 2793; epoch: 1; loss: 2.535057306289673; \n",
      "fold: TRAIN; iteration: 2794; epoch: 1; loss: 2.4904046058654785; \n",
      "fold: TRAIN; iteration: 2795; epoch: 1; loss: 2.63040828704834; \n",
      "fold: TRAIN; iteration: 2796; epoch: 1; loss: 2.327632188796997; \n",
      "fold: TRAIN; iteration: 2797; epoch: 1; loss: 2.393733263015747; \n",
      "fold: TRAIN; iteration: 2798; epoch: 1; loss: 2.3038854598999023; \n",
      "fold: TRAIN; iteration: 2799; epoch: 1; loss: 2.2545931339263916; \n",
      "fold: TRAIN; iteration: 2800; epoch: 1; loss: 2.4758620262145996; \n",
      "fold: TRAIN; iteration: 2801; epoch: 1; loss: 2.393934965133667; \n",
      "fold: TRAIN; iteration: 2802; epoch: 1; loss: 2.553570508956909; \n",
      "fold: TRAIN; iteration: 2803; epoch: 1; loss: 2.3906779289245605; \n",
      "fold: TRAIN; iteration: 2804; epoch: 1; loss: 2.532715320587158; \n",
      "fold: TRAIN; iteration: 2805; epoch: 1; loss: 2.5224196910858154; \n",
      "fold: TRAIN; iteration: 2806; epoch: 1; loss: 2.4099912643432617; \n",
      "fold: TRAIN; iteration: 2807; epoch: 1; loss: 2.4775662422180176; \n",
      "fold: TRAIN; iteration: 2808; epoch: 1; loss: 1.992621660232544; \n",
      "fold: TRAIN; iteration: 2809; epoch: 1; loss: 2.240851879119873; \n",
      "fold: TRAIN; iteration: 2810; epoch: 1; loss: 2.3564493656158447; \n",
      "fold: TRAIN; iteration: 2811; epoch: 1; loss: 2.693230390548706; \n",
      "fold: TRAIN; iteration: 2812; epoch: 1; loss: 2.3887553215026855; \n",
      "fold: TRAIN; iteration: 2813; epoch: 1; loss: 2.27400279045105; \n",
      "fold: TRAIN; iteration: 2814; epoch: 1; loss: 2.398649215698242; \n",
      "fold: TRAIN; iteration: 2815; epoch: 1; loss: 2.451190233230591; \n",
      "fold: TRAIN; iteration: 2816; epoch: 1; loss: 2.31807804107666; \n",
      "fold: TRAIN; iteration: 2817; epoch: 1; loss: 2.4300377368927; \n",
      "fold: TRAIN; iteration: 2818; epoch: 1; loss: 2.231034278869629; \n",
      "fold: TRAIN; iteration: 2819; epoch: 1; loss: 2.5509989261627197; \n",
      "fold: TRAIN; iteration: 2820; epoch: 1; loss: 2.3944430351257324; \n",
      "fold: TRAIN; iteration: 2821; epoch: 1; loss: 2.373779058456421; \n",
      "fold: TRAIN; iteration: 2822; epoch: 1; loss: 2.3455252647399902; \n",
      "fold: TRAIN; iteration: 2823; epoch: 1; loss: 2.1934878826141357; \n",
      "fold: TRAIN; iteration: 2824; epoch: 1; loss: 2.4951751232147217; \n",
      "fold: TRAIN; iteration: 2825; epoch: 1; loss: 2.1294667720794678; \n",
      "fold: TRAIN; iteration: 2826; epoch: 1; loss: 2.2128543853759766; \n",
      "fold: TRAIN; iteration: 2827; epoch: 1; loss: 2.3395025730133057; \n",
      "fold: TRAIN; iteration: 2828; epoch: 1; loss: 2.317617893218994; \n",
      "fold: TRAIN; iteration: 2829; epoch: 1; loss: 2.2109932899475098; \n",
      "fold: TRAIN; iteration: 2830; epoch: 1; loss: 2.2827320098876953; \n",
      "fold: TRAIN; iteration: 2831; epoch: 1; loss: 2.3118093013763428; \n",
      "fold: TRAIN; iteration: 2832; epoch: 1; loss: 2.0413596630096436; \n",
      "fold: TRAIN; iteration: 2833; epoch: 1; loss: 2.456474781036377; \n",
      "fold: TRAIN; iteration: 2834; epoch: 1; loss: 2.1633198261260986; \n",
      "fold: TRAIN; iteration: 2835; epoch: 1; loss: 2.2764475345611572; \n",
      "fold: TRAIN; iteration: 2836; epoch: 1; loss: 2.3886678218841553; \n",
      "fold: TRAIN; iteration: 2837; epoch: 1; loss: 2.299015998840332; \n",
      "fold: TRAIN; iteration: 2838; epoch: 1; loss: 2.445733070373535; \n",
      "fold: TRAIN; iteration: 2839; epoch: 1; loss: 2.383816719055176; \n",
      "fold: TRAIN; iteration: 2840; epoch: 1; loss: 2.3851168155670166; \n",
      "fold: TRAIN; iteration: 2841; epoch: 1; loss: 2.546849012374878; \n",
      "fold: TRAIN; iteration: 2842; epoch: 1; loss: 2.396907091140747; \n",
      "fold: TRAIN; iteration: 2843; epoch: 1; loss: 2.428926467895508; \n",
      "fold: TRAIN; iteration: 2844; epoch: 1; loss: 2.2893009185791016; \n",
      "fold: TRAIN; iteration: 2845; epoch: 1; loss: 2.3548834323883057; \n",
      "fold: TRAIN; iteration: 2846; epoch: 1; loss: 2.3491218090057373; \n",
      "fold: TRAIN; iteration: 2847; epoch: 1; loss: 2.4935390949249268; \n",
      "fold: TRAIN; iteration: 2848; epoch: 1; loss: 2.409987449645996; \n",
      "fold: TRAIN; iteration: 2849; epoch: 1; loss: 2.6179232597351074; \n",
      "fold: TRAIN; iteration: 2850; epoch: 1; loss: 2.381256341934204; \n",
      "fold: TRAIN; iteration: 2851; epoch: 1; loss: 2.492335319519043; \n",
      "fold: TRAIN; iteration: 2852; epoch: 1; loss: 2.396393060684204; \n",
      "fold: TRAIN; iteration: 2853; epoch: 1; loss: 2.3755197525024414; \n",
      "fold: TRAIN; iteration: 2854; epoch: 1; loss: 2.2727129459381104; \n",
      "fold: TRAIN; iteration: 2855; epoch: 1; loss: 2.3791120052337646; \n",
      "fold: TRAIN; iteration: 2856; epoch: 1; loss: 2.341423988342285; \n",
      "fold: TRAIN; iteration: 2857; epoch: 1; loss: 2.634218692779541; \n",
      "fold: TRAIN; iteration: 2858; epoch: 1; loss: 2.448237895965576; \n",
      "fold: TRAIN; iteration: 2859; epoch: 1; loss: 2.7258336544036865; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 2860; epoch: 1; loss: 2.401283025741577; \n",
      "fold: TRAIN; iteration: 2861; epoch: 1; loss: 2.346938133239746; \n",
      "fold: TRAIN; iteration: 2862; epoch: 1; loss: 2.272284984588623; \n",
      "fold: TRAIN; iteration: 2863; epoch: 1; loss: 2.404493808746338; \n",
      "fold: TRAIN; iteration: 2864; epoch: 1; loss: 2.4080655574798584; \n",
      "fold: TRAIN; iteration: 2865; epoch: 1; loss: 2.439314842224121; \n",
      "fold: TRAIN; iteration: 2866; epoch: 1; loss: 2.2850534915924072; \n",
      "fold: TRAIN; iteration: 2867; epoch: 1; loss: 2.231173038482666; \n",
      "fold: TRAIN; iteration: 2868; epoch: 1; loss: 2.304318428039551; \n",
      "fold: TRAIN; iteration: 2869; epoch: 1; loss: 2.417065382003784; \n",
      "fold: TRAIN; iteration: 2870; epoch: 1; loss: 2.4603192806243896; \n",
      "fold: TRAIN; iteration: 2871; epoch: 1; loss: 2.387542963027954; \n",
      "fold: TRAIN; iteration: 2872; epoch: 1; loss: 2.6225476264953613; \n",
      "fold: TRAIN; iteration: 2873; epoch: 1; loss: 2.344475507736206; \n",
      "fold: TRAIN; iteration: 2874; epoch: 1; loss: 2.3687021732330322; \n",
      "fold: TRAIN; iteration: 2875; epoch: 1; loss: 2.654930353164673; \n",
      "fold: TRAIN; iteration: 2876; epoch: 1; loss: 2.53226375579834; \n",
      "fold: TRAIN; iteration: 2877; epoch: 1; loss: 2.5030853748321533; \n",
      "fold: TRAIN; iteration: 2878; epoch: 1; loss: 2.3177294731140137; \n",
      "fold: TRAIN; iteration: 2879; epoch: 1; loss: 2.513307809829712; \n",
      "fold: TRAIN; iteration: 2880; epoch: 1; loss: 2.247006893157959; \n",
      "fold: TRAIN; iteration: 2881; epoch: 1; loss: 2.4917032718658447; \n",
      "fold: TRAIN; iteration: 2882; epoch: 1; loss: 2.2220113277435303; \n",
      "fold: TRAIN; iteration: 2883; epoch: 1; loss: 2.3852415084838867; \n",
      "fold: TRAIN; iteration: 2884; epoch: 1; loss: 2.4720122814178467; \n",
      "fold: TRAIN; iteration: 2885; epoch: 1; loss: 2.5492162704467773; \n",
      "fold: TRAIN; iteration: 2886; epoch: 1; loss: 2.3164308071136475; \n",
      "fold: TRAIN; iteration: 2887; epoch: 1; loss: 2.183345317840576; \n",
      "fold: TRAIN; iteration: 2888; epoch: 1; loss: 2.2839555740356445; \n",
      "fold: TRAIN; iteration: 2889; epoch: 1; loss: 2.462768316268921; \n",
      "fold: TRAIN; iteration: 2890; epoch: 1; loss: 2.6471331119537354; \n",
      "fold: TRAIN; iteration: 2891; epoch: 1; loss: 2.5531435012817383; \n",
      "fold: TRAIN; iteration: 2892; epoch: 1; loss: 2.4116995334625244; \n",
      "fold: TRAIN; iteration: 2893; epoch: 1; loss: 2.2370269298553467; \n",
      "fold: TRAIN; iteration: 2894; epoch: 1; loss: 2.3150432109832764; \n",
      "fold: TRAIN; iteration: 2895; epoch: 1; loss: 2.411351203918457; \n",
      "fold: TRAIN; iteration: 2896; epoch: 1; loss: 2.4535155296325684; \n",
      "fold: TRAIN; iteration: 2897; epoch: 1; loss: 2.2024428844451904; \n",
      "fold: TRAIN; iteration: 2898; epoch: 1; loss: 2.433497428894043; \n",
      "fold: TRAIN; iteration: 2899; epoch: 1; loss: 2.255859136581421; \n",
      "fold: TRAIN; iteration: 2900; epoch: 1; loss: 2.4842493534088135; \n",
      "fold: TRAIN; iteration: 2901; epoch: 1; loss: 2.2804107666015625; \n",
      "fold: TRAIN; iteration: 2902; epoch: 1; loss: 2.1277360916137695; \n",
      "fold: TRAIN; iteration: 2903; epoch: 1; loss: 2.3682875633239746; \n",
      "fold: TRAIN; iteration: 2904; epoch: 1; loss: 2.4132814407348633; \n",
      "fold: TRAIN; iteration: 2905; epoch: 1; loss: 2.3501131534576416; \n",
      "fold: TRAIN; iteration: 2906; epoch: 1; loss: 2.564755916595459; \n",
      "fold: TRAIN; iteration: 2907; epoch: 1; loss: 2.565791606903076; \n",
      "fold: TRAIN; iteration: 2908; epoch: 1; loss: 2.299607276916504; \n",
      "fold: TRAIN; iteration: 2909; epoch: 1; loss: 2.5761258602142334; \n",
      "fold: TRAIN; iteration: 2910; epoch: 1; loss: 2.5350327491760254; \n",
      "fold: TRAIN; iteration: 2911; epoch: 1; loss: 2.1670708656311035; \n",
      "fold: TRAIN; iteration: 2912; epoch: 1; loss: 2.2842164039611816; \n",
      "fold: TRAIN; iteration: 2913; epoch: 1; loss: 2.2636308670043945; \n",
      "fold: TRAIN; iteration: 2914; epoch: 1; loss: 2.6257402896881104; \n",
      "fold: TRAIN; iteration: 2915; epoch: 1; loss: 2.2477593421936035; \n",
      "fold: TRAIN; iteration: 2916; epoch: 1; loss: 2.2604427337646484; \n",
      "fold: TRAIN; iteration: 2917; epoch: 1; loss: 2.462989091873169; \n",
      "fold: TRAIN; iteration: 2918; epoch: 1; loss: 2.3145647048950195; \n",
      "fold: TRAIN; iteration: 2919; epoch: 1; loss: 2.55679988861084; \n",
      "fold: TRAIN; iteration: 2920; epoch: 1; loss: 2.753354787826538; \n",
      "fold: TRAIN; iteration: 2921; epoch: 1; loss: 2.4569764137268066; \n",
      "fold: TRAIN; iteration: 2922; epoch: 1; loss: 2.4456305503845215; \n",
      "fold: TRAIN; iteration: 2923; epoch: 1; loss: 2.332540512084961; \n",
      "fold: TRAIN; iteration: 2924; epoch: 1; loss: 2.388129949569702; \n",
      "fold: TRAIN; iteration: 2925; epoch: 1; loss: 2.36777663230896; \n",
      "fold: TRAIN; iteration: 2926; epoch: 1; loss: 2.3293800354003906; \n",
      "fold: TRAIN; iteration: 2927; epoch: 1; loss: 2.4765517711639404; \n",
      "fold: TRAIN; iteration: 2928; epoch: 1; loss: 2.18747615814209; \n",
      "fold: TRAIN; iteration: 2929; epoch: 1; loss: 2.4145309925079346; \n",
      "fold: TRAIN; iteration: 2930; epoch: 1; loss: 2.46222186088562; \n",
      "fold: TRAIN; iteration: 2931; epoch: 1; loss: 2.519526958465576; \n",
      "fold: TRAIN; iteration: 2932; epoch: 1; loss: 2.5621705055236816; \n",
      "fold: TRAIN; iteration: 2933; epoch: 1; loss: 2.156454563140869; \n",
      "fold: TRAIN; iteration: 2934; epoch: 1; loss: 2.1693129539489746; \n",
      "fold: TRAIN; iteration: 2935; epoch: 1; loss: 2.376011610031128; \n",
      "fold: TRAIN; iteration: 2936; epoch: 1; loss: 2.3289268016815186; \n",
      "fold: TRAIN; iteration: 2937; epoch: 1; loss: 2.237858772277832; \n",
      "fold: TRAIN; iteration: 2938; epoch: 1; loss: 2.4989757537841797; \n",
      "fold: TRAIN; iteration: 2939; epoch: 1; loss: 2.5123956203460693; \n",
      "fold: TRAIN; iteration: 2940; epoch: 1; loss: 2.329625129699707; \n",
      "fold: TRAIN; iteration: 2941; epoch: 1; loss: 2.369950771331787; \n",
      "fold: TRAIN; iteration: 2942; epoch: 1; loss: 2.492891311645508; \n",
      "fold: TRAIN; iteration: 2943; epoch: 1; loss: 2.431823492050171; \n",
      "fold: TRAIN; iteration: 2944; epoch: 1; loss: 2.337442636489868; \n",
      "fold: TRAIN; iteration: 2945; epoch: 1; loss: 2.4035000801086426; \n",
      "fold: TRAIN; iteration: 2946; epoch: 1; loss: 2.220236301422119; \n",
      "fold: TRAIN; iteration: 2947; epoch: 1; loss: 2.421935558319092; \n",
      "fold: TRAIN; iteration: 2948; epoch: 1; loss: 2.4416229724884033; \n",
      "fold: TRAIN; iteration: 2949; epoch: 1; loss: 2.254690408706665; \n",
      "fold: TRAIN; iteration: 2950; epoch: 1; loss: 2.384424924850464; \n",
      "fold: TRAIN; iteration: 2951; epoch: 1; loss: 2.430471181869507; \n",
      "fold: TRAIN; iteration: 2952; epoch: 1; loss: 2.289923667907715; \n",
      "fold: TRAIN; iteration: 2953; epoch: 1; loss: 2.1938576698303223; \n",
      "fold: TRAIN; iteration: 2954; epoch: 1; loss: 2.342869758605957; \n",
      "fold: TRAIN; iteration: 2955; epoch: 1; loss: 2.443264961242676; \n",
      "fold: TRAIN; iteration: 2956; epoch: 1; loss: 2.1520681381225586; \n",
      "fold: TRAIN; iteration: 2957; epoch: 1; loss: 2.4353508949279785; \n",
      "fold: TRAIN; iteration: 2958; epoch: 1; loss: 2.4577476978302; \n",
      "fold: TRAIN; iteration: 2959; epoch: 1; loss: 2.312596321105957; \n",
      "fold: TRAIN; iteration: 2960; epoch: 1; loss: 2.322030544281006; \n",
      "fold: TRAIN; iteration: 2961; epoch: 1; loss: 2.2837257385253906; \n",
      "fold: TRAIN; iteration: 2962; epoch: 1; loss: 2.3392739295959473; \n",
      "fold: TRAIN; iteration: 2963; epoch: 1; loss: 2.2774524688720703; \n",
      "fold: TRAIN; iteration: 2964; epoch: 1; loss: 2.2049078941345215; \n",
      "fold: TRAIN; iteration: 2965; epoch: 1; loss: 2.5465171337127686; \n",
      "fold: TRAIN; iteration: 2966; epoch: 1; loss: 2.421006441116333; \n",
      "fold: TRAIN; iteration: 2967; epoch: 1; loss: 2.3750462532043457; \n",
      "fold: TRAIN; iteration: 2968; epoch: 1; loss: 2.156741142272949; \n",
      "fold: TRAIN; iteration: 2969; epoch: 1; loss: 2.55380916595459; \n",
      "fold: TRAIN; iteration: 2970; epoch: 1; loss: 2.5422658920288086; \n",
      "fold: TRAIN; iteration: 2971; epoch: 1; loss: 2.30053973197937; \n",
      "fold: TRAIN; iteration: 2972; epoch: 1; loss: 2.4969935417175293; \n",
      "fold: TRAIN; iteration: 2973; epoch: 1; loss: 2.467992067337036; \n",
      "fold: TRAIN; iteration: 2974; epoch: 1; loss: 2.394106388092041; \n",
      "fold: TRAIN; iteration: 2975; epoch: 1; loss: 2.393493175506592; \n",
      "fold: TRAIN; iteration: 2976; epoch: 1; loss: 2.381547212600708; \n",
      "fold: TRAIN; iteration: 2977; epoch: 1; loss: 2.3599469661712646; \n",
      "fold: TRAIN; iteration: 2978; epoch: 1; loss: 2.422776222229004; \n",
      "fold: TRAIN; iteration: 2979; epoch: 1; loss: 2.451819896697998; \n",
      "fold: TRAIN; iteration: 2980; epoch: 1; loss: 2.361750841140747; \n",
      "fold: TRAIN; iteration: 2981; epoch: 1; loss: 2.4634475708007812; \n",
      "fold: TRAIN; iteration: 2982; epoch: 1; loss: 2.3742387294769287; \n",
      "fold: TRAIN; iteration: 2983; epoch: 1; loss: 2.360128402709961; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 2984; epoch: 1; loss: 2.3505094051361084; \n",
      "fold: TRAIN; iteration: 2985; epoch: 1; loss: 2.441866397857666; \n",
      "fold: TRAIN; iteration: 2986; epoch: 1; loss: 2.4761593341827393; \n",
      "fold: TRAIN; iteration: 2987; epoch: 1; loss: 2.00528621673584; \n",
      "fold: TRAIN; iteration: 2988; epoch: 1; loss: 2.6416726112365723; \n",
      "fold: TRAIN; iteration: 2989; epoch: 1; loss: 2.4183759689331055; \n",
      "fold: TRAIN; iteration: 2990; epoch: 1; loss: 2.167689561843872; \n",
      "fold: TRAIN; iteration: 2991; epoch: 1; loss: 2.4917895793914795; \n",
      "fold: TRAIN; iteration: 2992; epoch: 1; loss: 2.5994374752044678; \n",
      "fold: TRAIN; iteration: 2993; epoch: 1; loss: 2.2425413131713867; \n",
      "fold: TRAIN; iteration: 2994; epoch: 1; loss: 2.372849702835083; \n",
      "fold: TRAIN; iteration: 2995; epoch: 1; loss: 2.4537696838378906; \n",
      "fold: TRAIN; iteration: 2996; epoch: 1; loss: 2.3815953731536865; \n",
      "fold: TRAIN; iteration: 2997; epoch: 1; loss: 2.3303887844085693; \n",
      "fold: TRAIN; iteration: 2998; epoch: 1; loss: 2.399585723876953; \n",
      "fold: TRAIN; iteration: 2999; epoch: 1; loss: 2.512226104736328; \n",
      "validating model...\n",
      "saving\n",
      "fold: VALID; iteration: 3000; epoch: 1; loss: 2.398514643837424; \n",
      "fold: TRAIN; iteration: 3000; epoch: 1; loss: 2.4002223014831543; \n",
      "fold: TRAIN; iteration: 3001; epoch: 1; loss: 2.3453898429870605; \n",
      "fold: TRAIN; iteration: 3002; epoch: 1; loss: 2.250448226928711; \n",
      "fold: TRAIN; iteration: 3003; epoch: 1; loss: 2.313584089279175; \n",
      "fold: TRAIN; iteration: 3004; epoch: 1; loss: 2.4722564220428467; \n",
      "fold: TRAIN; iteration: 3005; epoch: 1; loss: 2.3576624393463135; \n",
      "fold: TRAIN; iteration: 3006; epoch: 1; loss: 2.5410845279693604; \n",
      "fold: TRAIN; iteration: 3007; epoch: 1; loss: 2.452395439147949; \n",
      "fold: TRAIN; iteration: 3008; epoch: 1; loss: 2.3799452781677246; \n",
      "fold: TRAIN; iteration: 3009; epoch: 1; loss: 2.3083341121673584; \n",
      "fold: TRAIN; iteration: 3010; epoch: 1; loss: 2.4223458766937256; \n",
      "fold: TRAIN; iteration: 3011; epoch: 1; loss: 2.379575729370117; \n",
      "fold: TRAIN; iteration: 3012; epoch: 1; loss: 2.5001795291900635; \n",
      "fold: TRAIN; iteration: 3013; epoch: 1; loss: 2.4420177936553955; \n",
      "fold: TRAIN; iteration: 3014; epoch: 1; loss: 2.2566356658935547; \n",
      "fold: TRAIN; iteration: 3015; epoch: 1; loss: 2.108591079711914; \n",
      "fold: TRAIN; iteration: 3016; epoch: 1; loss: 2.474839687347412; \n",
      "fold: TRAIN; iteration: 3017; epoch: 1; loss: 2.3259308338165283; \n",
      "fold: TRAIN; iteration: 3018; epoch: 1; loss: 2.592564105987549; \n",
      "fold: TRAIN; iteration: 3019; epoch: 1; loss: 2.240598678588867; \n",
      "fold: TRAIN; iteration: 3020; epoch: 1; loss: 2.391777276992798; \n",
      "fold: TRAIN; iteration: 3021; epoch: 1; loss: 2.459045171737671; \n",
      "fold: TRAIN; iteration: 3022; epoch: 1; loss: 2.468766450881958; \n",
      "fold: TRAIN; iteration: 3023; epoch: 1; loss: 2.2675580978393555; \n",
      "fold: TRAIN; iteration: 3024; epoch: 1; loss: 2.781712532043457; \n",
      "fold: TRAIN; iteration: 3025; epoch: 1; loss: 2.3606560230255127; \n",
      "fold: TRAIN; iteration: 3026; epoch: 1; loss: 2.549067974090576; \n",
      "fold: TRAIN; iteration: 3027; epoch: 1; loss: 2.312980890274048; \n",
      "fold: TRAIN; iteration: 3028; epoch: 1; loss: 2.370162010192871; \n",
      "fold: TRAIN; iteration: 3029; epoch: 1; loss: 2.1920762062072754; \n",
      "fold: TRAIN; iteration: 3030; epoch: 1; loss: 2.571690559387207; \n",
      "fold: TRAIN; iteration: 3031; epoch: 1; loss: 2.5278711318969727; \n",
      "fold: TRAIN; iteration: 3032; epoch: 1; loss: 2.220134973526001; \n",
      "fold: TRAIN; iteration: 3033; epoch: 1; loss: 2.4542789459228516; \n",
      "fold: TRAIN; iteration: 3034; epoch: 1; loss: 2.283226251602173; \n",
      "fold: TRAIN; iteration: 3035; epoch: 1; loss: 2.3446147441864014; \n",
      "fold: TRAIN; iteration: 3036; epoch: 1; loss: 2.4769372940063477; \n",
      "fold: TRAIN; iteration: 3037; epoch: 1; loss: 2.4015653133392334; \n",
      "fold: TRAIN; iteration: 3038; epoch: 1; loss: 2.2515268325805664; \n",
      "fold: TRAIN; iteration: 3039; epoch: 1; loss: 2.5046486854553223; \n",
      "fold: TRAIN; iteration: 3040; epoch: 1; loss: 2.4367783069610596; \n",
      "fold: TRAIN; iteration: 3041; epoch: 1; loss: 2.6470518112182617; \n",
      "fold: TRAIN; iteration: 3042; epoch: 1; loss: 2.127396821975708; \n",
      "fold: TRAIN; iteration: 3043; epoch: 1; loss: 2.5058248043060303; \n",
      "fold: TRAIN; iteration: 3044; epoch: 1; loss: 2.612028121948242; \n",
      "fold: TRAIN; iteration: 3045; epoch: 1; loss: 2.4574027061462402; \n",
      "fold: TRAIN; iteration: 3046; epoch: 1; loss: 2.5573041439056396; \n",
      "fold: TRAIN; iteration: 3047; epoch: 1; loss: 2.5447635650634766; \n",
      "fold: TRAIN; iteration: 3048; epoch: 1; loss: 2.5015196800231934; \n",
      "fold: TRAIN; iteration: 3049; epoch: 1; loss: 2.5947272777557373; \n",
      "fold: TRAIN; iteration: 3050; epoch: 1; loss: 2.1999621391296387; \n",
      "fold: TRAIN; iteration: 3051; epoch: 1; loss: 2.502638578414917; \n",
      "fold: TRAIN; iteration: 3052; epoch: 1; loss: 2.4067907333374023; \n",
      "fold: TRAIN; iteration: 3053; epoch: 1; loss: 2.490375280380249; \n",
      "fold: TRAIN; iteration: 3054; epoch: 1; loss: 2.3021984100341797; \n",
      "fold: TRAIN; iteration: 3055; epoch: 1; loss: 2.598902940750122; \n",
      "fold: TRAIN; iteration: 3056; epoch: 1; loss: 2.453392267227173; \n",
      "fold: TRAIN; iteration: 3057; epoch: 1; loss: 2.4158713817596436; \n",
      "fold: TRAIN; iteration: 3058; epoch: 1; loss: 2.541830062866211; \n",
      "fold: TRAIN; iteration: 3059; epoch: 1; loss: 2.2828028202056885; \n",
      "fold: TRAIN; iteration: 3060; epoch: 1; loss: 2.3996667861938477; \n",
      "fold: TRAIN; iteration: 3061; epoch: 1; loss: 2.441558599472046; \n",
      "fold: TRAIN; iteration: 3062; epoch: 1; loss: 2.4635112285614014; \n",
      "fold: TRAIN; iteration: 3063; epoch: 1; loss: 2.420666217803955; \n",
      "fold: TRAIN; iteration: 3064; epoch: 1; loss: 2.5119378566741943; \n",
      "fold: TRAIN; iteration: 3065; epoch: 1; loss: 2.319491147994995; \n",
      "fold: TRAIN; iteration: 3066; epoch: 1; loss: 2.2241294384002686; \n",
      "fold: TRAIN; iteration: 3067; epoch: 1; loss: 2.633995294570923; \n",
      "fold: TRAIN; iteration: 3068; epoch: 1; loss: 2.6896097660064697; \n",
      "fold: TRAIN; iteration: 3069; epoch: 1; loss: 2.481529951095581; \n",
      "fold: TRAIN; iteration: 3070; epoch: 1; loss: 2.4684624671936035; \n",
      "fold: TRAIN; iteration: 3071; epoch: 1; loss: 2.426316499710083; \n",
      "fold: TRAIN; iteration: 3072; epoch: 1; loss: 2.6088125705718994; \n",
      "fold: TRAIN; iteration: 3073; epoch: 1; loss: 2.254639148712158; \n",
      "fold: TRAIN; iteration: 3074; epoch: 1; loss: 2.2243616580963135; \n",
      "fold: TRAIN; iteration: 3075; epoch: 1; loss: 2.367197036743164; \n",
      "fold: TRAIN; iteration: 3076; epoch: 1; loss: 2.4007656574249268; \n",
      "fold: TRAIN; iteration: 3077; epoch: 1; loss: 2.234866142272949; \n",
      "fold: TRAIN; iteration: 3078; epoch: 1; loss: 2.518735647201538; \n",
      "fold: TRAIN; iteration: 3079; epoch: 1; loss: 2.423819065093994; \n",
      "fold: TRAIN; iteration: 3080; epoch: 1; loss: 2.1347885131835938; \n",
      "fold: TRAIN; iteration: 3081; epoch: 1; loss: 2.3106606006622314; \n",
      "fold: TRAIN; iteration: 3082; epoch: 1; loss: 2.6392455101013184; \n",
      "fold: TRAIN; iteration: 3083; epoch: 1; loss: 2.3682641983032227; \n",
      "fold: TRAIN; iteration: 3084; epoch: 1; loss: 2.353034257888794; \n",
      "fold: TRAIN; iteration: 3085; epoch: 1; loss: 2.520141363143921; \n",
      "fold: TRAIN; iteration: 3086; epoch: 1; loss: 2.381192207336426; \n",
      "fold: TRAIN; iteration: 3087; epoch: 1; loss: 2.4507956504821777; \n",
      "fold: TRAIN; iteration: 3088; epoch: 1; loss: 2.287095546722412; \n",
      "fold: TRAIN; iteration: 3089; epoch: 1; loss: 2.609431505203247; \n",
      "fold: TRAIN; iteration: 3090; epoch: 1; loss: 2.3333511352539062; \n",
      "fold: TRAIN; iteration: 3091; epoch: 1; loss: 2.2090837955474854; \n",
      "fold: TRAIN; iteration: 3092; epoch: 1; loss: 2.1801018714904785; \n",
      "fold: TRAIN; iteration: 3093; epoch: 1; loss: 2.3685810565948486; \n",
      "fold: TRAIN; iteration: 3094; epoch: 1; loss: 2.593606472015381; \n",
      "fold: TRAIN; iteration: 3095; epoch: 1; loss: 2.191436529159546; \n",
      "fold: TRAIN; iteration: 3096; epoch: 1; loss: 2.3593976497650146; \n",
      "fold: TRAIN; iteration: 3097; epoch: 1; loss: 2.561378240585327; \n",
      "fold: TRAIN; iteration: 3098; epoch: 1; loss: 2.0574471950531006; \n",
      "fold: TRAIN; iteration: 3099; epoch: 1; loss: 2.2566909790039062; \n",
      "fold: TRAIN; iteration: 3100; epoch: 1; loss: 2.346536159515381; \n",
      "fold: TRAIN; iteration: 3101; epoch: 1; loss: 2.4806952476501465; \n",
      "fold: TRAIN; iteration: 3102; epoch: 1; loss: 2.3982954025268555; \n",
      "fold: TRAIN; iteration: 3103; epoch: 1; loss: 2.7060914039611816; \n",
      "fold: TRAIN; iteration: 3104; epoch: 1; loss: 2.448812246322632; \n",
      "fold: TRAIN; iteration: 3105; epoch: 1; loss: 2.75456166267395; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 3106; epoch: 1; loss: 2.5270071029663086; \n",
      "fold: TRAIN; iteration: 3107; epoch: 1; loss: 2.404240369796753; \n",
      "fold: TRAIN; iteration: 3108; epoch: 1; loss: 2.1864173412323; \n",
      "fold: TRAIN; iteration: 3109; epoch: 1; loss: 2.3108863830566406; \n",
      "fold: TRAIN; iteration: 3110; epoch: 1; loss: 2.2591099739074707; \n",
      "fold: TRAIN; iteration: 3111; epoch: 1; loss: 2.7330358028411865; \n",
      "fold: TRAIN; iteration: 3112; epoch: 1; loss: 2.1783816814422607; \n",
      "fold: TRAIN; iteration: 3113; epoch: 1; loss: 2.4084367752075195; \n",
      "fold: TRAIN; iteration: 3114; epoch: 1; loss: 2.5336899757385254; \n",
      "fold: TRAIN; iteration: 3115; epoch: 1; loss: 2.3936843872070312; \n",
      "fold: TRAIN; iteration: 3116; epoch: 1; loss: 2.4488039016723633; \n",
      "fold: TRAIN; iteration: 3117; epoch: 1; loss: 2.6444005966186523; \n",
      "fold: TRAIN; iteration: 3118; epoch: 1; loss: 2.2446558475494385; \n",
      "fold: TRAIN; iteration: 3119; epoch: 1; loss: 2.3969788551330566; \n",
      "fold: TRAIN; iteration: 3120; epoch: 1; loss: 2.5829684734344482; \n",
      "fold: TRAIN; iteration: 3121; epoch: 1; loss: 2.009361982345581; \n",
      "fold: TRAIN; iteration: 3122; epoch: 1; loss: 2.587043523788452; \n",
      "fold: TRAIN; iteration: 3123; epoch: 1; loss: 2.4503281116485596; \n",
      "fold: TRAIN; iteration: 3124; epoch: 1; loss: 2.5341408252716064; \n",
      "fold: TRAIN; iteration: 3125; epoch: 1; loss: 2.529407024383545; \n",
      "fold: TRAIN; iteration: 3126; epoch: 1; loss: 2.419374704360962; \n",
      "fold: TRAIN; iteration: 3127; epoch: 1; loss: 2.355220079421997; \n",
      "fold: TRAIN; iteration: 3128; epoch: 1; loss: 2.1544108390808105; \n",
      "fold: TRAIN; iteration: 3129; epoch: 1; loss: 2.5569934844970703; \n",
      "fold: TRAIN; iteration: 3130; epoch: 1; loss: 2.6091973781585693; \n",
      "fold: TRAIN; iteration: 3131; epoch: 1; loss: 2.492602586746216; \n",
      "fold: TRAIN; iteration: 3132; epoch: 1; loss: 2.4107601642608643; \n",
      "fold: TRAIN; iteration: 3133; epoch: 1; loss: 2.3937268257141113; \n",
      "fold: TRAIN; iteration: 3134; epoch: 1; loss: 2.351593017578125; \n",
      "fold: TRAIN; iteration: 3135; epoch: 1; loss: 2.47129225730896; \n",
      "fold: TRAIN; iteration: 3136; epoch: 1; loss: 2.5190999507904053; \n",
      "fold: TRAIN; iteration: 3137; epoch: 1; loss: 2.3408379554748535; \n",
      "fold: TRAIN; iteration: 3138; epoch: 1; loss: 2.3090131282806396; \n",
      "fold: TRAIN; iteration: 3139; epoch: 1; loss: 2.4219300746917725; \n",
      "fold: TRAIN; iteration: 3140; epoch: 1; loss: 2.2165844440460205; \n",
      "fold: TRAIN; iteration: 3141; epoch: 1; loss: 2.1314966678619385; \n",
      "fold: TRAIN; iteration: 3142; epoch: 1; loss: 2.2530081272125244; \n",
      "fold: TRAIN; iteration: 3143; epoch: 1; loss: 2.236675262451172; \n",
      "fold: TRAIN; iteration: 3144; epoch: 2; loss: 2.3289954662323; \n",
      "fold: TRAIN; iteration: 3145; epoch: 2; loss: 2.0475125312805176; \n",
      "fold: TRAIN; iteration: 3146; epoch: 2; loss: 2.175194263458252; \n",
      "fold: TRAIN; iteration: 3147; epoch: 2; loss: 2.227329969406128; \n",
      "fold: TRAIN; iteration: 3148; epoch: 2; loss: 2.1031157970428467; \n",
      "fold: TRAIN; iteration: 3149; epoch: 2; loss: 2.3413922786712646; \n",
      "fold: TRAIN; iteration: 3150; epoch: 2; loss: 2.4884493350982666; \n",
      "fold: TRAIN; iteration: 3151; epoch: 2; loss: 2.510838508605957; \n",
      "fold: TRAIN; iteration: 3152; epoch: 2; loss: 2.248121976852417; \n",
      "fold: TRAIN; iteration: 3153; epoch: 2; loss: 2.2895281314849854; \n",
      "fold: TRAIN; iteration: 3154; epoch: 2; loss: 2.3056280612945557; \n",
      "fold: TRAIN; iteration: 3155; epoch: 2; loss: 2.1612000465393066; \n",
      "fold: TRAIN; iteration: 3156; epoch: 2; loss: 2.4158437252044678; \n",
      "fold: TRAIN; iteration: 3157; epoch: 2; loss: 2.3522963523864746; \n",
      "fold: TRAIN; iteration: 3158; epoch: 2; loss: 2.2815041542053223; \n",
      "fold: TRAIN; iteration: 3159; epoch: 2; loss: 2.35042142868042; \n",
      "fold: TRAIN; iteration: 3160; epoch: 2; loss: 2.2777960300445557; \n",
      "fold: TRAIN; iteration: 3161; epoch: 2; loss: 2.3960564136505127; \n",
      "fold: TRAIN; iteration: 3162; epoch: 2; loss: 2.380572557449341; \n",
      "fold: TRAIN; iteration: 3163; epoch: 2; loss: 2.252964973449707; \n",
      "fold: TRAIN; iteration: 3164; epoch: 2; loss: 2.4442124366760254; \n",
      "fold: TRAIN; iteration: 3165; epoch: 2; loss: 2.2447733879089355; \n",
      "fold: TRAIN; iteration: 3166; epoch: 2; loss: 2.336454391479492; \n",
      "fold: TRAIN; iteration: 3167; epoch: 2; loss: 2.3974382877349854; \n",
      "fold: TRAIN; iteration: 3168; epoch: 2; loss: 2.1222450733184814; \n",
      "fold: TRAIN; iteration: 3169; epoch: 2; loss: 2.0994951725006104; \n",
      "fold: TRAIN; iteration: 3170; epoch: 2; loss: 2.2025339603424072; \n",
      "fold: TRAIN; iteration: 3171; epoch: 2; loss: 2.3028879165649414; \n",
      "fold: TRAIN; iteration: 3172; epoch: 2; loss: 2.3820443153381348; \n",
      "fold: TRAIN; iteration: 3173; epoch: 2; loss: 2.4635109901428223; \n",
      "fold: TRAIN; iteration: 3174; epoch: 2; loss: 2.330239772796631; \n",
      "fold: TRAIN; iteration: 3175; epoch: 2; loss: 2.4998836517333984; \n",
      "fold: TRAIN; iteration: 3176; epoch: 2; loss: 2.5088376998901367; \n",
      "fold: TRAIN; iteration: 3177; epoch: 2; loss: 2.1504862308502197; \n",
      "fold: TRAIN; iteration: 3178; epoch: 2; loss: 2.531161308288574; \n",
      "fold: TRAIN; iteration: 3179; epoch: 2; loss: 2.440333843231201; \n",
      "fold: TRAIN; iteration: 3180; epoch: 2; loss: 2.3865604400634766; \n",
      "fold: TRAIN; iteration: 3181; epoch: 2; loss: 2.20605206489563; \n",
      "fold: TRAIN; iteration: 3182; epoch: 2; loss: 2.2439496517181396; \n",
      "fold: TRAIN; iteration: 3183; epoch: 2; loss: 2.572955846786499; \n",
      "fold: TRAIN; iteration: 3184; epoch: 2; loss: 2.31015682220459; \n",
      "fold: TRAIN; iteration: 3185; epoch: 2; loss: 2.1821329593658447; \n",
      "fold: TRAIN; iteration: 3186; epoch: 2; loss: 2.1942150592803955; \n",
      "fold: TRAIN; iteration: 3187; epoch: 2; loss: 2.5444610118865967; \n",
      "fold: TRAIN; iteration: 3188; epoch: 2; loss: 2.3042311668395996; \n",
      "fold: TRAIN; iteration: 3189; epoch: 2; loss: 2.3127729892730713; \n",
      "fold: TRAIN; iteration: 3190; epoch: 2; loss: 2.3287575244903564; \n",
      "fold: TRAIN; iteration: 3191; epoch: 2; loss: 2.1747090816497803; \n",
      "fold: TRAIN; iteration: 3192; epoch: 2; loss: 2.196721315383911; \n",
      "fold: TRAIN; iteration: 3193; epoch: 2; loss: 2.3432226181030273; \n",
      "fold: TRAIN; iteration: 3194; epoch: 2; loss: 2.272176742553711; \n",
      "fold: TRAIN; iteration: 3195; epoch: 2; loss: 2.3959877490997314; \n",
      "fold: TRAIN; iteration: 3196; epoch: 2; loss: 2.1867928504943848; \n",
      "fold: TRAIN; iteration: 3197; epoch: 2; loss: 2.2721059322357178; \n",
      "fold: TRAIN; iteration: 3198; epoch: 2; loss: 2.1868412494659424; \n",
      "fold: TRAIN; iteration: 3199; epoch: 2; loss: 2.2123568058013916; \n",
      "fold: TRAIN; iteration: 3200; epoch: 2; loss: 2.3877060413360596; \n",
      "fold: TRAIN; iteration: 3201; epoch: 2; loss: 2.3770182132720947; \n",
      "fold: TRAIN; iteration: 3202; epoch: 2; loss: 2.3196351528167725; \n",
      "fold: TRAIN; iteration: 3203; epoch: 2; loss: 2.438814401626587; \n",
      "fold: TRAIN; iteration: 3204; epoch: 2; loss: 2.1443777084350586; \n",
      "fold: TRAIN; iteration: 3205; epoch: 2; loss: 2.2158102989196777; \n",
      "fold: TRAIN; iteration: 3206; epoch: 2; loss: 2.367729663848877; \n",
      "fold: TRAIN; iteration: 3207; epoch: 2; loss: 2.2373337745666504; \n",
      "fold: TRAIN; iteration: 3208; epoch: 2; loss: 2.216442346572876; \n",
      "fold: TRAIN; iteration: 3209; epoch: 2; loss: 2.210801362991333; \n",
      "fold: TRAIN; iteration: 3210; epoch: 2; loss: 2.345471143722534; \n",
      "fold: TRAIN; iteration: 3211; epoch: 2; loss: 2.444753646850586; \n",
      "fold: TRAIN; iteration: 3212; epoch: 2; loss: 2.238541841506958; \n",
      "fold: TRAIN; iteration: 3213; epoch: 2; loss: 2.2710115909576416; \n",
      "fold: TRAIN; iteration: 3214; epoch: 2; loss: 2.203082323074341; \n",
      "fold: TRAIN; iteration: 3215; epoch: 2; loss: 2.298229694366455; \n",
      "fold: TRAIN; iteration: 3216; epoch: 2; loss: 2.285191059112549; \n",
      "fold: TRAIN; iteration: 3217; epoch: 2; loss: 2.219619035720825; \n",
      "fold: TRAIN; iteration: 3218; epoch: 2; loss: 2.4097461700439453; \n",
      "fold: TRAIN; iteration: 3219; epoch: 2; loss: 2.250807285308838; \n",
      "fold: TRAIN; iteration: 3220; epoch: 2; loss: 2.304180383682251; \n",
      "fold: TRAIN; iteration: 3221; epoch: 2; loss: 2.4168264865875244; \n",
      "fold: TRAIN; iteration: 3222; epoch: 2; loss: 2.1490249633789062; \n",
      "fold: TRAIN; iteration: 3223; epoch: 2; loss: 2.243373394012451; \n",
      "fold: TRAIN; iteration: 3224; epoch: 2; loss: 2.2795891761779785; \n",
      "fold: TRAIN; iteration: 3225; epoch: 2; loss: 2.310558557510376; \n",
      "fold: TRAIN; iteration: 3226; epoch: 2; loss: 2.6071083545684814; \n",
      "fold: TRAIN; iteration: 3227; epoch: 2; loss: 2.485675573348999; \n",
      "fold: TRAIN; iteration: 3228; epoch: 2; loss: 2.324937582015991; \n",
      "fold: TRAIN; iteration: 3229; epoch: 2; loss: 2.338989019393921; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 3230; epoch: 2; loss: 2.273813009262085; \n",
      "fold: TRAIN; iteration: 3231; epoch: 2; loss: 2.2386868000030518; \n",
      "fold: TRAIN; iteration: 3232; epoch: 2; loss: 2.1133675575256348; \n",
      "fold: TRAIN; iteration: 3233; epoch: 2; loss: 2.2407889366149902; \n",
      "fold: TRAIN; iteration: 3234; epoch: 2; loss: 2.2679011821746826; \n",
      "fold: TRAIN; iteration: 3235; epoch: 2; loss: 2.3651347160339355; \n",
      "fold: TRAIN; iteration: 3236; epoch: 2; loss: 2.245901346206665; \n",
      "fold: TRAIN; iteration: 3237; epoch: 2; loss: 2.4683640003204346; \n",
      "fold: TRAIN; iteration: 3238; epoch: 2; loss: 2.3961904048919678; \n",
      "fold: TRAIN; iteration: 3239; epoch: 2; loss: 2.242716073989868; \n",
      "fold: TRAIN; iteration: 3240; epoch: 2; loss: 2.1456732749938965; \n",
      "fold: TRAIN; iteration: 3241; epoch: 2; loss: 2.0182149410247803; \n",
      "fold: TRAIN; iteration: 3242; epoch: 2; loss: 2.3230180740356445; \n",
      "fold: TRAIN; iteration: 3243; epoch: 2; loss: 2.1486093997955322; \n",
      "fold: TRAIN; iteration: 3244; epoch: 2; loss: 2.2324366569519043; \n",
      "fold: TRAIN; iteration: 3245; epoch: 2; loss: 2.359433650970459; \n",
      "fold: TRAIN; iteration: 3246; epoch: 2; loss: 2.2040398120880127; \n",
      "fold: TRAIN; iteration: 3247; epoch: 2; loss: 2.284102201461792; \n",
      "fold: TRAIN; iteration: 3248; epoch: 2; loss: 2.5747382640838623; \n",
      "fold: TRAIN; iteration: 3249; epoch: 2; loss: 2.220867395401001; \n",
      "fold: TRAIN; iteration: 3250; epoch: 2; loss: 2.003521203994751; \n",
      "fold: TRAIN; iteration: 3251; epoch: 2; loss: 2.5331625938415527; \n",
      "fold: TRAIN; iteration: 3252; epoch: 2; loss: 2.36977219581604; \n",
      "fold: TRAIN; iteration: 3253; epoch: 2; loss: 2.3838706016540527; \n",
      "fold: TRAIN; iteration: 3254; epoch: 2; loss: 2.555020809173584; \n",
      "fold: TRAIN; iteration: 3255; epoch: 2; loss: 2.13698673248291; \n",
      "fold: TRAIN; iteration: 3256; epoch: 2; loss: 2.4179205894470215; \n",
      "fold: TRAIN; iteration: 3257; epoch: 2; loss: 2.17032527923584; \n",
      "fold: TRAIN; iteration: 3258; epoch: 2; loss: 2.5499889850616455; \n",
      "fold: TRAIN; iteration: 3259; epoch: 2; loss: 2.3702497482299805; \n",
      "fold: TRAIN; iteration: 3260; epoch: 2; loss: 2.0415210723876953; \n",
      "fold: TRAIN; iteration: 3261; epoch: 2; loss: 2.2536826133728027; \n",
      "fold: TRAIN; iteration: 3262; epoch: 2; loss: 2.317814588546753; \n",
      "fold: TRAIN; iteration: 3263; epoch: 2; loss: 2.548616409301758; \n",
      "fold: TRAIN; iteration: 3264; epoch: 2; loss: 2.631263017654419; \n",
      "fold: TRAIN; iteration: 3265; epoch: 2; loss: 2.177201509475708; \n",
      "fold: TRAIN; iteration: 3266; epoch: 2; loss: 2.3047735691070557; \n",
      "fold: TRAIN; iteration: 3267; epoch: 2; loss: 2.366870164871216; \n",
      "fold: TRAIN; iteration: 3268; epoch: 2; loss: 2.1992998123168945; \n",
      "fold: TRAIN; iteration: 3269; epoch: 2; loss: 2.5575454235076904; \n",
      "fold: TRAIN; iteration: 3270; epoch: 2; loss: 2.31950306892395; \n",
      "fold: TRAIN; iteration: 3271; epoch: 2; loss: 2.2041354179382324; \n",
      "fold: TRAIN; iteration: 3272; epoch: 2; loss: 2.225921630859375; \n",
      "fold: TRAIN; iteration: 3273; epoch: 2; loss: 2.418720245361328; \n",
      "fold: TRAIN; iteration: 3274; epoch: 2; loss: 2.1245224475860596; \n",
      "fold: TRAIN; iteration: 3275; epoch: 2; loss: 2.3267288208007812; \n",
      "fold: TRAIN; iteration: 3276; epoch: 2; loss: 2.2726948261260986; \n",
      "fold: TRAIN; iteration: 3277; epoch: 2; loss: 2.1822869777679443; \n",
      "fold: TRAIN; iteration: 3278; epoch: 2; loss: 2.401745557785034; \n",
      "fold: TRAIN; iteration: 3279; epoch: 2; loss: 2.2953860759735107; \n",
      "fold: TRAIN; iteration: 3280; epoch: 2; loss: 2.3414244651794434; \n",
      "fold: TRAIN; iteration: 3281; epoch: 2; loss: 2.1203908920288086; \n",
      "fold: TRAIN; iteration: 3282; epoch: 2; loss: 2.1340606212615967; \n",
      "fold: TRAIN; iteration: 3283; epoch: 2; loss: 2.2937171459198; \n",
      "fold: TRAIN; iteration: 3284; epoch: 2; loss: 2.0951530933380127; \n",
      "fold: TRAIN; iteration: 3285; epoch: 2; loss: 2.1956207752227783; \n",
      "fold: TRAIN; iteration: 3286; epoch: 2; loss: 2.4706990718841553; \n",
      "fold: TRAIN; iteration: 3287; epoch: 2; loss: 2.354830741882324; \n",
      "fold: TRAIN; iteration: 3288; epoch: 2; loss: 2.4424407482147217; \n",
      "fold: TRAIN; iteration: 3289; epoch: 2; loss: 2.2281153202056885; \n",
      "fold: TRAIN; iteration: 3290; epoch: 2; loss: 2.1927330493927; \n",
      "fold: TRAIN; iteration: 3291; epoch: 2; loss: 2.2947192192077637; \n",
      "fold: TRAIN; iteration: 3292; epoch: 2; loss: 2.330493211746216; \n",
      "fold: TRAIN; iteration: 3293; epoch: 2; loss: 2.2960925102233887; \n",
      "fold: TRAIN; iteration: 3294; epoch: 2; loss: 2.445258140563965; \n",
      "fold: TRAIN; iteration: 3295; epoch: 2; loss: 2.264082431793213; \n",
      "fold: TRAIN; iteration: 3296; epoch: 2; loss: 2.1052446365356445; \n",
      "fold: TRAIN; iteration: 3297; epoch: 2; loss: 2.3342552185058594; \n",
      "fold: TRAIN; iteration: 3298; epoch: 2; loss: 2.3487024307250977; \n",
      "fold: TRAIN; iteration: 3299; epoch: 2; loss: 2.3061459064483643; \n",
      "fold: TRAIN; iteration: 3300; epoch: 2; loss: 2.232736825942993; \n",
      "fold: TRAIN; iteration: 3301; epoch: 2; loss: 2.752479314804077; \n",
      "fold: TRAIN; iteration: 3302; epoch: 2; loss: 2.617419958114624; \n",
      "fold: TRAIN; iteration: 3303; epoch: 2; loss: 2.5421226024627686; \n",
      "fold: TRAIN; iteration: 3304; epoch: 2; loss: 2.2599611282348633; \n",
      "fold: TRAIN; iteration: 3305; epoch: 2; loss: 2.164250373840332; \n",
      "fold: TRAIN; iteration: 3306; epoch: 2; loss: 2.4555764198303223; \n",
      "fold: TRAIN; iteration: 3307; epoch: 2; loss: 2.462692975997925; \n",
      "fold: TRAIN; iteration: 3308; epoch: 2; loss: 2.412909507751465; \n",
      "fold: TRAIN; iteration: 3309; epoch: 2; loss: 2.4301023483276367; \n",
      "fold: TRAIN; iteration: 3310; epoch: 2; loss: 2.425060510635376; \n",
      "fold: TRAIN; iteration: 3311; epoch: 2; loss: 2.388526678085327; \n",
      "fold: TRAIN; iteration: 3312; epoch: 2; loss: 2.1782467365264893; \n",
      "fold: TRAIN; iteration: 3313; epoch: 2; loss: 2.423851251602173; \n",
      "fold: TRAIN; iteration: 3314; epoch: 2; loss: 2.0631043910980225; \n",
      "fold: TRAIN; iteration: 3315; epoch: 2; loss: 2.2078895568847656; \n",
      "fold: TRAIN; iteration: 3316; epoch: 2; loss: 2.2063217163085938; \n",
      "fold: TRAIN; iteration: 3317; epoch: 2; loss: 2.4135842323303223; \n",
      "fold: TRAIN; iteration: 3318; epoch: 2; loss: 2.2905280590057373; \n",
      "fold: TRAIN; iteration: 3319; epoch: 2; loss: 2.3580732345581055; \n",
      "fold: TRAIN; iteration: 3320; epoch: 2; loss: 2.2027642726898193; \n",
      "fold: TRAIN; iteration: 3321; epoch: 2; loss: 2.40837025642395; \n",
      "fold: TRAIN; iteration: 3322; epoch: 2; loss: 2.1508657932281494; \n",
      "fold: TRAIN; iteration: 3323; epoch: 2; loss: 2.160945177078247; \n",
      "fold: TRAIN; iteration: 3324; epoch: 2; loss: 2.090329170227051; \n",
      "fold: TRAIN; iteration: 3325; epoch: 2; loss: 2.283202648162842; \n",
      "fold: TRAIN; iteration: 3326; epoch: 2; loss: 2.331521511077881; \n",
      "fold: TRAIN; iteration: 3327; epoch: 2; loss: 2.0910897254943848; \n",
      "fold: TRAIN; iteration: 3328; epoch: 2; loss: 2.1443614959716797; \n",
      "fold: TRAIN; iteration: 3329; epoch: 2; loss: 2.3018109798431396; \n",
      "fold: TRAIN; iteration: 3330; epoch: 2; loss: 2.325437068939209; \n",
      "fold: TRAIN; iteration: 3331; epoch: 2; loss: 2.274221658706665; \n",
      "fold: TRAIN; iteration: 3332; epoch: 2; loss: 2.6002907752990723; \n",
      "fold: TRAIN; iteration: 3333; epoch: 2; loss: 2.7598655223846436; \n",
      "fold: TRAIN; iteration: 3334; epoch: 2; loss: 2.228329658508301; \n",
      "fold: TRAIN; iteration: 3335; epoch: 2; loss: 2.1791913509368896; \n",
      "fold: TRAIN; iteration: 3336; epoch: 2; loss: 2.225659132003784; \n",
      "fold: TRAIN; iteration: 3337; epoch: 2; loss: 2.540703535079956; \n",
      "fold: TRAIN; iteration: 3338; epoch: 2; loss: 2.5172243118286133; \n",
      "fold: TRAIN; iteration: 3339; epoch: 2; loss: 2.268296003341675; \n",
      "fold: TRAIN; iteration: 3340; epoch: 2; loss: 2.2226812839508057; \n",
      "fold: TRAIN; iteration: 3341; epoch: 2; loss: 2.3171401023864746; \n",
      "fold: TRAIN; iteration: 3342; epoch: 2; loss: 2.133941411972046; \n",
      "fold: TRAIN; iteration: 3343; epoch: 2; loss: 2.252455472946167; \n",
      "fold: TRAIN; iteration: 3344; epoch: 2; loss: 2.0914177894592285; \n",
      "fold: TRAIN; iteration: 3345; epoch: 2; loss: 2.3212380409240723; \n",
      "fold: TRAIN; iteration: 3346; epoch: 2; loss: 2.1428732872009277; \n",
      "fold: TRAIN; iteration: 3347; epoch: 2; loss: 2.251819372177124; \n",
      "fold: TRAIN; iteration: 3348; epoch: 2; loss: 2.336019992828369; \n",
      "fold: TRAIN; iteration: 3349; epoch: 2; loss: 2.4000327587127686; \n",
      "fold: TRAIN; iteration: 3350; epoch: 2; loss: 2.1275784969329834; \n",
      "fold: TRAIN; iteration: 3351; epoch: 2; loss: 2.118284225463867; \n",
      "fold: TRAIN; iteration: 3352; epoch: 2; loss: 2.32991623878479; \n",
      "fold: TRAIN; iteration: 3353; epoch: 2; loss: 2.2778894901275635; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 3354; epoch: 2; loss: 2.491927146911621; \n",
      "fold: TRAIN; iteration: 3355; epoch: 2; loss: 2.360029697418213; \n",
      "fold: TRAIN; iteration: 3356; epoch: 2; loss: 2.5090513229370117; \n",
      "fold: TRAIN; iteration: 3357; epoch: 2; loss: 2.171070098876953; \n",
      "fold: TRAIN; iteration: 3358; epoch: 2; loss: 2.5088226795196533; \n",
      "fold: TRAIN; iteration: 3359; epoch: 2; loss: 2.2675185203552246; \n",
      "fold: TRAIN; iteration: 3360; epoch: 2; loss: 2.2669506072998047; \n",
      "fold: TRAIN; iteration: 3361; epoch: 2; loss: 2.4270377159118652; \n",
      "fold: TRAIN; iteration: 3362; epoch: 2; loss: 2.4903016090393066; \n",
      "fold: TRAIN; iteration: 3363; epoch: 2; loss: 2.3609619140625; \n",
      "fold: TRAIN; iteration: 3364; epoch: 2; loss: 2.2734076976776123; \n",
      "fold: TRAIN; iteration: 3365; epoch: 2; loss: 2.287383556365967; \n",
      "fold: TRAIN; iteration: 3366; epoch: 2; loss: 2.4780800342559814; \n",
      "fold: TRAIN; iteration: 3367; epoch: 2; loss: 2.324146032333374; \n",
      "fold: TRAIN; iteration: 3368; epoch: 2; loss: 2.3795180320739746; \n",
      "fold: TRAIN; iteration: 3369; epoch: 2; loss: 2.504103899002075; \n",
      "fold: TRAIN; iteration: 3370; epoch: 2; loss: 2.4200894832611084; \n",
      "fold: TRAIN; iteration: 3371; epoch: 2; loss: 2.197736978530884; \n",
      "fold: TRAIN; iteration: 3372; epoch: 2; loss: 2.268745183944702; \n",
      "fold: TRAIN; iteration: 3373; epoch: 2; loss: 2.283578395843506; \n",
      "fold: TRAIN; iteration: 3374; epoch: 2; loss: 2.4248151779174805; \n",
      "fold: TRAIN; iteration: 3375; epoch: 2; loss: 2.416694164276123; \n",
      "fold: TRAIN; iteration: 3376; epoch: 2; loss: 2.1913585662841797; \n",
      "fold: TRAIN; iteration: 3377; epoch: 2; loss: 2.1979379653930664; \n",
      "fold: TRAIN; iteration: 3378; epoch: 2; loss: 2.3124775886535645; \n",
      "fold: TRAIN; iteration: 3379; epoch: 2; loss: 2.3523168563842773; \n",
      "fold: TRAIN; iteration: 3380; epoch: 2; loss: 2.3155505657196045; \n",
      "fold: TRAIN; iteration: 3381; epoch: 2; loss: 2.084395408630371; \n",
      "fold: TRAIN; iteration: 3382; epoch: 2; loss: 2.071538209915161; \n",
      "fold: TRAIN; iteration: 3383; epoch: 2; loss: 2.5209779739379883; \n",
      "fold: TRAIN; iteration: 3384; epoch: 2; loss: 2.1769661903381348; \n",
      "fold: TRAIN; iteration: 3385; epoch: 2; loss: 2.351196050643921; \n",
      "fold: TRAIN; iteration: 3386; epoch: 2; loss: 2.1691713333129883; \n",
      "fold: TRAIN; iteration: 3387; epoch: 2; loss: 2.3486647605895996; \n",
      "fold: TRAIN; iteration: 3388; epoch: 2; loss: 2.2608296871185303; \n",
      "fold: TRAIN; iteration: 3389; epoch: 2; loss: 2.3013505935668945; \n",
      "fold: TRAIN; iteration: 3390; epoch: 2; loss: 2.3021645545959473; \n",
      "fold: TRAIN; iteration: 3391; epoch: 2; loss: 2.3175716400146484; \n",
      "fold: TRAIN; iteration: 3392; epoch: 2; loss: 2.292555570602417; \n",
      "fold: TRAIN; iteration: 3393; epoch: 2; loss: 2.5208373069763184; \n",
      "fold: TRAIN; iteration: 3394; epoch: 2; loss: 2.0949692726135254; \n",
      "fold: TRAIN; iteration: 3395; epoch: 2; loss: 2.233524799346924; \n",
      "fold: TRAIN; iteration: 3396; epoch: 2; loss: 2.6918933391571045; \n",
      "fold: TRAIN; iteration: 3397; epoch: 2; loss: 2.529313087463379; \n",
      "fold: TRAIN; iteration: 3398; epoch: 2; loss: 2.159621000289917; \n",
      "fold: TRAIN; iteration: 3399; epoch: 2; loss: 2.569211721420288; \n",
      "fold: TRAIN; iteration: 3400; epoch: 2; loss: 2.3189938068389893; \n",
      "fold: TRAIN; iteration: 3401; epoch: 2; loss: 2.326392412185669; \n",
      "fold: TRAIN; iteration: 3402; epoch: 2; loss: 2.015800714492798; \n",
      "fold: TRAIN; iteration: 3403; epoch: 2; loss: 2.400113582611084; \n",
      "fold: TRAIN; iteration: 3404; epoch: 2; loss: 2.3936407566070557; \n",
      "fold: TRAIN; iteration: 3405; epoch: 2; loss: 2.253645420074463; \n",
      "fold: TRAIN; iteration: 3406; epoch: 2; loss: 2.4746575355529785; \n",
      "fold: TRAIN; iteration: 3407; epoch: 2; loss: 2.078810930252075; \n",
      "fold: TRAIN; iteration: 3408; epoch: 2; loss: 2.137608289718628; \n",
      "fold: TRAIN; iteration: 3409; epoch: 2; loss: 2.6102378368377686; \n",
      "fold: TRAIN; iteration: 3410; epoch: 2; loss: 2.569027900695801; \n",
      "fold: TRAIN; iteration: 3411; epoch: 2; loss: 2.331901788711548; \n",
      "fold: TRAIN; iteration: 3412; epoch: 2; loss: 2.3054895401000977; \n",
      "fold: TRAIN; iteration: 3413; epoch: 2; loss: 2.4602065086364746; \n",
      "fold: TRAIN; iteration: 3414; epoch: 2; loss: 2.178931474685669; \n",
      "fold: TRAIN; iteration: 3415; epoch: 2; loss: 2.4912755489349365; \n",
      "fold: TRAIN; iteration: 3416; epoch: 2; loss: 2.527747631072998; \n",
      "fold: TRAIN; iteration: 3417; epoch: 2; loss: 2.4250011444091797; \n",
      "fold: TRAIN; iteration: 3418; epoch: 2; loss: 2.3095474243164062; \n",
      "fold: TRAIN; iteration: 3419; epoch: 2; loss: 2.1609270572662354; \n",
      "fold: TRAIN; iteration: 3420; epoch: 2; loss: 2.388765811920166; \n",
      "fold: TRAIN; iteration: 3421; epoch: 2; loss: 2.2503440380096436; \n",
      "fold: TRAIN; iteration: 3422; epoch: 2; loss: 2.4103479385375977; \n",
      "fold: TRAIN; iteration: 3423; epoch: 2; loss: 2.5997252464294434; \n",
      "fold: TRAIN; iteration: 3424; epoch: 2; loss: 2.1646735668182373; \n",
      "fold: TRAIN; iteration: 3425; epoch: 2; loss: 2.1466126441955566; \n",
      "fold: TRAIN; iteration: 3426; epoch: 2; loss: 2.270494222640991; \n",
      "fold: TRAIN; iteration: 3427; epoch: 2; loss: 2.31048583984375; \n",
      "fold: TRAIN; iteration: 3428; epoch: 2; loss: 2.2493438720703125; \n",
      "fold: TRAIN; iteration: 3429; epoch: 2; loss: 2.129974603652954; \n",
      "fold: TRAIN; iteration: 3430; epoch: 2; loss: 2.4819793701171875; \n",
      "fold: TRAIN; iteration: 3431; epoch: 2; loss: 2.3332936763763428; \n",
      "fold: TRAIN; iteration: 3432; epoch: 2; loss: 2.4320106506347656; \n",
      "fold: TRAIN; iteration: 3433; epoch: 2; loss: 2.2391726970672607; \n",
      "fold: TRAIN; iteration: 3434; epoch: 2; loss: 2.3411591053009033; \n",
      "fold: TRAIN; iteration: 3435; epoch: 2; loss: 2.364495038986206; \n",
      "fold: TRAIN; iteration: 3436; epoch: 2; loss: 2.232266902923584; \n",
      "fold: TRAIN; iteration: 3437; epoch: 2; loss: 2.3989853858947754; \n",
      "fold: TRAIN; iteration: 3438; epoch: 2; loss: 2.213865280151367; \n",
      "fold: TRAIN; iteration: 3439; epoch: 2; loss: 2.475429058074951; \n",
      "fold: TRAIN; iteration: 3440; epoch: 2; loss: 2.294191360473633; \n",
      "fold: TRAIN; iteration: 3441; epoch: 2; loss: 2.227593183517456; \n",
      "fold: TRAIN; iteration: 3442; epoch: 2; loss: 2.4215903282165527; \n",
      "fold: TRAIN; iteration: 3443; epoch: 2; loss: 2.032371759414673; \n",
      "fold: TRAIN; iteration: 3444; epoch: 2; loss: 2.114178419113159; \n",
      "fold: TRAIN; iteration: 3445; epoch: 2; loss: 2.180936336517334; \n",
      "fold: TRAIN; iteration: 3446; epoch: 2; loss: 2.2079997062683105; \n",
      "fold: TRAIN; iteration: 3447; epoch: 2; loss: 2.558396816253662; \n",
      "fold: TRAIN; iteration: 3448; epoch: 2; loss: 2.2366268634796143; \n",
      "fold: TRAIN; iteration: 3449; epoch: 2; loss: 2.2089602947235107; \n",
      "fold: TRAIN; iteration: 3450; epoch: 2; loss: 2.2175865173339844; \n",
      "fold: TRAIN; iteration: 3451; epoch: 2; loss: 2.2928807735443115; \n",
      "fold: TRAIN; iteration: 3452; epoch: 2; loss: 2.3330774307250977; \n",
      "fold: TRAIN; iteration: 3453; epoch: 2; loss: 2.3106865882873535; \n",
      "fold: TRAIN; iteration: 3454; epoch: 2; loss: 2.4255502223968506; \n",
      "fold: TRAIN; iteration: 3455; epoch: 2; loss: 2.2702925205230713; \n",
      "fold: TRAIN; iteration: 3456; epoch: 2; loss: 2.242439031600952; \n",
      "fold: TRAIN; iteration: 3457; epoch: 2; loss: 2.371638298034668; \n",
      "fold: TRAIN; iteration: 3458; epoch: 2; loss: 2.4928951263427734; \n",
      "fold: TRAIN; iteration: 3459; epoch: 2; loss: 2.502687931060791; \n",
      "fold: TRAIN; iteration: 3460; epoch: 2; loss: 2.496821641921997; \n",
      "fold: TRAIN; iteration: 3461; epoch: 2; loss: 2.1964120864868164; \n",
      "fold: TRAIN; iteration: 3462; epoch: 2; loss: 2.3500850200653076; \n",
      "fold: TRAIN; iteration: 3463; epoch: 2; loss: 2.4305474758148193; \n",
      "fold: TRAIN; iteration: 3464; epoch: 2; loss: 2.403653860092163; \n",
      "fold: TRAIN; iteration: 3465; epoch: 2; loss: 2.371458053588867; \n",
      "fold: TRAIN; iteration: 3466; epoch: 2; loss: 2.2540640830993652; \n",
      "fold: TRAIN; iteration: 3467; epoch: 2; loss: 2.250136137008667; \n",
      "fold: TRAIN; iteration: 3468; epoch: 2; loss: 2.3563637733459473; \n",
      "fold: TRAIN; iteration: 3469; epoch: 2; loss: 2.2230193614959717; \n",
      "fold: TRAIN; iteration: 3470; epoch: 2; loss: 2.2314794063568115; \n",
      "fold: TRAIN; iteration: 3471; epoch: 2; loss: 2.35290265083313; \n",
      "fold: TRAIN; iteration: 3472; epoch: 2; loss: 2.583951711654663; \n",
      "fold: TRAIN; iteration: 3473; epoch: 2; loss: 2.5624020099639893; \n",
      "fold: TRAIN; iteration: 3474; epoch: 2; loss: 2.1703975200653076; \n",
      "fold: TRAIN; iteration: 3475; epoch: 2; loss: 2.405496597290039; \n",
      "fold: TRAIN; iteration: 3476; epoch: 2; loss: 2.2490456104278564; \n",
      "fold: TRAIN; iteration: 3477; epoch: 2; loss: 2.2185285091400146; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 3478; epoch: 2; loss: 2.2935304641723633; \n",
      "fold: TRAIN; iteration: 3479; epoch: 2; loss: 2.6176912784576416; \n",
      "fold: TRAIN; iteration: 3480; epoch: 2; loss: 2.4449732303619385; \n",
      "fold: TRAIN; iteration: 3481; epoch: 2; loss: 2.160722017288208; \n",
      "fold: TRAIN; iteration: 3482; epoch: 2; loss: 2.2919259071350098; \n",
      "fold: TRAIN; iteration: 3483; epoch: 2; loss: 2.2673299312591553; \n",
      "fold: TRAIN; iteration: 3484; epoch: 2; loss: 2.386441230773926; \n",
      "fold: TRAIN; iteration: 3485; epoch: 2; loss: 2.5147318840026855; \n",
      "fold: TRAIN; iteration: 3486; epoch: 2; loss: 2.3016974925994873; \n",
      "fold: TRAIN; iteration: 3487; epoch: 2; loss: 2.2609190940856934; \n",
      "fold: TRAIN; iteration: 3488; epoch: 2; loss: 2.3439154624938965; \n",
      "fold: TRAIN; iteration: 3489; epoch: 2; loss: 2.1621882915496826; \n",
      "fold: TRAIN; iteration: 3490; epoch: 2; loss: 2.3515121936798096; \n",
      "fold: TRAIN; iteration: 3491; epoch: 2; loss: 2.1770153045654297; \n",
      "fold: TRAIN; iteration: 3492; epoch: 2; loss: 2.4552202224731445; \n",
      "fold: TRAIN; iteration: 3493; epoch: 2; loss: 2.202521562576294; \n",
      "fold: TRAIN; iteration: 3494; epoch: 2; loss: 2.3690240383148193; \n",
      "fold: TRAIN; iteration: 3495; epoch: 2; loss: 2.414126396179199; \n",
      "fold: TRAIN; iteration: 3496; epoch: 2; loss: 2.1798880100250244; \n",
      "fold: TRAIN; iteration: 3497; epoch: 2; loss: 2.321059465408325; \n",
      "fold: TRAIN; iteration: 3498; epoch: 2; loss: 2.3241994380950928; \n",
      "fold: TRAIN; iteration: 3499; epoch: 2; loss: 2.14699649810791; \n",
      "fold: TRAIN; iteration: 3500; epoch: 2; loss: 2.3750271797180176; \n",
      "fold: TRAIN; iteration: 3501; epoch: 2; loss: 2.160271644592285; \n",
      "fold: TRAIN; iteration: 3502; epoch: 2; loss: 2.3199923038482666; \n",
      "fold: TRAIN; iteration: 3503; epoch: 2; loss: 2.2297275066375732; \n",
      "fold: TRAIN; iteration: 3504; epoch: 2; loss: 2.2771644592285156; \n",
      "fold: TRAIN; iteration: 3505; epoch: 2; loss: 2.4732489585876465; \n",
      "fold: TRAIN; iteration: 3506; epoch: 2; loss: 2.2569313049316406; \n",
      "fold: TRAIN; iteration: 3507; epoch: 2; loss: 2.2659103870391846; \n",
      "fold: TRAIN; iteration: 3508; epoch: 2; loss: 2.1956586837768555; \n",
      "fold: TRAIN; iteration: 3509; epoch: 2; loss: 2.216343402862549; \n",
      "fold: TRAIN; iteration: 3510; epoch: 2; loss: 2.4634995460510254; \n",
      "fold: TRAIN; iteration: 3511; epoch: 2; loss: 2.265448570251465; \n",
      "fold: TRAIN; iteration: 3512; epoch: 2; loss: 2.1242928504943848; \n",
      "fold: TRAIN; iteration: 3513; epoch: 2; loss: 2.171072483062744; \n",
      "fold: TRAIN; iteration: 3514; epoch: 2; loss: 2.2800796031951904; \n",
      "fold: TRAIN; iteration: 3515; epoch: 2; loss: 2.347402334213257; \n",
      "fold: TRAIN; iteration: 3516; epoch: 2; loss: 2.1977579593658447; \n",
      "fold: TRAIN; iteration: 3517; epoch: 2; loss: 2.53511118888855; \n",
      "fold: TRAIN; iteration: 3518; epoch: 2; loss: 2.4706482887268066; \n",
      "fold: TRAIN; iteration: 3519; epoch: 2; loss: 2.3793561458587646; \n",
      "fold: TRAIN; iteration: 3520; epoch: 2; loss: 2.3338699340820312; \n",
      "fold: TRAIN; iteration: 3521; epoch: 2; loss: 2.2493157386779785; \n",
      "fold: TRAIN; iteration: 3522; epoch: 2; loss: 2.6009252071380615; \n",
      "fold: TRAIN; iteration: 3523; epoch: 2; loss: 2.360175132751465; \n",
      "fold: TRAIN; iteration: 3524; epoch: 2; loss: 2.3190314769744873; \n",
      "fold: TRAIN; iteration: 3525; epoch: 2; loss: 2.2720072269439697; \n",
      "fold: TRAIN; iteration: 3526; epoch: 2; loss: 2.437685012817383; \n",
      "fold: TRAIN; iteration: 3527; epoch: 2; loss: 2.254971504211426; \n",
      "fold: TRAIN; iteration: 3528; epoch: 2; loss: 2.3750076293945312; \n",
      "fold: TRAIN; iteration: 3529; epoch: 2; loss: 2.1792099475860596; \n",
      "fold: TRAIN; iteration: 3530; epoch: 2; loss: 2.2804367542266846; \n",
      "fold: TRAIN; iteration: 3531; epoch: 2; loss: 2.2104902267456055; \n",
      "fold: TRAIN; iteration: 3532; epoch: 2; loss: 2.138617515563965; \n",
      "fold: TRAIN; iteration: 3533; epoch: 2; loss: 2.379120111465454; \n",
      "fold: TRAIN; iteration: 3534; epoch: 2; loss: 2.3025879859924316; \n",
      "fold: TRAIN; iteration: 3535; epoch: 2; loss: 2.337381362915039; \n",
      "fold: TRAIN; iteration: 3536; epoch: 2; loss: 2.3166463375091553; \n",
      "fold: TRAIN; iteration: 3537; epoch: 2; loss: 2.3940138816833496; \n",
      "fold: TRAIN; iteration: 3538; epoch: 2; loss: 2.3738574981689453; \n",
      "fold: TRAIN; iteration: 3539; epoch: 2; loss: 2.312371253967285; \n",
      "fold: TRAIN; iteration: 3540; epoch: 2; loss: 2.3391196727752686; \n",
      "fold: TRAIN; iteration: 3541; epoch: 2; loss: 2.31784725189209; \n",
      "fold: TRAIN; iteration: 3542; epoch: 2; loss: 2.486938238143921; \n",
      "fold: TRAIN; iteration: 3543; epoch: 2; loss: 2.3660037517547607; \n",
      "fold: TRAIN; iteration: 3544; epoch: 2; loss: 2.2893667221069336; \n",
      "fold: TRAIN; iteration: 3545; epoch: 2; loss: 2.2936089038848877; \n",
      "fold: TRAIN; iteration: 3546; epoch: 2; loss: 2.254709482192993; \n",
      "fold: TRAIN; iteration: 3547; epoch: 2; loss: 2.2455902099609375; \n",
      "fold: TRAIN; iteration: 3548; epoch: 2; loss: 2.1299595832824707; \n",
      "fold: TRAIN; iteration: 3549; epoch: 2; loss: 2.16772723197937; \n",
      "fold: TRAIN; iteration: 3550; epoch: 2; loss: 2.3577849864959717; \n",
      "fold: TRAIN; iteration: 3551; epoch: 2; loss: 2.2572615146636963; \n",
      "fold: TRAIN; iteration: 3552; epoch: 2; loss: 2.590104341506958; \n",
      "fold: TRAIN; iteration: 3553; epoch: 2; loss: 2.2700088024139404; \n",
      "fold: TRAIN; iteration: 3554; epoch: 2; loss: 2.232475519180298; \n",
      "fold: TRAIN; iteration: 3555; epoch: 2; loss: 2.267361640930176; \n",
      "fold: TRAIN; iteration: 3556; epoch: 2; loss: 2.2990992069244385; \n",
      "fold: TRAIN; iteration: 3557; epoch: 2; loss: 2.355332612991333; \n",
      "fold: TRAIN; iteration: 3558; epoch: 2; loss: 2.085733413696289; \n",
      "fold: TRAIN; iteration: 3559; epoch: 2; loss: 2.3917908668518066; \n",
      "fold: TRAIN; iteration: 3560; epoch: 2; loss: 2.305631399154663; \n",
      "fold: TRAIN; iteration: 3561; epoch: 2; loss: 2.4700441360473633; \n",
      "fold: TRAIN; iteration: 3562; epoch: 2; loss: 2.4828310012817383; \n",
      "fold: TRAIN; iteration: 3563; epoch: 2; loss: 2.343989372253418; \n",
      "fold: TRAIN; iteration: 3564; epoch: 2; loss: 2.2068185806274414; \n",
      "fold: TRAIN; iteration: 3565; epoch: 2; loss: 2.292018413543701; \n",
      "fold: TRAIN; iteration: 3566; epoch: 2; loss: 2.364863872528076; \n",
      "fold: TRAIN; iteration: 3567; epoch: 2; loss: 2.5901880264282227; \n",
      "fold: TRAIN; iteration: 3568; epoch: 2; loss: 2.3244471549987793; \n",
      "fold: TRAIN; iteration: 3569; epoch: 2; loss: 2.308664321899414; \n",
      "fold: TRAIN; iteration: 3570; epoch: 2; loss: 2.39327073097229; \n",
      "fold: TRAIN; iteration: 3571; epoch: 2; loss: 2.201164960861206; \n",
      "fold: TRAIN; iteration: 3572; epoch: 2; loss: 2.2657053470611572; \n",
      "fold: TRAIN; iteration: 3573; epoch: 2; loss: 2.2213220596313477; \n",
      "fold: TRAIN; iteration: 3574; epoch: 2; loss: 2.531632900238037; \n",
      "fold: TRAIN; iteration: 3575; epoch: 2; loss: 2.3702313899993896; \n",
      "fold: TRAIN; iteration: 3576; epoch: 2; loss: 2.3510210514068604; \n",
      "fold: TRAIN; iteration: 3577; epoch: 2; loss: 2.3388512134552; \n",
      "fold: TRAIN; iteration: 3578; epoch: 2; loss: 2.4889512062072754; \n",
      "fold: TRAIN; iteration: 3579; epoch: 2; loss: 2.1948087215423584; \n",
      "fold: TRAIN; iteration: 3580; epoch: 2; loss: 2.1783323287963867; \n",
      "fold: TRAIN; iteration: 3581; epoch: 2; loss: 2.544790744781494; \n",
      "fold: TRAIN; iteration: 3582; epoch: 2; loss: 2.3279683589935303; \n",
      "fold: TRAIN; iteration: 3583; epoch: 2; loss: 1.922855019569397; \n",
      "fold: TRAIN; iteration: 3584; epoch: 2; loss: 2.343662977218628; \n",
      "fold: TRAIN; iteration: 3585; epoch: 2; loss: 2.3206992149353027; \n",
      "fold: TRAIN; iteration: 3586; epoch: 2; loss: 2.4479901790618896; \n",
      "fold: TRAIN; iteration: 3587; epoch: 2; loss: 2.4177772998809814; \n",
      "fold: TRAIN; iteration: 3588; epoch: 2; loss: 2.5636208057403564; \n",
      "fold: TRAIN; iteration: 3589; epoch: 2; loss: 2.420847177505493; \n",
      "fold: TRAIN; iteration: 3590; epoch: 2; loss: 2.432734966278076; \n",
      "fold: TRAIN; iteration: 3591; epoch: 2; loss: 2.4589672088623047; \n",
      "fold: TRAIN; iteration: 3592; epoch: 2; loss: 2.493628978729248; \n",
      "fold: TRAIN; iteration: 3593; epoch: 2; loss: 2.2823102474212646; \n",
      "fold: TRAIN; iteration: 3594; epoch: 2; loss: 1.9870593547821045; \n",
      "fold: TRAIN; iteration: 3595; epoch: 2; loss: 2.3218863010406494; \n",
      "fold: TRAIN; iteration: 3596; epoch: 2; loss: 2.3028619289398193; \n",
      "fold: TRAIN; iteration: 3597; epoch: 2; loss: 2.295189619064331; \n",
      "fold: TRAIN; iteration: 3598; epoch: 2; loss: 2.1446337699890137; \n",
      "fold: TRAIN; iteration: 3599; epoch: 2; loss: 2.3766651153564453; \n",
      "fold: TRAIN; iteration: 3600; epoch: 2; loss: 2.5928804874420166; \n",
      "fold: TRAIN; iteration: 3601; epoch: 2; loss: 2.1867761611938477; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 3602; epoch: 2; loss: 2.0583252906799316; \n",
      "fold: TRAIN; iteration: 3603; epoch: 2; loss: 2.278346061706543; \n",
      "fold: TRAIN; iteration: 3604; epoch: 2; loss: 2.2918004989624023; \n",
      "fold: TRAIN; iteration: 3605; epoch: 2; loss: 2.359314203262329; \n",
      "fold: TRAIN; iteration: 3606; epoch: 2; loss: 2.388245105743408; \n",
      "fold: TRAIN; iteration: 3607; epoch: 2; loss: 2.1170129776000977; \n",
      "fold: TRAIN; iteration: 3608; epoch: 2; loss: 2.3357667922973633; \n",
      "fold: TRAIN; iteration: 3609; epoch: 2; loss: 2.3127927780151367; \n",
      "fold: TRAIN; iteration: 3610; epoch: 2; loss: 2.5908238887786865; \n",
      "fold: TRAIN; iteration: 3611; epoch: 2; loss: 2.488121271133423; \n",
      "fold: TRAIN; iteration: 3612; epoch: 2; loss: 2.3730742931365967; \n",
      "fold: TRAIN; iteration: 3613; epoch: 2; loss: 2.5102782249450684; \n",
      "fold: TRAIN; iteration: 3614; epoch: 2; loss: 2.1025748252868652; \n",
      "fold: TRAIN; iteration: 3615; epoch: 2; loss: 2.428440809249878; \n",
      "fold: TRAIN; iteration: 3616; epoch: 2; loss: 2.240539789199829; \n",
      "fold: TRAIN; iteration: 3617; epoch: 2; loss: 2.524777889251709; \n",
      "fold: TRAIN; iteration: 3618; epoch: 2; loss: 2.2712860107421875; \n",
      "fold: TRAIN; iteration: 3619; epoch: 2; loss: 2.4196083545684814; \n",
      "fold: TRAIN; iteration: 3620; epoch: 2; loss: 2.381565809249878; \n",
      "fold: TRAIN; iteration: 3621; epoch: 2; loss: 2.2934536933898926; \n",
      "fold: TRAIN; iteration: 3622; epoch: 2; loss: 2.452543258666992; \n",
      "fold: TRAIN; iteration: 3623; epoch: 2; loss: 2.354393243789673; \n",
      "fold: TRAIN; iteration: 3624; epoch: 2; loss: 2.2997593879699707; \n",
      "fold: TRAIN; iteration: 3625; epoch: 2; loss: 2.119306802749634; \n",
      "fold: TRAIN; iteration: 3626; epoch: 2; loss: 2.417940616607666; \n",
      "fold: TRAIN; iteration: 3627; epoch: 2; loss: 2.5082523822784424; \n",
      "fold: TRAIN; iteration: 3628; epoch: 2; loss: 2.5491104125976562; \n",
      "fold: TRAIN; iteration: 3629; epoch: 2; loss: 2.5356316566467285; \n",
      "fold: TRAIN; iteration: 3630; epoch: 2; loss: 2.1454861164093018; \n",
      "fold: TRAIN; iteration: 3631; epoch: 2; loss: 2.7652885913848877; \n",
      "fold: TRAIN; iteration: 3632; epoch: 2; loss: 2.2940027713775635; \n",
      "fold: TRAIN; iteration: 3633; epoch: 2; loss: 2.2156295776367188; \n",
      "fold: TRAIN; iteration: 3634; epoch: 2; loss: 2.051807165145874; \n",
      "fold: TRAIN; iteration: 3635; epoch: 2; loss: 2.4169511795043945; \n",
      "fold: TRAIN; iteration: 3636; epoch: 2; loss: 2.2377822399139404; \n",
      "fold: TRAIN; iteration: 3637; epoch: 2; loss: 2.0538017749786377; \n",
      "fold: TRAIN; iteration: 3638; epoch: 2; loss: 2.3580384254455566; \n",
      "fold: TRAIN; iteration: 3639; epoch: 2; loss: 2.503162384033203; \n",
      "fold: TRAIN; iteration: 3640; epoch: 2; loss: 2.119502305984497; \n",
      "fold: TRAIN; iteration: 3641; epoch: 2; loss: 2.1767873764038086; \n",
      "fold: TRAIN; iteration: 3642; epoch: 2; loss: 2.3158586025238037; \n",
      "fold: TRAIN; iteration: 3643; epoch: 2; loss: 2.236100673675537; \n",
      "fold: TRAIN; iteration: 3644; epoch: 2; loss: 2.456566095352173; \n",
      "fold: TRAIN; iteration: 3645; epoch: 2; loss: 2.1349875926971436; \n",
      "fold: TRAIN; iteration: 3646; epoch: 2; loss: 2.0507547855377197; \n",
      "fold: TRAIN; iteration: 3647; epoch: 2; loss: 2.2948713302612305; \n",
      "fold: TRAIN; iteration: 3648; epoch: 2; loss: 2.418511390686035; \n",
      "fold: TRAIN; iteration: 3649; epoch: 2; loss: 2.423190116882324; \n",
      "fold: TRAIN; iteration: 3650; epoch: 2; loss: 2.3847343921661377; \n",
      "fold: TRAIN; iteration: 3651; epoch: 2; loss: 2.504204034805298; \n",
      "fold: TRAIN; iteration: 3652; epoch: 2; loss: 2.144896984100342; \n",
      "fold: TRAIN; iteration: 3653; epoch: 2; loss: 2.238584280014038; \n",
      "fold: TRAIN; iteration: 3654; epoch: 2; loss: 2.210670232772827; \n",
      "fold: TRAIN; iteration: 3655; epoch: 2; loss: 2.289747953414917; \n",
      "fold: TRAIN; iteration: 3656; epoch: 2; loss: 2.2755091190338135; \n",
      "fold: TRAIN; iteration: 3657; epoch: 2; loss: 2.2834560871124268; \n",
      "fold: TRAIN; iteration: 3658; epoch: 2; loss: 2.284838914871216; \n",
      "fold: TRAIN; iteration: 3659; epoch: 2; loss: 2.527266025543213; \n",
      "fold: TRAIN; iteration: 3660; epoch: 2; loss: 2.731976270675659; \n",
      "fold: TRAIN; iteration: 3661; epoch: 2; loss: 2.2948529720306396; \n",
      "fold: TRAIN; iteration: 3662; epoch: 2; loss: 2.660860300064087; \n",
      "fold: TRAIN; iteration: 3663; epoch: 2; loss: 2.3753180503845215; \n",
      "fold: TRAIN; iteration: 3664; epoch: 2; loss: 2.3452470302581787; \n",
      "fold: TRAIN; iteration: 3665; epoch: 2; loss: 2.2730345726013184; \n",
      "fold: TRAIN; iteration: 3666; epoch: 2; loss: 2.4135382175445557; \n",
      "fold: TRAIN; iteration: 3667; epoch: 2; loss: 2.3386571407318115; \n",
      "fold: TRAIN; iteration: 3668; epoch: 2; loss: 2.1800172328948975; \n",
      "fold: TRAIN; iteration: 3669; epoch: 2; loss: 2.0991921424865723; \n",
      "fold: TRAIN; iteration: 3670; epoch: 2; loss: 2.5586447715759277; \n",
      "fold: TRAIN; iteration: 3671; epoch: 2; loss: 2.3973817825317383; \n",
      "fold: TRAIN; iteration: 3672; epoch: 2; loss: 2.3136940002441406; \n",
      "fold: TRAIN; iteration: 3673; epoch: 2; loss: 2.3312177658081055; \n",
      "fold: TRAIN; iteration: 3674; epoch: 2; loss: 2.1254498958587646; \n",
      "fold: TRAIN; iteration: 3675; epoch: 2; loss: 2.112570285797119; \n",
      "fold: TRAIN; iteration: 3676; epoch: 2; loss: 2.3788986206054688; \n",
      "fold: TRAIN; iteration: 3677; epoch: 2; loss: 2.418734312057495; \n",
      "fold: TRAIN; iteration: 3678; epoch: 2; loss: 2.4197707176208496; \n",
      "fold: TRAIN; iteration: 3679; epoch: 2; loss: 2.328808069229126; \n",
      "fold: TRAIN; iteration: 3680; epoch: 2; loss: 2.10685133934021; \n",
      "fold: TRAIN; iteration: 3681; epoch: 2; loss: 2.361922264099121; \n",
      "fold: TRAIN; iteration: 3682; epoch: 2; loss: 2.4518134593963623; \n",
      "fold: TRAIN; iteration: 3683; epoch: 2; loss: 2.1880929470062256; \n",
      "fold: TRAIN; iteration: 3684; epoch: 2; loss: 2.4235641956329346; \n",
      "fold: TRAIN; iteration: 3685; epoch: 2; loss: 2.1621522903442383; \n",
      "fold: TRAIN; iteration: 3686; epoch: 2; loss: 2.4223949909210205; \n",
      "fold: TRAIN; iteration: 3687; epoch: 2; loss: 2.333176612854004; \n",
      "fold: TRAIN; iteration: 3688; epoch: 2; loss: 2.158520221710205; \n",
      "fold: TRAIN; iteration: 3689; epoch: 2; loss: 2.2615723609924316; \n",
      "fold: TRAIN; iteration: 3690; epoch: 2; loss: 2.2336831092834473; \n",
      "fold: TRAIN; iteration: 3691; epoch: 2; loss: 2.57405948638916; \n",
      "fold: TRAIN; iteration: 3692; epoch: 2; loss: 2.1550610065460205; \n",
      "fold: TRAIN; iteration: 3693; epoch: 2; loss: 2.196770191192627; \n",
      "fold: TRAIN; iteration: 3694; epoch: 2; loss: 2.4379987716674805; \n",
      "fold: TRAIN; iteration: 3695; epoch: 2; loss: 2.2327516078948975; \n",
      "fold: TRAIN; iteration: 3696; epoch: 2; loss: 2.0931248664855957; \n",
      "fold: TRAIN; iteration: 3697; epoch: 2; loss: 2.309718132019043; \n",
      "fold: TRAIN; iteration: 3698; epoch: 2; loss: 2.339250087738037; \n",
      "fold: TRAIN; iteration: 3699; epoch: 2; loss: 2.3884634971618652; \n",
      "fold: TRAIN; iteration: 3700; epoch: 2; loss: 2.617999315261841; \n",
      "fold: TRAIN; iteration: 3701; epoch: 2; loss: 2.3173117637634277; \n",
      "fold: TRAIN; iteration: 3702; epoch: 2; loss: 2.206510305404663; \n",
      "fold: TRAIN; iteration: 3703; epoch: 2; loss: 2.407194137573242; \n",
      "fold: TRAIN; iteration: 3704; epoch: 2; loss: 2.282515048980713; \n",
      "fold: TRAIN; iteration: 3705; epoch: 2; loss: 2.375901937484741; \n",
      "fold: TRAIN; iteration: 3706; epoch: 2; loss: 2.3074512481689453; \n",
      "fold: TRAIN; iteration: 3707; epoch: 2; loss: 2.3480193614959717; \n",
      "fold: TRAIN; iteration: 3708; epoch: 2; loss: 2.365292549133301; \n",
      "fold: TRAIN; iteration: 3709; epoch: 2; loss: 2.637618064880371; \n",
      "fold: TRAIN; iteration: 3710; epoch: 2; loss: 2.0963494777679443; \n",
      "fold: TRAIN; iteration: 3711; epoch: 2; loss: 2.352792263031006; \n",
      "fold: TRAIN; iteration: 3712; epoch: 2; loss: 2.18117618560791; \n",
      "fold: TRAIN; iteration: 3713; epoch: 2; loss: 2.434462547302246; \n",
      "fold: TRAIN; iteration: 3714; epoch: 2; loss: 2.382204055786133; \n",
      "fold: TRAIN; iteration: 3715; epoch: 2; loss: 2.323976993560791; \n",
      "fold: TRAIN; iteration: 3716; epoch: 2; loss: 2.39250111579895; \n",
      "fold: TRAIN; iteration: 3717; epoch: 2; loss: 2.1746015548706055; \n",
      "fold: TRAIN; iteration: 3718; epoch: 2; loss: 2.3487517833709717; \n",
      "fold: TRAIN; iteration: 3719; epoch: 2; loss: 2.378255605697632; \n",
      "fold: TRAIN; iteration: 3720; epoch: 2; loss: 2.472306489944458; \n",
      "fold: TRAIN; iteration: 3721; epoch: 2; loss: 2.2615439891815186; \n",
      "fold: TRAIN; iteration: 3722; epoch: 2; loss: 2.3416779041290283; \n",
      "fold: TRAIN; iteration: 3723; epoch: 2; loss: 2.2941057682037354; \n",
      "fold: TRAIN; iteration: 3724; epoch: 2; loss: 2.399143934249878; \n",
      "fold: TRAIN; iteration: 3725; epoch: 2; loss: 2.3801581859588623; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 3726; epoch: 2; loss: 2.2085046768188477; \n",
      "fold: TRAIN; iteration: 3727; epoch: 2; loss: 2.308131694793701; \n",
      "fold: TRAIN; iteration: 3728; epoch: 2; loss: 2.164097547531128; \n",
      "fold: TRAIN; iteration: 3729; epoch: 2; loss: 2.4743127822875977; \n",
      "fold: TRAIN; iteration: 3730; epoch: 2; loss: 2.173811674118042; \n",
      "fold: TRAIN; iteration: 3731; epoch: 2; loss: 2.2861554622650146; \n",
      "fold: TRAIN; iteration: 3732; epoch: 2; loss: 2.2785420417785645; \n",
      "fold: TRAIN; iteration: 3733; epoch: 2; loss: 2.322174549102783; \n",
      "fold: TRAIN; iteration: 3734; epoch: 2; loss: 2.267749547958374; \n",
      "fold: TRAIN; iteration: 3735; epoch: 2; loss: 2.238739252090454; \n",
      "fold: TRAIN; iteration: 3736; epoch: 2; loss: 2.3773343563079834; \n",
      "fold: TRAIN; iteration: 3737; epoch: 2; loss: 2.611743688583374; \n",
      "fold: TRAIN; iteration: 3738; epoch: 2; loss: 2.403869390487671; \n",
      "fold: TRAIN; iteration: 3739; epoch: 2; loss: 2.657055616378784; \n",
      "fold: TRAIN; iteration: 3740; epoch: 2; loss: 2.342268705368042; \n",
      "fold: TRAIN; iteration: 3741; epoch: 2; loss: 2.431607246398926; \n",
      "fold: TRAIN; iteration: 3742; epoch: 2; loss: 2.3531758785247803; \n",
      "fold: TRAIN; iteration: 3743; epoch: 2; loss: 2.2744193077087402; \n",
      "fold: TRAIN; iteration: 3744; epoch: 2; loss: 2.1732311248779297; \n",
      "fold: TRAIN; iteration: 3745; epoch: 2; loss: 2.2749886512756348; \n",
      "fold: TRAIN; iteration: 3746; epoch: 2; loss: 2.184319257736206; \n",
      "fold: TRAIN; iteration: 3747; epoch: 2; loss: 2.5002336502075195; \n",
      "fold: TRAIN; iteration: 3748; epoch: 2; loss: 2.3682522773742676; \n",
      "fold: TRAIN; iteration: 3749; epoch: 2; loss: 2.2735254764556885; \n",
      "fold: TRAIN; iteration: 3750; epoch: 2; loss: 2.353921413421631; \n",
      "fold: TRAIN; iteration: 3751; epoch: 2; loss: 2.3180153369903564; \n",
      "fold: TRAIN; iteration: 3752; epoch: 2; loss: 2.3931984901428223; \n",
      "fold: TRAIN; iteration: 3753; epoch: 2; loss: 2.2603166103363037; \n",
      "fold: TRAIN; iteration: 3754; epoch: 2; loss: 2.22304368019104; \n",
      "fold: TRAIN; iteration: 3755; epoch: 2; loss: 2.133748769760132; \n",
      "fold: TRAIN; iteration: 3756; epoch: 2; loss: 2.4431686401367188; \n",
      "fold: TRAIN; iteration: 3757; epoch: 2; loss: 2.416787624359131; \n",
      "fold: TRAIN; iteration: 3758; epoch: 2; loss: 2.082765579223633; \n",
      "fold: TRAIN; iteration: 3759; epoch: 2; loss: 2.338629961013794; \n",
      "fold: TRAIN; iteration: 3760; epoch: 2; loss: 2.2447807788848877; \n",
      "fold: TRAIN; iteration: 3761; epoch: 2; loss: 2.365338087081909; \n",
      "fold: TRAIN; iteration: 3762; epoch: 2; loss: 2.37703275680542; \n",
      "fold: TRAIN; iteration: 3763; epoch: 2; loss: 2.3946590423583984; \n",
      "fold: TRAIN; iteration: 3764; epoch: 2; loss: 2.1885368824005127; \n",
      "fold: TRAIN; iteration: 3765; epoch: 2; loss: 2.2529139518737793; \n",
      "fold: TRAIN; iteration: 3766; epoch: 2; loss: 2.1737220287323; \n",
      "fold: TRAIN; iteration: 3767; epoch: 2; loss: 2.3691370487213135; \n",
      "fold: TRAIN; iteration: 3768; epoch: 2; loss: 2.3362174034118652; \n",
      "fold: TRAIN; iteration: 3769; epoch: 2; loss: 2.3367760181427; \n",
      "fold: TRAIN; iteration: 3770; epoch: 2; loss: 2.223977565765381; \n",
      "fold: TRAIN; iteration: 3771; epoch: 2; loss: 2.1270835399627686; \n",
      "fold: TRAIN; iteration: 3772; epoch: 2; loss: 2.4648184776306152; \n",
      "fold: TRAIN; iteration: 3773; epoch: 2; loss: 2.3186676502227783; \n",
      "fold: TRAIN; iteration: 3774; epoch: 2; loss: 2.2710442543029785; \n",
      "fold: TRAIN; iteration: 3775; epoch: 2; loss: 2.3059847354888916; \n",
      "fold: TRAIN; iteration: 3776; epoch: 2; loss: 2.375955820083618; \n",
      "fold: TRAIN; iteration: 3777; epoch: 2; loss: 2.1994521617889404; \n",
      "fold: TRAIN; iteration: 3778; epoch: 2; loss: 2.6770830154418945; \n",
      "fold: TRAIN; iteration: 3779; epoch: 2; loss: 2.292646646499634; \n",
      "fold: TRAIN; iteration: 3780; epoch: 2; loss: 2.213259696960449; \n",
      "fold: TRAIN; iteration: 3781; epoch: 2; loss: 2.2253363132476807; \n",
      "fold: TRAIN; iteration: 3782; epoch: 2; loss: 2.2126705646514893; \n",
      "fold: TRAIN; iteration: 3783; epoch: 2; loss: 2.3941028118133545; \n",
      "fold: TRAIN; iteration: 3784; epoch: 2; loss: 2.3181498050689697; \n",
      "fold: TRAIN; iteration: 3785; epoch: 2; loss: 2.0268332958221436; \n",
      "fold: TRAIN; iteration: 3786; epoch: 2; loss: 2.251720666885376; \n",
      "fold: TRAIN; iteration: 3787; epoch: 2; loss: 2.230555295944214; \n",
      "fold: TRAIN; iteration: 3788; epoch: 2; loss: 2.326266288757324; \n",
      "fold: TRAIN; iteration: 3789; epoch: 2; loss: 2.3633010387420654; \n",
      "fold: TRAIN; iteration: 3790; epoch: 2; loss: 2.1680681705474854; \n",
      "fold: TRAIN; iteration: 3791; epoch: 2; loss: 2.315992832183838; \n",
      "fold: TRAIN; iteration: 3792; epoch: 2; loss: 2.2969155311584473; \n",
      "fold: TRAIN; iteration: 3793; epoch: 2; loss: 2.4700357913970947; \n",
      "fold: TRAIN; iteration: 3794; epoch: 2; loss: 2.2675797939300537; \n",
      "fold: TRAIN; iteration: 3795; epoch: 2; loss: 2.349209785461426; \n",
      "fold: TRAIN; iteration: 3796; epoch: 2; loss: 2.335775375366211; \n",
      "fold: TRAIN; iteration: 3797; epoch: 2; loss: 2.250075340270996; \n",
      "fold: TRAIN; iteration: 3798; epoch: 2; loss: 2.430443286895752; \n",
      "fold: TRAIN; iteration: 3799; epoch: 2; loss: 2.138437271118164; \n",
      "fold: TRAIN; iteration: 3800; epoch: 2; loss: 2.170783758163452; \n",
      "fold: TRAIN; iteration: 3801; epoch: 2; loss: 2.272879123687744; \n",
      "fold: TRAIN; iteration: 3802; epoch: 2; loss: 2.2401673793792725; \n",
      "fold: TRAIN; iteration: 3803; epoch: 2; loss: 2.297095537185669; \n",
      "fold: TRAIN; iteration: 3804; epoch: 2; loss: 2.2804362773895264; \n",
      "fold: TRAIN; iteration: 3805; epoch: 2; loss: 2.1502959728240967; \n",
      "fold: TRAIN; iteration: 3806; epoch: 2; loss: 2.4689064025878906; \n",
      "fold: TRAIN; iteration: 3807; epoch: 2; loss: 2.14949893951416; \n",
      "fold: TRAIN; iteration: 3808; epoch: 2; loss: 2.517916202545166; \n",
      "fold: TRAIN; iteration: 3809; epoch: 2; loss: 2.471022129058838; \n",
      "fold: TRAIN; iteration: 3810; epoch: 2; loss: 2.2614288330078125; \n",
      "fold: TRAIN; iteration: 3811; epoch: 2; loss: 2.133401393890381; \n",
      "fold: TRAIN; iteration: 3812; epoch: 2; loss: 2.4288816452026367; \n",
      "fold: TRAIN; iteration: 3813; epoch: 2; loss: 2.149193525314331; \n",
      "fold: TRAIN; iteration: 3814; epoch: 2; loss: 2.339806079864502; \n",
      "fold: TRAIN; iteration: 3815; epoch: 2; loss: 2.377990961074829; \n",
      "fold: TRAIN; iteration: 3816; epoch: 2; loss: 2.3117315769195557; \n",
      "fold: TRAIN; iteration: 3817; epoch: 2; loss: 2.526319980621338; \n",
      "fold: TRAIN; iteration: 3818; epoch: 2; loss: 2.189873695373535; \n",
      "fold: TRAIN; iteration: 3819; epoch: 2; loss: 2.355119228363037; \n",
      "fold: TRAIN; iteration: 3820; epoch: 2; loss: 2.2235605716705322; \n",
      "fold: TRAIN; iteration: 3821; epoch: 2; loss: 2.318687677383423; \n",
      "fold: TRAIN; iteration: 3822; epoch: 2; loss: 2.4037864208221436; \n",
      "fold: TRAIN; iteration: 3823; epoch: 2; loss: 2.534790515899658; \n",
      "fold: TRAIN; iteration: 3824; epoch: 2; loss: 2.390550136566162; \n",
      "fold: TRAIN; iteration: 3825; epoch: 2; loss: 2.270913600921631; \n",
      "fold: TRAIN; iteration: 3826; epoch: 2; loss: 2.3305912017822266; \n",
      "fold: TRAIN; iteration: 3827; epoch: 2; loss: 2.4441041946411133; \n",
      "fold: TRAIN; iteration: 3828; epoch: 2; loss: 2.2608349323272705; \n",
      "fold: TRAIN; iteration: 3829; epoch: 2; loss: 2.2496213912963867; \n",
      "fold: TRAIN; iteration: 3830; epoch: 2; loss: 2.273393392562866; \n",
      "fold: TRAIN; iteration: 3831; epoch: 2; loss: 2.2783031463623047; \n",
      "fold: TRAIN; iteration: 3832; epoch: 2; loss: 2.4659316539764404; \n",
      "fold: TRAIN; iteration: 3833; epoch: 2; loss: 2.3764965534210205; \n",
      "fold: TRAIN; iteration: 3834; epoch: 2; loss: 2.0903987884521484; \n",
      "fold: TRAIN; iteration: 3835; epoch: 2; loss: 2.493542432785034; \n",
      "fold: TRAIN; iteration: 3836; epoch: 2; loss: 2.2523062229156494; \n",
      "fold: TRAIN; iteration: 3837; epoch: 2; loss: 2.249293565750122; \n",
      "fold: TRAIN; iteration: 3838; epoch: 2; loss: 2.5851922035217285; \n",
      "fold: TRAIN; iteration: 3839; epoch: 2; loss: 2.2724192142486572; \n",
      "fold: TRAIN; iteration: 3840; epoch: 2; loss: 2.3271164894104004; \n",
      "fold: TRAIN; iteration: 3841; epoch: 2; loss: 2.3495779037475586; \n",
      "fold: TRAIN; iteration: 3842; epoch: 2; loss: 2.2802371978759766; \n",
      "fold: TRAIN; iteration: 3843; epoch: 2; loss: 2.4076197147369385; \n",
      "fold: TRAIN; iteration: 3844; epoch: 2; loss: 2.4475839138031006; \n",
      "fold: TRAIN; iteration: 3845; epoch: 2; loss: 2.2495129108428955; \n",
      "fold: TRAIN; iteration: 3846; epoch: 2; loss: 2.4663825035095215; \n",
      "fold: TRAIN; iteration: 3847; epoch: 2; loss: 2.3256592750549316; \n",
      "fold: TRAIN; iteration: 3848; epoch: 2; loss: 2.29455304145813; \n",
      "fold: TRAIN; iteration: 3849; epoch: 2; loss: 2.2541120052337646; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 3850; epoch: 2; loss: 2.542485237121582; \n",
      "fold: TRAIN; iteration: 3851; epoch: 2; loss: 2.398263692855835; \n",
      "fold: TRAIN; iteration: 3852; epoch: 2; loss: 2.3770358562469482; \n",
      "fold: TRAIN; iteration: 3853; epoch: 2; loss: 2.2180960178375244; \n",
      "fold: TRAIN; iteration: 3854; epoch: 2; loss: 2.118105411529541; \n",
      "fold: TRAIN; iteration: 3855; epoch: 2; loss: 2.2839243412017822; \n",
      "fold: TRAIN; iteration: 3856; epoch: 2; loss: 2.3921926021575928; \n",
      "fold: TRAIN; iteration: 3857; epoch: 2; loss: 2.4336979389190674; \n",
      "fold: TRAIN; iteration: 3858; epoch: 2; loss: 2.2017180919647217; \n",
      "fold: TRAIN; iteration: 3859; epoch: 2; loss: 2.270534038543701; \n",
      "fold: TRAIN; iteration: 3860; epoch: 2; loss: 2.3185153007507324; \n",
      "fold: TRAIN; iteration: 3861; epoch: 2; loss: 2.272732973098755; \n",
      "fold: TRAIN; iteration: 3862; epoch: 2; loss: 2.4068384170532227; \n",
      "fold: TRAIN; iteration: 3863; epoch: 2; loss: 2.1851727962493896; \n",
      "fold: TRAIN; iteration: 3864; epoch: 2; loss: 2.2421834468841553; \n",
      "fold: TRAIN; iteration: 3865; epoch: 2; loss: 2.3595831394195557; \n",
      "fold: TRAIN; iteration: 3866; epoch: 2; loss: 2.5824036598205566; \n",
      "fold: TRAIN; iteration: 3867; epoch: 2; loss: 2.361647605895996; \n",
      "fold: TRAIN; iteration: 3868; epoch: 2; loss: 2.252373695373535; \n",
      "fold: TRAIN; iteration: 3869; epoch: 2; loss: 2.229443073272705; \n",
      "fold: TRAIN; iteration: 3870; epoch: 2; loss: 2.4300310611724854; \n",
      "fold: TRAIN; iteration: 3871; epoch: 2; loss: 2.3141117095947266; \n",
      "fold: TRAIN; iteration: 3872; epoch: 2; loss: 2.65885591506958; \n",
      "fold: TRAIN; iteration: 3873; epoch: 2; loss: 2.355053663253784; \n",
      "fold: TRAIN; iteration: 3874; epoch: 2; loss: 2.6825428009033203; \n",
      "fold: TRAIN; iteration: 3875; epoch: 2; loss: 2.5897927284240723; \n",
      "fold: TRAIN; iteration: 3876; epoch: 2; loss: 2.2937960624694824; \n",
      "fold: TRAIN; iteration: 3877; epoch: 2; loss: 2.291123390197754; \n",
      "fold: TRAIN; iteration: 3878; epoch: 2; loss: 2.3812270164489746; \n",
      "fold: TRAIN; iteration: 3879; epoch: 2; loss: 2.4688351154327393; \n",
      "fold: TRAIN; iteration: 3880; epoch: 2; loss: 2.644587516784668; \n",
      "fold: TRAIN; iteration: 3881; epoch: 2; loss: 2.397318124771118; \n",
      "fold: TRAIN; iteration: 3882; epoch: 2; loss: 2.230835437774658; \n",
      "fold: TRAIN; iteration: 3883; epoch: 2; loss: 2.247985601425171; \n",
      "fold: TRAIN; iteration: 3884; epoch: 2; loss: 2.264078140258789; \n",
      "fold: TRAIN; iteration: 3885; epoch: 2; loss: 2.1507790088653564; \n",
      "fold: TRAIN; iteration: 3886; epoch: 2; loss: 1.935110330581665; \n",
      "fold: TRAIN; iteration: 3887; epoch: 2; loss: 2.276212692260742; \n",
      "fold: TRAIN; iteration: 3888; epoch: 2; loss: 2.4991040229797363; \n",
      "fold: TRAIN; iteration: 3889; epoch: 2; loss: 2.3480238914489746; \n",
      "fold: TRAIN; iteration: 3890; epoch: 2; loss: 2.4108998775482178; \n",
      "fold: TRAIN; iteration: 3891; epoch: 2; loss: 2.3531222343444824; \n",
      "fold: TRAIN; iteration: 3892; epoch: 2; loss: 2.3464784622192383; \n",
      "fold: TRAIN; iteration: 3893; epoch: 2; loss: 2.171243190765381; \n",
      "fold: TRAIN; iteration: 3894; epoch: 2; loss: 2.1901655197143555; \n",
      "fold: TRAIN; iteration: 3895; epoch: 2; loss: 2.2973241806030273; \n",
      "fold: TRAIN; iteration: 3896; epoch: 2; loss: 2.412496566772461; \n",
      "fold: TRAIN; iteration: 3897; epoch: 2; loss: 2.53003191947937; \n",
      "fold: TRAIN; iteration: 3898; epoch: 2; loss: 2.3445065021514893; \n",
      "fold: TRAIN; iteration: 3899; epoch: 2; loss: 2.800502061843872; \n",
      "fold: TRAIN; iteration: 3900; epoch: 2; loss: 2.5221381187438965; \n",
      "fold: TRAIN; iteration: 3901; epoch: 2; loss: 2.3676559925079346; \n",
      "fold: TRAIN; iteration: 3902; epoch: 2; loss: 1.9849773645401; \n",
      "fold: TRAIN; iteration: 3903; epoch: 2; loss: 2.444563627243042; \n",
      "fold: TRAIN; iteration: 3904; epoch: 2; loss: 2.6121060848236084; \n",
      "fold: TRAIN; iteration: 3905; epoch: 2; loss: 2.342733383178711; \n",
      "fold: TRAIN; iteration: 3906; epoch: 2; loss: 2.2669174671173096; \n",
      "fold: TRAIN; iteration: 3907; epoch: 2; loss: 2.4705333709716797; \n",
      "fold: TRAIN; iteration: 3908; epoch: 2; loss: 2.1290993690490723; \n",
      "fold: TRAIN; iteration: 3909; epoch: 2; loss: 2.1717865467071533; \n",
      "fold: TRAIN; iteration: 3910; epoch: 2; loss: 2.323216438293457; \n",
      "fold: TRAIN; iteration: 3911; epoch: 2; loss: 2.3325088024139404; \n",
      "fold: TRAIN; iteration: 3912; epoch: 2; loss: 2.273096799850464; \n",
      "fold: TRAIN; iteration: 3913; epoch: 2; loss: 2.1923649311065674; \n",
      "fold: TRAIN; iteration: 3914; epoch: 2; loss: 2.386934757232666; \n",
      "fold: TRAIN; iteration: 3915; epoch: 2; loss: 2.3024697303771973; \n",
      "fold: TRAIN; iteration: 3916; epoch: 2; loss: 2.415915012359619; \n",
      "fold: TRAIN; iteration: 3917; epoch: 2; loss: 2.0088868141174316; \n",
      "fold: TRAIN; iteration: 3918; epoch: 2; loss: 2.1900296211242676; \n",
      "fold: TRAIN; iteration: 3919; epoch: 2; loss: 2.30491042137146; \n",
      "fold: TRAIN; iteration: 3920; epoch: 2; loss: 2.556206703186035; \n",
      "fold: TRAIN; iteration: 3921; epoch: 2; loss: 2.277405261993408; \n",
      "fold: TRAIN; iteration: 3922; epoch: 2; loss: 2.406496047973633; \n",
      "fold: TRAIN; iteration: 3923; epoch: 2; loss: 2.14676570892334; \n",
      "fold: TRAIN; iteration: 3924; epoch: 2; loss: 2.2792110443115234; \n",
      "fold: TRAIN; iteration: 3925; epoch: 2; loss: 2.4228265285491943; \n",
      "fold: TRAIN; iteration: 3926; epoch: 2; loss: 2.2536461353302; \n",
      "fold: TRAIN; iteration: 3927; epoch: 2; loss: 2.4561514854431152; \n",
      "fold: TRAIN; iteration: 3928; epoch: 2; loss: 2.1703836917877197; \n",
      "fold: TRAIN; iteration: 3929; epoch: 2; loss: 2.2248337268829346; \n",
      "fold: TRAIN; iteration: 3930; epoch: 2; loss: 2.498901128768921; \n",
      "fold: TRAIN; iteration: 3931; epoch: 2; loss: 2.298401355743408; \n",
      "fold: TRAIN; iteration: 3932; epoch: 2; loss: 2.412311315536499; \n",
      "fold: TRAIN; iteration: 3933; epoch: 2; loss: 2.414276123046875; \n",
      "fold: TRAIN; iteration: 3934; epoch: 2; loss: 2.465607166290283; \n",
      "fold: TRAIN; iteration: 3935; epoch: 2; loss: 2.6353025436401367; \n",
      "fold: TRAIN; iteration: 3936; epoch: 2; loss: 2.4198336601257324; \n",
      "fold: TRAIN; iteration: 3937; epoch: 2; loss: 2.5266854763031006; \n",
      "fold: TRAIN; iteration: 3938; epoch: 2; loss: 2.3223683834075928; \n",
      "fold: TRAIN; iteration: 3939; epoch: 2; loss: 2.436069965362549; \n",
      "fold: TRAIN; iteration: 3940; epoch: 2; loss: 2.394061803817749; \n",
      "fold: TRAIN; iteration: 3941; epoch: 2; loss: 2.1766538619995117; \n",
      "fold: TRAIN; iteration: 3942; epoch: 2; loss: 2.2946395874023438; \n",
      "fold: TRAIN; iteration: 3943; epoch: 2; loss: 2.4607584476470947; \n",
      "fold: TRAIN; iteration: 3944; epoch: 2; loss: 2.3727824687957764; \n",
      "fold: TRAIN; iteration: 3945; epoch: 2; loss: 2.0111169815063477; \n",
      "fold: TRAIN; iteration: 3946; epoch: 2; loss: 2.3915605545043945; \n",
      "fold: TRAIN; iteration: 3947; epoch: 2; loss: 2.2157812118530273; \n",
      "fold: TRAIN; iteration: 3948; epoch: 2; loss: 2.443045139312744; \n",
      "fold: TRAIN; iteration: 3949; epoch: 2; loss: 2.3499503135681152; \n",
      "fold: TRAIN; iteration: 3950; epoch: 2; loss: 2.3523778915405273; \n",
      "fold: TRAIN; iteration: 3951; epoch: 2; loss: 2.3147058486938477; \n",
      "fold: TRAIN; iteration: 3952; epoch: 2; loss: 2.220517158508301; \n",
      "fold: TRAIN; iteration: 3953; epoch: 2; loss: 2.115199565887451; \n",
      "fold: TRAIN; iteration: 3954; epoch: 2; loss: 2.4818413257598877; \n",
      "fold: TRAIN; iteration: 3955; epoch: 2; loss: 2.3365938663482666; \n",
      "fold: TRAIN; iteration: 3956; epoch: 2; loss: 2.281461715698242; \n",
      "fold: TRAIN; iteration: 3957; epoch: 2; loss: 2.3531174659729004; \n",
      "fold: TRAIN; iteration: 3958; epoch: 2; loss: 2.245677947998047; \n",
      "fold: TRAIN; iteration: 3959; epoch: 2; loss: 2.257601261138916; \n",
      "fold: TRAIN; iteration: 3960; epoch: 2; loss: 2.1827468872070312; \n",
      "fold: TRAIN; iteration: 3961; epoch: 2; loss: 2.27801775932312; \n",
      "fold: TRAIN; iteration: 3962; epoch: 2; loss: 2.496422529220581; \n",
      "fold: TRAIN; iteration: 3963; epoch: 2; loss: 2.2614264488220215; \n",
      "fold: TRAIN; iteration: 3964; epoch: 2; loss: 2.430712938308716; \n",
      "fold: TRAIN; iteration: 3965; epoch: 2; loss: 2.239267349243164; \n",
      "fold: TRAIN; iteration: 3966; epoch: 2; loss: 2.2958667278289795; \n",
      "fold: TRAIN; iteration: 3967; epoch: 2; loss: 2.1702017784118652; \n",
      "fold: TRAIN; iteration: 3968; epoch: 2; loss: 2.461892604827881; \n",
      "fold: TRAIN; iteration: 3969; epoch: 2; loss: 2.216169834136963; \n",
      "fold: TRAIN; iteration: 3970; epoch: 2; loss: 2.1875641345977783; \n",
      "fold: TRAIN; iteration: 3971; epoch: 2; loss: 2.2893106937408447; \n",
      "fold: TRAIN; iteration: 3972; epoch: 2; loss: 2.2843828201293945; \n",
      "fold: TRAIN; iteration: 3973; epoch: 2; loss: 2.355849504470825; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 3974; epoch: 2; loss: 2.1139955520629883; \n",
      "fold: TRAIN; iteration: 3975; epoch: 2; loss: 2.007845163345337; \n",
      "fold: TRAIN; iteration: 3976; epoch: 2; loss: 2.602780818939209; \n",
      "fold: TRAIN; iteration: 3977; epoch: 2; loss: 2.416825294494629; \n",
      "fold: TRAIN; iteration: 3978; epoch: 2; loss: 2.026388168334961; \n",
      "fold: TRAIN; iteration: 3979; epoch: 2; loss: 2.4257922172546387; \n",
      "fold: TRAIN; iteration: 3980; epoch: 2; loss: 2.2799811363220215; \n",
      "fold: TRAIN; iteration: 3981; epoch: 2; loss: 2.3969364166259766; \n",
      "fold: TRAIN; iteration: 3982; epoch: 2; loss: 1.9037188291549683; \n",
      "fold: TRAIN; iteration: 3983; epoch: 2; loss: 2.3072516918182373; \n",
      "fold: TRAIN; iteration: 3984; epoch: 2; loss: 2.391751289367676; \n",
      "fold: TRAIN; iteration: 3985; epoch: 2; loss: 2.182945489883423; \n",
      "fold: TRAIN; iteration: 3986; epoch: 2; loss: 2.4117507934570312; \n",
      "fold: TRAIN; iteration: 3987; epoch: 2; loss: 2.240705966949463; \n",
      "fold: TRAIN; iteration: 3988; epoch: 2; loss: 2.3361172676086426; \n",
      "fold: TRAIN; iteration: 3989; epoch: 2; loss: 2.3947207927703857; \n",
      "fold: TRAIN; iteration: 3990; epoch: 2; loss: 2.344332218170166; \n",
      "fold: TRAIN; iteration: 3991; epoch: 2; loss: 2.046708106994629; \n",
      "fold: TRAIN; iteration: 3992; epoch: 2; loss: 2.190981864929199; \n",
      "fold: TRAIN; iteration: 3993; epoch: 2; loss: 2.1862001419067383; \n",
      "fold: TRAIN; iteration: 3994; epoch: 2; loss: 2.2273550033569336; \n",
      "fold: TRAIN; iteration: 3995; epoch: 2; loss: 2.139859914779663; \n",
      "fold: TRAIN; iteration: 3996; epoch: 2; loss: 2.270862102508545; \n",
      "fold: TRAIN; iteration: 3997; epoch: 2; loss: 2.343991756439209; \n",
      "fold: TRAIN; iteration: 3998; epoch: 2; loss: 2.4051690101623535; \n",
      "fold: TRAIN; iteration: 3999; epoch: 2; loss: 2.4643447399139404; \n",
      "validating model...\n",
      "saving\n",
      "fold: VALID; iteration: 4000; epoch: 2; loss: 2.3801551762749167; \n",
      "fold: TRAIN; iteration: 4000; epoch: 2; loss: 2.1987204551696777; \n",
      "fold: TRAIN; iteration: 4001; epoch: 2; loss: 2.244980812072754; \n",
      "fold: TRAIN; iteration: 4002; epoch: 2; loss: 2.2086281776428223; \n",
      "fold: TRAIN; iteration: 4003; epoch: 2; loss: 2.1901309490203857; \n",
      "fold: TRAIN; iteration: 4004; epoch: 2; loss: 2.578564405441284; \n",
      "fold: TRAIN; iteration: 4005; epoch: 2; loss: 2.3805084228515625; \n",
      "fold: TRAIN; iteration: 4006; epoch: 2; loss: 2.3055901527404785; \n",
      "fold: TRAIN; iteration: 4007; epoch: 2; loss: 2.3992905616760254; \n",
      "fold: TRAIN; iteration: 4008; epoch: 2; loss: 2.1584222316741943; \n",
      "fold: TRAIN; iteration: 4009; epoch: 2; loss: 2.0549728870391846; \n",
      "fold: TRAIN; iteration: 4010; epoch: 2; loss: 2.2153518199920654; \n",
      "fold: TRAIN; iteration: 4011; epoch: 2; loss: 2.4342408180236816; \n",
      "fold: TRAIN; iteration: 4012; epoch: 2; loss: 2.3083677291870117; \n",
      "fold: TRAIN; iteration: 4013; epoch: 2; loss: 2.2405920028686523; \n",
      "fold: TRAIN; iteration: 4014; epoch: 2; loss: 2.3524680137634277; \n",
      "fold: TRAIN; iteration: 4015; epoch: 2; loss: 2.2518529891967773; \n",
      "fold: TRAIN; iteration: 4016; epoch: 2; loss: 2.5157642364501953; \n",
      "fold: TRAIN; iteration: 4017; epoch: 2; loss: 2.373414993286133; \n",
      "fold: TRAIN; iteration: 4018; epoch: 2; loss: 2.1861376762390137; \n",
      "fold: TRAIN; iteration: 4019; epoch: 2; loss: 2.5053720474243164; \n",
      "fold: TRAIN; iteration: 4020; epoch: 2; loss: 2.191282033920288; \n",
      "fold: TRAIN; iteration: 4021; epoch: 2; loss: 2.2615649700164795; \n",
      "fold: TRAIN; iteration: 4022; epoch: 2; loss: 2.1260392665863037; \n",
      "fold: TRAIN; iteration: 4023; epoch: 2; loss: 2.2375595569610596; \n",
      "fold: TRAIN; iteration: 4024; epoch: 2; loss: 2.0190980434417725; \n",
      "fold: TRAIN; iteration: 4025; epoch: 2; loss: 2.2485105991363525; \n",
      "fold: TRAIN; iteration: 4026; epoch: 2; loss: 2.4259510040283203; \n",
      "fold: TRAIN; iteration: 4027; epoch: 2; loss: 2.268284797668457; \n",
      "fold: TRAIN; iteration: 4028; epoch: 2; loss: 2.1950669288635254; \n",
      "fold: TRAIN; iteration: 4029; epoch: 2; loss: 2.3395309448242188; \n",
      "fold: TRAIN; iteration: 4030; epoch: 2; loss: 2.10452938079834; \n",
      "fold: TRAIN; iteration: 4031; epoch: 2; loss: 2.3466475009918213; \n",
      "fold: TRAIN; iteration: 4032; epoch: 2; loss: 2.3537471294403076; \n",
      "fold: TRAIN; iteration: 4033; epoch: 2; loss: 2.384167194366455; \n",
      "fold: TRAIN; iteration: 4034; epoch: 2; loss: 2.5938117504119873; \n",
      "fold: TRAIN; iteration: 4035; epoch: 2; loss: 2.256664991378784; \n",
      "fold: TRAIN; iteration: 4036; epoch: 2; loss: 2.250159502029419; \n",
      "fold: TRAIN; iteration: 4037; epoch: 2; loss: 2.270368814468384; \n",
      "fold: TRAIN; iteration: 4038; epoch: 2; loss: 2.322819232940674; \n",
      "fold: TRAIN; iteration: 4039; epoch: 2; loss: 2.397547960281372; \n",
      "fold: TRAIN; iteration: 4040; epoch: 2; loss: 2.2194297313690186; \n",
      "fold: TRAIN; iteration: 4041; epoch: 2; loss: 2.2479965686798096; \n",
      "fold: TRAIN; iteration: 4042; epoch: 2; loss: 2.276718854904175; \n",
      "fold: TRAIN; iteration: 4043; epoch: 2; loss: 2.324747085571289; \n",
      "fold: TRAIN; iteration: 4044; epoch: 2; loss: 2.3022594451904297; \n",
      "fold: TRAIN; iteration: 4045; epoch: 2; loss: 2.221766233444214; \n",
      "fold: TRAIN; iteration: 4046; epoch: 2; loss: 2.1003012657165527; \n",
      "fold: TRAIN; iteration: 4047; epoch: 2; loss: 2.559725522994995; \n",
      "fold: TRAIN; iteration: 4048; epoch: 2; loss: 2.361931800842285; \n",
      "fold: TRAIN; iteration: 4049; epoch: 2; loss: 2.238959789276123; \n",
      "fold: TRAIN; iteration: 4050; epoch: 2; loss: 2.2561473846435547; \n",
      "fold: TRAIN; iteration: 4051; epoch: 2; loss: 2.0706558227539062; \n",
      "fold: TRAIN; iteration: 4052; epoch: 2; loss: 2.3483970165252686; \n",
      "fold: TRAIN; iteration: 4053; epoch: 2; loss: 2.231027126312256; \n",
      "fold: TRAIN; iteration: 4054; epoch: 2; loss: 2.2592737674713135; \n",
      "fold: TRAIN; iteration: 4055; epoch: 2; loss: 2.078174114227295; \n",
      "fold: TRAIN; iteration: 4056; epoch: 2; loss: 2.556905508041382; \n",
      "fold: TRAIN; iteration: 4057; epoch: 2; loss: 2.3217523097991943; \n",
      "fold: TRAIN; iteration: 4058; epoch: 2; loss: 2.1428542137145996; \n",
      "fold: TRAIN; iteration: 4059; epoch: 2; loss: 2.1827878952026367; \n",
      "fold: TRAIN; iteration: 4060; epoch: 2; loss: 2.188260555267334; \n",
      "fold: TRAIN; iteration: 4061; epoch: 2; loss: 2.6227047443389893; \n",
      "fold: TRAIN; iteration: 4062; epoch: 2; loss: 2.4915690422058105; \n",
      "fold: TRAIN; iteration: 4063; epoch: 2; loss: 2.1981234550476074; \n",
      "fold: TRAIN; iteration: 4064; epoch: 2; loss: 2.1949872970581055; \n",
      "fold: TRAIN; iteration: 4065; epoch: 2; loss: 2.5856173038482666; \n",
      "fold: TRAIN; iteration: 4066; epoch: 2; loss: 2.2652316093444824; \n",
      "fold: TRAIN; iteration: 4067; epoch: 2; loss: 2.1747405529022217; \n",
      "fold: TRAIN; iteration: 4068; epoch: 2; loss: 2.4192357063293457; \n",
      "fold: TRAIN; iteration: 4069; epoch: 2; loss: 2.29573392868042; \n",
      "fold: TRAIN; iteration: 4070; epoch: 2; loss: 2.206075668334961; \n",
      "fold: TRAIN; iteration: 4071; epoch: 2; loss: 2.2780447006225586; \n",
      "fold: TRAIN; iteration: 4072; epoch: 2; loss: 2.1559433937072754; \n",
      "fold: TRAIN; iteration: 4073; epoch: 2; loss: 2.1170880794525146; \n",
      "fold: TRAIN; iteration: 4074; epoch: 2; loss: 2.190798044204712; \n",
      "fold: TRAIN; iteration: 4075; epoch: 2; loss: 2.3319945335388184; \n",
      "fold: TRAIN; iteration: 4076; epoch: 2; loss: 2.4190304279327393; \n",
      "fold: TRAIN; iteration: 4077; epoch: 2; loss: 2.230581283569336; \n",
      "fold: TRAIN; iteration: 4078; epoch: 2; loss: 2.5392038822174072; \n",
      "fold: TRAIN; iteration: 4079; epoch: 2; loss: 2.265136241912842; \n",
      "fold: TRAIN; iteration: 4080; epoch: 2; loss: 2.362774133682251; \n",
      "fold: TRAIN; iteration: 4081; epoch: 2; loss: 2.2000815868377686; \n",
      "fold: TRAIN; iteration: 4082; epoch: 2; loss: 2.33536434173584; \n",
      "fold: TRAIN; iteration: 4083; epoch: 2; loss: 2.351907253265381; \n",
      "fold: TRAIN; iteration: 4084; epoch: 2; loss: 2.333376407623291; \n",
      "fold: TRAIN; iteration: 4085; epoch: 2; loss: 2.1335678100585938; \n",
      "fold: TRAIN; iteration: 4086; epoch: 2; loss: 2.397298574447632; \n",
      "fold: TRAIN; iteration: 4087; epoch: 2; loss: 2.2365965843200684; \n",
      "fold: TRAIN; iteration: 4088; epoch: 2; loss: 1.987757682800293; \n",
      "fold: TRAIN; iteration: 4089; epoch: 2; loss: 2.289475440979004; \n",
      "fold: TRAIN; iteration: 4090; epoch: 2; loss: 2.271217107772827; \n",
      "fold: TRAIN; iteration: 4091; epoch: 2; loss: 2.5873584747314453; \n",
      "fold: TRAIN; iteration: 4092; epoch: 2; loss: 2.4456887245178223; \n",
      "fold: TRAIN; iteration: 4093; epoch: 2; loss: 2.2538955211639404; \n",
      "fold: TRAIN; iteration: 4094; epoch: 2; loss: 2.4801087379455566; \n",
      "fold: TRAIN; iteration: 4095; epoch: 2; loss: 2.400306463241577; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 4096; epoch: 2; loss: 2.3675601482391357; \n",
      "fold: TRAIN; iteration: 4097; epoch: 2; loss: 2.4430859088897705; \n",
      "fold: TRAIN; iteration: 4098; epoch: 2; loss: 2.497957706451416; \n",
      "fold: TRAIN; iteration: 4099; epoch: 2; loss: 2.22216534614563; \n",
      "fold: TRAIN; iteration: 4100; epoch: 2; loss: 2.3245835304260254; \n",
      "fold: TRAIN; iteration: 4101; epoch: 2; loss: 2.4409425258636475; \n",
      "fold: TRAIN; iteration: 4102; epoch: 2; loss: 2.2669389247894287; \n",
      "fold: TRAIN; iteration: 4103; epoch: 2; loss: 2.328145980834961; \n",
      "fold: TRAIN; iteration: 4104; epoch: 2; loss: 2.3272781372070312; \n",
      "fold: TRAIN; iteration: 4105; epoch: 2; loss: 2.3961215019226074; \n",
      "fold: TRAIN; iteration: 4106; epoch: 2; loss: 2.28759765625; \n",
      "fold: TRAIN; iteration: 4107; epoch: 2; loss: 2.32083797454834; \n",
      "fold: TRAIN; iteration: 4108; epoch: 2; loss: 2.4056169986724854; \n",
      "fold: TRAIN; iteration: 4109; epoch: 2; loss: 2.233320713043213; \n",
      "fold: TRAIN; iteration: 4110; epoch: 2; loss: 2.2122249603271484; \n",
      "fold: TRAIN; iteration: 4111; epoch: 2; loss: 2.4243431091308594; \n",
      "fold: TRAIN; iteration: 4112; epoch: 2; loss: 2.2557876110076904; \n",
      "fold: TRAIN; iteration: 4113; epoch: 2; loss: 2.3517465591430664; \n",
      "fold: TRAIN; iteration: 4114; epoch: 2; loss: 2.3683743476867676; \n",
      "fold: TRAIN; iteration: 4115; epoch: 2; loss: 2.3508460521698; \n",
      "fold: TRAIN; iteration: 4116; epoch: 2; loss: 2.1873362064361572; \n",
      "fold: TRAIN; iteration: 4117; epoch: 2; loss: 2.567847967147827; \n",
      "fold: TRAIN; iteration: 4118; epoch: 2; loss: 2.171773910522461; \n",
      "fold: TRAIN; iteration: 4119; epoch: 2; loss: 2.1854119300842285; \n",
      "fold: TRAIN; iteration: 4120; epoch: 2; loss: 2.2632100582122803; \n",
      "fold: TRAIN; iteration: 4121; epoch: 2; loss: 2.401590585708618; \n",
      "fold: TRAIN; iteration: 4122; epoch: 2; loss: 2.4067602157592773; \n",
      "fold: TRAIN; iteration: 4123; epoch: 2; loss: 2.1165201663970947; \n",
      "fold: TRAIN; iteration: 4124; epoch: 2; loss: 2.3715124130249023; \n",
      "fold: TRAIN; iteration: 4125; epoch: 2; loss: 2.0345664024353027; \n",
      "fold: TRAIN; iteration: 4126; epoch: 2; loss: 2.3412890434265137; \n",
      "fold: TRAIN; iteration: 4127; epoch: 2; loss: 2.06943416595459; \n",
      "fold: TRAIN; iteration: 4128; epoch: 2; loss: 2.018472909927368; \n",
      "fold: TRAIN; iteration: 4129; epoch: 2; loss: 2.051246166229248; \n",
      "fold: TRAIN; iteration: 4130; epoch: 2; loss: 2.577162742614746; \n",
      "fold: TRAIN; iteration: 4131; epoch: 2; loss: 2.095784902572632; \n",
      "fold: TRAIN; iteration: 4132; epoch: 2; loss: 2.4992268085479736; \n",
      "fold: TRAIN; iteration: 4133; epoch: 2; loss: 2.3075218200683594; \n",
      "fold: TRAIN; iteration: 4134; epoch: 2; loss: 2.2290163040161133; \n",
      "fold: TRAIN; iteration: 4135; epoch: 2; loss: 2.4591078758239746; \n",
      "fold: TRAIN; iteration: 4136; epoch: 2; loss: 2.423680305480957; \n",
      "fold: TRAIN; iteration: 4137; epoch: 2; loss: 2.2636306285858154; \n",
      "fold: TRAIN; iteration: 4138; epoch: 2; loss: 2.4482882022857666; \n",
      "fold: TRAIN; iteration: 4139; epoch: 2; loss: 2.3346071243286133; \n",
      "fold: TRAIN; iteration: 4140; epoch: 2; loss: 2.318587303161621; \n",
      "fold: TRAIN; iteration: 4141; epoch: 2; loss: 2.3675336837768555; \n",
      "fold: TRAIN; iteration: 4142; epoch: 2; loss: 2.3476760387420654; \n",
      "fold: TRAIN; iteration: 4143; epoch: 2; loss: 2.3219306468963623; \n",
      "fold: TRAIN; iteration: 4144; epoch: 2; loss: 2.2938132286071777; \n",
      "fold: TRAIN; iteration: 4145; epoch: 2; loss: 2.51126766204834; \n",
      "fold: TRAIN; iteration: 4146; epoch: 2; loss: 2.3680970668792725; \n",
      "fold: TRAIN; iteration: 4147; epoch: 2; loss: 2.316220283508301; \n",
      "fold: TRAIN; iteration: 4148; epoch: 2; loss: 2.0489068031311035; \n",
      "fold: TRAIN; iteration: 4149; epoch: 2; loss: 2.178534507751465; \n",
      "fold: TRAIN; iteration: 4150; epoch: 2; loss: 2.338801622390747; \n",
      "fold: TRAIN; iteration: 4151; epoch: 2; loss: 2.4653851985931396; \n",
      "fold: TRAIN; iteration: 4152; epoch: 2; loss: 2.413951873779297; \n",
      "fold: TRAIN; iteration: 4153; epoch: 2; loss: 2.234872817993164; \n",
      "fold: TRAIN; iteration: 4154; epoch: 2; loss: 2.0950591564178467; \n",
      "fold: TRAIN; iteration: 4155; epoch: 2; loss: 2.4387450218200684; \n",
      "fold: TRAIN; iteration: 4156; epoch: 2; loss: 2.4245054721832275; \n",
      "fold: TRAIN; iteration: 4157; epoch: 2; loss: 2.292250633239746; \n",
      "fold: TRAIN; iteration: 4158; epoch: 2; loss: 2.23354434967041; \n",
      "fold: TRAIN; iteration: 4159; epoch: 2; loss: 2.522245168685913; \n",
      "fold: TRAIN; iteration: 4160; epoch: 2; loss: 2.429309606552124; \n",
      "fold: TRAIN; iteration: 4161; epoch: 2; loss: 2.3230068683624268; \n",
      "fold: TRAIN; iteration: 4162; epoch: 2; loss: 2.344627618789673; \n",
      "fold: TRAIN; iteration: 4163; epoch: 2; loss: 2.3320605754852295; \n",
      "fold: TRAIN; iteration: 4164; epoch: 2; loss: 2.3623905181884766; \n",
      "fold: TRAIN; iteration: 4165; epoch: 2; loss: 2.4102089405059814; \n",
      "fold: TRAIN; iteration: 4166; epoch: 2; loss: 2.0952200889587402; \n",
      "fold: TRAIN; iteration: 4167; epoch: 2; loss: 2.1947879791259766; \n",
      "fold: TRAIN; iteration: 4168; epoch: 2; loss: 2.190669298171997; \n",
      "fold: TRAIN; iteration: 4169; epoch: 2; loss: 2.3276500701904297; \n",
      "fold: TRAIN; iteration: 4170; epoch: 2; loss: 2.334639549255371; \n",
      "fold: TRAIN; iteration: 4171; epoch: 2; loss: 2.009122848510742; \n",
      "fold: TRAIN; iteration: 4172; epoch: 2; loss: 2.3116698265075684; \n",
      "fold: TRAIN; iteration: 4173; epoch: 2; loss: 2.2525312900543213; \n",
      "fold: TRAIN; iteration: 4174; epoch: 2; loss: 2.25331449508667; \n",
      "fold: TRAIN; iteration: 4175; epoch: 2; loss: 2.0345849990844727; \n",
      "fold: TRAIN; iteration: 4176; epoch: 2; loss: 2.3389699459075928; \n",
      "fold: TRAIN; iteration: 4177; epoch: 2; loss: 2.191579818725586; \n",
      "fold: TRAIN; iteration: 4178; epoch: 2; loss: 2.312096357345581; \n",
      "fold: TRAIN; iteration: 4179; epoch: 2; loss: 2.479090929031372; \n",
      "fold: TRAIN; iteration: 4180; epoch: 2; loss: 2.3013858795166016; \n",
      "fold: TRAIN; iteration: 4181; epoch: 2; loss: 2.389474630355835; \n",
      "fold: TRAIN; iteration: 4182; epoch: 2; loss: 2.235527276992798; \n",
      "fold: TRAIN; iteration: 4183; epoch: 2; loss: 2.3110835552215576; \n",
      "fold: TRAIN; iteration: 4184; epoch: 2; loss: 2.2604589462280273; \n",
      "fold: TRAIN; iteration: 4185; epoch: 2; loss: 2.1636574268341064; \n",
      "fold: TRAIN; iteration: 4186; epoch: 2; loss: 2.397148609161377; \n",
      "fold: TRAIN; iteration: 4187; epoch: 2; loss: 2.1819376945495605; \n",
      "fold: TRAIN; iteration: 4188; epoch: 2; loss: 2.1382577419281006; \n",
      "fold: TRAIN; iteration: 4189; epoch: 2; loss: 2.4011881351470947; \n",
      "fold: TRAIN; iteration: 4190; epoch: 2; loss: 2.2915544509887695; \n",
      "fold: TRAIN; iteration: 4191; epoch: 2; loss: 2.4958608150482178; \n",
      "fold: TRAIN; iteration: 4192; epoch: 2; loss: 2.3726396560668945; \n",
      "fold: TRAIN; iteration: 4193; epoch: 2; loss: 2.365185022354126; \n",
      "fold: TRAIN; iteration: 4194; epoch: 2; loss: 2.2809982299804688; \n",
      "fold: TRAIN; iteration: 4195; epoch: 2; loss: 2.115901231765747; \n",
      "fold: TRAIN; iteration: 4196; epoch: 2; loss: 2.517836809158325; \n",
      "fold: TRAIN; iteration: 4197; epoch: 2; loss: 2.277686834335327; \n",
      "fold: TRAIN; iteration: 4198; epoch: 2; loss: 2.503713846206665; \n",
      "fold: TRAIN; iteration: 4199; epoch: 2; loss: 2.2772703170776367; \n",
      "fold: TRAIN; iteration: 4200; epoch: 2; loss: 2.225497245788574; \n",
      "fold: TRAIN; iteration: 4201; epoch: 2; loss: 2.3186843395233154; \n",
      "fold: TRAIN; iteration: 4202; epoch: 2; loss: 2.5348267555236816; \n",
      "fold: TRAIN; iteration: 4203; epoch: 2; loss: 2.266253709793091; \n",
      "fold: TRAIN; iteration: 4204; epoch: 2; loss: 2.104571580886841; \n",
      "fold: TRAIN; iteration: 4205; epoch: 2; loss: 2.2366435527801514; \n",
      "fold: TRAIN; iteration: 4206; epoch: 2; loss: 2.3139734268188477; \n",
      "fold: TRAIN; iteration: 4207; epoch: 2; loss: 2.1403868198394775; \n",
      "fold: TRAIN; iteration: 4208; epoch: 2; loss: 2.128659963607788; \n",
      "fold: TRAIN; iteration: 4209; epoch: 2; loss: 2.315178871154785; \n",
      "fold: TRAIN; iteration: 4210; epoch: 2; loss: 2.3509421348571777; \n",
      "fold: TRAIN; iteration: 4211; epoch: 2; loss: 2.347745418548584; \n",
      "fold: TRAIN; iteration: 4212; epoch: 2; loss: 2.2452032566070557; \n",
      "fold: TRAIN; iteration: 4213; epoch: 2; loss: 2.3298439979553223; \n",
      "fold: TRAIN; iteration: 4214; epoch: 2; loss: 2.309265375137329; \n",
      "fold: TRAIN; iteration: 4215; epoch: 2; loss: 2.42622709274292; \n",
      "fold: TRAIN; iteration: 4216; epoch: 2; loss: 2.1889455318450928; \n",
      "fold: TRAIN; iteration: 4217; epoch: 2; loss: 2.4834330081939697; \n",
      "fold: TRAIN; iteration: 4218; epoch: 2; loss: 1.9582678079605103; \n",
      "fold: TRAIN; iteration: 4219; epoch: 2; loss: 2.124181032180786; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 4220; epoch: 2; loss: 2.5405678749084473; \n",
      "fold: TRAIN; iteration: 4221; epoch: 2; loss: 2.543806552886963; \n",
      "fold: TRAIN; iteration: 4222; epoch: 2; loss: 2.4509027004241943; \n",
      "fold: TRAIN; iteration: 4223; epoch: 2; loss: 2.3238658905029297; \n",
      "fold: TRAIN; iteration: 4224; epoch: 2; loss: 2.3589906692504883; \n",
      "fold: TRAIN; iteration: 4225; epoch: 2; loss: 2.2137291431427; \n",
      "fold: TRAIN; iteration: 4226; epoch: 2; loss: 2.2831368446350098; \n",
      "fold: TRAIN; iteration: 4227; epoch: 2; loss: 2.2480854988098145; \n",
      "fold: TRAIN; iteration: 4228; epoch: 2; loss: 2.474946975708008; \n",
      "fold: TRAIN; iteration: 4229; epoch: 2; loss: 2.404674768447876; \n",
      "fold: TRAIN; iteration: 4230; epoch: 2; loss: 2.486173629760742; \n",
      "fold: TRAIN; iteration: 4231; epoch: 2; loss: 2.2916808128356934; \n",
      "fold: TRAIN; iteration: 4232; epoch: 2; loss: 2.401798963546753; \n",
      "fold: TRAIN; iteration: 4233; epoch: 2; loss: 2.325068950653076; \n",
      "fold: TRAIN; iteration: 4234; epoch: 2; loss: 2.2907979488372803; \n",
      "fold: TRAIN; iteration: 4235; epoch: 2; loss: 2.1967344284057617; \n",
      "fold: TRAIN; iteration: 4236; epoch: 2; loss: 2.4742684364318848; \n",
      "fold: TRAIN; iteration: 4237; epoch: 2; loss: 2.1925301551818848; \n",
      "fold: TRAIN; iteration: 4238; epoch: 2; loss: 2.3358025550842285; \n",
      "fold: TRAIN; iteration: 4239; epoch: 2; loss: 2.5187416076660156; \n",
      "fold: TRAIN; iteration: 4240; epoch: 2; loss: 2.276556968688965; \n",
      "fold: TRAIN; iteration: 4241; epoch: 2; loss: 2.5316052436828613; \n",
      "fold: TRAIN; iteration: 4242; epoch: 2; loss: 2.416365623474121; \n",
      "fold: TRAIN; iteration: 4243; epoch: 2; loss: 2.4070241451263428; \n",
      "fold: TRAIN; iteration: 4244; epoch: 2; loss: 2.4636425971984863; \n",
      "fold: TRAIN; iteration: 4245; epoch: 2; loss: 2.1343300342559814; \n",
      "fold: TRAIN; iteration: 4246; epoch: 2; loss: 2.1357157230377197; \n",
      "fold: TRAIN; iteration: 4247; epoch: 2; loss: 2.145420789718628; \n",
      "fold: TRAIN; iteration: 4248; epoch: 2; loss: 2.406588077545166; \n",
      "fold: TRAIN; iteration: 4249; epoch: 2; loss: 2.1599907875061035; \n",
      "fold: TRAIN; iteration: 4250; epoch: 2; loss: 2.398853063583374; \n",
      "fold: TRAIN; iteration: 4251; epoch: 2; loss: 2.4524459838867188; \n",
      "fold: TRAIN; iteration: 4252; epoch: 2; loss: 2.186789035797119; \n",
      "fold: TRAIN; iteration: 4253; epoch: 2; loss: 2.502607822418213; \n",
      "fold: TRAIN; iteration: 4254; epoch: 2; loss: 2.357260227203369; \n",
      "fold: TRAIN; iteration: 4255; epoch: 2; loss: 2.1951489448547363; \n",
      "fold: TRAIN; iteration: 4256; epoch: 2; loss: 2.4136507511138916; \n",
      "fold: TRAIN; iteration: 4257; epoch: 2; loss: 2.360384941101074; \n",
      "fold: TRAIN; iteration: 4258; epoch: 2; loss: 2.2358438968658447; \n",
      "fold: TRAIN; iteration: 4259; epoch: 2; loss: 2.5925118923187256; \n",
      "fold: TRAIN; iteration: 4260; epoch: 2; loss: 2.3171401023864746; \n",
      "fold: TRAIN; iteration: 4261; epoch: 2; loss: 2.4332082271575928; \n",
      "fold: TRAIN; iteration: 4262; epoch: 2; loss: 2.3279635906219482; \n",
      "fold: TRAIN; iteration: 4263; epoch: 2; loss: 2.569659471511841; \n",
      "fold: TRAIN; iteration: 4264; epoch: 2; loss: 2.3456597328186035; \n",
      "fold: TRAIN; iteration: 4265; epoch: 2; loss: 2.1267309188842773; \n",
      "fold: TRAIN; iteration: 4266; epoch: 2; loss: 2.2370574474334717; \n",
      "fold: TRAIN; iteration: 4267; epoch: 2; loss: 2.3039731979370117; \n",
      "fold: TRAIN; iteration: 4268; epoch: 2; loss: 2.1882715225219727; \n",
      "fold: TRAIN; iteration: 4269; epoch: 2; loss: 2.306941270828247; \n",
      "fold: TRAIN; iteration: 4270; epoch: 2; loss: 2.2832233905792236; \n",
      "fold: TRAIN; iteration: 4271; epoch: 2; loss: 2.522244930267334; \n",
      "fold: TRAIN; iteration: 4272; epoch: 2; loss: 2.441195487976074; \n",
      "fold: TRAIN; iteration: 4273; epoch: 2; loss: 2.5559804439544678; \n",
      "fold: TRAIN; iteration: 4274; epoch: 2; loss: 2.144817590713501; \n",
      "fold: TRAIN; iteration: 4275; epoch: 2; loss: 2.3352620601654053; \n",
      "fold: TRAIN; iteration: 4276; epoch: 2; loss: 2.2061846256256104; \n",
      "fold: TRAIN; iteration: 4277; epoch: 2; loss: 2.276745557785034; \n",
      "fold: TRAIN; iteration: 4278; epoch: 2; loss: 2.1787760257720947; \n",
      "fold: TRAIN; iteration: 4279; epoch: 2; loss: 2.306262254714966; \n",
      "fold: TRAIN; iteration: 4280; epoch: 2; loss: 2.3186635971069336; \n",
      "fold: TRAIN; iteration: 4281; epoch: 2; loss: 2.3758232593536377; \n",
      "fold: TRAIN; iteration: 4282; epoch: 2; loss: 2.377307415008545; \n",
      "fold: TRAIN; iteration: 4283; epoch: 2; loss: 2.289412021636963; \n",
      "fold: TRAIN; iteration: 4284; epoch: 2; loss: 2.2421185970306396; \n",
      "fold: TRAIN; iteration: 4285; epoch: 2; loss: 2.010448455810547; \n",
      "fold: TRAIN; iteration: 4286; epoch: 2; loss: 2.3915181159973145; \n",
      "fold: TRAIN; iteration: 4287; epoch: 2; loss: 2.315549850463867; \n",
      "fold: TRAIN; iteration: 4288; epoch: 2; loss: 2.3841359615325928; \n",
      "fold: TRAIN; iteration: 4289; epoch: 2; loss: 2.294802188873291; \n",
      "fold: TRAIN; iteration: 4290; epoch: 2; loss: 2.3481240272521973; \n",
      "fold: TRAIN; iteration: 4291; epoch: 2; loss: 2.527268171310425; \n",
      "fold: TRAIN; iteration: 4292; epoch: 2; loss: 2.31069016456604; \n",
      "fold: TRAIN; iteration: 4293; epoch: 2; loss: 2.5218992233276367; \n",
      "fold: TRAIN; iteration: 4294; epoch: 2; loss: 2.320178747177124; \n",
      "fold: TRAIN; iteration: 4295; epoch: 2; loss: 2.4252448081970215; \n",
      "fold: TRAIN; iteration: 4296; epoch: 2; loss: 2.346891403198242; \n",
      "fold: TRAIN; iteration: 4297; epoch: 2; loss: 2.385660171508789; \n",
      "fold: TRAIN; iteration: 4298; epoch: 2; loss: 2.730990409851074; \n",
      "fold: TRAIN; iteration: 4299; epoch: 2; loss: 2.126027822494507; \n",
      "fold: TRAIN; iteration: 4300; epoch: 2; loss: 2.367852210998535; \n",
      "fold: TRAIN; iteration: 4301; epoch: 2; loss: 2.5202810764312744; \n",
      "fold: TRAIN; iteration: 4302; epoch: 2; loss: 2.3088481426239014; \n",
      "fold: TRAIN; iteration: 4303; epoch: 2; loss: 2.3083090782165527; \n",
      "fold: TRAIN; iteration: 4304; epoch: 2; loss: 2.2805895805358887; \n",
      "fold: TRAIN; iteration: 4305; epoch: 2; loss: 2.378689765930176; \n",
      "fold: TRAIN; iteration: 4306; epoch: 2; loss: 2.1397085189819336; \n",
      "fold: TRAIN; iteration: 4307; epoch: 2; loss: 2.1305832862854004; \n",
      "fold: TRAIN; iteration: 4308; epoch: 2; loss: 2.193133592605591; \n",
      "fold: TRAIN; iteration: 4309; epoch: 2; loss: 2.167827844619751; \n",
      "fold: TRAIN; iteration: 4310; epoch: 2; loss: 2.116572618484497; \n",
      "fold: TRAIN; iteration: 4311; epoch: 2; loss: 2.297419786453247; \n",
      "fold: TRAIN; iteration: 4312; epoch: 2; loss: 2.139552116394043; \n",
      "fold: TRAIN; iteration: 4313; epoch: 2; loss: 2.267214298248291; \n",
      "fold: TRAIN; iteration: 4314; epoch: 2; loss: 2.7176482677459717; \n",
      "fold: TRAIN; iteration: 4315; epoch: 2; loss: 2.1630630493164062; \n",
      "fold: TRAIN; iteration: 4316; epoch: 2; loss: 2.1240906715393066; \n",
      "fold: TRAIN; iteration: 4317; epoch: 2; loss: 2.386037588119507; \n",
      "fold: TRAIN; iteration: 4318; epoch: 2; loss: 2.4223904609680176; \n",
      "fold: TRAIN; iteration: 4319; epoch: 2; loss: 2.198258399963379; \n",
      "fold: TRAIN; iteration: 4320; epoch: 2; loss: 2.418334722518921; \n",
      "fold: TRAIN; iteration: 4321; epoch: 2; loss: 2.4496185779571533; \n",
      "fold: TRAIN; iteration: 4322; epoch: 2; loss: 2.13057804107666; \n",
      "fold: TRAIN; iteration: 4323; epoch: 2; loss: 2.126373291015625; \n",
      "fold: TRAIN; iteration: 4324; epoch: 2; loss: 2.3864870071411133; \n",
      "fold: TRAIN; iteration: 4325; epoch: 2; loss: 2.084785223007202; \n",
      "fold: TRAIN; iteration: 4326; epoch: 2; loss: 2.337559223175049; \n",
      "fold: TRAIN; iteration: 4327; epoch: 2; loss: 2.0363528728485107; \n",
      "fold: TRAIN; iteration: 4328; epoch: 2; loss: 2.380246639251709; \n",
      "fold: TRAIN; iteration: 4329; epoch: 2; loss: 2.305251359939575; \n",
      "fold: TRAIN; iteration: 4330; epoch: 2; loss: 2.270163059234619; \n",
      "fold: TRAIN; iteration: 4331; epoch: 2; loss: 2.327463150024414; \n",
      "fold: TRAIN; iteration: 4332; epoch: 2; loss: 2.4730231761932373; \n",
      "fold: TRAIN; iteration: 4333; epoch: 2; loss: 2.361112356185913; \n",
      "fold: TRAIN; iteration: 4334; epoch: 2; loss: 2.376373291015625; \n",
      "fold: TRAIN; iteration: 4335; epoch: 2; loss: 2.1611664295196533; \n",
      "fold: TRAIN; iteration: 4336; epoch: 2; loss: 2.457172393798828; \n",
      "fold: TRAIN; iteration: 4337; epoch: 2; loss: 2.2707419395446777; \n",
      "fold: TRAIN; iteration: 4338; epoch: 2; loss: 2.2026474475860596; \n",
      "fold: TRAIN; iteration: 4339; epoch: 2; loss: 2.432217836380005; \n",
      "fold: TRAIN; iteration: 4340; epoch: 2; loss: 2.31722092628479; \n",
      "fold: TRAIN; iteration: 4341; epoch: 2; loss: 2.121640205383301; \n",
      "fold: TRAIN; iteration: 4342; epoch: 2; loss: 2.139643669128418; \n",
      "fold: TRAIN; iteration: 4343; epoch: 2; loss: 2.2205512523651123; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 4344; epoch: 2; loss: 2.5048575401306152; \n",
      "fold: TRAIN; iteration: 4345; epoch: 2; loss: 2.0360584259033203; \n",
      "fold: TRAIN; iteration: 4346; epoch: 2; loss: 2.3670339584350586; \n",
      "fold: TRAIN; iteration: 4347; epoch: 2; loss: 2.472322940826416; \n",
      "fold: TRAIN; iteration: 4348; epoch: 2; loss: 2.2562265396118164; \n",
      "fold: TRAIN; iteration: 4349; epoch: 2; loss: 2.300591230392456; \n",
      "fold: TRAIN; iteration: 4350; epoch: 2; loss: 2.2424662113189697; \n",
      "fold: TRAIN; iteration: 4351; epoch: 2; loss: 2.2516016960144043; \n",
      "fold: TRAIN; iteration: 4352; epoch: 2; loss: 2.3833694458007812; \n",
      "fold: TRAIN; iteration: 4353; epoch: 2; loss: 2.132946729660034; \n",
      "fold: TRAIN; iteration: 4354; epoch: 2; loss: 2.3480069637298584; \n",
      "fold: TRAIN; iteration: 4355; epoch: 2; loss: 2.297471046447754; \n",
      "fold: TRAIN; iteration: 4356; epoch: 2; loss: 2.3113744258880615; \n",
      "fold: TRAIN; iteration: 4357; epoch: 2; loss: 2.3801684379577637; \n",
      "fold: TRAIN; iteration: 4358; epoch: 2; loss: 2.220369577407837; \n",
      "fold: TRAIN; iteration: 4359; epoch: 2; loss: 2.240596294403076; \n",
      "fold: TRAIN; iteration: 4360; epoch: 2; loss: 2.3746936321258545; \n",
      "fold: TRAIN; iteration: 4361; epoch: 2; loss: 2.2530477046966553; \n",
      "fold: TRAIN; iteration: 4362; epoch: 2; loss: 2.0934112071990967; \n",
      "fold: TRAIN; iteration: 4363; epoch: 2; loss: 2.4581518173217773; \n",
      "fold: TRAIN; iteration: 4364; epoch: 2; loss: 2.434053421020508; \n",
      "fold: TRAIN; iteration: 4365; epoch: 2; loss: 2.5551302433013916; \n",
      "fold: TRAIN; iteration: 4366; epoch: 2; loss: 2.244736433029175; \n",
      "fold: TRAIN; iteration: 4367; epoch: 2; loss: 2.46856951713562; \n",
      "fold: TRAIN; iteration: 4368; epoch: 2; loss: 2.4569928646087646; \n",
      "fold: TRAIN; iteration: 4369; epoch: 2; loss: 2.2043662071228027; \n",
      "fold: TRAIN; iteration: 4370; epoch: 2; loss: 2.2456436157226562; \n",
      "fold: TRAIN; iteration: 4371; epoch: 2; loss: 2.3541312217712402; \n",
      "fold: TRAIN; iteration: 4372; epoch: 2; loss: 2.1191747188568115; \n",
      "fold: TRAIN; iteration: 4373; epoch: 2; loss: 2.345158338546753; \n",
      "fold: TRAIN; iteration: 4374; epoch: 2; loss: 2.2578771114349365; \n",
      "fold: TRAIN; iteration: 4375; epoch: 2; loss: 2.535898208618164; \n",
      "fold: TRAIN; iteration: 4376; epoch: 2; loss: 2.209559202194214; \n",
      "fold: TRAIN; iteration: 4377; epoch: 2; loss: 2.2983314990997314; \n",
      "fold: TRAIN; iteration: 4378; epoch: 2; loss: 2.3725600242614746; \n",
      "fold: TRAIN; iteration: 4379; epoch: 2; loss: 2.3306214809417725; \n",
      "fold: TRAIN; iteration: 4380; epoch: 2; loss: 2.1816623210906982; \n",
      "fold: TRAIN; iteration: 4381; epoch: 2; loss: 2.280510187149048; \n",
      "fold: TRAIN; iteration: 4382; epoch: 2; loss: 2.231593132019043; \n",
      "fold: TRAIN; iteration: 4383; epoch: 2; loss: 2.56050181388855; \n",
      "fold: TRAIN; iteration: 4384; epoch: 2; loss: 2.6024065017700195; \n",
      "fold: TRAIN; iteration: 4385; epoch: 2; loss: 2.492644786834717; \n",
      "fold: TRAIN; iteration: 4386; epoch: 2; loss: 2.399533748626709; \n",
      "fold: TRAIN; iteration: 4387; epoch: 2; loss: 2.4442408084869385; \n",
      "fold: TRAIN; iteration: 4388; epoch: 2; loss: 2.357506275177002; \n",
      "fold: TRAIN; iteration: 4389; epoch: 2; loss: 2.1769962310791016; \n",
      "fold: TRAIN; iteration: 4390; epoch: 2; loss: 2.486466884613037; \n",
      "fold: TRAIN; iteration: 4391; epoch: 2; loss: 2.2033541202545166; \n",
      "fold: TRAIN; iteration: 4392; epoch: 2; loss: 2.268834114074707; \n",
      "fold: TRAIN; iteration: 4393; epoch: 2; loss: 2.1240522861480713; \n",
      "fold: TRAIN; iteration: 4394; epoch: 2; loss: 2.1835556030273438; \n",
      "fold: TRAIN; iteration: 4395; epoch: 2; loss: 2.4765779972076416; \n",
      "fold: TRAIN; iteration: 4396; epoch: 2; loss: 2.324247360229492; \n",
      "fold: TRAIN; iteration: 4397; epoch: 2; loss: 2.3812215328216553; \n",
      "fold: TRAIN; iteration: 4398; epoch: 2; loss: 2.3661251068115234; \n",
      "fold: TRAIN; iteration: 4399; epoch: 2; loss: 2.268291711807251; \n",
      "fold: TRAIN; iteration: 4400; epoch: 2; loss: 2.0823867321014404; \n",
      "fold: TRAIN; iteration: 4401; epoch: 2; loss: 2.1941943168640137; \n",
      "fold: TRAIN; iteration: 4402; epoch: 2; loss: 2.4548583030700684; \n",
      "fold: TRAIN; iteration: 4403; epoch: 2; loss: 2.091433525085449; \n",
      "fold: TRAIN; iteration: 4404; epoch: 2; loss: 2.251159906387329; \n",
      "fold: TRAIN; iteration: 4405; epoch: 2; loss: 2.5537171363830566; \n",
      "fold: TRAIN; iteration: 4406; epoch: 2; loss: 2.1916251182556152; \n",
      "fold: TRAIN; iteration: 4407; epoch: 2; loss: 2.2796905040740967; \n",
      "fold: TRAIN; iteration: 4408; epoch: 2; loss: 2.2258172035217285; \n",
      "fold: TRAIN; iteration: 4409; epoch: 2; loss: 2.2872965335845947; \n",
      "fold: TRAIN; iteration: 4410; epoch: 2; loss: 2.329782485961914; \n",
      "fold: TRAIN; iteration: 4411; epoch: 2; loss: 2.160393476486206; \n",
      "fold: TRAIN; iteration: 4412; epoch: 2; loss: 2.4325499534606934; \n",
      "fold: TRAIN; iteration: 4413; epoch: 2; loss: 2.487889528274536; \n",
      "fold: TRAIN; iteration: 4414; epoch: 2; loss: 2.302363872528076; \n",
      "fold: TRAIN; iteration: 4415; epoch: 2; loss: 2.3976011276245117; \n",
      "fold: TRAIN; iteration: 4416; epoch: 2; loss: 2.311957359313965; \n",
      "fold: TRAIN; iteration: 4417; epoch: 2; loss: 2.2274184226989746; \n",
      "fold: TRAIN; iteration: 4418; epoch: 2; loss: 2.291905164718628; \n",
      "fold: TRAIN; iteration: 4419; epoch: 2; loss: 2.4155189990997314; \n",
      "fold: TRAIN; iteration: 4420; epoch: 2; loss: 2.224320411682129; \n",
      "fold: TRAIN; iteration: 4421; epoch: 2; loss: 2.447474956512451; \n",
      "fold: TRAIN; iteration: 4422; epoch: 2; loss: 2.4106783866882324; \n",
      "fold: TRAIN; iteration: 4423; epoch: 2; loss: 2.0867583751678467; \n",
      "fold: TRAIN; iteration: 4424; epoch: 2; loss: 2.345538854598999; \n",
      "fold: TRAIN; iteration: 4425; epoch: 2; loss: 2.250718593597412; \n",
      "fold: TRAIN; iteration: 4426; epoch: 2; loss: 2.5568084716796875; \n",
      "fold: TRAIN; iteration: 4427; epoch: 2; loss: 2.527291774749756; \n",
      "fold: TRAIN; iteration: 4428; epoch: 2; loss: 2.2713420391082764; \n",
      "fold: TRAIN; iteration: 4429; epoch: 2; loss: 2.267606496810913; \n",
      "fold: TRAIN; iteration: 4430; epoch: 2; loss: 2.4708969593048096; \n",
      "fold: TRAIN; iteration: 4431; epoch: 2; loss: 2.3487043380737305; \n",
      "fold: TRAIN; iteration: 4432; epoch: 2; loss: 2.510141372680664; \n",
      "fold: TRAIN; iteration: 4433; epoch: 2; loss: 2.502251148223877; \n",
      "fold: TRAIN; iteration: 4434; epoch: 2; loss: 2.159822940826416; \n",
      "fold: TRAIN; iteration: 4435; epoch: 2; loss: 2.3083302974700928; \n",
      "fold: TRAIN; iteration: 4436; epoch: 2; loss: 2.2879838943481445; \n",
      "fold: TRAIN; iteration: 4437; epoch: 2; loss: 2.2877120971679688; \n",
      "fold: TRAIN; iteration: 4438; epoch: 2; loss: 2.290820360183716; \n",
      "fold: TRAIN; iteration: 4439; epoch: 2; loss: 2.4330403804779053; \n",
      "fold: TRAIN; iteration: 4440; epoch: 2; loss: 2.157472610473633; \n",
      "fold: TRAIN; iteration: 4441; epoch: 2; loss: 2.098895788192749; \n",
      "fold: TRAIN; iteration: 4442; epoch: 2; loss: 2.4340202808380127; \n",
      "fold: TRAIN; iteration: 4443; epoch: 2; loss: 2.0888187885284424; \n",
      "fold: TRAIN; iteration: 4444; epoch: 2; loss: 2.2146434783935547; \n",
      "fold: TRAIN; iteration: 4445; epoch: 2; loss: 2.2297043800354004; \n",
      "fold: TRAIN; iteration: 4446; epoch: 2; loss: 2.4484570026397705; \n",
      "fold: TRAIN; iteration: 4447; epoch: 2; loss: 2.368777275085449; \n",
      "fold: TRAIN; iteration: 4448; epoch: 2; loss: 2.2506916522979736; \n",
      "fold: TRAIN; iteration: 4449; epoch: 2; loss: 2.1570358276367188; \n",
      "fold: TRAIN; iteration: 4450; epoch: 2; loss: 2.3391575813293457; \n",
      "fold: TRAIN; iteration: 4451; epoch: 2; loss: 2.3088159561157227; \n",
      "fold: TRAIN; iteration: 4452; epoch: 2; loss: 2.322918176651001; \n",
      "fold: TRAIN; iteration: 4453; epoch: 2; loss: 2.1959638595581055; \n",
      "fold: TRAIN; iteration: 4454; epoch: 2; loss: 2.382521390914917; \n",
      "fold: TRAIN; iteration: 4455; epoch: 2; loss: 2.3909387588500977; \n",
      "fold: TRAIN; iteration: 4456; epoch: 2; loss: 2.3010001182556152; \n",
      "fold: TRAIN; iteration: 4457; epoch: 2; loss: 2.3427011966705322; \n",
      "fold: TRAIN; iteration: 4458; epoch: 2; loss: 2.3321568965911865; \n",
      "fold: TRAIN; iteration: 4459; epoch: 2; loss: 2.2801320552825928; \n",
      "fold: TRAIN; iteration: 4460; epoch: 2; loss: 2.1821694374084473; \n",
      "fold: TRAIN; iteration: 4461; epoch: 2; loss: 2.1895503997802734; \n",
      "fold: TRAIN; iteration: 4462; epoch: 2; loss: 2.550835609436035; \n",
      "fold: TRAIN; iteration: 4463; epoch: 2; loss: 2.276038885116577; \n",
      "fold: TRAIN; iteration: 4464; epoch: 2; loss: 2.091207504272461; \n",
      "fold: TRAIN; iteration: 4465; epoch: 2; loss: 2.340975284576416; \n",
      "fold: TRAIN; iteration: 4466; epoch: 2; loss: 2.319082736968994; \n",
      "fold: TRAIN; iteration: 4467; epoch: 2; loss: 2.553584098815918; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 4468; epoch: 2; loss: 2.352860927581787; \n",
      "fold: TRAIN; iteration: 4469; epoch: 2; loss: 2.0925426483154297; \n",
      "fold: TRAIN; iteration: 4470; epoch: 2; loss: 2.282815933227539; \n",
      "fold: TRAIN; iteration: 4471; epoch: 2; loss: 2.3434762954711914; \n",
      "fold: TRAIN; iteration: 4472; epoch: 2; loss: 2.126650333404541; \n",
      "fold: TRAIN; iteration: 4473; epoch: 2; loss: 2.2715022563934326; \n",
      "fold: TRAIN; iteration: 4474; epoch: 2; loss: 2.5036263465881348; \n",
      "fold: TRAIN; iteration: 4475; epoch: 2; loss: 2.366729974746704; \n",
      "fold: TRAIN; iteration: 4476; epoch: 2; loss: 2.2685163021087646; \n",
      "fold: TRAIN; iteration: 4477; epoch: 2; loss: 2.393211603164673; \n",
      "fold: TRAIN; iteration: 4478; epoch: 2; loss: 2.499356269836426; \n",
      "fold: TRAIN; iteration: 4479; epoch: 2; loss: 2.509449005126953; \n",
      "fold: TRAIN; iteration: 4480; epoch: 2; loss: 2.289952516555786; \n",
      "fold: TRAIN; iteration: 4481; epoch: 2; loss: 2.3282830715179443; \n",
      "fold: TRAIN; iteration: 4482; epoch: 2; loss: 2.057835340499878; \n",
      "fold: TRAIN; iteration: 4483; epoch: 2; loss: 2.3142833709716797; \n",
      "fold: TRAIN; iteration: 4484; epoch: 2; loss: 2.252265453338623; \n",
      "fold: TRAIN; iteration: 4485; epoch: 2; loss: 2.348217248916626; \n",
      "fold: TRAIN; iteration: 4486; epoch: 2; loss: 2.451073169708252; \n",
      "fold: TRAIN; iteration: 4487; epoch: 2; loss: 2.39665150642395; \n",
      "fold: TRAIN; iteration: 4488; epoch: 2; loss: 2.2278518676757812; \n",
      "fold: TRAIN; iteration: 4489; epoch: 2; loss: 2.399940252304077; \n",
      "fold: TRAIN; iteration: 4490; epoch: 2; loss: 2.613553047180176; \n",
      "fold: TRAIN; iteration: 4491; epoch: 2; loss: 2.3365273475646973; \n",
      "fold: TRAIN; iteration: 4492; epoch: 2; loss: 2.3242976665496826; \n",
      "fold: TRAIN; iteration: 4493; epoch: 2; loss: 2.5183422565460205; \n",
      "fold: TRAIN; iteration: 4494; epoch: 2; loss: 2.2325949668884277; \n",
      "fold: TRAIN; iteration: 4495; epoch: 2; loss: 2.2552003860473633; \n",
      "fold: TRAIN; iteration: 4496; epoch: 2; loss: 2.2293567657470703; \n",
      "fold: TRAIN; iteration: 4497; epoch: 2; loss: 2.3878049850463867; \n",
      "fold: TRAIN; iteration: 4498; epoch: 2; loss: 2.200411558151245; \n",
      "fold: TRAIN; iteration: 4499; epoch: 2; loss: 2.2445812225341797; \n",
      "fold: TRAIN; iteration: 4500; epoch: 2; loss: 2.1915671825408936; \n",
      "fold: TRAIN; iteration: 4501; epoch: 2; loss: 2.3553364276885986; \n",
      "fold: TRAIN; iteration: 4502; epoch: 2; loss: 2.356208086013794; \n",
      "fold: TRAIN; iteration: 4503; epoch: 2; loss: 2.2169830799102783; \n",
      "fold: TRAIN; iteration: 4504; epoch: 2; loss: 2.460552453994751; \n",
      "fold: TRAIN; iteration: 4505; epoch: 2; loss: 2.202287435531616; \n",
      "fold: TRAIN; iteration: 4506; epoch: 2; loss: 2.2785227298736572; \n",
      "fold: TRAIN; iteration: 4507; epoch: 2; loss: 2.587782621383667; \n",
      "fold: TRAIN; iteration: 4508; epoch: 2; loss: 2.3070497512817383; \n",
      "fold: TRAIN; iteration: 4509; epoch: 2; loss: 2.162760019302368; \n",
      "fold: TRAIN; iteration: 4510; epoch: 2; loss: 2.3600993156433105; \n",
      "fold: TRAIN; iteration: 4511; epoch: 2; loss: 2.5300378799438477; \n",
      "fold: TRAIN; iteration: 4512; epoch: 2; loss: 1.868381381034851; \n",
      "fold: TRAIN; iteration: 4513; epoch: 2; loss: 2.1562204360961914; \n",
      "fold: TRAIN; iteration: 4514; epoch: 2; loss: 2.2700083255767822; \n",
      "fold: TRAIN; iteration: 4515; epoch: 2; loss: 2.3037350177764893; \n",
      "fold: TRAIN; iteration: 4516; epoch: 2; loss: 2.2645089626312256; \n",
      "fold: TRAIN; iteration: 4517; epoch: 2; loss: 2.0206689834594727; \n",
      "fold: TRAIN; iteration: 4518; epoch: 2; loss: 2.315000295639038; \n",
      "fold: TRAIN; iteration: 4519; epoch: 2; loss: 2.4582035541534424; \n",
      "fold: TRAIN; iteration: 4520; epoch: 2; loss: 2.450772762298584; \n",
      "fold: TRAIN; iteration: 4521; epoch: 2; loss: 2.3362514972686768; \n",
      "fold: TRAIN; iteration: 4522; epoch: 2; loss: 2.410492420196533; \n",
      "fold: TRAIN; iteration: 4523; epoch: 2; loss: 2.1754634380340576; \n",
      "fold: TRAIN; iteration: 4524; epoch: 2; loss: 2.2601048946380615; \n",
      "fold: TRAIN; iteration: 4525; epoch: 2; loss: 2.556734323501587; \n",
      "fold: TRAIN; iteration: 4526; epoch: 2; loss: 2.3061068058013916; \n",
      "fold: TRAIN; iteration: 4527; epoch: 2; loss: 2.4134905338287354; \n",
      "fold: TRAIN; iteration: 4528; epoch: 2; loss: 2.125432252883911; \n",
      "fold: TRAIN; iteration: 4529; epoch: 2; loss: 2.2062277793884277; \n",
      "fold: TRAIN; iteration: 4530; epoch: 2; loss: 2.22283673286438; \n",
      "fold: TRAIN; iteration: 4531; epoch: 2; loss: 2.338026523590088; \n",
      "fold: TRAIN; iteration: 4532; epoch: 2; loss: 2.3687987327575684; \n",
      "fold: TRAIN; iteration: 4533; epoch: 2; loss: 2.25578236579895; \n",
      "fold: TRAIN; iteration: 4534; epoch: 2; loss: 2.3736767768859863; \n",
      "fold: TRAIN; iteration: 4535; epoch: 2; loss: 2.181121826171875; \n",
      "fold: TRAIN; iteration: 4536; epoch: 2; loss: 2.4844584465026855; \n",
      "fold: TRAIN; iteration: 4537; epoch: 2; loss: 2.2897472381591797; \n",
      "fold: TRAIN; iteration: 4538; epoch: 2; loss: 2.3538382053375244; \n",
      "fold: TRAIN; iteration: 4539; epoch: 2; loss: 2.251145124435425; \n",
      "fold: TRAIN; iteration: 4540; epoch: 2; loss: 2.3549437522888184; \n",
      "fold: TRAIN; iteration: 4541; epoch: 2; loss: 2.343602180480957; \n",
      "fold: TRAIN; iteration: 4542; epoch: 2; loss: 2.2201130390167236; \n",
      "fold: TRAIN; iteration: 4543; epoch: 2; loss: 2.3138532638549805; \n",
      "fold: TRAIN; iteration: 4544; epoch: 2; loss: 2.5347447395324707; \n",
      "fold: TRAIN; iteration: 4545; epoch: 2; loss: 2.446969985961914; \n",
      "fold: TRAIN; iteration: 4546; epoch: 2; loss: 2.113293170928955; \n",
      "fold: TRAIN; iteration: 4547; epoch: 2; loss: 2.362497091293335; \n",
      "fold: TRAIN; iteration: 4548; epoch: 2; loss: 2.2012741565704346; \n",
      "fold: TRAIN; iteration: 4549; epoch: 2; loss: 2.0432512760162354; \n",
      "fold: TRAIN; iteration: 4550; epoch: 2; loss: 2.306083917617798; \n",
      "fold: TRAIN; iteration: 4551; epoch: 2; loss: 2.399648666381836; \n",
      "fold: TRAIN; iteration: 4552; epoch: 2; loss: 2.357689380645752; \n",
      "fold: TRAIN; iteration: 4553; epoch: 2; loss: 2.303696393966675; \n",
      "fold: TRAIN; iteration: 4554; epoch: 2; loss: 2.3456482887268066; \n",
      "fold: TRAIN; iteration: 4555; epoch: 2; loss: 2.298793077468872; \n",
      "fold: TRAIN; iteration: 4556; epoch: 2; loss: 2.492475986480713; \n",
      "fold: TRAIN; iteration: 4557; epoch: 2; loss: 2.2644119262695312; \n",
      "fold: TRAIN; iteration: 4558; epoch: 2; loss: 2.397202968597412; \n",
      "fold: TRAIN; iteration: 4559; epoch: 2; loss: 2.4585933685302734; \n",
      "fold: TRAIN; iteration: 4560; epoch: 2; loss: 2.3151845932006836; \n",
      "fold: TRAIN; iteration: 4561; epoch: 2; loss: 2.145106554031372; \n",
      "fold: TRAIN; iteration: 4562; epoch: 2; loss: 2.4302215576171875; \n",
      "fold: TRAIN; iteration: 4563; epoch: 2; loss: 2.173008918762207; \n",
      "fold: TRAIN; iteration: 4564; epoch: 2; loss: 2.1260483264923096; \n",
      "fold: TRAIN; iteration: 4565; epoch: 2; loss: 2.4067163467407227; \n",
      "fold: TRAIN; iteration: 4566; epoch: 2; loss: 2.4031243324279785; \n",
      "fold: TRAIN; iteration: 4567; epoch: 2; loss: 2.2827720642089844; \n",
      "fold: TRAIN; iteration: 4568; epoch: 2; loss: 2.2694127559661865; \n",
      "fold: TRAIN; iteration: 4569; epoch: 2; loss: 2.202803373336792; \n",
      "fold: TRAIN; iteration: 4570; epoch: 2; loss: 2.364093065261841; \n",
      "fold: TRAIN; iteration: 4571; epoch: 2; loss: 2.255077600479126; \n",
      "fold: TRAIN; iteration: 4572; epoch: 2; loss: 2.1373724937438965; \n",
      "fold: TRAIN; iteration: 4573; epoch: 2; loss: 2.307420015335083; \n",
      "fold: TRAIN; iteration: 4574; epoch: 2; loss: 2.305840253829956; \n",
      "fold: TRAIN; iteration: 4575; epoch: 2; loss: 2.3212029933929443; \n",
      "fold: TRAIN; iteration: 4576; epoch: 2; loss: 2.3096494674682617; \n",
      "fold: TRAIN; iteration: 4577; epoch: 2; loss: 2.1147773265838623; \n",
      "fold: TRAIN; iteration: 4578; epoch: 2; loss: 2.1635916233062744; \n",
      "fold: TRAIN; iteration: 4579; epoch: 2; loss: 2.368786096572876; \n",
      "fold: TRAIN; iteration: 4580; epoch: 2; loss: 2.249943971633911; \n",
      "fold: TRAIN; iteration: 4581; epoch: 2; loss: 2.1927528381347656; \n",
      "fold: TRAIN; iteration: 4582; epoch: 2; loss: 2.3671681880950928; \n",
      "fold: TRAIN; iteration: 4583; epoch: 2; loss: 2.276717185974121; \n",
      "fold: TRAIN; iteration: 4584; epoch: 2; loss: 2.1828505992889404; \n",
      "fold: TRAIN; iteration: 4585; epoch: 2; loss: 2.1001195907592773; \n",
      "fold: TRAIN; iteration: 4586; epoch: 2; loss: 2.5577456951141357; \n",
      "fold: TRAIN; iteration: 4587; epoch: 2; loss: 1.9255610704421997; \n",
      "fold: TRAIN; iteration: 4588; epoch: 2; loss: 2.3443145751953125; \n",
      "fold: TRAIN; iteration: 4589; epoch: 2; loss: 2.3009886741638184; \n",
      "fold: TRAIN; iteration: 4590; epoch: 2; loss: 2.186615228652954; \n",
      "fold: TRAIN; iteration: 4591; epoch: 2; loss: 2.5342743396759033; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 4592; epoch: 2; loss: 2.354154586791992; \n",
      "fold: TRAIN; iteration: 4593; epoch: 2; loss: 2.4365670680999756; \n",
      "fold: TRAIN; iteration: 4594; epoch: 2; loss: 2.447401285171509; \n",
      "fold: TRAIN; iteration: 4595; epoch: 2; loss: 1.995021939277649; \n",
      "fold: TRAIN; iteration: 4596; epoch: 2; loss: 2.3553082942962646; \n",
      "fold: TRAIN; iteration: 4597; epoch: 2; loss: 2.0885465145111084; \n",
      "fold: TRAIN; iteration: 4598; epoch: 2; loss: 2.3672449588775635; \n",
      "fold: TRAIN; iteration: 4599; epoch: 2; loss: 2.2814829349517822; \n",
      "fold: TRAIN; iteration: 4600; epoch: 2; loss: 2.2744157314300537; \n",
      "fold: TRAIN; iteration: 4601; epoch: 2; loss: 2.3832623958587646; \n",
      "fold: TRAIN; iteration: 4602; epoch: 2; loss: 2.4733572006225586; \n",
      "fold: TRAIN; iteration: 4603; epoch: 2; loss: 2.5019516944885254; \n",
      "fold: TRAIN; iteration: 4604; epoch: 2; loss: 2.227966070175171; \n",
      "fold: TRAIN; iteration: 4605; epoch: 2; loss: 2.4027762413024902; \n",
      "fold: TRAIN; iteration: 4606; epoch: 2; loss: 2.1453940868377686; \n",
      "fold: TRAIN; iteration: 4607; epoch: 2; loss: 2.3108208179473877; \n",
      "fold: TRAIN; iteration: 4608; epoch: 2; loss: 2.219545602798462; \n",
      "fold: TRAIN; iteration: 4609; epoch: 2; loss: 2.0766141414642334; \n",
      "fold: TRAIN; iteration: 4610; epoch: 2; loss: 2.4354636669158936; \n",
      "fold: TRAIN; iteration: 4611; epoch: 2; loss: 2.1719813346862793; \n",
      "fold: TRAIN; iteration: 4612; epoch: 2; loss: 2.2069764137268066; \n",
      "fold: TRAIN; iteration: 4613; epoch: 2; loss: 2.2625925540924072; \n",
      "fold: TRAIN; iteration: 4614; epoch: 2; loss: 2.482110023498535; \n",
      "fold: TRAIN; iteration: 4615; epoch: 2; loss: 2.355471611022949; \n",
      "fold: TRAIN; iteration: 4616; epoch: 2; loss: 2.244434356689453; \n",
      "fold: TRAIN; iteration: 4617; epoch: 2; loss: 2.0473477840423584; \n",
      "fold: TRAIN; iteration: 4618; epoch: 2; loss: 2.2233622074127197; \n",
      "fold: TRAIN; iteration: 4619; epoch: 2; loss: 2.2583839893341064; \n",
      "fold: TRAIN; iteration: 4620; epoch: 2; loss: 2.2858824729919434; \n",
      "fold: TRAIN; iteration: 4621; epoch: 2; loss: 2.273115634918213; \n",
      "fold: TRAIN; iteration: 4622; epoch: 2; loss: 2.231193780899048; \n",
      "fold: TRAIN; iteration: 4623; epoch: 2; loss: 2.254132032394409; \n",
      "fold: TRAIN; iteration: 4624; epoch: 2; loss: 2.367577314376831; \n",
      "fold: TRAIN; iteration: 4625; epoch: 2; loss: 2.4155890941619873; \n",
      "fold: TRAIN; iteration: 4626; epoch: 2; loss: 2.562760353088379; \n",
      "fold: TRAIN; iteration: 4627; epoch: 2; loss: 2.315143346786499; \n",
      "fold: TRAIN; iteration: 4628; epoch: 2; loss: 2.2411746978759766; \n",
      "fold: TRAIN; iteration: 4629; epoch: 2; loss: 2.292785882949829; \n",
      "fold: TRAIN; iteration: 4630; epoch: 2; loss: 2.198474168777466; \n",
      "fold: TRAIN; iteration: 4631; epoch: 2; loss: 2.1797573566436768; \n",
      "fold: TRAIN; iteration: 4632; epoch: 2; loss: 2.592226505279541; \n",
      "fold: TRAIN; iteration: 4633; epoch: 2; loss: 2.111419439315796; \n",
      "fold: TRAIN; iteration: 4634; epoch: 2; loss: 2.2691142559051514; \n",
      "fold: TRAIN; iteration: 4635; epoch: 2; loss: 2.3111913204193115; \n",
      "fold: TRAIN; iteration: 4636; epoch: 2; loss: 2.5768134593963623; \n",
      "fold: TRAIN; iteration: 4637; epoch: 2; loss: 2.3410441875457764; \n",
      "fold: TRAIN; iteration: 4638; epoch: 2; loss: 2.1096744537353516; \n",
      "fold: TRAIN; iteration: 4639; epoch: 2; loss: 2.3272855281829834; \n",
      "fold: TRAIN; iteration: 4640; epoch: 2; loss: 2.3118462562561035; \n",
      "fold: TRAIN; iteration: 4641; epoch: 2; loss: 2.482954502105713; \n",
      "fold: TRAIN; iteration: 4642; epoch: 2; loss: 2.3977479934692383; \n",
      "fold: TRAIN; iteration: 4643; epoch: 2; loss: 2.505204677581787; \n",
      "fold: TRAIN; iteration: 4644; epoch: 2; loss: 2.2419707775115967; \n",
      "fold: TRAIN; iteration: 4645; epoch: 2; loss: 2.3417556285858154; \n",
      "fold: TRAIN; iteration: 4646; epoch: 2; loss: 2.352654218673706; \n",
      "fold: TRAIN; iteration: 4647; epoch: 2; loss: 2.5130927562713623; \n",
      "fold: TRAIN; iteration: 4648; epoch: 2; loss: 2.3799092769622803; \n",
      "fold: TRAIN; iteration: 4649; epoch: 2; loss: 2.2115001678466797; \n",
      "fold: TRAIN; iteration: 4650; epoch: 2; loss: 2.381260633468628; \n",
      "fold: TRAIN; iteration: 4651; epoch: 2; loss: 2.3866591453552246; \n",
      "fold: TRAIN; iteration: 4652; epoch: 2; loss: 2.2097177505493164; \n",
      "fold: TRAIN; iteration: 4653; epoch: 2; loss: 2.1803112030029297; \n",
      "fold: TRAIN; iteration: 4654; epoch: 2; loss: 2.237962007522583; \n",
      "fold: TRAIN; iteration: 4655; epoch: 2; loss: 2.107168436050415; \n",
      "fold: TRAIN; iteration: 4656; epoch: 2; loss: 2.2938649654388428; \n",
      "fold: TRAIN; iteration: 4657; epoch: 2; loss: 2.364396095275879; \n",
      "fold: TRAIN; iteration: 4658; epoch: 2; loss: 2.369647264480591; \n",
      "fold: TRAIN; iteration: 4659; epoch: 2; loss: 2.4224319458007812; \n",
      "fold: TRAIN; iteration: 4660; epoch: 2; loss: 2.407015800476074; \n",
      "fold: TRAIN; iteration: 4661; epoch: 2; loss: 2.1790781021118164; \n",
      "fold: TRAIN; iteration: 4662; epoch: 2; loss: 2.11405086517334; \n",
      "fold: TRAIN; iteration: 4663; epoch: 2; loss: 2.2153964042663574; \n",
      "fold: TRAIN; iteration: 4664; epoch: 2; loss: 2.3951194286346436; \n",
      "fold: TRAIN; iteration: 4665; epoch: 2; loss: 2.3578803539276123; \n",
      "fold: TRAIN; iteration: 4666; epoch: 2; loss: 2.1942074298858643; \n",
      "fold: TRAIN; iteration: 4667; epoch: 2; loss: 2.297899007797241; \n",
      "fold: TRAIN; iteration: 4668; epoch: 2; loss: 2.108243227005005; \n",
      "fold: TRAIN; iteration: 4669; epoch: 2; loss: 2.1043293476104736; \n",
      "fold: TRAIN; iteration: 4670; epoch: 2; loss: 2.2147388458251953; \n",
      "fold: TRAIN; iteration: 4671; epoch: 2; loss: 2.463435649871826; \n",
      "fold: TRAIN; iteration: 4672; epoch: 2; loss: 2.281198024749756; \n",
      "fold: TRAIN; iteration: 4673; epoch: 2; loss: 2.152500629425049; \n",
      "fold: TRAIN; iteration: 4674; epoch: 2; loss: 2.4547512531280518; \n",
      "fold: TRAIN; iteration: 4675; epoch: 2; loss: 2.4087610244750977; \n",
      "fold: TRAIN; iteration: 4676; epoch: 2; loss: 2.535508394241333; \n",
      "fold: TRAIN; iteration: 4677; epoch: 2; loss: 2.3485796451568604; \n",
      "fold: TRAIN; iteration: 4678; epoch: 2; loss: 2.1286404132843018; \n",
      "fold: TRAIN; iteration: 4679; epoch: 2; loss: 2.167522668838501; \n",
      "fold: TRAIN; iteration: 4680; epoch: 2; loss: 2.550102472305298; \n",
      "fold: TRAIN; iteration: 4681; epoch: 2; loss: 1.9397920370101929; \n",
      "fold: TRAIN; iteration: 4682; epoch: 2; loss: 2.155778408050537; \n",
      "fold: TRAIN; iteration: 4683; epoch: 2; loss: 2.298051595687866; \n",
      "fold: TRAIN; iteration: 4684; epoch: 2; loss: 2.067486524581909; \n",
      "fold: TRAIN; iteration: 4685; epoch: 2; loss: 2.4907753467559814; \n",
      "fold: TRAIN; iteration: 4686; epoch: 2; loss: 2.455331802368164; \n",
      "fold: TRAIN; iteration: 4687; epoch: 2; loss: 2.0467007160186768; \n",
      "fold: TRAIN; iteration: 4688; epoch: 2; loss: 2.3577709197998047; \n",
      "fold: TRAIN; iteration: 4689; epoch: 2; loss: 1.983189582824707; \n",
      "fold: TRAIN; iteration: 4690; epoch: 2; loss: 2.32767915725708; \n",
      "fold: TRAIN; iteration: 4691; epoch: 2; loss: 2.292503595352173; \n",
      "fold: TRAIN; iteration: 4692; epoch: 2; loss: 2.317437171936035; \n",
      "fold: TRAIN; iteration: 4693; epoch: 2; loss: 2.3202102184295654; \n",
      "fold: TRAIN; iteration: 4694; epoch: 2; loss: 2.2892887592315674; \n",
      "fold: TRAIN; iteration: 4695; epoch: 2; loss: 2.259089946746826; \n",
      "fold: TRAIN; iteration: 4696; epoch: 2; loss: 2.1854066848754883; \n",
      "fold: TRAIN; iteration: 4697; epoch: 2; loss: 2.3558449745178223; \n",
      "fold: TRAIN; iteration: 4698; epoch: 2; loss: 2.3332455158233643; \n",
      "fold: TRAIN; iteration: 4699; epoch: 2; loss: 2.738208055496216; \n",
      "fold: TRAIN; iteration: 4700; epoch: 2; loss: 2.173311710357666; \n",
      "fold: TRAIN; iteration: 4701; epoch: 2; loss: 2.128138542175293; \n",
      "fold: TRAIN; iteration: 4702; epoch: 2; loss: 2.1477909088134766; \n",
      "fold: TRAIN; iteration: 4703; epoch: 2; loss: 2.3340413570404053; \n",
      "fold: TRAIN; iteration: 4704; epoch: 2; loss: 2.431868076324463; \n",
      "fold: TRAIN; iteration: 4705; epoch: 2; loss: 2.399251937866211; \n",
      "fold: TRAIN; iteration: 4706; epoch: 2; loss: 2.2428956031799316; \n",
      "fold: TRAIN; iteration: 4707; epoch: 2; loss: 2.3665430545806885; \n",
      "fold: TRAIN; iteration: 4708; epoch: 2; loss: 2.3875136375427246; \n",
      "fold: TRAIN; iteration: 4709; epoch: 2; loss: 2.5297462940216064; \n",
      "fold: TRAIN; iteration: 4710; epoch: 2; loss: 2.2495009899139404; \n",
      "fold: TRAIN; iteration: 4711; epoch: 2; loss: 2.2799699306488037; \n",
      "fold: TRAIN; iteration: 4712; epoch: 2; loss: 2.3507888317108154; \n",
      "fold: TRAIN; iteration: 4713; epoch: 2; loss: 2.380694627761841; \n",
      "fold: TRAIN; iteration: 4714; epoch: 2; loss: 2.3363869190216064; \n",
      "fold: TRAIN; iteration: 4715; epoch: 2; loss: 2.0717806816101074; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 4716; epoch: 3; loss: 2.2308833599090576; \n",
      "fold: TRAIN; iteration: 4717; epoch: 3; loss: 2.093364953994751; \n",
      "fold: TRAIN; iteration: 4718; epoch: 3; loss: 2.2315328121185303; \n",
      "fold: TRAIN; iteration: 4719; epoch: 3; loss: 2.150278091430664; \n",
      "fold: TRAIN; iteration: 4720; epoch: 3; loss: 2.316976308822632; \n",
      "fold: TRAIN; iteration: 4721; epoch: 3; loss: 2.4137773513793945; \n",
      "fold: TRAIN; iteration: 4722; epoch: 3; loss: 2.2995874881744385; \n",
      "fold: TRAIN; iteration: 4723; epoch: 3; loss: 2.232205390930176; \n",
      "fold: TRAIN; iteration: 4724; epoch: 3; loss: 2.474453926086426; \n",
      "fold: TRAIN; iteration: 4725; epoch: 3; loss: 2.1124813556671143; \n",
      "fold: TRAIN; iteration: 4726; epoch: 3; loss: 2.402430772781372; \n",
      "fold: TRAIN; iteration: 4727; epoch: 3; loss: 2.2117347717285156; \n",
      "fold: TRAIN; iteration: 4728; epoch: 3; loss: 2.398481845855713; \n",
      "fold: TRAIN; iteration: 4729; epoch: 3; loss: 2.0480098724365234; \n",
      "fold: TRAIN; iteration: 4730; epoch: 3; loss: 2.1864893436431885; \n",
      "fold: TRAIN; iteration: 4731; epoch: 3; loss: 2.21610951423645; \n",
      "fold: TRAIN; iteration: 4732; epoch: 3; loss: 2.191444158554077; \n",
      "fold: TRAIN; iteration: 4733; epoch: 3; loss: 2.0862274169921875; \n",
      "fold: TRAIN; iteration: 4734; epoch: 3; loss: 2.376565456390381; \n",
      "fold: TRAIN; iteration: 4735; epoch: 3; loss: 2.322740077972412; \n",
      "fold: TRAIN; iteration: 4736; epoch: 3; loss: 2.3110928535461426; \n",
      "fold: TRAIN; iteration: 4737; epoch: 3; loss: 2.137025833129883; \n",
      "fold: TRAIN; iteration: 4738; epoch: 3; loss: 2.332550287246704; \n",
      "fold: TRAIN; iteration: 4739; epoch: 3; loss: 2.2843406200408936; \n",
      "fold: TRAIN; iteration: 4740; epoch: 3; loss: 2.238621711730957; \n",
      "fold: TRAIN; iteration: 4741; epoch: 3; loss: 2.22302508354187; \n",
      "fold: TRAIN; iteration: 4742; epoch: 3; loss: 2.379487991333008; \n",
      "fold: TRAIN; iteration: 4743; epoch: 3; loss: 2.214935064315796; \n",
      "fold: TRAIN; iteration: 4744; epoch: 3; loss: 2.2032010555267334; \n",
      "fold: TRAIN; iteration: 4745; epoch: 3; loss: 2.353729724884033; \n",
      "fold: TRAIN; iteration: 4746; epoch: 3; loss: 2.1272575855255127; \n",
      "fold: TRAIN; iteration: 4747; epoch: 3; loss: 2.2927162647247314; \n",
      "fold: TRAIN; iteration: 4748; epoch: 3; loss: 2.271512031555176; \n",
      "fold: TRAIN; iteration: 4749; epoch: 3; loss: 2.331631660461426; \n",
      "fold: TRAIN; iteration: 4750; epoch: 3; loss: 2.157212018966675; \n",
      "fold: TRAIN; iteration: 4751; epoch: 3; loss: 2.248995780944824; \n",
      "fold: TRAIN; iteration: 4752; epoch: 3; loss: 2.3747503757476807; \n",
      "fold: TRAIN; iteration: 4753; epoch: 3; loss: 2.2294321060180664; \n",
      "fold: TRAIN; iteration: 4754; epoch: 3; loss: 2.3097589015960693; \n",
      "fold: TRAIN; iteration: 4755; epoch: 3; loss: 2.179807662963867; \n",
      "fold: TRAIN; iteration: 4756; epoch: 3; loss: 2.2391533851623535; \n",
      "fold: TRAIN; iteration: 4757; epoch: 3; loss: 2.0431299209594727; \n",
      "fold: TRAIN; iteration: 4758; epoch: 3; loss: 2.2794952392578125; \n",
      "fold: TRAIN; iteration: 4759; epoch: 3; loss: 2.2292120456695557; \n",
      "fold: TRAIN; iteration: 4760; epoch: 3; loss: 2.196951389312744; \n",
      "fold: TRAIN; iteration: 4761; epoch: 3; loss: 2.2974460124969482; \n",
      "fold: TRAIN; iteration: 4762; epoch: 3; loss: 2.1699399948120117; \n",
      "fold: TRAIN; iteration: 4763; epoch: 3; loss: 2.4357755184173584; \n",
      "fold: TRAIN; iteration: 4764; epoch: 3; loss: 2.0177414417266846; \n",
      "fold: TRAIN; iteration: 4765; epoch: 3; loss: 2.2802412509918213; \n",
      "fold: TRAIN; iteration: 4766; epoch: 3; loss: 2.322108745574951; \n",
      "fold: TRAIN; iteration: 4767; epoch: 3; loss: 2.3665952682495117; \n",
      "fold: TRAIN; iteration: 4768; epoch: 3; loss: 2.079765796661377; \n",
      "fold: TRAIN; iteration: 4769; epoch: 3; loss: 2.2580153942108154; \n",
      "fold: TRAIN; iteration: 4770; epoch: 3; loss: 2.2244765758514404; \n",
      "fold: TRAIN; iteration: 4771; epoch: 3; loss: 2.292975902557373; \n",
      "fold: TRAIN; iteration: 4772; epoch: 3; loss: 2.524205446243286; \n",
      "fold: TRAIN; iteration: 4773; epoch: 3; loss: 2.323714017868042; \n",
      "fold: TRAIN; iteration: 4774; epoch: 3; loss: 2.215085983276367; \n",
      "fold: TRAIN; iteration: 4775; epoch: 3; loss: 2.5085413455963135; \n",
      "fold: TRAIN; iteration: 4776; epoch: 3; loss: 2.2566018104553223; \n",
      "fold: TRAIN; iteration: 4777; epoch: 3; loss: 2.5279793739318848; \n",
      "fold: TRAIN; iteration: 4778; epoch: 3; loss: 2.336207151412964; \n",
      "fold: TRAIN; iteration: 4779; epoch: 3; loss: 2.190664768218994; \n",
      "fold: TRAIN; iteration: 4780; epoch: 3; loss: 2.2512588500976562; \n",
      "fold: TRAIN; iteration: 4781; epoch: 3; loss: 2.3228979110717773; \n",
      "fold: TRAIN; iteration: 4782; epoch: 3; loss: 2.3680505752563477; \n",
      "fold: TRAIN; iteration: 4783; epoch: 3; loss: 2.387962579727173; \n",
      "fold: TRAIN; iteration: 4784; epoch: 3; loss: 2.1372671127319336; \n",
      "fold: TRAIN; iteration: 4785; epoch: 3; loss: 2.192985773086548; \n",
      "fold: TRAIN; iteration: 4786; epoch: 3; loss: 2.216174602508545; \n",
      "fold: TRAIN; iteration: 4787; epoch: 3; loss: 2.169771671295166; \n",
      "fold: TRAIN; iteration: 4788; epoch: 3; loss: 2.5084760189056396; \n",
      "fold: TRAIN; iteration: 4789; epoch: 3; loss: 2.13352108001709; \n",
      "fold: TRAIN; iteration: 4790; epoch: 3; loss: 2.427633047103882; \n",
      "fold: TRAIN; iteration: 4791; epoch: 3; loss: 2.310988664627075; \n",
      "fold: TRAIN; iteration: 4792; epoch: 3; loss: 2.3424291610717773; \n",
      "fold: TRAIN; iteration: 4793; epoch: 3; loss: 2.1611030101776123; \n",
      "fold: TRAIN; iteration: 4794; epoch: 3; loss: 2.507513999938965; \n",
      "fold: TRAIN; iteration: 4795; epoch: 3; loss: 2.224785089492798; \n",
      "fold: TRAIN; iteration: 4796; epoch: 3; loss: 2.1314938068389893; \n",
      "fold: TRAIN; iteration: 4797; epoch: 3; loss: 2.212857723236084; \n",
      "fold: TRAIN; iteration: 4798; epoch: 3; loss: 2.1057262420654297; \n",
      "fold: TRAIN; iteration: 4799; epoch: 3; loss: 2.1340842247009277; \n",
      "fold: TRAIN; iteration: 4800; epoch: 3; loss: 2.294867753982544; \n",
      "fold: TRAIN; iteration: 4801; epoch: 3; loss: 2.327859401702881; \n",
      "fold: TRAIN; iteration: 4802; epoch: 3; loss: 2.316257953643799; \n",
      "fold: TRAIN; iteration: 4803; epoch: 3; loss: 2.1829833984375; \n",
      "fold: TRAIN; iteration: 4804; epoch: 3; loss: 2.2690212726593018; \n",
      "fold: TRAIN; iteration: 4805; epoch: 3; loss: 2.2514710426330566; \n",
      "fold: TRAIN; iteration: 4806; epoch: 3; loss: 2.1920371055603027; \n",
      "fold: TRAIN; iteration: 4807; epoch: 3; loss: 1.907019019126892; \n",
      "fold: TRAIN; iteration: 4808; epoch: 3; loss: 2.162527084350586; \n",
      "fold: TRAIN; iteration: 4809; epoch: 3; loss: 2.282449245452881; \n",
      "fold: TRAIN; iteration: 4810; epoch: 3; loss: 2.0941245555877686; \n",
      "fold: TRAIN; iteration: 4811; epoch: 3; loss: 2.083519220352173; \n",
      "fold: TRAIN; iteration: 4812; epoch: 3; loss: 2.127943754196167; \n",
      "fold: TRAIN; iteration: 4813; epoch: 3; loss: 2.386627435684204; \n",
      "fold: TRAIN; iteration: 4814; epoch: 3; loss: 2.017123222351074; \n",
      "fold: TRAIN; iteration: 4815; epoch: 3; loss: 2.123866319656372; \n",
      "fold: TRAIN; iteration: 4816; epoch: 3; loss: 2.158186435699463; \n",
      "fold: TRAIN; iteration: 4817; epoch: 3; loss: 2.1196541786193848; \n",
      "fold: TRAIN; iteration: 4818; epoch: 3; loss: 1.9825080633163452; \n",
      "fold: TRAIN; iteration: 4819; epoch: 3; loss: 2.440183162689209; \n",
      "fold: TRAIN; iteration: 4820; epoch: 3; loss: 2.427773952484131; \n",
      "fold: TRAIN; iteration: 4821; epoch: 3; loss: 2.316344738006592; \n",
      "fold: TRAIN; iteration: 4822; epoch: 3; loss: 2.0804190635681152; \n",
      "fold: TRAIN; iteration: 4823; epoch: 3; loss: 2.2519800662994385; \n",
      "fold: TRAIN; iteration: 4824; epoch: 3; loss: 2.3229176998138428; \n",
      "fold: TRAIN; iteration: 4825; epoch: 3; loss: 2.4001970291137695; \n",
      "fold: TRAIN; iteration: 4826; epoch: 3; loss: 2.1479218006134033; \n",
      "fold: TRAIN; iteration: 4827; epoch: 3; loss: 2.060293436050415; \n",
      "fold: TRAIN; iteration: 4828; epoch: 3; loss: 2.336836338043213; \n",
      "fold: TRAIN; iteration: 4829; epoch: 3; loss: 2.1357204914093018; \n",
      "fold: TRAIN; iteration: 4830; epoch: 3; loss: 2.3767426013946533; \n",
      "fold: TRAIN; iteration: 4831; epoch: 3; loss: 2.109246015548706; \n",
      "fold: TRAIN; iteration: 4832; epoch: 3; loss: 2.2115824222564697; \n",
      "fold: TRAIN; iteration: 4833; epoch: 3; loss: 1.9902740716934204; \n",
      "fold: TRAIN; iteration: 4834; epoch: 3; loss: 2.104691743850708; \n",
      "fold: TRAIN; iteration: 4835; epoch: 3; loss: 2.4553451538085938; \n",
      "fold: TRAIN; iteration: 4836; epoch: 3; loss: 2.563312292098999; \n",
      "fold: TRAIN; iteration: 4837; epoch: 3; loss: 2.4350075721740723; \n",
      "fold: TRAIN; iteration: 4838; epoch: 3; loss: 2.2296578884124756; \n",
      "fold: TRAIN; iteration: 4839; epoch: 3; loss: 2.259810209274292; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 4840; epoch: 3; loss: 2.3593873977661133; \n",
      "fold: TRAIN; iteration: 4841; epoch: 3; loss: 2.058021068572998; \n",
      "fold: TRAIN; iteration: 4842; epoch: 3; loss: 2.196720600128174; \n",
      "fold: TRAIN; iteration: 4843; epoch: 3; loss: 2.3180832862854004; \n",
      "fold: TRAIN; iteration: 4844; epoch: 3; loss: 2.320814609527588; \n",
      "fold: TRAIN; iteration: 4845; epoch: 3; loss: 2.3287293910980225; \n",
      "fold: TRAIN; iteration: 4846; epoch: 3; loss: 2.421903133392334; \n",
      "fold: TRAIN; iteration: 4847; epoch: 3; loss: 2.4095516204833984; \n",
      "fold: TRAIN; iteration: 4848; epoch: 3; loss: 2.2260313034057617; \n",
      "fold: TRAIN; iteration: 4849; epoch: 3; loss: 2.3337180614471436; \n",
      "fold: TRAIN; iteration: 4850; epoch: 3; loss: 2.229820489883423; \n",
      "fold: TRAIN; iteration: 4851; epoch: 3; loss: 2.2396962642669678; \n",
      "fold: TRAIN; iteration: 4852; epoch: 3; loss: 2.105031728744507; \n",
      "fold: TRAIN; iteration: 4853; epoch: 3; loss: 2.1833603382110596; \n",
      "fold: TRAIN; iteration: 4854; epoch: 3; loss: 2.3569302558898926; \n",
      "fold: TRAIN; iteration: 4855; epoch: 3; loss: 2.165846347808838; \n",
      "fold: TRAIN; iteration: 4856; epoch: 3; loss: 2.1650702953338623; \n",
      "fold: TRAIN; iteration: 4857; epoch: 3; loss: 2.212669849395752; \n",
      "fold: TRAIN; iteration: 4858; epoch: 3; loss: 2.2455217838287354; \n",
      "fold: TRAIN; iteration: 4859; epoch: 3; loss: 2.4616894721984863; \n",
      "fold: TRAIN; iteration: 4860; epoch: 3; loss: 2.341550350189209; \n",
      "fold: TRAIN; iteration: 4861; epoch: 3; loss: 2.4079480171203613; \n",
      "fold: TRAIN; iteration: 4862; epoch: 3; loss: 2.1523001194000244; \n",
      "fold: TRAIN; iteration: 4863; epoch: 3; loss: 2.0258402824401855; \n",
      "fold: TRAIN; iteration: 4864; epoch: 3; loss: 2.4318151473999023; \n",
      "fold: TRAIN; iteration: 4865; epoch: 3; loss: 2.250396728515625; \n",
      "fold: TRAIN; iteration: 4866; epoch: 3; loss: 2.1454992294311523; \n",
      "fold: TRAIN; iteration: 4867; epoch: 3; loss: 2.4385695457458496; \n",
      "fold: TRAIN; iteration: 4868; epoch: 3; loss: 2.3463053703308105; \n",
      "fold: TRAIN; iteration: 4869; epoch: 3; loss: 2.071333885192871; \n",
      "fold: TRAIN; iteration: 4870; epoch: 3; loss: 2.454699754714966; \n",
      "fold: TRAIN; iteration: 4871; epoch: 3; loss: 2.0976672172546387; \n",
      "fold: TRAIN; iteration: 4872; epoch: 3; loss: 2.1705782413482666; \n",
      "fold: TRAIN; iteration: 4873; epoch: 3; loss: 2.2056665420532227; \n",
      "fold: TRAIN; iteration: 4874; epoch: 3; loss: 2.2337892055511475; \n",
      "fold: TRAIN; iteration: 4875; epoch: 3; loss: 2.0878489017486572; \n",
      "fold: TRAIN; iteration: 4876; epoch: 3; loss: 2.022120714187622; \n",
      "fold: TRAIN; iteration: 4877; epoch: 3; loss: 2.238877296447754; \n",
      "fold: TRAIN; iteration: 4878; epoch: 3; loss: 2.3476057052612305; \n",
      "fold: TRAIN; iteration: 4879; epoch: 3; loss: 2.175989866256714; \n",
      "fold: TRAIN; iteration: 4880; epoch: 3; loss: 2.2576324939727783; \n",
      "fold: TRAIN; iteration: 4881; epoch: 3; loss: 2.1707608699798584; \n",
      "fold: TRAIN; iteration: 4882; epoch: 3; loss: 2.1876261234283447; \n",
      "fold: TRAIN; iteration: 4883; epoch: 3; loss: 2.1293303966522217; \n",
      "fold: TRAIN; iteration: 4884; epoch: 3; loss: 2.3088998794555664; \n",
      "fold: TRAIN; iteration: 4885; epoch: 3; loss: 2.1396360397338867; \n",
      "fold: TRAIN; iteration: 4886; epoch: 3; loss: 2.2097997665405273; \n",
      "fold: TRAIN; iteration: 4887; epoch: 3; loss: 2.107583999633789; \n",
      "fold: TRAIN; iteration: 4888; epoch: 3; loss: 2.49923038482666; \n",
      "fold: TRAIN; iteration: 4889; epoch: 3; loss: 2.282057046890259; \n",
      "fold: TRAIN; iteration: 4890; epoch: 3; loss: 2.2738497257232666; \n",
      "fold: TRAIN; iteration: 4891; epoch: 3; loss: 2.1476263999938965; \n",
      "fold: TRAIN; iteration: 4892; epoch: 3; loss: 2.165097236633301; \n",
      "fold: TRAIN; iteration: 4893; epoch: 3; loss: 2.2354536056518555; \n",
      "fold: TRAIN; iteration: 4894; epoch: 3; loss: 2.2211380004882812; \n",
      "fold: TRAIN; iteration: 4895; epoch: 3; loss: 2.2522597312927246; \n",
      "fold: TRAIN; iteration: 4896; epoch: 3; loss: 2.230947494506836; \n",
      "fold: TRAIN; iteration: 4897; epoch: 3; loss: 2.016026496887207; \n",
      "fold: TRAIN; iteration: 4898; epoch: 3; loss: 2.1128759384155273; \n",
      "fold: TRAIN; iteration: 4899; epoch: 3; loss: 2.315324544906616; \n",
      "fold: TRAIN; iteration: 4900; epoch: 3; loss: 2.3159492015838623; \n",
      "fold: TRAIN; iteration: 4901; epoch: 3; loss: 2.2505452632904053; \n",
      "fold: TRAIN; iteration: 4902; epoch: 3; loss: 2.0904698371887207; \n",
      "fold: TRAIN; iteration: 4903; epoch: 3; loss: 2.301612615585327; \n",
      "fold: TRAIN; iteration: 4904; epoch: 3; loss: 2.1493654251098633; \n",
      "fold: TRAIN; iteration: 4905; epoch: 3; loss: 2.2816498279571533; \n",
      "fold: TRAIN; iteration: 4906; epoch: 3; loss: 2.267122268676758; \n",
      "fold: TRAIN; iteration: 4907; epoch: 3; loss: 2.1301450729370117; \n",
      "fold: TRAIN; iteration: 4908; epoch: 3; loss: 2.182049036026001; \n",
      "fold: TRAIN; iteration: 4909; epoch: 3; loss: 2.4616992473602295; \n",
      "fold: TRAIN; iteration: 4910; epoch: 3; loss: 2.259275436401367; \n",
      "fold: TRAIN; iteration: 4911; epoch: 3; loss: 2.1835150718688965; \n",
      "fold: TRAIN; iteration: 4912; epoch: 3; loss: 2.078369379043579; \n",
      "fold: TRAIN; iteration: 4913; epoch: 3; loss: 2.0630688667297363; \n",
      "fold: TRAIN; iteration: 4914; epoch: 3; loss: 2.2446067333221436; \n",
      "fold: TRAIN; iteration: 4915; epoch: 3; loss: 2.168023109436035; \n",
      "fold: TRAIN; iteration: 4916; epoch: 3; loss: 2.254254102706909; \n",
      "fold: TRAIN; iteration: 4917; epoch: 3; loss: 2.320758581161499; \n",
      "fold: TRAIN; iteration: 4918; epoch: 3; loss: 2.306915760040283; \n",
      "fold: TRAIN; iteration: 4919; epoch: 3; loss: 2.391967535018921; \n",
      "fold: TRAIN; iteration: 4920; epoch: 3; loss: 2.196045160293579; \n",
      "fold: TRAIN; iteration: 4921; epoch: 3; loss: 2.2659096717834473; \n",
      "fold: TRAIN; iteration: 4922; epoch: 3; loss: 2.202720880508423; \n",
      "fold: TRAIN; iteration: 4923; epoch: 3; loss: 2.16762113571167; \n",
      "fold: TRAIN; iteration: 4924; epoch: 3; loss: 2.029606580734253; \n",
      "fold: TRAIN; iteration: 4925; epoch: 3; loss: 2.2314488887786865; \n",
      "fold: TRAIN; iteration: 4926; epoch: 3; loss: 2.284362554550171; \n",
      "fold: TRAIN; iteration: 4927; epoch: 3; loss: 2.3727188110351562; \n",
      "fold: TRAIN; iteration: 4928; epoch: 3; loss: 2.1582541465759277; \n",
      "fold: TRAIN; iteration: 4929; epoch: 3; loss: 2.0706288814544678; \n",
      "fold: TRAIN; iteration: 4930; epoch: 3; loss: 2.2428700923919678; \n",
      "fold: TRAIN; iteration: 4931; epoch: 3; loss: 2.0216498374938965; \n",
      "fold: TRAIN; iteration: 4932; epoch: 3; loss: 2.1508491039276123; \n",
      "fold: TRAIN; iteration: 4933; epoch: 3; loss: 2.370927333831787; \n",
      "fold: TRAIN; iteration: 4934; epoch: 3; loss: 2.3532826900482178; \n",
      "fold: TRAIN; iteration: 4935; epoch: 3; loss: 1.8988653421401978; \n",
      "fold: TRAIN; iteration: 4936; epoch: 3; loss: 2.413569450378418; \n",
      "fold: TRAIN; iteration: 4937; epoch: 3; loss: 2.157648801803589; \n",
      "fold: TRAIN; iteration: 4938; epoch: 3; loss: 2.0751068592071533; \n",
      "fold: TRAIN; iteration: 4939; epoch: 3; loss: 2.234515905380249; \n",
      "fold: TRAIN; iteration: 4940; epoch: 3; loss: 2.174940586090088; \n",
      "fold: TRAIN; iteration: 4941; epoch: 3; loss: 2.4262726306915283; \n",
      "fold: TRAIN; iteration: 4942; epoch: 3; loss: 2.20674991607666; \n",
      "fold: TRAIN; iteration: 4943; epoch: 3; loss: 2.1818041801452637; \n",
      "fold: TRAIN; iteration: 4944; epoch: 3; loss: 2.1214919090270996; \n",
      "fold: TRAIN; iteration: 4945; epoch: 3; loss: 2.0693962574005127; \n",
      "fold: TRAIN; iteration: 4946; epoch: 3; loss: 2.233625888824463; \n",
      "fold: TRAIN; iteration: 4947; epoch: 3; loss: 2.381392002105713; \n",
      "fold: TRAIN; iteration: 4948; epoch: 3; loss: 2.392063856124878; \n",
      "fold: TRAIN; iteration: 4949; epoch: 3; loss: 2.1611104011535645; \n",
      "fold: TRAIN; iteration: 4950; epoch: 3; loss: 2.083441972732544; \n",
      "fold: TRAIN; iteration: 4951; epoch: 3; loss: 2.249483585357666; \n",
      "fold: TRAIN; iteration: 4952; epoch: 3; loss: 2.4467315673828125; \n",
      "fold: TRAIN; iteration: 4953; epoch: 3; loss: 2.277902841567993; \n",
      "fold: TRAIN; iteration: 4954; epoch: 3; loss: 2.1940441131591797; \n",
      "fold: TRAIN; iteration: 4955; epoch: 3; loss: 1.999396800994873; \n",
      "fold: TRAIN; iteration: 4956; epoch: 3; loss: 2.187605619430542; \n",
      "fold: TRAIN; iteration: 4957; epoch: 3; loss: 2.320659875869751; \n",
      "fold: TRAIN; iteration: 4958; epoch: 3; loss: 2.17238712310791; \n",
      "fold: TRAIN; iteration: 4959; epoch: 3; loss: 2.302459239959717; \n",
      "fold: TRAIN; iteration: 4960; epoch: 3; loss: 2.226249933242798; \n",
      "fold: TRAIN; iteration: 4961; epoch: 3; loss: 2.27139949798584; \n",
      "fold: TRAIN; iteration: 4962; epoch: 3; loss: 2.18685245513916; \n",
      "fold: TRAIN; iteration: 4963; epoch: 3; loss: 2.095730781555176; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 4964; epoch: 3; loss: 2.1684045791625977; \n",
      "fold: TRAIN; iteration: 4965; epoch: 3; loss: 2.16280460357666; \n",
      "fold: TRAIN; iteration: 4966; epoch: 3; loss: 2.322796583175659; \n",
      "fold: TRAIN; iteration: 4967; epoch: 3; loss: 2.1229615211486816; \n",
      "fold: TRAIN; iteration: 4968; epoch: 3; loss: 2.048750877380371; \n",
      "fold: TRAIN; iteration: 4969; epoch: 3; loss: 2.1473588943481445; \n",
      "fold: TRAIN; iteration: 4970; epoch: 3; loss: 2.4118165969848633; \n",
      "fold: TRAIN; iteration: 4971; epoch: 3; loss: 2.242921829223633; \n",
      "fold: TRAIN; iteration: 4972; epoch: 3; loss: 2.4116930961608887; \n",
      "fold: TRAIN; iteration: 4973; epoch: 3; loss: 2.0478944778442383; \n",
      "fold: TRAIN; iteration: 4974; epoch: 3; loss: 2.161745548248291; \n",
      "fold: TRAIN; iteration: 4975; epoch: 3; loss: 2.2137277126312256; \n",
      "fold: TRAIN; iteration: 4976; epoch: 3; loss: 2.2155098915100098; \n",
      "fold: TRAIN; iteration: 4977; epoch: 3; loss: 2.2580041885375977; \n",
      "fold: TRAIN; iteration: 4978; epoch: 3; loss: 2.3420896530151367; \n",
      "fold: TRAIN; iteration: 4979; epoch: 3; loss: 2.429521322250366; \n",
      "fold: TRAIN; iteration: 4980; epoch: 3; loss: 2.463083267211914; \n",
      "fold: TRAIN; iteration: 4981; epoch: 3; loss: 2.3208038806915283; \n",
      "fold: TRAIN; iteration: 4982; epoch: 3; loss: 2.2611846923828125; \n",
      "fold: TRAIN; iteration: 4983; epoch: 3; loss: 2.31632399559021; \n",
      "fold: TRAIN; iteration: 4984; epoch: 3; loss: 2.416217565536499; \n",
      "fold: TRAIN; iteration: 4985; epoch: 3; loss: 2.087789535522461; \n",
      "fold: TRAIN; iteration: 4986; epoch: 3; loss: 1.9593102931976318; \n",
      "fold: TRAIN; iteration: 4987; epoch: 3; loss: 2.0376272201538086; \n",
      "fold: TRAIN; iteration: 4988; epoch: 3; loss: 2.2445428371429443; \n",
      "fold: TRAIN; iteration: 4989; epoch: 3; loss: 2.3036961555480957; \n",
      "fold: TRAIN; iteration: 4990; epoch: 3; loss: 2.2853505611419678; \n",
      "fold: TRAIN; iteration: 4991; epoch: 3; loss: 2.2331860065460205; \n",
      "fold: TRAIN; iteration: 4992; epoch: 3; loss: 2.2643747329711914; \n",
      "fold: TRAIN; iteration: 4993; epoch: 3; loss: 2.495332717895508; \n",
      "fold: TRAIN; iteration: 4994; epoch: 3; loss: 2.35288405418396; \n",
      "fold: TRAIN; iteration: 4995; epoch: 3; loss: 2.320648431777954; \n",
      "fold: TRAIN; iteration: 4996; epoch: 3; loss: 2.0939228534698486; \n",
      "fold: TRAIN; iteration: 4997; epoch: 3; loss: 2.4687600135803223; \n",
      "fold: TRAIN; iteration: 4998; epoch: 3; loss: 2.3063783645629883; \n",
      "fold: TRAIN; iteration: 4999; epoch: 3; loss: 2.1630241870880127; \n",
      "validating model...\n",
      "saving\n",
      "fold: VALID; iteration: 5000; epoch: 3; loss: 2.3495076235602883; \n",
      "fold: TRAIN; iteration: 5000; epoch: 3; loss: 2.513925075531006; \n",
      "fold: TRAIN; iteration: 5001; epoch: 3; loss: 2.3170247077941895; \n",
      "fold: TRAIN; iteration: 5002; epoch: 3; loss: 2.167576313018799; \n",
      "fold: TRAIN; iteration: 5003; epoch: 3; loss: 2.1396634578704834; \n",
      "fold: TRAIN; iteration: 5004; epoch: 3; loss: 2.136784315109253; \n",
      "fold: TRAIN; iteration: 5005; epoch: 3; loss: 2.27176570892334; \n",
      "fold: TRAIN; iteration: 5006; epoch: 3; loss: 2.3360278606414795; \n",
      "fold: TRAIN; iteration: 5007; epoch: 3; loss: 2.2939095497131348; \n",
      "fold: TRAIN; iteration: 5008; epoch: 3; loss: 2.338242292404175; \n",
      "fold: TRAIN; iteration: 5009; epoch: 3; loss: 2.367546796798706; \n",
      "fold: TRAIN; iteration: 5010; epoch: 3; loss: 2.2718937397003174; \n",
      "fold: TRAIN; iteration: 5011; epoch: 3; loss: 2.0139505863189697; \n",
      "fold: TRAIN; iteration: 5012; epoch: 3; loss: 2.0240423679351807; \n",
      "fold: TRAIN; iteration: 5013; epoch: 3; loss: 2.3699495792388916; \n",
      "fold: TRAIN; iteration: 5014; epoch: 3; loss: 2.3340141773223877; \n",
      "fold: TRAIN; iteration: 5015; epoch: 3; loss: 2.1806461811065674; \n",
      "fold: TRAIN; iteration: 5016; epoch: 3; loss: 2.2717056274414062; \n",
      "fold: TRAIN; iteration: 5017; epoch: 3; loss: 2.5029382705688477; \n",
      "fold: TRAIN; iteration: 5018; epoch: 3; loss: 2.3364880084991455; \n",
      "fold: TRAIN; iteration: 5019; epoch: 3; loss: 2.3145742416381836; \n",
      "fold: TRAIN; iteration: 5020; epoch: 3; loss: 2.0304601192474365; \n",
      "fold: TRAIN; iteration: 5021; epoch: 3; loss: 2.3015174865722656; \n",
      "fold: TRAIN; iteration: 5022; epoch: 3; loss: 2.143817663192749; \n",
      "fold: TRAIN; iteration: 5023; epoch: 3; loss: 2.0685715675354004; \n",
      "fold: TRAIN; iteration: 5024; epoch: 3; loss: 2.2242417335510254; \n",
      "fold: TRAIN; iteration: 5025; epoch: 3; loss: 2.2680420875549316; \n",
      "fold: TRAIN; iteration: 5026; epoch: 3; loss: 2.232393741607666; \n",
      "fold: TRAIN; iteration: 5027; epoch: 3; loss: 2.2296183109283447; \n",
      "fold: TRAIN; iteration: 5028; epoch: 3; loss: 2.124762773513794; \n",
      "fold: TRAIN; iteration: 5029; epoch: 3; loss: 2.2647271156311035; \n",
      "fold: TRAIN; iteration: 5030; epoch: 3; loss: 2.4246726036071777; \n",
      "fold: TRAIN; iteration: 5031; epoch: 3; loss: 2.148550510406494; \n",
      "fold: TRAIN; iteration: 5032; epoch: 3; loss: 2.362205743789673; \n",
      "fold: TRAIN; iteration: 5033; epoch: 3; loss: 2.3478147983551025; \n",
      "fold: TRAIN; iteration: 5034; epoch: 3; loss: 2.1645097732543945; \n",
      "fold: TRAIN; iteration: 5035; epoch: 3; loss: 2.0764193534851074; \n",
      "fold: TRAIN; iteration: 5036; epoch: 3; loss: 2.3225221633911133; \n",
      "fold: TRAIN; iteration: 5037; epoch: 3; loss: 2.2402424812316895; \n",
      "fold: TRAIN; iteration: 5038; epoch: 3; loss: 2.3292882442474365; \n",
      "fold: TRAIN; iteration: 5039; epoch: 3; loss: 2.328768730163574; \n",
      "fold: TRAIN; iteration: 5040; epoch: 3; loss: 2.1247713565826416; \n",
      "fold: TRAIN; iteration: 5041; epoch: 3; loss: 2.563577175140381; \n",
      "fold: TRAIN; iteration: 5042; epoch: 3; loss: 2.2796249389648438; \n",
      "fold: TRAIN; iteration: 5043; epoch: 3; loss: 2.215092658996582; \n",
      "fold: TRAIN; iteration: 5044; epoch: 3; loss: 2.1464977264404297; \n",
      "fold: TRAIN; iteration: 5045; epoch: 3; loss: 2.2501168251037598; \n",
      "fold: TRAIN; iteration: 5046; epoch: 3; loss: 2.455179214477539; \n",
      "fold: TRAIN; iteration: 5047; epoch: 3; loss: 2.023837089538574; \n",
      "fold: TRAIN; iteration: 5048; epoch: 3; loss: 2.393568754196167; \n",
      "fold: TRAIN; iteration: 5049; epoch: 3; loss: 2.143167495727539; \n",
      "fold: TRAIN; iteration: 5050; epoch: 3; loss: 2.0529625415802; \n",
      "fold: TRAIN; iteration: 5051; epoch: 3; loss: 2.41904878616333; \n",
      "fold: TRAIN; iteration: 5052; epoch: 3; loss: 2.1743052005767822; \n",
      "fold: TRAIN; iteration: 5053; epoch: 3; loss: 2.4708876609802246; \n",
      "fold: TRAIN; iteration: 5054; epoch: 3; loss: 2.124849796295166; \n",
      "fold: TRAIN; iteration: 5055; epoch: 3; loss: 2.3055195808410645; \n",
      "fold: TRAIN; iteration: 5056; epoch: 3; loss: 1.8412986993789673; \n",
      "fold: TRAIN; iteration: 5057; epoch: 3; loss: 2.506190299987793; \n",
      "fold: TRAIN; iteration: 5058; epoch: 3; loss: 2.060859441757202; \n",
      "fold: TRAIN; iteration: 5059; epoch: 3; loss: 2.35038161277771; \n",
      "fold: TRAIN; iteration: 5060; epoch: 3; loss: 2.3085739612579346; \n",
      "fold: TRAIN; iteration: 5061; epoch: 3; loss: 2.182344436645508; \n",
      "fold: TRAIN; iteration: 5062; epoch: 3; loss: 2.152594566345215; \n",
      "fold: TRAIN; iteration: 5063; epoch: 3; loss: 2.111189842224121; \n",
      "fold: TRAIN; iteration: 5064; epoch: 3; loss: 2.2473764419555664; \n",
      "fold: TRAIN; iteration: 5065; epoch: 3; loss: 2.1312355995178223; \n",
      "fold: TRAIN; iteration: 5066; epoch: 3; loss: 2.023305654525757; \n",
      "fold: TRAIN; iteration: 5067; epoch: 3; loss: 2.174990653991699; \n",
      "fold: TRAIN; iteration: 5068; epoch: 3; loss: 2.402348756790161; \n",
      "fold: TRAIN; iteration: 5069; epoch: 3; loss: 2.2383556365966797; \n",
      "fold: TRAIN; iteration: 5070; epoch: 3; loss: 2.2851526737213135; \n",
      "fold: TRAIN; iteration: 5071; epoch: 3; loss: 2.3286049365997314; \n",
      "fold: TRAIN; iteration: 5072; epoch: 3; loss: 2.2799386978149414; \n",
      "fold: TRAIN; iteration: 5073; epoch: 3; loss: 2.3113842010498047; \n",
      "fold: TRAIN; iteration: 5074; epoch: 3; loss: 2.3803811073303223; \n",
      "fold: TRAIN; iteration: 5075; epoch: 3; loss: 2.2857704162597656; \n",
      "fold: TRAIN; iteration: 5076; epoch: 3; loss: 2.261526346206665; \n",
      "fold: TRAIN; iteration: 5077; epoch: 3; loss: 2.33956241607666; \n",
      "fold: TRAIN; iteration: 5078; epoch: 3; loss: 2.352207899093628; \n",
      "fold: TRAIN; iteration: 5079; epoch: 3; loss: 2.1285147666931152; \n",
      "fold: TRAIN; iteration: 5080; epoch: 3; loss: 2.557603120803833; \n",
      "fold: TRAIN; iteration: 5081; epoch: 3; loss: 2.357085943222046; \n",
      "fold: TRAIN; iteration: 5082; epoch: 3; loss: 2.2223219871520996; \n",
      "fold: TRAIN; iteration: 5083; epoch: 3; loss: 2.402599573135376; \n",
      "fold: TRAIN; iteration: 5084; epoch: 3; loss: 2.326292037963867; \n",
      "fold: TRAIN; iteration: 5085; epoch: 3; loss: 2.1424553394317627; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 5086; epoch: 3; loss: 2.174572706222534; \n",
      "fold: TRAIN; iteration: 5087; epoch: 3; loss: 2.1135478019714355; \n",
      "fold: TRAIN; iteration: 5088; epoch: 3; loss: 2.311033248901367; \n",
      "fold: TRAIN; iteration: 5089; epoch: 3; loss: 2.3039441108703613; \n",
      "fold: TRAIN; iteration: 5090; epoch: 3; loss: 2.297203302383423; \n",
      "fold: TRAIN; iteration: 5091; epoch: 3; loss: 2.3317465782165527; \n",
      "fold: TRAIN; iteration: 5092; epoch: 3; loss: 2.1797242164611816; \n",
      "fold: TRAIN; iteration: 5093; epoch: 3; loss: 2.3144290447235107; \n",
      "fold: TRAIN; iteration: 5094; epoch: 3; loss: 2.2920730113983154; \n",
      "fold: TRAIN; iteration: 5095; epoch: 3; loss: 2.4444284439086914; \n",
      "fold: TRAIN; iteration: 5096; epoch: 3; loss: 2.3666634559631348; \n",
      "fold: TRAIN; iteration: 5097; epoch: 3; loss: 2.4668827056884766; \n",
      "fold: TRAIN; iteration: 5098; epoch: 3; loss: 2.2540242671966553; \n",
      "fold: TRAIN; iteration: 5099; epoch: 3; loss: 2.1780877113342285; \n",
      "fold: TRAIN; iteration: 5100; epoch: 3; loss: 2.2957100868225098; \n",
      "fold: TRAIN; iteration: 5101; epoch: 3; loss: 2.5351309776306152; \n",
      "fold: TRAIN; iteration: 5102; epoch: 3; loss: 2.0559346675872803; \n",
      "fold: TRAIN; iteration: 5103; epoch: 3; loss: 2.2714970111846924; \n",
      "fold: TRAIN; iteration: 5104; epoch: 3; loss: 2.247260093688965; \n",
      "fold: TRAIN; iteration: 5105; epoch: 3; loss: 2.3420841693878174; \n",
      "fold: TRAIN; iteration: 5106; epoch: 3; loss: 2.3065290451049805; \n",
      "fold: TRAIN; iteration: 5107; epoch: 3; loss: 2.328150510787964; \n",
      "fold: TRAIN; iteration: 5108; epoch: 3; loss: 2.164241075515747; \n",
      "fold: TRAIN; iteration: 5109; epoch: 3; loss: 2.3475615978240967; \n",
      "fold: TRAIN; iteration: 5110; epoch: 3; loss: 2.38456130027771; \n",
      "fold: TRAIN; iteration: 5111; epoch: 3; loss: 2.436408758163452; \n",
      "fold: TRAIN; iteration: 5112; epoch: 3; loss: 2.3170559406280518; \n",
      "fold: TRAIN; iteration: 5113; epoch: 3; loss: 2.1506187915802; \n",
      "fold: TRAIN; iteration: 5114; epoch: 3; loss: 2.04457950592041; \n",
      "fold: TRAIN; iteration: 5115; epoch: 3; loss: 2.4330098628997803; \n",
      "fold: TRAIN; iteration: 5116; epoch: 3; loss: 2.5268709659576416; \n",
      "fold: TRAIN; iteration: 5117; epoch: 3; loss: 2.092085599899292; \n",
      "fold: TRAIN; iteration: 5118; epoch: 3; loss: 2.3424911499023438; \n",
      "fold: TRAIN; iteration: 5119; epoch: 3; loss: 2.3824880123138428; \n",
      "fold: TRAIN; iteration: 5120; epoch: 3; loss: 2.0268542766571045; \n",
      "fold: TRAIN; iteration: 5121; epoch: 3; loss: 2.1807339191436768; \n",
      "fold: TRAIN; iteration: 5122; epoch: 3; loss: 2.3330118656158447; \n",
      "fold: TRAIN; iteration: 5123; epoch: 3; loss: 2.2031867504119873; \n",
      "fold: TRAIN; iteration: 5124; epoch: 3; loss: 2.3864028453826904; \n",
      "fold: TRAIN; iteration: 5125; epoch: 3; loss: 2.426090955734253; \n",
      "fold: TRAIN; iteration: 5126; epoch: 3; loss: 2.4223122596740723; \n",
      "fold: TRAIN; iteration: 5127; epoch: 3; loss: 2.429107427597046; \n",
      "fold: TRAIN; iteration: 5128; epoch: 3; loss: 2.2596991062164307; \n",
      "fold: TRAIN; iteration: 5129; epoch: 3; loss: 2.2038955688476562; \n",
      "fold: TRAIN; iteration: 5130; epoch: 3; loss: 2.15334415435791; \n",
      "fold: TRAIN; iteration: 5131; epoch: 3; loss: 2.526501417160034; \n",
      "fold: TRAIN; iteration: 5132; epoch: 3; loss: 2.2433478832244873; \n",
      "fold: TRAIN; iteration: 5133; epoch: 3; loss: 2.0402655601501465; \n",
      "fold: TRAIN; iteration: 5134; epoch: 3; loss: 2.310199022293091; \n",
      "fold: TRAIN; iteration: 5135; epoch: 3; loss: 2.444469690322876; \n",
      "fold: TRAIN; iteration: 5136; epoch: 3; loss: 2.324561595916748; \n",
      "fold: TRAIN; iteration: 5137; epoch: 3; loss: 2.3689610958099365; \n",
      "fold: TRAIN; iteration: 5138; epoch: 3; loss: 2.3089327812194824; \n",
      "fold: TRAIN; iteration: 5139; epoch: 3; loss: 2.19114089012146; \n",
      "fold: TRAIN; iteration: 5140; epoch: 3; loss: 2.304575204849243; \n",
      "fold: TRAIN; iteration: 5141; epoch: 3; loss: 2.251373529434204; \n",
      "fold: TRAIN; iteration: 5142; epoch: 3; loss: 2.2261741161346436; \n",
      "fold: TRAIN; iteration: 5143; epoch: 3; loss: 2.3555312156677246; \n",
      "fold: TRAIN; iteration: 5144; epoch: 3; loss: 2.0872647762298584; \n",
      "fold: TRAIN; iteration: 5145; epoch: 3; loss: 2.578643560409546; \n",
      "fold: TRAIN; iteration: 5146; epoch: 3; loss: 2.191147565841675; \n",
      "fold: TRAIN; iteration: 5147; epoch: 3; loss: 2.516016721725464; \n",
      "fold: TRAIN; iteration: 5148; epoch: 3; loss: 2.142960786819458; \n",
      "fold: TRAIN; iteration: 5149; epoch: 3; loss: 2.1298131942749023; \n",
      "fold: TRAIN; iteration: 5150; epoch: 3; loss: 2.111368179321289; \n",
      "fold: TRAIN; iteration: 5151; epoch: 3; loss: 2.42165470123291; \n",
      "fold: TRAIN; iteration: 5152; epoch: 3; loss: 2.1837151050567627; \n",
      "fold: TRAIN; iteration: 5153; epoch: 3; loss: 2.120582342147827; \n",
      "fold: TRAIN; iteration: 5154; epoch: 3; loss: 2.072155237197876; \n",
      "fold: TRAIN; iteration: 5155; epoch: 3; loss: 2.411839246749878; \n",
      "fold: TRAIN; iteration: 5156; epoch: 3; loss: 2.1145598888397217; \n",
      "fold: TRAIN; iteration: 5157; epoch: 3; loss: 2.266352415084839; \n",
      "fold: TRAIN; iteration: 5158; epoch: 3; loss: 2.2839932441711426; \n",
      "fold: TRAIN; iteration: 5159; epoch: 3; loss: 2.1804661750793457; \n",
      "fold: TRAIN; iteration: 5160; epoch: 3; loss: 2.2216861248016357; \n",
      "fold: TRAIN; iteration: 5161; epoch: 3; loss: 2.2745182514190674; \n",
      "fold: TRAIN; iteration: 5162; epoch: 3; loss: 2.413283586502075; \n",
      "fold: TRAIN; iteration: 5163; epoch: 3; loss: 2.311349391937256; \n",
      "fold: TRAIN; iteration: 5164; epoch: 3; loss: 2.1930017471313477; \n",
      "fold: TRAIN; iteration: 5165; epoch: 3; loss: 2.1478514671325684; \n",
      "fold: TRAIN; iteration: 5166; epoch: 3; loss: 2.265687942504883; \n",
      "fold: TRAIN; iteration: 5167; epoch: 3; loss: 2.17197322845459; \n",
      "fold: TRAIN; iteration: 5168; epoch: 3; loss: 2.2131316661834717; \n",
      "fold: TRAIN; iteration: 5169; epoch: 3; loss: 2.309730052947998; \n",
      "fold: TRAIN; iteration: 5170; epoch: 3; loss: 2.3729593753814697; \n",
      "fold: TRAIN; iteration: 5171; epoch: 3; loss: 2.389200210571289; \n",
      "fold: TRAIN; iteration: 5172; epoch: 3; loss: 2.3080244064331055; \n",
      "fold: TRAIN; iteration: 5173; epoch: 3; loss: 2.199101209640503; \n",
      "fold: TRAIN; iteration: 5174; epoch: 3; loss: 1.930280327796936; \n",
      "fold: TRAIN; iteration: 5175; epoch: 3; loss: 2.1986687183380127; \n",
      "fold: TRAIN; iteration: 5176; epoch: 3; loss: 2.217534065246582; \n",
      "fold: TRAIN; iteration: 5177; epoch: 3; loss: 2.2956981658935547; \n",
      "fold: TRAIN; iteration: 5178; epoch: 3; loss: 2.219510078430176; \n",
      "fold: TRAIN; iteration: 5179; epoch: 3; loss: 2.1639795303344727; \n",
      "fold: TRAIN; iteration: 5180; epoch: 3; loss: 2.245758056640625; \n",
      "fold: TRAIN; iteration: 5181; epoch: 3; loss: 2.2528390884399414; \n",
      "fold: TRAIN; iteration: 5182; epoch: 3; loss: 2.329599380493164; \n",
      "fold: TRAIN; iteration: 5183; epoch: 3; loss: 2.157675266265869; \n",
      "fold: TRAIN; iteration: 5184; epoch: 3; loss: 2.2887816429138184; \n",
      "fold: TRAIN; iteration: 5185; epoch: 3; loss: 2.3826704025268555; \n",
      "fold: TRAIN; iteration: 5186; epoch: 3; loss: 2.1397767066955566; \n",
      "fold: TRAIN; iteration: 5187; epoch: 3; loss: 2.199578046798706; \n",
      "fold: TRAIN; iteration: 5188; epoch: 3; loss: 2.204918384552002; \n",
      "fold: TRAIN; iteration: 5189; epoch: 3; loss: 2.189650297164917; \n",
      "fold: TRAIN; iteration: 5190; epoch: 3; loss: 2.262622594833374; \n",
      "fold: TRAIN; iteration: 5191; epoch: 3; loss: 2.298933744430542; \n",
      "fold: TRAIN; iteration: 5192; epoch: 3; loss: 2.155571222305298; \n",
      "fold: TRAIN; iteration: 5193; epoch: 3; loss: 2.4443609714508057; \n",
      "fold: TRAIN; iteration: 5194; epoch: 3; loss: 2.1593756675720215; \n",
      "fold: TRAIN; iteration: 5195; epoch: 3; loss: 2.3921561241149902; \n",
      "fold: TRAIN; iteration: 5196; epoch: 3; loss: 2.106997013092041; \n",
      "fold: TRAIN; iteration: 5197; epoch: 3; loss: 2.1780426502227783; \n",
      "fold: TRAIN; iteration: 5198; epoch: 3; loss: 1.921249508857727; \n",
      "fold: TRAIN; iteration: 5199; epoch: 3; loss: 2.3062970638275146; \n",
      "fold: TRAIN; iteration: 5200; epoch: 3; loss: 2.267279624938965; \n",
      "fold: TRAIN; iteration: 5201; epoch: 3; loss: 2.2234046459198; \n",
      "fold: TRAIN; iteration: 5202; epoch: 3; loss: 2.152509927749634; \n",
      "fold: TRAIN; iteration: 5203; epoch: 3; loss: 2.399462938308716; \n",
      "fold: TRAIN; iteration: 5204; epoch: 3; loss: 1.9821505546569824; \n",
      "fold: TRAIN; iteration: 5205; epoch: 3; loss: 2.1116559505462646; \n",
      "fold: TRAIN; iteration: 5206; epoch: 3; loss: 2.2838222980499268; \n",
      "fold: TRAIN; iteration: 5207; epoch: 3; loss: 2.3052942752838135; \n",
      "fold: TRAIN; iteration: 5208; epoch: 3; loss: 2.0793204307556152; \n",
      "fold: TRAIN; iteration: 5209; epoch: 3; loss: 2.1062424182891846; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 5210; epoch: 3; loss: 2.1599597930908203; \n",
      "fold: TRAIN; iteration: 5211; epoch: 3; loss: 2.3075335025787354; \n",
      "fold: TRAIN; iteration: 5212; epoch: 3; loss: 2.2544543743133545; \n",
      "fold: TRAIN; iteration: 5213; epoch: 3; loss: 2.1686599254608154; \n",
      "fold: TRAIN; iteration: 5214; epoch: 3; loss: 2.4153943061828613; \n",
      "fold: TRAIN; iteration: 5215; epoch: 3; loss: 2.2297403812408447; \n",
      "fold: TRAIN; iteration: 5216; epoch: 3; loss: 2.2023003101348877; \n",
      "fold: TRAIN; iteration: 5217; epoch: 3; loss: 2.292957067489624; \n",
      "fold: TRAIN; iteration: 5218; epoch: 3; loss: 2.3238980770111084; \n",
      "fold: TRAIN; iteration: 5219; epoch: 3; loss: 2.2902278900146484; \n",
      "fold: TRAIN; iteration: 5220; epoch: 3; loss: 1.9527878761291504; \n",
      "fold: TRAIN; iteration: 5221; epoch: 3; loss: 2.1740224361419678; \n",
      "fold: TRAIN; iteration: 5222; epoch: 3; loss: 2.1557271480560303; \n",
      "fold: TRAIN; iteration: 5223; epoch: 3; loss: 2.4852216243743896; \n",
      "fold: TRAIN; iteration: 5224; epoch: 3; loss: 2.241579294204712; \n",
      "fold: TRAIN; iteration: 5225; epoch: 3; loss: 2.1427841186523438; \n",
      "fold: TRAIN; iteration: 5226; epoch: 3; loss: 2.5414657592773438; \n",
      "fold: TRAIN; iteration: 5227; epoch: 3; loss: 2.224497079849243; \n",
      "fold: TRAIN; iteration: 5228; epoch: 3; loss: 1.9853219985961914; \n",
      "fold: TRAIN; iteration: 5229; epoch: 3; loss: 2.411794900894165; \n",
      "fold: TRAIN; iteration: 5230; epoch: 3; loss: 2.0780913829803467; \n",
      "fold: TRAIN; iteration: 5231; epoch: 3; loss: 2.1647789478302; \n",
      "fold: TRAIN; iteration: 5232; epoch: 3; loss: 2.319274425506592; \n",
      "fold: TRAIN; iteration: 5233; epoch: 3; loss: 2.4224367141723633; \n",
      "fold: TRAIN; iteration: 5234; epoch: 3; loss: 2.1990158557891846; \n",
      "fold: TRAIN; iteration: 5235; epoch: 3; loss: 2.325486898422241; \n",
      "fold: TRAIN; iteration: 5236; epoch: 3; loss: 2.393604040145874; \n",
      "fold: TRAIN; iteration: 5237; epoch: 3; loss: 2.2307162284851074; \n",
      "fold: TRAIN; iteration: 5238; epoch: 3; loss: 2.218087911605835; \n",
      "fold: TRAIN; iteration: 5239; epoch: 3; loss: 2.0911405086517334; \n",
      "fold: TRAIN; iteration: 5240; epoch: 3; loss: 2.132366180419922; \n",
      "fold: TRAIN; iteration: 5241; epoch: 3; loss: 2.2753052711486816; \n",
      "fold: TRAIN; iteration: 5242; epoch: 3; loss: 2.1788010597229004; \n",
      "fold: TRAIN; iteration: 5243; epoch: 3; loss: 2.3428544998168945; \n",
      "fold: TRAIN; iteration: 5244; epoch: 3; loss: 2.3111820220947266; \n",
      "fold: TRAIN; iteration: 5245; epoch: 3; loss: 2.315962791442871; \n",
      "fold: TRAIN; iteration: 5246; epoch: 3; loss: 2.304647445678711; \n",
      "fold: TRAIN; iteration: 5247; epoch: 3; loss: 2.105304479598999; \n",
      "fold: TRAIN; iteration: 5248; epoch: 3; loss: 2.351534366607666; \n",
      "fold: TRAIN; iteration: 5249; epoch: 3; loss: 2.1867518424987793; \n",
      "fold: TRAIN; iteration: 5250; epoch: 3; loss: 1.983986496925354; \n",
      "fold: TRAIN; iteration: 5251; epoch: 3; loss: 2.286665201187134; \n",
      "fold: TRAIN; iteration: 5252; epoch: 3; loss: 2.3937833309173584; \n",
      "fold: TRAIN; iteration: 5253; epoch: 3; loss: 2.427185297012329; \n",
      "fold: TRAIN; iteration: 5254; epoch: 3; loss: 2.5177621841430664; \n",
      "fold: TRAIN; iteration: 5255; epoch: 3; loss: 2.271332263946533; \n",
      "fold: TRAIN; iteration: 5256; epoch: 3; loss: 2.3790066242218018; \n",
      "fold: TRAIN; iteration: 5257; epoch: 3; loss: 2.027508020401001; \n",
      "fold: TRAIN; iteration: 5258; epoch: 3; loss: 2.198761224746704; \n",
      "fold: TRAIN; iteration: 5259; epoch: 3; loss: 2.1813833713531494; \n",
      "fold: TRAIN; iteration: 5260; epoch: 3; loss: 2.2510645389556885; \n",
      "fold: TRAIN; iteration: 5261; epoch: 3; loss: 2.0011281967163086; \n",
      "fold: TRAIN; iteration: 5262; epoch: 3; loss: 2.338040351867676; \n",
      "fold: TRAIN; iteration: 5263; epoch: 3; loss: 2.292848825454712; \n",
      "fold: TRAIN; iteration: 5264; epoch: 3; loss: 2.537435531616211; \n",
      "fold: TRAIN; iteration: 5265; epoch: 3; loss: 2.1662518978118896; \n",
      "fold: TRAIN; iteration: 5266; epoch: 3; loss: 2.306288957595825; \n",
      "fold: TRAIN; iteration: 5267; epoch: 3; loss: 2.20021915435791; \n",
      "fold: TRAIN; iteration: 5268; epoch: 3; loss: 2.1842916011810303; \n",
      "fold: TRAIN; iteration: 5269; epoch: 3; loss: 2.278380870819092; \n",
      "fold: TRAIN; iteration: 5270; epoch: 3; loss: 2.146934747695923; \n",
      "fold: TRAIN; iteration: 5271; epoch: 3; loss: 2.0505199432373047; \n",
      "fold: TRAIN; iteration: 5272; epoch: 3; loss: 2.026327610015869; \n",
      "fold: TRAIN; iteration: 5273; epoch: 3; loss: 2.2635385990142822; \n",
      "fold: TRAIN; iteration: 5274; epoch: 3; loss: 2.181262969970703; \n",
      "fold: TRAIN; iteration: 5275; epoch: 3; loss: 2.07372784614563; \n",
      "fold: TRAIN; iteration: 5276; epoch: 3; loss: 2.602620840072632; \n",
      "fold: TRAIN; iteration: 5277; epoch: 3; loss: 2.183159589767456; \n",
      "fold: TRAIN; iteration: 5278; epoch: 3; loss: 2.081820487976074; \n",
      "fold: TRAIN; iteration: 5279; epoch: 3; loss: 2.128340244293213; \n",
      "fold: TRAIN; iteration: 5280; epoch: 3; loss: 2.291804313659668; \n",
      "fold: TRAIN; iteration: 5281; epoch: 3; loss: 2.305784225463867; \n",
      "fold: TRAIN; iteration: 5282; epoch: 3; loss: 2.251307725906372; \n",
      "fold: TRAIN; iteration: 5283; epoch: 3; loss: 2.108166456222534; \n",
      "fold: TRAIN; iteration: 5284; epoch: 3; loss: 2.180183172225952; \n",
      "fold: TRAIN; iteration: 5285; epoch: 3; loss: 2.394702196121216; \n",
      "fold: TRAIN; iteration: 5286; epoch: 3; loss: 2.249075174331665; \n",
      "fold: TRAIN; iteration: 5287; epoch: 3; loss: 2.157402753829956; \n",
      "fold: TRAIN; iteration: 5288; epoch: 3; loss: 2.3755884170532227; \n",
      "fold: TRAIN; iteration: 5289; epoch: 3; loss: 2.156708002090454; \n",
      "fold: TRAIN; iteration: 5290; epoch: 3; loss: 2.206843852996826; \n",
      "fold: TRAIN; iteration: 5291; epoch: 3; loss: 2.3627123832702637; \n",
      "fold: TRAIN; iteration: 5292; epoch: 3; loss: 2.028202533721924; \n",
      "fold: TRAIN; iteration: 5293; epoch: 3; loss: 2.401628017425537; \n",
      "fold: TRAIN; iteration: 5294; epoch: 3; loss: 2.17075252532959; \n",
      "fold: TRAIN; iteration: 5295; epoch: 3; loss: 2.226087808609009; \n",
      "fold: TRAIN; iteration: 5296; epoch: 3; loss: 2.308255910873413; \n",
      "fold: TRAIN; iteration: 5297; epoch: 3; loss: 2.200479030609131; \n",
      "fold: TRAIN; iteration: 5298; epoch: 3; loss: 2.156534194946289; \n",
      "fold: TRAIN; iteration: 5299; epoch: 3; loss: 2.4409775733947754; \n",
      "fold: TRAIN; iteration: 5300; epoch: 3; loss: 2.138704776763916; \n",
      "fold: TRAIN; iteration: 5301; epoch: 3; loss: 2.3392179012298584; \n",
      "fold: TRAIN; iteration: 5302; epoch: 3; loss: 2.1960294246673584; \n",
      "fold: TRAIN; iteration: 5303; epoch: 3; loss: 2.2334060668945312; \n",
      "fold: TRAIN; iteration: 5304; epoch: 3; loss: 2.293034315109253; \n",
      "fold: TRAIN; iteration: 5305; epoch: 3; loss: 2.1859853267669678; \n",
      "fold: TRAIN; iteration: 5306; epoch: 3; loss: 2.3986337184906006; \n",
      "fold: TRAIN; iteration: 5307; epoch: 3; loss: 2.16793155670166; \n",
      "fold: TRAIN; iteration: 5308; epoch: 3; loss: 2.1108314990997314; \n",
      "fold: TRAIN; iteration: 5309; epoch: 3; loss: 2.1374411582946777; \n",
      "fold: TRAIN; iteration: 5310; epoch: 3; loss: 2.081765651702881; \n",
      "fold: TRAIN; iteration: 5311; epoch: 3; loss: 2.1821517944335938; \n",
      "fold: TRAIN; iteration: 5312; epoch: 3; loss: 2.4285035133361816; \n",
      "fold: TRAIN; iteration: 5313; epoch: 3; loss: 2.3718395233154297; \n",
      "fold: TRAIN; iteration: 5314; epoch: 3; loss: 2.196587562561035; \n",
      "fold: TRAIN; iteration: 5315; epoch: 3; loss: 2.3775954246520996; \n",
      "fold: TRAIN; iteration: 5316; epoch: 3; loss: 2.3085639476776123; \n",
      "fold: TRAIN; iteration: 5317; epoch: 3; loss: 2.234483480453491; \n",
      "fold: TRAIN; iteration: 5318; epoch: 3; loss: 2.270883798599243; \n",
      "fold: TRAIN; iteration: 5319; epoch: 3; loss: 2.251112461090088; \n",
      "fold: TRAIN; iteration: 5320; epoch: 3; loss: 2.076326608657837; \n",
      "fold: TRAIN; iteration: 5321; epoch: 3; loss: 2.169605255126953; \n",
      "fold: TRAIN; iteration: 5322; epoch: 3; loss: 2.175813913345337; \n",
      "fold: TRAIN; iteration: 5323; epoch: 3; loss: 2.321577787399292; \n",
      "fold: TRAIN; iteration: 5324; epoch: 3; loss: 2.4000461101531982; \n",
      "fold: TRAIN; iteration: 5325; epoch: 3; loss: 2.2703917026519775; \n",
      "fold: TRAIN; iteration: 5326; epoch: 3; loss: 2.1861908435821533; \n",
      "fold: TRAIN; iteration: 5327; epoch: 3; loss: 2.165323257446289; \n",
      "fold: TRAIN; iteration: 5328; epoch: 3; loss: 2.086162805557251; \n",
      "fold: TRAIN; iteration: 5329; epoch: 3; loss: 2.183213710784912; \n",
      "fold: TRAIN; iteration: 5330; epoch: 3; loss: 2.275487184524536; \n",
      "fold: TRAIN; iteration: 5331; epoch: 3; loss: 2.134664535522461; \n",
      "fold: TRAIN; iteration: 5332; epoch: 3; loss: 2.1748299598693848; \n",
      "fold: TRAIN; iteration: 5333; epoch: 3; loss: 2.5300450325012207; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 5334; epoch: 3; loss: 2.137690544128418; \n",
      "fold: TRAIN; iteration: 5335; epoch: 3; loss: 2.1437885761260986; \n",
      "fold: TRAIN; iteration: 5336; epoch: 3; loss: 2.1641993522644043; \n",
      "fold: TRAIN; iteration: 5337; epoch: 3; loss: 2.3727622032165527; \n",
      "fold: TRAIN; iteration: 5338; epoch: 3; loss: 2.173328161239624; \n",
      "fold: TRAIN; iteration: 5339; epoch: 3; loss: 2.367058753967285; \n",
      "fold: TRAIN; iteration: 5340; epoch: 3; loss: 2.2832589149475098; \n",
      "fold: TRAIN; iteration: 5341; epoch: 3; loss: 2.374035596847534; \n",
      "fold: TRAIN; iteration: 5342; epoch: 3; loss: 2.300290822982788; \n",
      "fold: TRAIN; iteration: 5343; epoch: 3; loss: 2.176379442214966; \n",
      "fold: TRAIN; iteration: 5344; epoch: 3; loss: 2.2565298080444336; \n",
      "fold: TRAIN; iteration: 5345; epoch: 3; loss: 2.3869712352752686; \n",
      "fold: TRAIN; iteration: 5346; epoch: 3; loss: 1.9969210624694824; \n",
      "fold: TRAIN; iteration: 5347; epoch: 3; loss: 2.259150743484497; \n",
      "fold: TRAIN; iteration: 5348; epoch: 3; loss: 2.0520153045654297; \n",
      "fold: TRAIN; iteration: 5349; epoch: 3; loss: 2.4313464164733887; \n",
      "fold: TRAIN; iteration: 5350; epoch: 3; loss: 2.1327316761016846; \n",
      "fold: TRAIN; iteration: 5351; epoch: 3; loss: 2.317016839981079; \n",
      "fold: TRAIN; iteration: 5352; epoch: 3; loss: 2.2622432708740234; \n",
      "fold: TRAIN; iteration: 5353; epoch: 3; loss: 2.222885847091675; \n",
      "fold: TRAIN; iteration: 5354; epoch: 3; loss: 2.1645336151123047; \n",
      "fold: TRAIN; iteration: 5355; epoch: 3; loss: 2.3980255126953125; \n",
      "fold: TRAIN; iteration: 5356; epoch: 3; loss: 2.249671220779419; \n",
      "fold: TRAIN; iteration: 5357; epoch: 3; loss: 2.133744239807129; \n",
      "fold: TRAIN; iteration: 5358; epoch: 3; loss: 2.411522626876831; \n",
      "fold: TRAIN; iteration: 5359; epoch: 3; loss: 2.0759060382843018; \n",
      "fold: TRAIN; iteration: 5360; epoch: 3; loss: 2.2173399925231934; \n",
      "fold: TRAIN; iteration: 5361; epoch: 3; loss: 1.9610209465026855; \n",
      "fold: TRAIN; iteration: 5362; epoch: 3; loss: 2.187452793121338; \n",
      "fold: TRAIN; iteration: 5363; epoch: 3; loss: 2.168257474899292; \n",
      "fold: TRAIN; iteration: 5364; epoch: 3; loss: 2.1932132244110107; \n",
      "fold: TRAIN; iteration: 5365; epoch: 3; loss: 2.1506736278533936; \n",
      "fold: TRAIN; iteration: 5366; epoch: 3; loss: 2.2369470596313477; \n",
      "fold: TRAIN; iteration: 5367; epoch: 3; loss: 2.1982157230377197; \n",
      "fold: TRAIN; iteration: 5368; epoch: 3; loss: 2.1264724731445312; \n",
      "fold: TRAIN; iteration: 5369; epoch: 3; loss: 2.392293930053711; \n",
      "fold: TRAIN; iteration: 5370; epoch: 3; loss: 2.2296884059906006; \n",
      "fold: TRAIN; iteration: 5371; epoch: 3; loss: 2.2093441486358643; \n",
      "fold: TRAIN; iteration: 5372; epoch: 3; loss: 2.493128538131714; \n",
      "fold: TRAIN; iteration: 5373; epoch: 3; loss: 2.139500379562378; \n",
      "fold: TRAIN; iteration: 5374; epoch: 3; loss: 2.1956255435943604; \n",
      "fold: TRAIN; iteration: 5375; epoch: 3; loss: 1.99884831905365; \n",
      "fold: TRAIN; iteration: 5376; epoch: 3; loss: 2.0361297130584717; \n",
      "fold: TRAIN; iteration: 5377; epoch: 3; loss: 2.309210777282715; \n",
      "fold: TRAIN; iteration: 5378; epoch: 3; loss: 1.991013526916504; \n",
      "fold: TRAIN; iteration: 5379; epoch: 3; loss: 2.257754325866699; \n",
      "fold: TRAIN; iteration: 5380; epoch: 3; loss: 2.271902322769165; \n",
      "fold: TRAIN; iteration: 5381; epoch: 3; loss: 2.426525592803955; \n",
      "fold: TRAIN; iteration: 5382; epoch: 3; loss: 2.462763786315918; \n",
      "fold: TRAIN; iteration: 5383; epoch: 3; loss: 1.9010484218597412; \n",
      "fold: TRAIN; iteration: 5384; epoch: 3; loss: 2.128270149230957; \n",
      "fold: TRAIN; iteration: 5385; epoch: 3; loss: 2.3947925567626953; \n",
      "fold: TRAIN; iteration: 5386; epoch: 3; loss: 2.164497137069702; \n",
      "fold: TRAIN; iteration: 5387; epoch: 3; loss: 1.9547215700149536; \n",
      "fold: TRAIN; iteration: 5388; epoch: 3; loss: 2.174481153488159; \n",
      "fold: TRAIN; iteration: 5389; epoch: 3; loss: 2.2529354095458984; \n",
      "fold: TRAIN; iteration: 5390; epoch: 3; loss: 2.5423595905303955; \n",
      "fold: TRAIN; iteration: 5391; epoch: 3; loss: 2.27020263671875; \n",
      "fold: TRAIN; iteration: 5392; epoch: 3; loss: 1.9843031167984009; \n",
      "fold: TRAIN; iteration: 5393; epoch: 3; loss: 2.304048538208008; \n",
      "fold: TRAIN; iteration: 5394; epoch: 3; loss: 2.336552381515503; \n",
      "fold: TRAIN; iteration: 5395; epoch: 3; loss: 2.09545636177063; \n",
      "fold: TRAIN; iteration: 5396; epoch: 3; loss: 2.241442918777466; \n",
      "fold: TRAIN; iteration: 5397; epoch: 3; loss: 2.442112445831299; \n",
      "fold: TRAIN; iteration: 5398; epoch: 3; loss: 2.2319984436035156; \n",
      "fold: TRAIN; iteration: 5399; epoch: 3; loss: 2.3770835399627686; \n",
      "fold: TRAIN; iteration: 5400; epoch: 3; loss: 2.2429099082946777; \n",
      "fold: TRAIN; iteration: 5401; epoch: 3; loss: 2.3313510417938232; \n",
      "fold: TRAIN; iteration: 5402; epoch: 3; loss: 2.359795331954956; \n",
      "fold: TRAIN; iteration: 5403; epoch: 3; loss: 2.282611846923828; \n",
      "fold: TRAIN; iteration: 5404; epoch: 3; loss: 2.366997480392456; \n",
      "fold: TRAIN; iteration: 5405; epoch: 3; loss: 2.0681581497192383; \n",
      "fold: TRAIN; iteration: 5406; epoch: 3; loss: 2.0674216747283936; \n",
      "fold: TRAIN; iteration: 5407; epoch: 3; loss: 2.378103733062744; \n",
      "fold: TRAIN; iteration: 5408; epoch: 3; loss: 2.36807918548584; \n",
      "fold: TRAIN; iteration: 5409; epoch: 3; loss: 2.2701516151428223; \n",
      "fold: TRAIN; iteration: 5410; epoch: 3; loss: 2.353672504425049; \n",
      "fold: TRAIN; iteration: 5411; epoch: 3; loss: 2.198418617248535; \n",
      "fold: TRAIN; iteration: 5412; epoch: 3; loss: 2.1326637268066406; \n",
      "fold: TRAIN; iteration: 5413; epoch: 3; loss: 2.2921669483184814; \n",
      "fold: TRAIN; iteration: 5414; epoch: 3; loss: 2.2036077976226807; \n",
      "fold: TRAIN; iteration: 5415; epoch: 3; loss: 2.234205961227417; \n",
      "fold: TRAIN; iteration: 5416; epoch: 3; loss: 2.1725575923919678; \n",
      "fold: TRAIN; iteration: 5417; epoch: 3; loss: 2.4688053131103516; \n",
      "fold: TRAIN; iteration: 5418; epoch: 3; loss: 2.1745972633361816; \n",
      "fold: TRAIN; iteration: 5419; epoch: 3; loss: 2.47847580909729; \n",
      "fold: TRAIN; iteration: 5420; epoch: 3; loss: 2.2758519649505615; \n",
      "fold: TRAIN; iteration: 5421; epoch: 3; loss: 2.2960472106933594; \n",
      "fold: TRAIN; iteration: 5422; epoch: 3; loss: 2.035644292831421; \n",
      "fold: TRAIN; iteration: 5423; epoch: 3; loss: 2.1491892337799072; \n",
      "fold: TRAIN; iteration: 5424; epoch: 3; loss: 2.1057169437408447; \n",
      "fold: TRAIN; iteration: 5425; epoch: 3; loss: 2.366647481918335; \n",
      "fold: TRAIN; iteration: 5426; epoch: 3; loss: 2.04727840423584; \n",
      "fold: TRAIN; iteration: 5427; epoch: 3; loss: 2.3442931175231934; \n",
      "fold: TRAIN; iteration: 5428; epoch: 3; loss: 2.250548839569092; \n",
      "fold: TRAIN; iteration: 5429; epoch: 3; loss: 2.2999770641326904; \n",
      "fold: TRAIN; iteration: 5430; epoch: 3; loss: 2.2066004276275635; \n",
      "fold: TRAIN; iteration: 5431; epoch: 3; loss: 2.5607526302337646; \n",
      "fold: TRAIN; iteration: 5432; epoch: 3; loss: 2.173866033554077; \n",
      "fold: TRAIN; iteration: 5433; epoch: 3; loss: 2.316727876663208; \n",
      "fold: TRAIN; iteration: 5434; epoch: 3; loss: 2.214181900024414; \n",
      "fold: TRAIN; iteration: 5435; epoch: 3; loss: 2.31059193611145; \n",
      "fold: TRAIN; iteration: 5436; epoch: 3; loss: 2.361006736755371; \n",
      "fold: TRAIN; iteration: 5437; epoch: 3; loss: 1.8904858827590942; \n",
      "fold: TRAIN; iteration: 5438; epoch: 3; loss: 2.1541876792907715; \n",
      "fold: TRAIN; iteration: 5439; epoch: 3; loss: 2.3215885162353516; \n",
      "fold: TRAIN; iteration: 5440; epoch: 3; loss: 2.0689878463745117; \n",
      "fold: TRAIN; iteration: 5441; epoch: 3; loss: 1.9995980262756348; \n",
      "fold: TRAIN; iteration: 5442; epoch: 3; loss: 2.170474052429199; \n",
      "fold: TRAIN; iteration: 5443; epoch: 3; loss: 2.1913230419158936; \n",
      "fold: TRAIN; iteration: 5444; epoch: 3; loss: 2.248427391052246; \n",
      "fold: TRAIN; iteration: 5445; epoch: 3; loss: 2.0682144165039062; \n",
      "fold: TRAIN; iteration: 5446; epoch: 3; loss: 2.2650296688079834; \n",
      "fold: TRAIN; iteration: 5447; epoch: 3; loss: 2.124054193496704; \n",
      "fold: TRAIN; iteration: 5448; epoch: 3; loss: 2.1299469470977783; \n",
      "fold: TRAIN; iteration: 5449; epoch: 3; loss: 2.13850474357605; \n",
      "fold: TRAIN; iteration: 5450; epoch: 3; loss: 2.1936330795288086; \n",
      "fold: TRAIN; iteration: 5451; epoch: 3; loss: 2.2908525466918945; \n",
      "fold: TRAIN; iteration: 5452; epoch: 3; loss: 2.1792428493499756; \n",
      "fold: TRAIN; iteration: 5453; epoch: 3; loss: 2.161806344985962; \n",
      "fold: TRAIN; iteration: 5454; epoch: 3; loss: 2.4790172576904297; \n",
      "fold: TRAIN; iteration: 5455; epoch: 3; loss: 2.2108302116394043; \n",
      "fold: TRAIN; iteration: 5456; epoch: 3; loss: 2.3125479221343994; \n",
      "fold: TRAIN; iteration: 5457; epoch: 3; loss: 2.153679609298706; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 5458; epoch: 3; loss: 2.1360106468200684; \n",
      "fold: TRAIN; iteration: 5459; epoch: 3; loss: 2.2507517337799072; \n",
      "fold: TRAIN; iteration: 5460; epoch: 3; loss: 2.2910501956939697; \n",
      "fold: TRAIN; iteration: 5461; epoch: 3; loss: 2.310136318206787; \n",
      "fold: TRAIN; iteration: 5462; epoch: 3; loss: 2.1956586837768555; \n",
      "fold: TRAIN; iteration: 5463; epoch: 3; loss: 2.4403936862945557; \n",
      "fold: TRAIN; iteration: 5464; epoch: 3; loss: 2.386075735092163; \n",
      "fold: TRAIN; iteration: 5465; epoch: 3; loss: 2.1878204345703125; \n",
      "fold: TRAIN; iteration: 5466; epoch: 3; loss: 2.212019443511963; \n",
      "fold: TRAIN; iteration: 5467; epoch: 3; loss: 2.063716173171997; \n",
      "fold: TRAIN; iteration: 5468; epoch: 3; loss: 2.2041268348693848; \n",
      "fold: TRAIN; iteration: 5469; epoch: 3; loss: 2.0529260635375977; \n",
      "fold: TRAIN; iteration: 5470; epoch: 3; loss: 2.18660044670105; \n",
      "fold: TRAIN; iteration: 5471; epoch: 3; loss: 2.277057647705078; \n",
      "fold: TRAIN; iteration: 5472; epoch: 3; loss: 2.323221206665039; \n",
      "fold: TRAIN; iteration: 5473; epoch: 3; loss: 2.301938533782959; \n",
      "fold: TRAIN; iteration: 5474; epoch: 3; loss: 2.1857903003692627; \n",
      "fold: TRAIN; iteration: 5475; epoch: 3; loss: 2.1640419960021973; \n",
      "fold: TRAIN; iteration: 5476; epoch: 3; loss: 2.2616782188415527; \n",
      "fold: TRAIN; iteration: 5477; epoch: 3; loss: 2.238621473312378; \n",
      "fold: TRAIN; iteration: 5478; epoch: 3; loss: 2.403846502304077; \n",
      "fold: TRAIN; iteration: 5479; epoch: 3; loss: 2.410909652709961; \n",
      "fold: TRAIN; iteration: 5480; epoch: 3; loss: 2.3913450241088867; \n",
      "fold: TRAIN; iteration: 5481; epoch: 3; loss: 2.0886151790618896; \n",
      "fold: TRAIN; iteration: 5482; epoch: 3; loss: 2.0985474586486816; \n",
      "fold: TRAIN; iteration: 5483; epoch: 3; loss: 2.1184210777282715; \n",
      "fold: TRAIN; iteration: 5484; epoch: 3; loss: 2.161363124847412; \n",
      "fold: TRAIN; iteration: 5485; epoch: 3; loss: 2.2561492919921875; \n",
      "fold: TRAIN; iteration: 5486; epoch: 3; loss: 2.0915842056274414; \n",
      "fold: TRAIN; iteration: 5487; epoch: 3; loss: 1.9246503114700317; \n",
      "fold: TRAIN; iteration: 5488; epoch: 3; loss: 2.158621072769165; \n",
      "fold: TRAIN; iteration: 5489; epoch: 3; loss: 2.115572452545166; \n",
      "fold: TRAIN; iteration: 5490; epoch: 3; loss: 2.392118453979492; \n",
      "fold: TRAIN; iteration: 5491; epoch: 3; loss: 2.5472588539123535; \n",
      "fold: TRAIN; iteration: 5492; epoch: 3; loss: 2.339848279953003; \n",
      "fold: TRAIN; iteration: 5493; epoch: 3; loss: 2.3132762908935547; \n",
      "fold: TRAIN; iteration: 5494; epoch: 3; loss: 2.125349521636963; \n",
      "fold: TRAIN; iteration: 5495; epoch: 3; loss: 2.466235399246216; \n",
      "fold: TRAIN; iteration: 5496; epoch: 3; loss: 2.4475698471069336; \n",
      "fold: TRAIN; iteration: 5497; epoch: 3; loss: 2.2214667797088623; \n",
      "fold: TRAIN; iteration: 5498; epoch: 3; loss: 2.233905792236328; \n",
      "fold: TRAIN; iteration: 5499; epoch: 3; loss: 2.191638231277466; \n",
      "fold: TRAIN; iteration: 5500; epoch: 3; loss: 2.524976968765259; \n",
      "fold: TRAIN; iteration: 5501; epoch: 3; loss: 2.163729190826416; \n",
      "fold: TRAIN; iteration: 5502; epoch: 3; loss: 2.4913201332092285; \n",
      "fold: TRAIN; iteration: 5503; epoch: 3; loss: 2.415456771850586; \n",
      "fold: TRAIN; iteration: 5504; epoch: 3; loss: 2.2214348316192627; \n",
      "fold: TRAIN; iteration: 5505; epoch: 3; loss: 2.094167470932007; \n",
      "fold: TRAIN; iteration: 5506; epoch: 3; loss: 2.083799123764038; \n",
      "fold: TRAIN; iteration: 5507; epoch: 3; loss: 2.3196115493774414; \n",
      "fold: TRAIN; iteration: 5508; epoch: 3; loss: 2.4235758781433105; \n",
      "fold: TRAIN; iteration: 5509; epoch: 3; loss: 2.3211257457733154; \n",
      "fold: TRAIN; iteration: 5510; epoch: 3; loss: 2.2405054569244385; \n",
      "fold: TRAIN; iteration: 5511; epoch: 3; loss: 2.192723274230957; \n",
      "fold: TRAIN; iteration: 5512; epoch: 3; loss: 2.3280539512634277; \n",
      "fold: TRAIN; iteration: 5513; epoch: 3; loss: 2.1882236003875732; \n",
      "fold: TRAIN; iteration: 5514; epoch: 3; loss: 2.178497791290283; \n",
      "fold: TRAIN; iteration: 5515; epoch: 3; loss: 2.3848698139190674; \n",
      "fold: TRAIN; iteration: 5516; epoch: 3; loss: 2.129554033279419; \n",
      "fold: TRAIN; iteration: 5517; epoch: 3; loss: 2.336336851119995; \n",
      "fold: TRAIN; iteration: 5518; epoch: 3; loss: 2.1997482776641846; \n",
      "fold: TRAIN; iteration: 5519; epoch: 3; loss: 2.3315353393554688; \n",
      "fold: TRAIN; iteration: 5520; epoch: 3; loss: 2.1476004123687744; \n",
      "fold: TRAIN; iteration: 5521; epoch: 3; loss: 2.264746904373169; \n",
      "fold: TRAIN; iteration: 5522; epoch: 3; loss: 2.2619986534118652; \n",
      "fold: TRAIN; iteration: 5523; epoch: 3; loss: 2.175179958343506; \n",
      "fold: TRAIN; iteration: 5524; epoch: 3; loss: 2.3877522945404053; \n",
      "fold: TRAIN; iteration: 5525; epoch: 3; loss: 2.155397415161133; \n",
      "fold: TRAIN; iteration: 5526; epoch: 3; loss: 2.3086698055267334; \n",
      "fold: TRAIN; iteration: 5527; epoch: 3; loss: 2.191791296005249; \n",
      "fold: TRAIN; iteration: 5528; epoch: 3; loss: 2.3440685272216797; \n",
      "fold: TRAIN; iteration: 5529; epoch: 3; loss: 2.2702231407165527; \n",
      "fold: TRAIN; iteration: 5530; epoch: 3; loss: 2.3722774982452393; \n",
      "fold: TRAIN; iteration: 5531; epoch: 3; loss: 2.2166576385498047; \n",
      "fold: TRAIN; iteration: 5532; epoch: 3; loss: 2.2299180030822754; \n",
      "fold: TRAIN; iteration: 5533; epoch: 3; loss: 2.2161295413970947; \n",
      "fold: TRAIN; iteration: 5534; epoch: 3; loss: 2.346365451812744; \n",
      "fold: TRAIN; iteration: 5535; epoch: 3; loss: 2.2685489654541016; \n",
      "fold: TRAIN; iteration: 5536; epoch: 3; loss: 2.013897657394409; \n",
      "fold: TRAIN; iteration: 5537; epoch: 3; loss: 2.197075605392456; \n",
      "fold: TRAIN; iteration: 5538; epoch: 3; loss: 2.2507400512695312; \n",
      "fold: TRAIN; iteration: 5539; epoch: 3; loss: 2.2939348220825195; \n",
      "fold: TRAIN; iteration: 5540; epoch: 3; loss: 2.404529094696045; \n",
      "fold: TRAIN; iteration: 5541; epoch: 3; loss: 2.2256078720092773; \n",
      "fold: TRAIN; iteration: 5542; epoch: 3; loss: 2.3335535526275635; \n",
      "fold: TRAIN; iteration: 5543; epoch: 3; loss: 2.1610894203186035; \n",
      "fold: TRAIN; iteration: 5544; epoch: 3; loss: 2.3471076488494873; \n",
      "fold: TRAIN; iteration: 5545; epoch: 3; loss: 2.1472384929656982; \n",
      "fold: TRAIN; iteration: 5546; epoch: 3; loss: 2.3352060317993164; \n",
      "fold: TRAIN; iteration: 5547; epoch: 3; loss: 2.1394574642181396; \n",
      "fold: TRAIN; iteration: 5548; epoch: 3; loss: 2.0974602699279785; \n",
      "fold: TRAIN; iteration: 5549; epoch: 3; loss: 2.2236452102661133; \n",
      "fold: TRAIN; iteration: 5550; epoch: 3; loss: 2.4594528675079346; \n",
      "fold: TRAIN; iteration: 5551; epoch: 3; loss: 2.2007813453674316; \n",
      "fold: TRAIN; iteration: 5552; epoch: 3; loss: 2.275153875350952; \n",
      "fold: TRAIN; iteration: 5553; epoch: 3; loss: 1.9300051927566528; \n",
      "fold: TRAIN; iteration: 5554; epoch: 3; loss: 2.109529972076416; \n",
      "fold: TRAIN; iteration: 5555; epoch: 3; loss: 2.3013124465942383; \n",
      "fold: TRAIN; iteration: 5556; epoch: 3; loss: 2.0549087524414062; \n",
      "fold: TRAIN; iteration: 5557; epoch: 3; loss: 2.4032416343688965; \n",
      "fold: TRAIN; iteration: 5558; epoch: 3; loss: 2.02298903465271; \n",
      "fold: TRAIN; iteration: 5559; epoch: 3; loss: 2.4315614700317383; \n",
      "fold: TRAIN; iteration: 5560; epoch: 3; loss: 2.3822357654571533; \n",
      "fold: TRAIN; iteration: 5561; epoch: 3; loss: 2.263132095336914; \n",
      "fold: TRAIN; iteration: 5562; epoch: 3; loss: 2.147702217102051; \n",
      "fold: TRAIN; iteration: 5563; epoch: 3; loss: 2.3233368396759033; \n",
      "fold: TRAIN; iteration: 5564; epoch: 3; loss: 2.2668426036834717; \n",
      "fold: TRAIN; iteration: 5565; epoch: 3; loss: 2.273916244506836; \n",
      "fold: TRAIN; iteration: 5566; epoch: 3; loss: 2.100525379180908; \n",
      "fold: TRAIN; iteration: 5567; epoch: 3; loss: 2.2170228958129883; \n",
      "fold: TRAIN; iteration: 5568; epoch: 3; loss: 2.1881704330444336; \n",
      "fold: TRAIN; iteration: 5569; epoch: 3; loss: 2.436689853668213; \n",
      "fold: TRAIN; iteration: 5570; epoch: 3; loss: 2.3337111473083496; \n",
      "fold: TRAIN; iteration: 5571; epoch: 3; loss: 2.0775349140167236; \n",
      "fold: TRAIN; iteration: 5572; epoch: 3; loss: 2.094357967376709; \n",
      "fold: TRAIN; iteration: 5573; epoch: 3; loss: 2.3639676570892334; \n",
      "fold: TRAIN; iteration: 5574; epoch: 3; loss: 2.2564592361450195; \n",
      "fold: TRAIN; iteration: 5575; epoch: 3; loss: 2.1355981826782227; \n",
      "fold: TRAIN; iteration: 5576; epoch: 3; loss: 2.0101358890533447; \n",
      "fold: TRAIN; iteration: 5577; epoch: 3; loss: 2.2235960960388184; \n",
      "fold: TRAIN; iteration: 5578; epoch: 3; loss: 2.276524543762207; \n",
      "fold: TRAIN; iteration: 5579; epoch: 3; loss: 2.1791253089904785; \n",
      "fold: TRAIN; iteration: 5580; epoch: 3; loss: 1.9824520349502563; \n",
      "fold: TRAIN; iteration: 5581; epoch: 3; loss: 2.2964696884155273; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 5582; epoch: 3; loss: 2.2144875526428223; \n",
      "fold: TRAIN; iteration: 5583; epoch: 3; loss: 2.2806026935577393; \n",
      "fold: TRAIN; iteration: 5584; epoch: 3; loss: 2.4250307083129883; \n",
      "fold: TRAIN; iteration: 5585; epoch: 3; loss: 2.3106837272644043; \n",
      "fold: TRAIN; iteration: 5586; epoch: 3; loss: 2.2654001712799072; \n",
      "fold: TRAIN; iteration: 5587; epoch: 3; loss: 2.2809479236602783; \n",
      "fold: TRAIN; iteration: 5588; epoch: 3; loss: 2.1827392578125; \n",
      "fold: TRAIN; iteration: 5589; epoch: 3; loss: 2.1660280227661133; \n",
      "fold: TRAIN; iteration: 5590; epoch: 3; loss: 2.0450079441070557; \n",
      "fold: TRAIN; iteration: 5591; epoch: 3; loss: 2.2786505222320557; \n",
      "fold: TRAIN; iteration: 5592; epoch: 3; loss: 2.3732571601867676; \n",
      "fold: TRAIN; iteration: 5593; epoch: 3; loss: 2.3295743465423584; \n",
      "fold: TRAIN; iteration: 5594; epoch: 3; loss: 2.055497884750366; \n",
      "fold: TRAIN; iteration: 5595; epoch: 3; loss: 2.090789556503296; \n",
      "fold: TRAIN; iteration: 5596; epoch: 3; loss: 2.57309627532959; \n",
      "fold: TRAIN; iteration: 5597; epoch: 3; loss: 2.3351361751556396; \n",
      "fold: TRAIN; iteration: 5598; epoch: 3; loss: 2.2327163219451904; \n",
      "fold: TRAIN; iteration: 5599; epoch: 3; loss: 2.1862659454345703; \n",
      "fold: TRAIN; iteration: 5600; epoch: 3; loss: 2.26652455329895; \n",
      "fold: TRAIN; iteration: 5601; epoch: 3; loss: 2.3068528175354004; \n",
      "fold: TRAIN; iteration: 5602; epoch: 3; loss: 2.1798529624938965; \n",
      "fold: TRAIN; iteration: 5603; epoch: 3; loss: 2.219644784927368; \n",
      "fold: TRAIN; iteration: 5604; epoch: 3; loss: 2.1666829586029053; \n",
      "fold: TRAIN; iteration: 5605; epoch: 3; loss: 2.2720112800598145; \n",
      "fold: TRAIN; iteration: 5606; epoch: 3; loss: 2.1473708152770996; \n",
      "fold: TRAIN; iteration: 5607; epoch: 3; loss: 2.0065488815307617; \n",
      "fold: TRAIN; iteration: 5608; epoch: 3; loss: 2.159738302230835; \n",
      "fold: TRAIN; iteration: 5609; epoch: 3; loss: 2.3195879459381104; \n",
      "fold: TRAIN; iteration: 5610; epoch: 3; loss: 2.2323977947235107; \n",
      "fold: TRAIN; iteration: 5611; epoch: 3; loss: 2.5181756019592285; \n",
      "fold: TRAIN; iteration: 5612; epoch: 3; loss: 2.2837328910827637; \n",
      "fold: TRAIN; iteration: 5613; epoch: 3; loss: 2.3261947631835938; \n",
      "fold: TRAIN; iteration: 5614; epoch: 3; loss: 2.149688720703125; \n",
      "fold: TRAIN; iteration: 5615; epoch: 3; loss: 2.161688804626465; \n",
      "fold: TRAIN; iteration: 5616; epoch: 3; loss: 2.302457571029663; \n"
     ]
    }
   ],
   "source": [
    "docs.create_imputation(\n",
    "    'image_captioner',\n",
    "    model='conditional_lm',\n",
    "    loss='autoregressive_loss',\n",
    "    target='captioning_tokenizer',\n",
    "    splitter='captioning_splitter',\n",
    "    validation_sets=['captioning'],\n",
    "    batch_size=50,\n",
    "    lr=0.001,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cd74bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.DeleteResult at 0x173667ee0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs['_imputations'].delete_many({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8de1319",
   "metadata": {},
   "source": [
    "Now we have trained and evaluated several models of various types. This includes multiple interacting models with mutual dependencies. In the case of our own efficient semantic search, and also the attribute predictor, these models are downstream of the image clip model, in the sense that at inference time, clip must be present in order to be able to execute these models. In the case of attribute prediction, the training task was downstream from the \n",
    "spacy pipeline for part-of-speech tagging; these tags were used to produce targets for training. However at run-time, the spacy pipeline won't be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74500ec3",
   "metadata": {},
   "source": [
    "The models which we've added and trained are now ready to go, and when new data is added or updated to the collection, they will automatically process this data, and insert the model outputs into the collection documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa15fe60",
   "metadata": {},
   "source": [
    "Here is the complete set of models which exist in the collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6eedbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fb555c",
   "metadata": {},
   "outputs": [],
   "source": [
    "del docs.models['conditional_lm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67816835",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = docs.models['conditional_lm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1081e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduperdb.models.utils import apply_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1976e2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "r = list(docs.find(features={'img': 'clip'}).limit(random.randrange(1000)))[-1]\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472635cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_model(m, r, single=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e772643",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.find_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b1fe7c",
   "metadata": {},
   "source": [
    "Not all of these respond to incoming data, for that we need to specify the `active` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f54582",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.list_models(active=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3689545a",
   "metadata": {},
   "source": [
    "We can see that these models have processed all documents and their outputs saved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59381c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.find_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3951ff",
   "metadata": {},
   "source": [
    "Now, let's test what happens when we add new data to the collection, by adding the remaining data points from the \n",
    "CoCo data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2653f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "update = [{**r, \"update\": True} for r in data[-1000:]]\n",
    "docs.insert_many(update, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
