{"metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.7"}}, "nbformat": 4, "nbformat_minor": 5, "cells": [{"cell_type": "markdown", "id": "38c1a328-fd86-4c5f-bd54-b8664f433608", "metadata": {}, "source": ["<!-- TABS -->\n", "# Retrieval augmented generation"]}, {"cell_type": "markdown", "id": "ec24191c-ed06-4264-9cd1-c8c0d7c23f0b", "metadata": {}, "source": ["The first step in any SuperDuperDB application is to connect to your data-backend with SuperDuperDB:"]}, {"cell_type": "markdown", "id": "32f8484d-2e35-472a-9b24-1a30ec1d144b", "metadata": {}, "source": ["<!-- TABS -->\n", "## Connect to SuperDuperDB"]}, {"cell_type": "code", "execution_count": null, "id": "61976f44-8139-41c0-a73e-569c6d16c4b1", "metadata": {}, "outputs": [], "source": ["# <tab: MongoDB>\n", "from superduperdb import superduper\n", "\n", "db = superduper('mongodb://localhost:27017/documents')"]}, {"cell_type": "code", "execution_count": null, "id": "e981a457", "metadata": {}, "outputs": [], "source": ["# <tab: SQLite>\n", "from superduperdb import superduper\n", "\n", "db = superduper('sqlite://my_db.db')"]}, {"cell_type": "code", "execution_count": null, "id": "8b41f2d7", "metadata": {}, "outputs": [], "source": ["# <testing: >\n", "import pandas as pd\n", "data = [{'A': 10, 'B': 20, 'C':30}, {'x':100, 'y': 200, 'z': 300}]\n", "df = pd.DataFrame(data=data)\n", "df.to_csv('my.csv')"]}, {"cell_type": "markdown", "id": "e40544ac-0d97-46df-8bb5-4151baa72406", "metadata": {}, "source": ["Once you have done that you are ready to define your datatype(s) which you would like to \"search\"."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- TABS -->\n", "## Insert data\n", "\n", "In order to create data, we need to create a `Schema` for encoding our special `Datatype` column(s) in the databackend."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["N_DATA = round(len(data) - len(data) // 4)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: MongoDB>\n", "from superduperdb import Document\n", "\n", "if schema is None:\n", "    data = Document([{'x': datatype(x)} for x in data])    \n", "    db.execute(collection.insert_many(data[:N_DATA]))\n", "else:\n", "    data = Document([{'x': x} for x in data])    \n", "    db.execute(collection.insert_many(data[:N_DATA], schema='my_schema'))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: SQL>\n", "from superduperdb import Document\n", "\n", "db.execute(table.insert([Document({'x': x}) for x in data[:N_DATA]]))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sample_datapoint = data[-1]"]}, {"cell_type": "markdown", "id": "c9a2cd87-723f-4cee-87c7-9b8181c9e54b", "metadata": {}, "source": ["<!-- TABS -->\n", "## Build text embedding model"]}, {"cell_type": "code", "execution_count": null, "id": "a9b1f538-65ca-499e-b6d0-2dd733f81723", "metadata": {}, "outputs": [], "source": ["# <tab: OpenAI>\n", "%pip install openai\n", "\n", "from superduperdb.ext.openai import OpenAIEmbedding\n", "model = OpenAIEmbedding(identifier='text-embedding-ada-002')"]}, {"cell_type": "code", "execution_count": null, "id": "e83facd8-8823-492f-a2c6-659f38d8e6ec", "metadata": {}, "outputs": [], "source": ["# <tab: JinaAI>\n", "%pip install jina\n", "\n", "from superduperdb.ext.jina import JinaEmbedding\n", " \n", "# define the model\n", "model = JinaEmbedding(identifier='jina-embeddings-v2-base-en')"]}, {"cell_type": "code", "execution_count": null, "id": "3b4a9a60-41df-461d-b165-1d136ee25694", "metadata": {}, "outputs": [], "source": ["# <tab: Sentence-Transformers>\n", "%pip install sentence-transformers\n", "\n", "from superduperdb import vector\n", "import sentence_transformers\n", "from superduperdb.ext.sentence_transformers import SentenceTransformer\n", "\n", "model = SentenceTransformer(\n", "    identifier=\"embedding\",\n", "    object=sentence_transformers.SentenceTransformer(\"BAAI/bge-small-en\"),\n", "    datatype=vector(shape=(1024,)),\n", "    postprocess=lambda x: x.tolist(),\n", "    predict_kwargs={\"show_progress_bar\": True},\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "b1219380-13ce-4301-90e6-6ede2eee1497", "metadata": {}, "outputs": [], "source": ["# <tab: Transformers>\n", "%pip install transformers torch\n", "\n", "import dataclasses as dc\n", "from superduperdb.components.model import _Predictor, ensure_initialized\n", "from transformers import AutoTokenizer, AutoModel\n", "import torch\n", "\n", "@dc.dataclass(kw_only=True)\n", "class TransformerEmbedding(_Predictor):\n", "    pretrained_model_name_or_path : str\n", "\n", "    def init(self):\n", "        self.tokenizer = AutoTokenizer.from_pretrained(self.pretrained_model_name_or_path)\n", "        self.model = AutoModel.from_pretrained(self.pretrained_model_name_or_path)\n", "        self.model.eval()\n", "\n", "    @ensure_initialized\n", "    def predict_one(self, x):\n", "        return self.predict([x])[0]\n", "        \n", "    @ensure_initialized\n", "    def predict(self, dataset):\n", "        encoded_input = self.tokenizer(dataset, padding=True, truncation=True, return_tensors='pt')\n", "        # Compute token embeddings\n", "        with torch.no_grad():\n", "            model_output = self.model(**encoded_input)\n", "            # Perform pooling. In this case, cls pooling.\n", "            sentence_embeddings = model_output[0][:, 0]\n", "        # normalize embeddings\n", "        sentence_embeddings = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1)\n", "        return sentence_embeddings.tolist()\n", "\n", "\n", "model = TransformerEmbedding(identifier=\"embedding\", pretrained_model_name_or_path=\"BAAI/bge-small-en\")"]}, {"cell_type": "code", "execution_count": null, "id": "b9b238cf-56d5-44b4-87b0-9d8d55bdf36f", "metadata": {}, "outputs": [], "source": ["model.predict_one(\"What is SuperDuperDB\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- TABS -->\n", "## Perform a vector search"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from superduperdb import Document\n", "\n", "item = Document({'x': datatype(sample_datapoint)})"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Once we have this search target, we can execute a search as follows:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: MongoDB>\n", "select = collection.find().like(sample_datapoint)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: SQL>\n", "select = table.like(item)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["results = db.execute(select)"]}, {"cell_type": "markdown", "id": "1179a67b-4e40-496b-9851-98f32d42faa0", "metadata": {}, "source": ["<!-- TABS -->\n", "## Build LLM"]}, {"cell_type": "code", "execution_count": null, "id": "f98e5ff4", "metadata": {}, "outputs": [], "source": ["# <tab: OpenAI>\n", "from superduperdb.ext.openai import OpenAIChatCompletion\n", "\n", "llm = OpenAIChatCompletion(identifier='llm', model='gpt-3.5-turbo')"]}, {"cell_type": "code", "execution_count": null, "id": "9bf39c47", "metadata": {}, "outputs": [], "source": ["# <tab: Anthropic>\n", "\n", "from superduperdb.ext.anthropic import AnthropicCompletions\n", "llm = AnthropicCompletions(identifier='llm', model='claude-2')"]}, {"cell_type": "code", "execution_count": null, "id": "95e48deb", "metadata": {}, "outputs": [], "source": ["# <tab: vLLM>\n", "from superduperdb.ext.vllm import VllmModel\n", "\n", "predict_kwargs = {\n", "    \"max_tokens\": 1024,\n", "    \"temperature\": 0.8,\n", "}\n", "\n", "\n", "llm = VllmModel(\n", "    identifier=\"llm\",\n", "    model_name=\"TheBloke/Mistral-7B-Instruct-v0.2-AWQ\",\n", "    vllm_kwargs={\n", "        \"gpu_memory_utilization\": 0.7,\n", "        \"max_model_len\": 10240,\n", "        \"quantization\": \"awq\",\n", "    },\n", "    predict_kwargs=predict_kwargs,\n", ")\n"]}, {"cell_type": "code", "execution_count": null, "id": "fe4ac344", "metadata": {}, "outputs": [], "source": ["# <tab: Transformers>\n", "\n", "from superduperdb.ext.transformers import LLM\n", "\n", "llm = LLM.from_pretrained(\"facebook/opt-125m\", identifier=\"llm\")"]}, {"cell_type": "code", "execution_count": null, "id": "1fdbfae2-af7d-4845-bce5-0cb230e3614e", "metadata": {}, "outputs": [], "source": ["# <tab: Llama.cpp>\n", "!huggingface-cli download Qwen/Qwen1.5-0.5B-Chat-GGUF qwen1_5-0_5b-chat-q8_0.gguf --local-dir . --local-dir-use-symlinks False\n", "\n", "from superduperdb.ext.llamacpp.model import LlamaCpp\n", "llm = LlamaCpp(identifier=\"llm\", model_name_or_path=\"./qwen1_5-0_5b-chat-q8_0.gguf\")"]}, {"cell_type": "markdown", "id": "eb99c178-dbb9-42bf-85e8-a0ddbe740143", "metadata": {}, "source": ["### Using LLM for text generation"]}, {"cell_type": "code", "execution_count": null, "id": "3778ab16", "metadata": {}, "outputs": [], "source": ["llm.predict_one('Tell me about the SuperDuperDB', temperature=0.7)"]}, {"cell_type": "markdown", "id": "7a2715b3-1dbf-47ae-b959-8e4395d19cce", "metadata": {}, "source": ["### Use in combination with Prompt"]}, {"cell_type": "code", "execution_count": null, "id": "c28fdaf6", "metadata": {}, "outputs": [], "source": ["from superduperdb.components.model import SequentialModel, Model\n", "\n", "prompt_model = Model(\n", "    identifier=\"prompt\", object=lambda text: f\"The German version of sentence '{text}' is: \"\n", ")\n", "\n", "model = SequentialModel(identifier=\"The translator\", predictors=[prompt_model, llm])\n"]}, {"cell_type": "code", "execution_count": null, "id": "ee8fe44f-ea37-4044-9143-6969f9af4773", "metadata": {}, "outputs": [], "source": ["model.predict_one('Tell me about SuperDuperDB')"]}]}