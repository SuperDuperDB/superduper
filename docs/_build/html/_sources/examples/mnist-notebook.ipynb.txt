{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a6ac9b2",
   "metadata": {},
   "source": [
    "# MNIST: Handwritten digit recognition with SuperDuperDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c096450",
   "metadata": {},
   "source": [
    "The [MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database) is the classic hello-world for machine learning and AI.\n",
    "\n",
    "In this tutorial we implement MNIST classification using the paradigmatic \"LeNet\" based on the un-preprocessed images.\n",
    "\n",
    "First we import the SuperDuperDB client, and create a fresh collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32752579",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superduperdb.mongodb.client import SuperDuperClient\n",
    "\n",
    "import io\n",
    "import numpy\n",
    "import PIL.Image\n",
    "import PIL.JpegImagePlugin\n",
    "import PIL.PngImagePlugin\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "the_client = SuperDuperClient()\n",
    "docs = the_client.mnist.digits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5938a97",
   "metadata": {},
   "source": [
    "The data is available as `PIL.Image` images with labels in the `torchvision` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a767f640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "mnist_data = list(torchvision.datasets.MNIST(root='./data', download=True))\n",
    "random.shuffle(mnist_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6c4852",
   "metadata": {},
   "source": [
    "SuperDuperDB is based on MongoDB, which does not support images and tensors and other special data types out of the box. In order to remedy this, we create custom SuperDuperDB **types**.\n",
    "These types handle:\n",
    "    \n",
    "- How to store images as bytes in SuperDuperDB and how to reinstantiate the images from the bytes\n",
    "- How to store tensors in SuperDuperDB and how to retrieve these from the database again\n",
    "\n",
    "We do this by creating the classes in python with `.encode` and `.decode` methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37eb3b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image:\n",
    "    types = (PIL.JpegImagePlugin.JpegImageFile, PIL.Image.Image,\n",
    "             PIL.PngImagePlugin.PngImageFile)\n",
    "\n",
    "    @staticmethod\n",
    "    def encode(x):\n",
    "        buffer = io.BytesIO()\n",
    "        x.save(buffer, format='png')\n",
    "        return buffer.getvalue()\n",
    "\n",
    "    @staticmethod\n",
    "    def decode(bytes_):\n",
    "        return PIL.Image.open(io.BytesIO(bytes_))\n",
    "\n",
    "\n",
    "class FloatTensor:\n",
    "    types = (torch.FloatTensor, torch.Tensor)\n",
    "\n",
    "    @staticmethod\n",
    "    def encode(x):\n",
    "        x = x.numpy()\n",
    "        assert x.dtype == numpy.float32\n",
    "        return memoryview(x).tobytes()\n",
    "\n",
    "    @staticmethod\n",
    "    def decode(bytes_):\n",
    "        array = numpy.frombuffer(bytes_, dtype=numpy.float32)\n",
    "        return torch.from_numpy(array).type(torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fcc7a8",
   "metadata": {},
   "source": [
    "Once these classes are ready, we can add instances of these to SuperDuperDB, giving each type a suitable name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d53db4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.create_type('image', Image(), serializer='dill')\n",
    "docs.create_type('float_tensor', FloatTensor(), serializer='dill')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fde0ff4",
   "metadata": {},
   "source": [
    "Now we have these custom types, we can insert the data into SuperDuperDB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab329bef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_, jobs = docs.insert_many([{'img': x[0], 'class': x[1]} for x in mnist_data[:-1000]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029370c4",
   "metadata": {},
   "source": [
    "When data is inserted into SuperDuperDB, certain actions/ jobs are triggered. These include downloading content into the database from provided URIs, and running model **watchers** over the added data, if these have been added.\n",
    "\n",
    "The second output from the `insert_many` statement give a dictionary of ids of the asynchronous jobs which were created.\n",
    "These can also be seen in the job list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34754835",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'identifier': '94756b3a-2202-433c-b003-9f84fd21c004',\n",
       "  'time': datetime.datetime(2023, 3, 27, 17, 2, 56, 739000),\n",
       "  'status': 'pending',\n",
       "  'method': '_download_content'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.database.list_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935f0f4c",
   "metadata": {},
   "source": [
    "In this case, only one job was created - to download content. We can watch the stdout/stderr of this job like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f94ed471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 0 urls\n"
     ]
    }
   ],
   "source": [
    "docs.watch_job(jobs['download'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69d8bad",
   "metadata": {},
   "source": [
    "You can see that all data apart from the final 1000 have been added:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e686e9ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.count_documents({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb82b244",
   "metadata": {},
   "source": [
    "You'll see that when we fetch data from the database, it's in exactly the form that we want. For example, the images have been saved and recalled as `PIL.Image` types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0db28bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA20lEQVR4nN3OsUqCYRyF8WPpFtU3ZC4uggRBVyA4OLqIk1PCh3gBLm7dQFC0dAMurk1O0VLaJw6SNGnOUTjYEqE8rw45SPzfG+hZfxw40j/ttDleOedW7vIP7Iftzy82vUqS4r+Sbg3KGUmKZsqeSFfbsxCA514lkC5gnttePkQ/t9Kdk5SqSPdd+1PwAk9Jz+EakPFYZwnnMdvy33C9Y1txAqOUbUeP8JG27SCCYcm2vQiWBduCPtC07bgHNHZtrAONuG3VOUwTth2+wTRrm0JYVD2ms3dufOZpDfz3Y25UOFmhAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.find_one()['img']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f47ac2",
   "metadata": {},
   "source": [
    "Now that we've added the data to SuperDuperDB, we're ready to create a model. This is a simple PyTorch model implementing the iconic [LeNet architecture](https://en.wikipedia.org/wiki/LeNet). In addition to the standard PyTorch `.forward` method, SuperDuperDB allows users to specify `.preprocess` and `.postprocess` methods which define respectively:\n",
    "\n",
    "- how the data is converted from the in-database form, to tensor\n",
    "- from the output form back into the form to be stored in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1af679f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label(x):\n",
    "    return torch.tensor(x)\n",
    "\n",
    "\n",
    "class LeNet5(torch.nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),\n",
    "            torch.nn.BatchNorm2d(6),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "            torch.nn.BatchNorm2d(16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc = torch.nn.Linear(400, 120)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.fc1 = torch.nn.Linear(120, 84)\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(84, num_classes)\n",
    "\n",
    "    def preprocess(self, x):\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((32, 32)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(0.1307,), std=(0.3081,))]\n",
    "        )(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "    def postprocess(self, x):\n",
    "        return int(x.topk(1)[1].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac1be87",
   "metadata": {},
   "source": [
    "Let's test this model on a single image. `Collection.apply_model` applies the `preprocess`, `forward` and `postprocess` methods serially, creating a singleton batch prior to the `forward` and unpacking the batch after the `forward`. A similar logic is applied in all functionality which involves applying a model to the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "793093a8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.apply_model(LeNet5(10), docs.find()[23]['img'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce812615",
   "metadata": {},
   "source": [
    "Now that we have our model we need a target for learning - for this we use `label`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5615985",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.create_model('lenet', LeNet5(10), serializer='dill')\n",
    "docs.create_function('label', label, serializer='dill')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fead4f",
   "metadata": {},
   "source": [
    "Finally we need a loss function - this is a vanilla `torch` function, so we don't need to write extra code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a055b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.create_objective('classification', torch.nn.CrossEntropyLoss(), serializer='dill')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3637fcfd",
   "metadata": {},
   "source": [
    "And a metric to measure performance. Defined metrics are applied serially over individual data points, and the results are averaged:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "552eb1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(x, y):\n",
    "    return x == y\n",
    "\n",
    "docs.create_metric('accuracy', accuracy, serializer='dill')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dd18b1",
   "metadata": {},
   "source": [
    "When measuring performance, SuperDuperDB requires users to create a separate validation set, which is saved for posterity and reproducibility reasons - edits and deletes on the main collection don't affect this validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43a550cd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:00, 25826.36it/s]\n"
     ]
    }
   ],
   "source": [
    "docs.create_validation_set('classification', sample_size=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483f5746",
   "metadata": {},
   "source": [
    "Now we're ready to create the model using the `Collection.create_imputation`. This trains a model to predict one part of the data using another part, specified respectively by `model_key` and `target_key`; these are subkeys of the collection documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81f37e03",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "jobs = docs.create_imputation(\n",
    "    identifier='predictor',\n",
    "    model='lenet',\n",
    "    model_key='img',\n",
    "    target='label',\n",
    "    target_key='class',\n",
    "    objective='classification',\n",
    "    metrics=['accuracy'],\n",
    "    n_iterations=1000,\n",
    "    validation_interval=50,\n",
    "    validation_sets=('classification',)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485729b4",
   "metadata": {},
   "source": [
    "This command creates two jobs, one to train the model, and another to apply the model to the data after training. As before, the jobs are spawned asynchronously. We can watch the output of the jobs, but in the meantime we can also do other things in our environment, and with the database. Stopping the `watch_job` command, simply breaks the connection to the logs (doesn't stop the job)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21a86159",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: VALID; iteration: 0; epoch: 0; classification/accuracy: 0.048; objective: 2.3110132773717242; \n",
      "fold: TRAIN; iteration: 0; epoch: 0; objective: 2.308685064315796; \n",
      "fold: TRAIN; iteration: 1; epoch: 0; objective: 2.297574758529663; \n",
      "fold: TRAIN; iteration: 2; epoch: 0; objective: 2.2829301357269287; \n",
      "fold: TRAIN; iteration: 3; epoch: 0; objective: 2.3012170791625977; \n",
      "fold: TRAIN; iteration: 4; epoch: 0; objective: 2.284682273864746; \n",
      "fold: TRAIN; iteration: 5; epoch: 0; objective: 2.2731776237487793; \n",
      "fold: TRAIN; iteration: 6; epoch: 0; objective: 2.2876882553100586; \n",
      "fold: TRAIN; iteration: 7; epoch: 0; objective: 2.291152238845825; \n",
      "fold: TRAIN; iteration: 8; epoch: 0; objective: 2.2720654010772705; \n",
      "fold: TRAIN; iteration: 9; epoch: 0; objective: 2.2809369564056396; \n",
      "fold: TRAIN; iteration: 10; epoch: 0; objective: 2.2670164108276367; \n",
      "fold: TRAIN; iteration: 11; epoch: 0; objective: 2.2795052528381348; \n",
      "fold: TRAIN; iteration: 12; epoch: 0; objective: 2.2532029151916504; \n",
      "fold: TRAIN; iteration: 13; epoch: 0; objective: 2.2409369945526123; \n",
      "fold: TRAIN; iteration: 14; epoch: 0; objective: 2.2381467819213867; \n",
      "fold: TRAIN; iteration: 15; epoch: 0; objective: 2.2466988563537598; \n",
      "fold: TRAIN; iteration: 16; epoch: 0; objective: 2.228008508682251; \n",
      "fold: TRAIN; iteration: 17; epoch: 0; objective: 2.2353744506835938; \n",
      "fold: TRAIN; iteration: 18; epoch: 0; objective: 2.233978748321533; \n",
      "fold: TRAIN; iteration: 19; epoch: 0; objective: 2.220913887023926; \n",
      "fold: TRAIN; iteration: 20; epoch: 0; objective: 2.2235710620880127; \n",
      "fold: TRAIN; iteration: 21; epoch: 0; objective: 2.2159011363983154; \n",
      "fold: TRAIN; iteration: 22; epoch: 0; objective: 2.2194619178771973; \n",
      "fold: TRAIN; iteration: 23; epoch: 0; objective: 2.2242653369903564; \n",
      "fold: TRAIN; iteration: 24; epoch: 0; objective: 2.2201812267303467; \n",
      "fold: TRAIN; iteration: 25; epoch: 0; objective: 2.1877024173736572; \n",
      "fold: TRAIN; iteration: 26; epoch: 0; objective: 2.1867330074310303; \n",
      "fold: TRAIN; iteration: 27; epoch: 0; objective: 2.1860411167144775; \n",
      "fold: TRAIN; iteration: 28; epoch: 0; objective: 2.2026491165161133; \n",
      "fold: TRAIN; iteration: 29; epoch: 0; objective: 2.1925694942474365; \n",
      "fold: TRAIN; iteration: 30; epoch: 0; objective: 2.177600622177124; \n",
      "fold: TRAIN; iteration: 31; epoch: 0; objective: 2.184030055999756; \n",
      "fold: TRAIN; iteration: 32; epoch: 0; objective: 2.1714212894439697; \n",
      "fold: TRAIN; iteration: 33; epoch: 0; objective: 2.166768789291382; \n",
      "fold: TRAIN; iteration: 34; epoch: 0; objective: 2.163599967956543; \n",
      "fold: TRAIN; iteration: 35; epoch: 0; objective: 2.178396701812744; \n",
      "fold: TRAIN; iteration: 36; epoch: 0; objective: 2.1369612216949463; \n",
      "fold: TRAIN; iteration: 37; epoch: 0; objective: 2.1408331394195557; \n",
      "fold: TRAIN; iteration: 38; epoch: 0; objective: 2.1341922283172607; \n",
      "fold: TRAIN; iteration: 39; epoch: 0; objective: 2.1425812244415283; \n",
      "fold: TRAIN; iteration: 40; epoch: 0; objective: 2.118696928024292; \n",
      "fold: TRAIN; iteration: 41; epoch: 0; objective: 2.120541572570801; \n",
      "fold: TRAIN; iteration: 42; epoch: 0; objective: 2.0664491653442383; \n",
      "fold: TRAIN; iteration: 43; epoch: 0; objective: 2.111994743347168; \n",
      "fold: TRAIN; iteration: 44; epoch: 0; objective: 2.1069254875183105; \n",
      "fold: TRAIN; iteration: 45; epoch: 0; objective: 2.0793323516845703; \n",
      "fold: TRAIN; iteration: 46; epoch: 0; objective: 2.1000640392303467; \n",
      "fold: TRAIN; iteration: 47; epoch: 0; objective: 2.090277671813965; \n",
      "fold: TRAIN; iteration: 48; epoch: 0; objective: 2.0750815868377686; \n",
      "fold: TRAIN; iteration: 49; epoch: 0; objective: 2.068101406097412; \n",
      "validating model...\n",
      "saving\n",
      "fold: VALID; iteration: 50; epoch: 0; classification/accuracy: 0.584; objective: 2.0651561578114825; \n",
      "fold: TRAIN; iteration: 50; epoch: 0; objective: 2.0772299766540527; \n",
      "fold: TRAIN; iteration: 51; epoch: 0; objective: 2.077511787414551; \n",
      "fold: TRAIN; iteration: 52; epoch: 0; objective: 2.061453342437744; \n",
      "fold: TRAIN; iteration: 53; epoch: 0; objective: 2.0282208919525146; \n",
      "fold: TRAIN; iteration: 54; epoch: 0; objective: 2.0522677898406982; \n",
      "fold: TRAIN; iteration: 55; epoch: 0; objective: 2.0470306873321533; \n",
      "fold: TRAIN; iteration: 56; epoch: 0; objective: 2.026196241378784; \n",
      "fold: TRAIN; iteration: 57; epoch: 0; objective: 1.9833694696426392; \n",
      "fold: TRAIN; iteration: 58; epoch: 0; objective: 1.9961957931518555; \n",
      "fold: TRAIN; iteration: 59; epoch: 0; objective: 1.9861377477645874; \n",
      "fold: TRAIN; iteration: 60; epoch: 0; objective: 1.9589751958847046; \n",
      "fold: TRAIN; iteration: 61; epoch: 0; objective: 1.9920473098754883; \n",
      "fold: TRAIN; iteration: 62; epoch: 0; objective: 1.9533600807189941; \n",
      "fold: TRAIN; iteration: 63; epoch: 0; objective: 1.9611096382141113; \n",
      "fold: TRAIN; iteration: 64; epoch: 0; objective: 1.9264737367630005; \n",
      "fold: TRAIN; iteration: 65; epoch: 0; objective: 1.937672734260559; \n",
      "fold: TRAIN; iteration: 66; epoch: 0; objective: 1.910826563835144; \n",
      "fold: TRAIN; iteration: 67; epoch: 0; objective: 1.932340145111084; \n",
      "fold: TRAIN; iteration: 68; epoch: 0; objective: 1.9167404174804688; \n",
      "fold: TRAIN; iteration: 69; epoch: 0; objective: 1.8899414539337158; \n",
      "fold: TRAIN; iteration: 70; epoch: 0; objective: 1.8750643730163574; \n",
      "fold: TRAIN; iteration: 71; epoch: 0; objective: 1.8703351020812988; \n",
      "fold: TRAIN; iteration: 72; epoch: 0; objective: 1.816910982131958; \n",
      "fold: TRAIN; iteration: 73; epoch: 0; objective: 1.833722710609436; \n",
      "fold: TRAIN; iteration: 74; epoch: 0; objective: 1.856638789176941; \n",
      "fold: TRAIN; iteration: 75; epoch: 0; objective: 1.827927827835083; \n",
      "fold: TRAIN; iteration: 76; epoch: 0; objective: 1.8312007188796997; \n",
      "fold: TRAIN; iteration: 77; epoch: 0; objective: 1.7847802639007568; \n",
      "fold: TRAIN; iteration: 78; epoch: 0; objective: 1.7991377115249634; \n",
      "fold: TRAIN; iteration: 79; epoch: 0; objective: 1.8079094886779785; \n",
      "fold: TRAIN; iteration: 80; epoch: 0; objective: 1.7577625513076782; \n",
      "fold: TRAIN; iteration: 81; epoch: 0; objective: 1.7854645252227783; \n",
      "fold: TRAIN; iteration: 82; epoch: 0; objective: 1.7817187309265137; \n",
      "fold: TRAIN; iteration: 83; epoch: 0; objective: 1.7233870029449463; \n",
      "fold: TRAIN; iteration: 84; epoch: 0; objective: 1.7469534873962402; \n",
      "fold: TRAIN; iteration: 85; epoch: 0; objective: 1.7285447120666504; \n",
      "fold: TRAIN; iteration: 86; epoch: 0; objective: 1.753340244293213; \n",
      "fold: TRAIN; iteration: 87; epoch: 0; objective: 1.69362211227417; \n",
      "fold: TRAIN; iteration: 88; epoch: 0; objective: 1.6487454175949097; \n",
      "fold: TRAIN; iteration: 89; epoch: 0; objective: 1.712538242340088; \n"
     ]
    }
   ],
   "source": [
    "docs.watch_job(jobs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e4b3b5",
   "metadata": {},
   "source": [
    "We can continue watching the job, by executing the command again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d0117e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: VALID; iteration: 0; epoch: 0; classification/accuracy: 0.048; objective: 2.3110132773717242; \n",
      "fold: TRAIN; iteration: 0; epoch: 0; objective: 2.308685064315796; \n",
      "fold: TRAIN; iteration: 1; epoch: 0; objective: 2.297574758529663; \n",
      "fold: TRAIN; iteration: 2; epoch: 0; objective: 2.2829301357269287; \n",
      "fold: TRAIN; iteration: 3; epoch: 0; objective: 2.3012170791625977; \n",
      "fold: TRAIN; iteration: 4; epoch: 0; objective: 2.284682273864746; \n",
      "fold: TRAIN; iteration: 5; epoch: 0; objective: 2.2731776237487793; \n",
      "fold: TRAIN; iteration: 6; epoch: 0; objective: 2.2876882553100586; \n",
      "fold: TRAIN; iteration: 7; epoch: 0; objective: 2.291152238845825; \n",
      "fold: TRAIN; iteration: 8; epoch: 0; objective: 2.2720654010772705; \n",
      "fold: TRAIN; iteration: 9; epoch: 0; objective: 2.2809369564056396; \n",
      "fold: TRAIN; iteration: 10; epoch: 0; objective: 2.2670164108276367; \n",
      "fold: TRAIN; iteration: 11; epoch: 0; objective: 2.2795052528381348; \n",
      "fold: TRAIN; iteration: 12; epoch: 0; objective: 2.2532029151916504; \n",
      "fold: TRAIN; iteration: 13; epoch: 0; objective: 2.2409369945526123; \n",
      "fold: TRAIN; iteration: 14; epoch: 0; objective: 2.2381467819213867; \n",
      "fold: TRAIN; iteration: 15; epoch: 0; objective: 2.2466988563537598; \n",
      "fold: TRAIN; iteration: 16; epoch: 0; objective: 2.228008508682251; \n",
      "fold: TRAIN; iteration: 17; epoch: 0; objective: 2.2353744506835938; \n",
      "fold: TRAIN; iteration: 18; epoch: 0; objective: 2.233978748321533; \n",
      "fold: TRAIN; iteration: 19; epoch: 0; objective: 2.220913887023926; \n",
      "fold: TRAIN; iteration: 20; epoch: 0; objective: 2.2235710620880127; \n",
      "fold: TRAIN; iteration: 21; epoch: 0; objective: 2.2159011363983154; \n",
      "fold: TRAIN; iteration: 22; epoch: 0; objective: 2.2194619178771973; \n",
      "fold: TRAIN; iteration: 23; epoch: 0; objective: 2.2242653369903564; \n",
      "fold: TRAIN; iteration: 24; epoch: 0; objective: 2.2201812267303467; \n",
      "fold: TRAIN; iteration: 25; epoch: 0; objective: 2.1877024173736572; \n",
      "fold: TRAIN; iteration: 26; epoch: 0; objective: 2.1867330074310303; \n",
      "fold: TRAIN; iteration: 27; epoch: 0; objective: 2.1860411167144775; \n",
      "fold: TRAIN; iteration: 28; epoch: 0; objective: 2.2026491165161133; \n",
      "fold: TRAIN; iteration: 29; epoch: 0; objective: 2.1925694942474365; \n",
      "fold: TRAIN; iteration: 30; epoch: 0; objective: 2.177600622177124; \n",
      "fold: TRAIN; iteration: 31; epoch: 0; objective: 2.184030055999756; \n",
      "fold: TRAIN; iteration: 32; epoch: 0; objective: 2.1714212894439697; \n",
      "fold: TRAIN; iteration: 33; epoch: 0; objective: 2.166768789291382; \n",
      "fold: TRAIN; iteration: 34; epoch: 0; objective: 2.163599967956543; \n",
      "fold: TRAIN; iteration: 35; epoch: 0; objective: 2.178396701812744; \n",
      "fold: TRAIN; iteration: 36; epoch: 0; objective: 2.1369612216949463; \n",
      "fold: TRAIN; iteration: 37; epoch: 0; objective: 2.1408331394195557; \n",
      "fold: TRAIN; iteration: 38; epoch: 0; objective: 2.1341922283172607; \n",
      "fold: TRAIN; iteration: 39; epoch: 0; objective: 2.1425812244415283; \n",
      "fold: TRAIN; iteration: 40; epoch: 0; objective: 2.118696928024292; \n",
      "fold: TRAIN; iteration: 41; epoch: 0; objective: 2.120541572570801; \n",
      "fold: TRAIN; iteration: 42; epoch: 0; objective: 2.0664491653442383; \n",
      "fold: TRAIN; iteration: 43; epoch: 0; objective: 2.111994743347168; \n",
      "fold: TRAIN; iteration: 44; epoch: 0; objective: 2.1069254875183105; \n",
      "fold: TRAIN; iteration: 45; epoch: 0; objective: 2.0793323516845703; \n",
      "fold: TRAIN; iteration: 46; epoch: 0; objective: 2.1000640392303467; \n",
      "fold: TRAIN; iteration: 47; epoch: 0; objective: 2.090277671813965; \n",
      "fold: TRAIN; iteration: 48; epoch: 0; objective: 2.0750815868377686; \n",
      "fold: TRAIN; iteration: 49; epoch: 0; objective: 2.068101406097412; \n",
      "validating model...\n",
      "saving\n",
      "fold: VALID; iteration: 50; epoch: 0; classification/accuracy: 0.584; objective: 2.0651561578114825; \n",
      "fold: TRAIN; iteration: 50; epoch: 0; objective: 2.0772299766540527; \n",
      "fold: TRAIN; iteration: 51; epoch: 0; objective: 2.077511787414551; \n",
      "fold: TRAIN; iteration: 52; epoch: 0; objective: 2.061453342437744; \n",
      "fold: TRAIN; iteration: 53; epoch: 0; objective: 2.0282208919525146; \n",
      "fold: TRAIN; iteration: 54; epoch: 0; objective: 2.0522677898406982; \n",
      "fold: TRAIN; iteration: 55; epoch: 0; objective: 2.0470306873321533; \n",
      "fold: TRAIN; iteration: 56; epoch: 0; objective: 2.026196241378784; \n",
      "fold: TRAIN; iteration: 57; epoch: 0; objective: 1.9833694696426392; \n",
      "fold: TRAIN; iteration: 58; epoch: 0; objective: 1.9961957931518555; \n",
      "fold: TRAIN; iteration: 59; epoch: 0; objective: 1.9861377477645874; \n",
      "fold: TRAIN; iteration: 60; epoch: 0; objective: 1.9589751958847046; \n",
      "fold: TRAIN; iteration: 61; epoch: 0; objective: 1.9920473098754883; \n",
      "fold: TRAIN; iteration: 62; epoch: 0; objective: 1.9533600807189941; \n",
      "fold: TRAIN; iteration: 63; epoch: 0; objective: 1.9611096382141113; \n",
      "fold: TRAIN; iteration: 64; epoch: 0; objective: 1.9264737367630005; \n",
      "fold: TRAIN; iteration: 65; epoch: 0; objective: 1.937672734260559; \n",
      "fold: TRAIN; iteration: 66; epoch: 0; objective: 1.910826563835144; \n",
      "fold: TRAIN; iteration: 67; epoch: 0; objective: 1.932340145111084; \n",
      "fold: TRAIN; iteration: 68; epoch: 0; objective: 1.9167404174804688; \n",
      "fold: TRAIN; iteration: 69; epoch: 0; objective: 1.8899414539337158; \n",
      "fold: TRAIN; iteration: 70; epoch: 0; objective: 1.8750643730163574; \n",
      "fold: TRAIN; iteration: 71; epoch: 0; objective: 1.8703351020812988; \n",
      "fold: TRAIN; iteration: 72; epoch: 0; objective: 1.816910982131958; \n",
      "fold: TRAIN; iteration: 73; epoch: 0; objective: 1.833722710609436; \n",
      "fold: TRAIN; iteration: 74; epoch: 0; objective: 1.856638789176941; \n",
      "fold: TRAIN; iteration: 75; epoch: 0; objective: 1.827927827835083; \n",
      "fold: TRAIN; iteration: 76; epoch: 0; objective: 1.8312007188796997; \n",
      "fold: TRAIN; iteration: 77; epoch: 0; objective: 1.7847802639007568; \n",
      "fold: TRAIN; iteration: 78; epoch: 0; objective: 1.7991377115249634; \n",
      "fold: TRAIN; iteration: 79; epoch: 0; objective: 1.8079094886779785; \n",
      "fold: TRAIN; iteration: 80; epoch: 0; objective: 1.7577625513076782; \n",
      "fold: TRAIN; iteration: 81; epoch: 0; objective: 1.7854645252227783; \n",
      "fold: TRAIN; iteration: 82; epoch: 0; objective: 1.7817187309265137; \n",
      "fold: TRAIN; iteration: 83; epoch: 0; objective: 1.7233870029449463; \n",
      "fold: TRAIN; iteration: 84; epoch: 0; objective: 1.7469534873962402; \n",
      "fold: TRAIN; iteration: 85; epoch: 0; objective: 1.7285447120666504; \n",
      "fold: TRAIN; iteration: 86; epoch: 0; objective: 1.753340244293213; \n",
      "fold: TRAIN; iteration: 87; epoch: 0; objective: 1.69362211227417; \n",
      "fold: TRAIN; iteration: 88; epoch: 0; objective: 1.6487454175949097; \n",
      "fold: TRAIN; iteration: 89; epoch: 0; objective: 1.712538242340088; \n",
      "fold: TRAIN; iteration: 90; epoch: 0; objective: 1.7086501121520996; \n",
      "fold: TRAIN; iteration: 91; epoch: 0; objective: 1.691982626914978; \n",
      "fold: TRAIN; iteration: 92; epoch: 0; objective: 1.6723966598510742; \n",
      "fold: TRAIN; iteration: 93; epoch: 0; objective: 1.6283453702926636; \n",
      "fold: TRAIN; iteration: 94; epoch: 0; objective: 1.6149089336395264; \n",
      "fold: TRAIN; iteration: 95; epoch: 0; objective: 1.653446078300476; \n",
      "fold: TRAIN; iteration: 96; epoch: 0; objective: 1.648511528968811; \n",
      "fold: TRAIN; iteration: 97; epoch: 0; objective: 1.5106571912765503; \n",
      "fold: TRAIN; iteration: 98; epoch: 0; objective: 1.5759865045547485; \n",
      "fold: TRAIN; iteration: 99; epoch: 0; objective: 1.6457374095916748; \n",
      "validating model...\n",
      "saving\n",
      "fold: VALID; iteration: 100; epoch: 0; classification/accuracy: 0.736; objective: 1.5489568869272867; \n",
      "fold: TRAIN; iteration: 100; epoch: 0; objective: 1.5388517379760742; \n",
      "fold: TRAIN; iteration: 101; epoch: 0; objective: 1.5783321857452393; \n",
      "fold: TRAIN; iteration: 102; epoch: 0; objective: 1.459061622619629; \n",
      "fold: TRAIN; iteration: 103; epoch: 0; objective: 1.5350021123886108; \n",
      "fold: TRAIN; iteration: 104; epoch: 0; objective: 1.485479712486267; \n",
      "fold: TRAIN; iteration: 105; epoch: 0; objective: 1.5092706680297852; \n",
      "fold: TRAIN; iteration: 106; epoch: 0; objective: 1.4164519309997559; \n",
      "fold: TRAIN; iteration: 107; epoch: 0; objective: 1.493746280670166; \n",
      "fold: TRAIN; iteration: 108; epoch: 0; objective: 1.464590311050415; \n",
      "fold: TRAIN; iteration: 109; epoch: 0; objective: 1.4190788269042969; \n",
      "fold: TRAIN; iteration: 110; epoch: 0; objective: 1.3700015544891357; \n",
      "fold: TRAIN; iteration: 111; epoch: 0; objective: 1.3817120790481567; \n",
      "fold: TRAIN; iteration: 112; epoch: 0; objective: 1.498458743095398; \n",
      "fold: TRAIN; iteration: 113; epoch: 0; objective: 1.363298773765564; \n",
      "fold: TRAIN; iteration: 114; epoch: 0; objective: 1.414991021156311; \n",
      "fold: TRAIN; iteration: 115; epoch: 0; objective: 1.3477489948272705; \n",
      "fold: TRAIN; iteration: 116; epoch: 0; objective: 1.3577934503555298; \n",
      "fold: TRAIN; iteration: 117; epoch: 0; objective: 1.333818793296814; \n",
      "fold: TRAIN; iteration: 118; epoch: 0; objective: 1.2973687648773193; \n",
      "fold: TRAIN; iteration: 119; epoch: 0; objective: 1.3838218450546265; \n",
      "fold: TRAIN; iteration: 120; epoch: 0; objective: 1.3362393379211426; \n",
      "fold: TRAIN; iteration: 121; epoch: 0; objective: 1.3427870273590088; \n",
      "fold: TRAIN; iteration: 122; epoch: 0; objective: 1.3146530389785767; \n",
      "fold: TRAIN; iteration: 123; epoch: 0; objective: 1.3212884664535522; \n",
      "fold: TRAIN; iteration: 124; epoch: 0; objective: 1.2648059129714966; \n",
      "fold: TRAIN; iteration: 125; epoch: 0; objective: 1.1792470216751099; \n",
      "fold: TRAIN; iteration: 126; epoch: 0; objective: 1.3255343437194824; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 127; epoch: 0; objective: 1.2521576881408691; \n",
      "fold: TRAIN; iteration: 128; epoch: 0; objective: 1.1828417778015137; \n",
      "fold: TRAIN; iteration: 129; epoch: 0; objective: 1.1941351890563965; \n",
      "fold: TRAIN; iteration: 130; epoch: 0; objective: 1.2203545570373535; \n",
      "fold: TRAIN; iteration: 131; epoch: 0; objective: 1.2901480197906494; \n",
      "fold: TRAIN; iteration: 132; epoch: 0; objective: 1.1473500728607178; \n",
      "fold: TRAIN; iteration: 133; epoch: 0; objective: 1.21315336227417; \n",
      "fold: TRAIN; iteration: 134; epoch: 0; objective: 1.0979293584823608; \n",
      "fold: TRAIN; iteration: 135; epoch: 0; objective: 1.204796552658081; \n",
      "fold: TRAIN; iteration: 136; epoch: 0; objective: 1.18722665309906; \n",
      "fold: TRAIN; iteration: 137; epoch: 0; objective: 1.2087420225143433; \n",
      "fold: TRAIN; iteration: 138; epoch: 0; objective: 1.148308515548706; \n",
      "fold: TRAIN; iteration: 139; epoch: 0; objective: 1.1596767902374268; \n",
      "fold: TRAIN; iteration: 140; epoch: 0; objective: 1.0537848472595215; \n",
      "fold: TRAIN; iteration: 141; epoch: 0; objective: 1.059078335762024; \n",
      "fold: TRAIN; iteration: 142; epoch: 0; objective: 1.1056193113327026; \n",
      "fold: TRAIN; iteration: 143; epoch: 0; objective: 1.0761150121688843; \n",
      "fold: TRAIN; iteration: 144; epoch: 0; objective: 0.9907460808753967; \n",
      "fold: TRAIN; iteration: 145; epoch: 0; objective: 1.0361244678497314; \n",
      "fold: TRAIN; iteration: 146; epoch: 0; objective: 1.111603856086731; \n",
      "fold: TRAIN; iteration: 147; epoch: 0; objective: 0.8748308420181274; \n",
      "fold: TRAIN; iteration: 148; epoch: 0; objective: 1.0344175100326538; \n",
      "fold: TRAIN; iteration: 149; epoch: 0; objective: 1.0673104524612427; \n",
      "validating model...\n",
      "saving\n",
      "fold: VALID; iteration: 150; epoch: 0; classification/accuracy: 0.808; objective: 0.9873368521531423; \n",
      "fold: TRAIN; iteration: 150; epoch: 0; objective: 0.9553033709526062; \n",
      "fold: TRAIN; iteration: 151; epoch: 0; objective: 0.9281198978424072; \n",
      "fold: TRAIN; iteration: 152; epoch: 0; objective: 1.0514863729476929; \n",
      "fold: TRAIN; iteration: 153; epoch: 0; objective: 0.9282118082046509; \n",
      "fold: TRAIN; iteration: 154; epoch: 0; objective: 1.0207396745681763; \n",
      "fold: TRAIN; iteration: 155; epoch: 0; objective: 0.8938087224960327; \n",
      "fold: TRAIN; iteration: 156; epoch: 0; objective: 1.0280849933624268; \n",
      "fold: TRAIN; iteration: 157; epoch: 0; objective: 1.024795651435852; \n",
      "fold: TRAIN; iteration: 158; epoch: 0; objective: 0.9485607743263245; \n",
      "fold: TRAIN; iteration: 159; epoch: 0; objective: 0.9444960951805115; \n",
      "fold: TRAIN; iteration: 160; epoch: 0; objective: 0.9559438228607178; \n",
      "fold: TRAIN; iteration: 161; epoch: 0; objective: 0.883927583694458; \n",
      "fold: TRAIN; iteration: 162; epoch: 0; objective: 0.8086864948272705; \n",
      "fold: TRAIN; iteration: 163; epoch: 0; objective: 0.8442445993423462; \n",
      "fold: TRAIN; iteration: 164; epoch: 0; objective: 0.8373837471008301; \n",
      "fold: TRAIN; iteration: 165; epoch: 0; objective: 0.8384016156196594; \n",
      "fold: TRAIN; iteration: 166; epoch: 0; objective: 0.8444591760635376; \n",
      "fold: TRAIN; iteration: 167; epoch: 0; objective: 0.7695553302764893; \n",
      "fold: TRAIN; iteration: 168; epoch: 0; objective: 0.8766631484031677; \n",
      "fold: TRAIN; iteration: 169; epoch: 0; objective: 0.8856397271156311; \n",
      "fold: TRAIN; iteration: 170; epoch: 0; objective: 0.8711178302764893; \n",
      "fold: TRAIN; iteration: 171; epoch: 0; objective: 0.7945302724838257; \n",
      "fold: TRAIN; iteration: 172; epoch: 0; objective: 0.74613356590271; \n",
      "fold: TRAIN; iteration: 173; epoch: 0; objective: 0.7815412282943726; \n",
      "fold: TRAIN; iteration: 174; epoch: 0; objective: 0.8006216287612915; \n",
      "fold: TRAIN; iteration: 175; epoch: 0; objective: 0.795737624168396; \n",
      "fold: TRAIN; iteration: 176; epoch: 0; objective: 0.8316761255264282; \n",
      "fold: TRAIN; iteration: 177; epoch: 0; objective: 0.7394404411315918; \n",
      "fold: TRAIN; iteration: 178; epoch: 0; objective: 0.664289116859436; \n",
      "fold: TRAIN; iteration: 179; epoch: 0; objective: 0.9171271324157715; \n",
      "fold: TRAIN; iteration: 180; epoch: 0; objective: 0.7596015334129333; \n",
      "fold: TRAIN; iteration: 181; epoch: 0; objective: 0.6966711282730103; \n",
      "fold: TRAIN; iteration: 182; epoch: 0; objective: 0.6404881477355957; \n",
      "fold: TRAIN; iteration: 183; epoch: 0; objective: 0.7150827050209045; \n",
      "fold: TRAIN; iteration: 184; epoch: 0; objective: 0.7412192821502686; \n",
      "fold: TRAIN; iteration: 185; epoch: 0; objective: 0.7173486351966858; \n",
      "fold: TRAIN; iteration: 186; epoch: 0; objective: 0.6350332498550415; \n",
      "fold: TRAIN; iteration: 187; epoch: 0; objective: 0.6974350214004517; \n",
      "fold: TRAIN; iteration: 188; epoch: 0; objective: 0.7056358456611633; \n",
      "fold: TRAIN; iteration: 189; epoch: 0; objective: 0.7059516310691833; \n",
      "fold: TRAIN; iteration: 190; epoch: 0; objective: 0.6726677417755127; \n",
      "fold: TRAIN; iteration: 191; epoch: 0; objective: 0.7273571491241455; \n",
      "fold: TRAIN; iteration: 192; epoch: 0; objective: 0.6550860404968262; \n",
      "fold: TRAIN; iteration: 193; epoch: 0; objective: 0.7349218726158142; \n",
      "fold: TRAIN; iteration: 194; epoch: 0; objective: 0.6709476709365845; \n",
      "fold: TRAIN; iteration: 195; epoch: 0; objective: 0.6846724152565002; \n",
      "fold: TRAIN; iteration: 196; epoch: 0; objective: 0.6110948324203491; \n",
      "fold: TRAIN; iteration: 197; epoch: 0; objective: 0.6061646938323975; \n",
      "fold: TRAIN; iteration: 198; epoch: 0; objective: 0.5485150218009949; \n",
      "fold: TRAIN; iteration: 199; epoch: 0; objective: 0.5606725215911865; \n",
      "validating model...\n",
      "saving\n",
      "fold: VALID; iteration: 200; epoch: 0; classification/accuracy: 0.864; objective: 0.6416231413682302; \n",
      "fold: TRAIN; iteration: 200; epoch: 0; objective: 0.5524110198020935; \n",
      "fold: TRAIN; iteration: 201; epoch: 0; objective: 0.5731329917907715; \n",
      "fold: TRAIN; iteration: 202; epoch: 0; objective: 0.5998770594596863; \n",
      "fold: TRAIN; iteration: 203; epoch: 0; objective: 0.6987865567207336; \n",
      "fold: TRAIN; iteration: 204; epoch: 0; objective: 0.584966242313385; \n",
      "fold: TRAIN; iteration: 205; epoch: 0; objective: 0.544420599937439; \n",
      "fold: TRAIN; iteration: 206; epoch: 0; objective: 0.6289203763008118; \n",
      "fold: TRAIN; iteration: 207; epoch: 0; objective: 0.5928811430931091; \n",
      "fold: TRAIN; iteration: 208; epoch: 0; objective: 0.5664693713188171; \n",
      "fold: TRAIN; iteration: 209; epoch: 0; objective: 0.6178005933761597; \n",
      "fold: TRAIN; iteration: 210; epoch: 0; objective: 0.5685259699821472; \n",
      "fold: TRAIN; iteration: 211; epoch: 0; objective: 0.5617220997810364; \n",
      "fold: TRAIN; iteration: 212; epoch: 0; objective: 0.6207371950149536; \n",
      "fold: TRAIN; iteration: 213; epoch: 0; objective: 0.5728380680084229; \n",
      "fold: TRAIN; iteration: 214; epoch: 0; objective: 0.6330482363700867; \n",
      "fold: TRAIN; iteration: 215; epoch: 0; objective: 0.6580941081047058; \n",
      "fold: TRAIN; iteration: 216; epoch: 0; objective: 0.5361674427986145; \n",
      "fold: TRAIN; iteration: 217; epoch: 0; objective: 0.5886209607124329; \n",
      "fold: TRAIN; iteration: 218; epoch: 0; objective: 0.5150170922279358; \n",
      "fold: TRAIN; iteration: 219; epoch: 0; objective: 0.5986332297325134; \n",
      "fold: TRAIN; iteration: 220; epoch: 0; objective: 0.5638222098350525; \n",
      "fold: TRAIN; iteration: 221; epoch: 0; objective: 0.5477975606918335; \n",
      "fold: TRAIN; iteration: 222; epoch: 0; objective: 0.5144258141517639; \n",
      "fold: TRAIN; iteration: 223; epoch: 0; objective: 0.5075914263725281; \n",
      "fold: TRAIN; iteration: 224; epoch: 0; objective: 0.5279732346534729; \n",
      "fold: TRAIN; iteration: 225; epoch: 0; objective: 0.5959885716438293; \n",
      "fold: TRAIN; iteration: 226; epoch: 0; objective: 0.5398979783058167; \n",
      "fold: TRAIN; iteration: 227; epoch: 0; objective: 0.4430556893348694; \n",
      "fold: TRAIN; iteration: 228; epoch: 0; objective: 0.47684070467948914; \n",
      "fold: TRAIN; iteration: 229; epoch: 0; objective: 0.5749251842498779; \n",
      "fold: TRAIN; iteration: 230; epoch: 0; objective: 0.5780391097068787; \n",
      "fold: TRAIN; iteration: 231; epoch: 0; objective: 0.6113887429237366; \n",
      "fold: TRAIN; iteration: 232; epoch: 0; objective: 0.4975585639476776; \n",
      "fold: TRAIN; iteration: 233; epoch: 0; objective: 0.48368850350379944; \n",
      "fold: TRAIN; iteration: 234; epoch: 0; objective: 0.41788777709007263; \n",
      "fold: TRAIN; iteration: 235; epoch: 0; objective: 0.5862511992454529; \n",
      "fold: TRAIN; iteration: 236; epoch: 0; objective: 0.5322731137275696; \n",
      "fold: TRAIN; iteration: 237; epoch: 0; objective: 0.4178231358528137; \n",
      "fold: TRAIN; iteration: 238; epoch: 0; objective: 0.580333948135376; \n",
      "fold: TRAIN; iteration: 239; epoch: 0; objective: 0.497701495885849; \n",
      "fold: TRAIN; iteration: 240; epoch: 0; objective: 0.5496392250061035; \n",
      "fold: TRAIN; iteration: 241; epoch: 0; objective: 0.5565035343170166; \n",
      "fold: TRAIN; iteration: 242; epoch: 0; objective: 0.4882383644580841; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 243; epoch: 0; objective: 0.6302251219749451; \n",
      "fold: TRAIN; iteration: 244; epoch: 0; objective: 0.46008768677711487; \n",
      "fold: TRAIN; iteration: 245; epoch: 0; objective: 0.439983069896698; \n",
      "fold: TRAIN; iteration: 246; epoch: 0; objective: 0.5037180185317993; \n",
      "fold: TRAIN; iteration: 247; epoch: 0; objective: 0.4908507466316223; \n",
      "fold: TRAIN; iteration: 248; epoch: 0; objective: 0.4270007312297821; \n",
      "fold: TRAIN; iteration: 249; epoch: 0; objective: 0.48576876521110535; \n",
      "validating model...\n",
      "saving\n",
      "fold: VALID; iteration: 250; epoch: 0; classification/accuracy: 0.884; objective: 0.451803328593572; \n",
      "fold: TRAIN; iteration: 250; epoch: 0; objective: 0.4691663980484009; \n",
      "fold: TRAIN; iteration: 251; epoch: 0; objective: 0.576862633228302; \n",
      "fold: TRAIN; iteration: 252; epoch: 0; objective: 0.404197096824646; \n",
      "fold: TRAIN; iteration: 253; epoch: 0; objective: 0.3991774618625641; \n",
      "fold: TRAIN; iteration: 254; epoch: 0; objective: 0.37582331895828247; \n",
      "fold: TRAIN; iteration: 255; epoch: 0; objective: 0.5221420526504517; \n",
      "fold: TRAIN; iteration: 256; epoch: 0; objective: 0.43266594409942627; \n",
      "fold: TRAIN; iteration: 257; epoch: 0; objective: 0.4960709512233734; \n",
      "fold: TRAIN; iteration: 258; epoch: 0; objective: 0.48083826899528503; \n",
      "fold: TRAIN; iteration: 259; epoch: 0; objective: 0.3852514326572418; \n",
      "fold: TRAIN; iteration: 260; epoch: 0; objective: 0.3466404378414154; \n",
      "fold: TRAIN; iteration: 261; epoch: 0; objective: 0.39219409227371216; \n",
      "fold: TRAIN; iteration: 262; epoch: 0; objective: 0.4777238965034485; \n",
      "fold: TRAIN; iteration: 263; epoch: 0; objective: 0.44763603806495667; \n",
      "fold: TRAIN; iteration: 264; epoch: 0; objective: 0.4250473380088806; \n",
      "fold: TRAIN; iteration: 265; epoch: 0; objective: 0.3971410393714905; \n",
      "fold: TRAIN; iteration: 266; epoch: 0; objective: 0.40332740545272827; \n",
      "fold: TRAIN; iteration: 267; epoch: 0; objective: 0.3768453896045685; \n",
      "fold: TRAIN; iteration: 268; epoch: 0; objective: 0.38706374168395996; \n",
      "fold: TRAIN; iteration: 269; epoch: 0; objective: 0.37947556376457214; \n",
      "fold: TRAIN; iteration: 270; epoch: 0; objective: 0.452815443277359; \n",
      "fold: TRAIN; iteration: 271; epoch: 0; objective: 0.493867963552475; \n",
      "fold: TRAIN; iteration: 272; epoch: 0; objective: 0.3992939293384552; \n",
      "fold: TRAIN; iteration: 273; epoch: 0; objective: 0.3131028413772583; \n",
      "fold: TRAIN; iteration: 274; epoch: 0; objective: 0.4151868522167206; \n",
      "fold: TRAIN; iteration: 275; epoch: 0; objective: 0.4162626266479492; \n",
      "fold: TRAIN; iteration: 276; epoch: 0; objective: 0.3619062304496765; \n",
      "fold: TRAIN; iteration: 277; epoch: 0; objective: 0.37764960527420044; \n",
      "fold: TRAIN; iteration: 278; epoch: 0; objective: 0.2639358639717102; \n",
      "fold: TRAIN; iteration: 279; epoch: 0; objective: 0.35389968752861023; \n",
      "fold: TRAIN; iteration: 280; epoch: 0; objective: 0.4452621042728424; \n",
      "fold: TRAIN; iteration: 281; epoch: 0; objective: 0.4970174729824066; \n",
      "fold: TRAIN; iteration: 282; epoch: 0; objective: 0.46091488003730774; \n",
      "fold: TRAIN; iteration: 283; epoch: 0; objective: 0.3952816426753998; \n",
      "fold: TRAIN; iteration: 284; epoch: 0; objective: 0.4577915668487549; \n",
      "fold: TRAIN; iteration: 285; epoch: 0; objective: 0.4291832745075226; \n",
      "fold: TRAIN; iteration: 286; epoch: 0; objective: 0.2811763286590576; \n",
      "fold: TRAIN; iteration: 287; epoch: 0; objective: 0.4609934985637665; \n",
      "fold: TRAIN; iteration: 288; epoch: 0; objective: 0.34105420112609863; \n",
      "fold: TRAIN; iteration: 289; epoch: 0; objective: 0.46035289764404297; \n",
      "fold: TRAIN; iteration: 290; epoch: 0; objective: 0.39008629322052; \n",
      "fold: TRAIN; iteration: 291; epoch: 0; objective: 0.460020512342453; \n",
      "fold: TRAIN; iteration: 292; epoch: 0; objective: 0.36825576424598694; \n",
      "fold: TRAIN; iteration: 293; epoch: 0; objective: 0.4127294421195984; \n",
      "fold: TRAIN; iteration: 294; epoch: 0; objective: 0.39770039916038513; \n",
      "fold: TRAIN; iteration: 295; epoch: 0; objective: 0.3827143609523773; \n",
      "fold: TRAIN; iteration: 296; epoch: 0; objective: 0.31575194001197815; \n",
      "fold: TRAIN; iteration: 297; epoch: 0; objective: 0.3411363363265991; \n",
      "fold: TRAIN; iteration: 298; epoch: 0; objective: 0.3008173704147339; \n",
      "fold: TRAIN; iteration: 299; epoch: 0; objective: 0.32981377840042114; \n",
      "validating model...\n",
      "saving\n",
      "fold: VALID; iteration: 300; epoch: 0; classification/accuracy: 0.896; objective: 0.35037993391354877; \n",
      "fold: TRAIN; iteration: 300; epoch: 0; objective: 0.3884207606315613; \n",
      "fold: TRAIN; iteration: 301; epoch: 0; objective: 0.4104924499988556; \n",
      "fold: TRAIN; iteration: 302; epoch: 0; objective: 0.3189840018749237; \n",
      "fold: TRAIN; iteration: 303; epoch: 0; objective: 0.49520379304885864; \n",
      "fold: TRAIN; iteration: 304; epoch: 0; objective: 0.3654320240020752; \n",
      "fold: TRAIN; iteration: 305; epoch: 0; objective: 0.36922839283943176; \n",
      "fold: TRAIN; iteration: 306; epoch: 0; objective: 0.3083850145339966; \n",
      "fold: TRAIN; iteration: 307; epoch: 0; objective: 0.21791332960128784; \n",
      "fold: TRAIN; iteration: 308; epoch: 0; objective: 0.25590789318084717; \n",
      "fold: TRAIN; iteration: 309; epoch: 0; objective: 0.32256436347961426; \n",
      "fold: TRAIN; iteration: 310; epoch: 0; objective: 0.41546449065208435; \n",
      "fold: TRAIN; iteration: 311; epoch: 0; objective: 0.4138581454753876; \n",
      "fold: TRAIN; iteration: 312; epoch: 0; objective: 0.44572311639785767; \n",
      "fold: TRAIN; iteration: 313; epoch: 0; objective: 0.3566538095474243; \n",
      "fold: TRAIN; iteration: 314; epoch: 0; objective: 0.31700828671455383; \n",
      "fold: TRAIN; iteration: 315; epoch: 0; objective: 0.27538084983825684; \n",
      "fold: TRAIN; iteration: 316; epoch: 0; objective: 0.38182908296585083; \n",
      "fold: TRAIN; iteration: 317; epoch: 0; objective: 0.3178442120552063; \n",
      "fold: TRAIN; iteration: 318; epoch: 0; objective: 0.3055446743965149; \n",
      "fold: TRAIN; iteration: 319; epoch: 0; objective: 0.4917789697647095; \n",
      "fold: TRAIN; iteration: 320; epoch: 0; objective: 0.3592788279056549; \n",
      "fold: TRAIN; iteration: 321; epoch: 0; objective: 0.3168669641017914; \n",
      "fold: TRAIN; iteration: 322; epoch: 0; objective: 0.3328417241573334; \n",
      "fold: TRAIN; iteration: 323; epoch: 0; objective: 0.31958815455436707; \n",
      "fold: TRAIN; iteration: 324; epoch: 0; objective: 0.2781318426132202; \n",
      "fold: TRAIN; iteration: 325; epoch: 0; objective: 0.2303498089313507; \n",
      "fold: TRAIN; iteration: 326; epoch: 0; objective: 0.3737356662750244; \n",
      "fold: TRAIN; iteration: 327; epoch: 0; objective: 0.30438005924224854; \n",
      "fold: TRAIN; iteration: 328; epoch: 0; objective: 0.3121303617954254; \n",
      "fold: TRAIN; iteration: 329; epoch: 0; objective: 0.3315315246582031; \n",
      "fold: TRAIN; iteration: 330; epoch: 0; objective: 0.3182876408100128; \n",
      "fold: TRAIN; iteration: 331; epoch: 0; objective: 0.34026435017585754; \n",
      "fold: TRAIN; iteration: 332; epoch: 0; objective: 0.25233665108680725; \n",
      "fold: TRAIN; iteration: 333; epoch: 0; objective: 0.30373942852020264; \n",
      "fold: TRAIN; iteration: 334; epoch: 0; objective: 0.3453518748283386; \n",
      "fold: TRAIN; iteration: 335; epoch: 0; objective: 0.27508705854415894; \n",
      "fold: TRAIN; iteration: 336; epoch: 0; objective: 0.25642529129981995; \n",
      "fold: TRAIN; iteration: 337; epoch: 0; objective: 0.2675687074661255; \n",
      "fold: TRAIN; iteration: 338; epoch: 0; objective: 0.3089216351509094; \n",
      "fold: TRAIN; iteration: 339; epoch: 0; objective: 0.3620477020740509; \n",
      "fold: TRAIN; iteration: 340; epoch: 0; objective: 0.32604044675827026; \n",
      "fold: TRAIN; iteration: 341; epoch: 0; objective: 0.31357109546661377; \n",
      "fold: TRAIN; iteration: 342; epoch: 0; objective: 0.24581754207611084; \n",
      "fold: TRAIN; iteration: 343; epoch: 0; objective: 0.2585369050502777; \n",
      "fold: TRAIN; iteration: 344; epoch: 0; objective: 0.20343568921089172; \n",
      "fold: TRAIN; iteration: 345; epoch: 0; objective: 0.33888623118400574; \n",
      "fold: TRAIN; iteration: 346; epoch: 0; objective: 0.33794358372688293; \n",
      "fold: TRAIN; iteration: 347; epoch: 0; objective: 0.29893505573272705; \n",
      "fold: TRAIN; iteration: 348; epoch: 0; objective: 0.2963196039199829; \n",
      "fold: TRAIN; iteration: 349; epoch: 0; objective: 0.34523075819015503; \n",
      "validating model...\n",
      "saving\n",
      "fold: VALID; iteration: 350; epoch: 0; classification/accuracy: 0.912; objective: 0.29230905175209043; \n",
      "fold: TRAIN; iteration: 350; epoch: 0; objective: 0.2768441140651703; \n",
      "fold: TRAIN; iteration: 351; epoch: 0; objective: 0.3161417543888092; \n",
      "fold: TRAIN; iteration: 352; epoch: 0; objective: 0.23402588069438934; \n",
      "fold: TRAIN; iteration: 353; epoch: 0; objective: 0.35462820529937744; \n",
      "fold: TRAIN; iteration: 354; epoch: 0; objective: 0.26664280891418457; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 355; epoch: 0; objective: 0.22250282764434814; \n",
      "fold: TRAIN; iteration: 356; epoch: 0; objective: 0.26922518014907837; \n",
      "fold: TRAIN; iteration: 357; epoch: 0; objective: 0.3312653601169586; \n",
      "fold: TRAIN; iteration: 358; epoch: 0; objective: 0.306863009929657; \n",
      "fold: TRAIN; iteration: 359; epoch: 0; objective: 0.2578064799308777; \n",
      "fold: TRAIN; iteration: 360; epoch: 0; objective: 0.34224486351013184; \n",
      "fold: TRAIN; iteration: 361; epoch: 0; objective: 0.187997967004776; \n",
      "fold: TRAIN; iteration: 362; epoch: 0; objective: 0.32630929350852966; \n",
      "fold: TRAIN; iteration: 363; epoch: 0; objective: 0.25733163952827454; \n",
      "fold: TRAIN; iteration: 364; epoch: 0; objective: 0.31608423590660095; \n",
      "fold: TRAIN; iteration: 365; epoch: 0; objective: 0.366179883480072; \n",
      "fold: TRAIN; iteration: 366; epoch: 0; objective: 0.33990100026130676; \n",
      "fold: TRAIN; iteration: 367; epoch: 0; objective: 0.3026387691497803; \n",
      "fold: TRAIN; iteration: 368; epoch: 0; objective: 0.18078182637691498; \n",
      "fold: TRAIN; iteration: 369; epoch: 0; objective: 0.31508690118789673; \n",
      "fold: TRAIN; iteration: 370; epoch: 0; objective: 0.3361470699310303; \n",
      "fold: TRAIN; iteration: 371; epoch: 0; objective: 0.20317630469799042; \n",
      "fold: TRAIN; iteration: 372; epoch: 0; objective: 0.2807629704475403; \n",
      "fold: TRAIN; iteration: 373; epoch: 0; objective: 0.3306344151496887; \n",
      "fold: TRAIN; iteration: 374; epoch: 0; objective: 0.2602258622646332; \n",
      "fold: TRAIN; iteration: 375; epoch: 0; objective: 0.294003963470459; \n",
      "fold: TRAIN; iteration: 376; epoch: 0; objective: 0.32854458689689636; \n",
      "fold: TRAIN; iteration: 377; epoch: 0; objective: 0.2110057771205902; \n",
      "fold: TRAIN; iteration: 378; epoch: 0; objective: 0.27702534198760986; \n",
      "fold: TRAIN; iteration: 379; epoch: 0; objective: 0.26298296451568604; \n",
      "fold: TRAIN; iteration: 380; epoch: 0; objective: 0.44413691759109497; \n",
      "fold: TRAIN; iteration: 381; epoch: 0; objective: 0.2480943650007248; \n",
      "fold: TRAIN; iteration: 382; epoch: 0; objective: 0.24809619784355164; \n",
      "fold: TRAIN; iteration: 383; epoch: 0; objective: 0.1918671578168869; \n",
      "fold: TRAIN; iteration: 384; epoch: 0; objective: 0.2477605640888214; \n",
      "fold: TRAIN; iteration: 385; epoch: 0; objective: 0.2528572380542755; \n",
      "fold: TRAIN; iteration: 386; epoch: 0; objective: 0.1984337866306305; \n",
      "fold: TRAIN; iteration: 387; epoch: 0; objective: 0.2470925748348236; \n",
      "fold: TRAIN; iteration: 388; epoch: 0; objective: 0.20278017222881317; \n",
      "fold: TRAIN; iteration: 389; epoch: 0; objective: 0.24604254961013794; \n",
      "fold: TRAIN; iteration: 390; epoch: 0; objective: 0.31949999928474426; \n",
      "fold: TRAIN; iteration: 391; epoch: 0; objective: 0.337195485830307; \n",
      "fold: TRAIN; iteration: 392; epoch: 0; objective: 0.3418445885181427; \n",
      "fold: TRAIN; iteration: 393; epoch: 0; objective: 0.3306071162223816; \n",
      "fold: TRAIN; iteration: 394; epoch: 0; objective: 0.2407837063074112; \n",
      "fold: TRAIN; iteration: 395; epoch: 0; objective: 0.36058586835861206; \n",
      "fold: TRAIN; iteration: 396; epoch: 0; objective: 0.26730090379714966; \n",
      "fold: TRAIN; iteration: 397; epoch: 0; objective: 0.3105281889438629; \n",
      "fold: TRAIN; iteration: 398; epoch: 0; objective: 0.25328680872917175; \n",
      "fold: TRAIN; iteration: 399; epoch: 0; objective: 0.2442336082458496; \n",
      "validating model...\n",
      "saving\n",
      "fold: VALID; iteration: 400; epoch: 0; classification/accuracy: 0.916; objective: 0.24675621291001637; \n",
      "fold: TRAIN; iteration: 400; epoch: 0; objective: 0.2625192403793335; \n",
      "fold: TRAIN; iteration: 401; epoch: 0; objective: 0.2856789827346802; \n",
      "fold: TRAIN; iteration: 402; epoch: 0; objective: 0.2593337893486023; \n",
      "fold: TRAIN; iteration: 403; epoch: 0; objective: 0.3368138372898102; \n",
      "fold: TRAIN; iteration: 404; epoch: 0; objective: 0.21703064441680908; \n",
      "fold: TRAIN; iteration: 405; epoch: 0; objective: 0.30032292008399963; \n",
      "fold: TRAIN; iteration: 406; epoch: 0; objective: 0.2777790129184723; \n",
      "fold: TRAIN; iteration: 407; epoch: 0; objective: 0.24385595321655273; \n",
      "fold: TRAIN; iteration: 408; epoch: 0; objective: 0.34384241700172424; \n",
      "fold: TRAIN; iteration: 409; epoch: 0; objective: 0.23612819612026215; \n",
      "fold: TRAIN; iteration: 410; epoch: 0; objective: 0.2894740104675293; \n",
      "fold: TRAIN; iteration: 411; epoch: 0; objective: 0.26173990964889526; \n",
      "fold: TRAIN; iteration: 412; epoch: 0; objective: 0.2930750250816345; \n",
      "fold: TRAIN; iteration: 413; epoch: 0; objective: 0.2808097004890442; \n",
      "fold: TRAIN; iteration: 414; epoch: 0; objective: 0.2790738344192505; \n",
      "fold: TRAIN; iteration: 415; epoch: 0; objective: 0.25176265835762024; \n",
      "fold: TRAIN; iteration: 416; epoch: 0; objective: 0.2805478274822235; \n",
      "fold: TRAIN; iteration: 417; epoch: 0; objective: 0.18595218658447266; \n",
      "fold: TRAIN; iteration: 418; epoch: 0; objective: 0.2885960638523102; \n",
      "fold: TRAIN; iteration: 419; epoch: 0; objective: 0.2728252112865448; \n",
      "fold: TRAIN; iteration: 420; epoch: 0; objective: 0.14040805399417877; \n",
      "fold: TRAIN; iteration: 421; epoch: 0; objective: 0.2693161070346832; \n",
      "fold: TRAIN; iteration: 422; epoch: 0; objective: 0.2252017855644226; \n",
      "fold: TRAIN; iteration: 423; epoch: 0; objective: 0.16970288753509521; \n",
      "fold: TRAIN; iteration: 424; epoch: 0; objective: 0.20474845170974731; \n",
      "fold: TRAIN; iteration: 425; epoch: 0; objective: 0.2338188737630844; \n",
      "fold: TRAIN; iteration: 426; epoch: 0; objective: 0.2860945761203766; \n",
      "fold: TRAIN; iteration: 427; epoch: 0; objective: 0.22340461611747742; \n",
      "fold: TRAIN; iteration: 428; epoch: 0; objective: 0.21929721534252167; \n",
      "fold: TRAIN; iteration: 429; epoch: 0; objective: 0.1729525774717331; \n",
      "fold: TRAIN; iteration: 430; epoch: 0; objective: 0.1452544629573822; \n",
      "fold: TRAIN; iteration: 431; epoch: 0; objective: 0.2521149516105652; \n",
      "fold: TRAIN; iteration: 432; epoch: 0; objective: 0.30004021525382996; \n",
      "fold: TRAIN; iteration: 433; epoch: 0; objective: 0.18049336969852448; \n",
      "fold: TRAIN; iteration: 434; epoch: 0; objective: 0.25346001982688904; \n",
      "fold: TRAIN; iteration: 435; epoch: 0; objective: 0.2329639196395874; \n",
      "fold: TRAIN; iteration: 436; epoch: 0; objective: 0.23564575612545013; \n",
      "fold: TRAIN; iteration: 437; epoch: 0; objective: 0.2699601948261261; \n",
      "fold: TRAIN; iteration: 438; epoch: 0; objective: 0.26351380348205566; \n",
      "fold: TRAIN; iteration: 439; epoch: 0; objective: 0.1844683587551117; \n",
      "fold: TRAIN; iteration: 440; epoch: 0; objective: 0.27691227197647095; \n",
      "fold: TRAIN; iteration: 441; epoch: 0; objective: 0.1639537811279297; \n",
      "fold: TRAIN; iteration: 442; epoch: 0; objective: 0.286668062210083; \n",
      "fold: TRAIN; iteration: 443; epoch: 0; objective: 0.2069004476070404; \n",
      "fold: TRAIN; iteration: 444; epoch: 0; objective: 0.23070532083511353; \n",
      "fold: TRAIN; iteration: 445; epoch: 0; objective: 0.1823454052209854; \n",
      "fold: TRAIN; iteration: 446; epoch: 0; objective: 0.257651686668396; \n",
      "fold: TRAIN; iteration: 447; epoch: 0; objective: 0.20659533143043518; \n",
      "fold: TRAIN; iteration: 448; epoch: 0; objective: 0.2471970170736313; \n",
      "fold: TRAIN; iteration: 449; epoch: 0; objective: 0.17757461965084076; \n",
      "validating model...\n",
      "saving\n",
      "fold: VALID; iteration: 450; epoch: 0; classification/accuracy: 0.92; objective: 0.21056613624095916; \n",
      "fold: TRAIN; iteration: 450; epoch: 0; objective: 0.3436805307865143; \n",
      "fold: TRAIN; iteration: 451; epoch: 0; objective: 0.23695938289165497; \n",
      "fold: TRAIN; iteration: 452; epoch: 0; objective: 0.29445770382881165; \n",
      "fold: TRAIN; iteration: 453; epoch: 0; objective: 0.2298242151737213; \n",
      "fold: TRAIN; iteration: 454; epoch: 0; objective: 0.16260269284248352; \n",
      "fold: TRAIN; iteration: 455; epoch: 0; objective: 0.1670287847518921; \n",
      "fold: TRAIN; iteration: 456; epoch: 0; objective: 0.29464030265808105; \n",
      "fold: TRAIN; iteration: 457; epoch: 0; objective: 0.26952311396598816; \n",
      "fold: TRAIN; iteration: 458; epoch: 0; objective: 0.25887927412986755; \n",
      "fold: TRAIN; iteration: 459; epoch: 0; objective: 0.2283255159854889; \n",
      "fold: TRAIN; iteration: 460; epoch: 0; objective: 0.20522798597812653; \n",
      "fold: TRAIN; iteration: 461; epoch: 0; objective: 0.24169865250587463; \n",
      "fold: TRAIN; iteration: 462; epoch: 0; objective: 0.16830572485923767; \n",
      "fold: TRAIN; iteration: 463; epoch: 0; objective: 0.21455959975719452; \n",
      "fold: TRAIN; iteration: 464; epoch: 0; objective: 0.15567980706691742; \n",
      "fold: TRAIN; iteration: 465; epoch: 0; objective: 0.25333526730537415; \n",
      "fold: TRAIN; iteration: 466; epoch: 0; objective: 0.22035934031009674; \n",
      "fold: TRAIN; iteration: 467; epoch: 0; objective: 0.1339200735092163; \n",
      "fold: TRAIN; iteration: 468; epoch: 0; objective: 0.12972094118595123; \n",
      "fold: TRAIN; iteration: 469; epoch: 0; objective: 0.2563173174858093; \n",
      "fold: TRAIN; iteration: 470; epoch: 0; objective: 0.27959388494491577; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 471; epoch: 0; objective: 0.17715391516685486; \n",
      "fold: TRAIN; iteration: 472; epoch: 0; objective: 0.22243236005306244; \n",
      "fold: TRAIN; iteration: 473; epoch: 0; objective: 0.2017333060503006; \n",
      "fold: TRAIN; iteration: 474; epoch: 0; objective: 0.19562242925167084; \n",
      "fold: TRAIN; iteration: 475; epoch: 0; objective: 0.29030925035476685; \n",
      "fold: TRAIN; iteration: 476; epoch: 0; objective: 0.2628055810928345; \n",
      "fold: TRAIN; iteration: 477; epoch: 0; objective: 0.2315705120563507; \n",
      "fold: TRAIN; iteration: 478; epoch: 0; objective: 0.20442894101142883; \n",
      "fold: TRAIN; iteration: 479; epoch: 0; objective: 0.16538427770137787; \n",
      "fold: TRAIN; iteration: 480; epoch: 0; objective: 0.17901235818862915; \n",
      "fold: TRAIN; iteration: 481; epoch: 0; objective: 0.22716030478477478; \n",
      "fold: TRAIN; iteration: 482; epoch: 0; objective: 0.1822156012058258; \n",
      "fold: TRAIN; iteration: 483; epoch: 0; objective: 0.2607152462005615; \n",
      "fold: TRAIN; iteration: 484; epoch: 0; objective: 0.1956377476453781; \n",
      "fold: TRAIN; iteration: 485; epoch: 0; objective: 0.23572520911693573; \n",
      "fold: TRAIN; iteration: 486; epoch: 0; objective: 0.20163284242153168; \n",
      "fold: TRAIN; iteration: 487; epoch: 0; objective: 0.2183588743209839; \n",
      "fold: TRAIN; iteration: 488; epoch: 0; objective: 0.24798429012298584; \n",
      "fold: TRAIN; iteration: 489; epoch: 0; objective: 0.2613402307033539; \n",
      "fold: TRAIN; iteration: 490; epoch: 0; objective: 0.2674197852611542; \n",
      "fold: TRAIN; iteration: 491; epoch: 0; objective: 0.23024417459964752; \n",
      "fold: TRAIN; iteration: 492; epoch: 0; objective: 0.1974906176328659; \n",
      "fold: TRAIN; iteration: 493; epoch: 0; objective: 0.1252833902835846; \n",
      "fold: TRAIN; iteration: 494; epoch: 0; objective: 0.15930241346359253; \n",
      "fold: TRAIN; iteration: 495; epoch: 0; objective: 0.21083824336528778; \n",
      "fold: TRAIN; iteration: 496; epoch: 0; objective: 0.22166134417057037; \n",
      "fold: TRAIN; iteration: 497; epoch: 0; objective: 0.1736297607421875; \n",
      "fold: TRAIN; iteration: 498; epoch: 0; objective: 0.2207067906856537; \n",
      "fold: TRAIN; iteration: 499; epoch: 0; objective: 0.25420472025871277; \n",
      "validating model...\n",
      "saving\n",
      "fold: VALID; iteration: 500; epoch: 0; classification/accuracy: 0.924; objective: 0.19069528977076214; \n",
      "fold: TRAIN; iteration: 500; epoch: 0; objective: 0.18816803395748138; \n",
      "fold: TRAIN; iteration: 501; epoch: 0; objective: 0.12287291884422302; \n",
      "fold: TRAIN; iteration: 502; epoch: 0; objective: 0.18035119771957397; \n",
      "fold: TRAIN; iteration: 503; epoch: 0; objective: 0.2056800276041031; \n",
      "fold: TRAIN; iteration: 504; epoch: 0; objective: 0.15656442940235138; \n",
      "fold: TRAIN; iteration: 505; epoch: 0; objective: 0.1946607530117035; \n",
      "fold: TRAIN; iteration: 506; epoch: 0; objective: 0.12684255838394165; \n",
      "fold: TRAIN; iteration: 507; epoch: 0; objective: 0.28900614380836487; \n",
      "fold: TRAIN; iteration: 508; epoch: 0; objective: 0.12665358185768127; \n",
      "fold: TRAIN; iteration: 509; epoch: 0; objective: 0.17089062929153442; \n",
      "fold: TRAIN; iteration: 510; epoch: 0; objective: 0.1135038211941719; \n",
      "fold: TRAIN; iteration: 511; epoch: 0; objective: 0.1541869044303894; \n",
      "fold: TRAIN; iteration: 512; epoch: 0; objective: 0.3308180868625641; \n",
      "fold: TRAIN; iteration: 513; epoch: 0; objective: 0.19410045444965363; \n",
      "fold: TRAIN; iteration: 514; epoch: 0; objective: 0.1776244342327118; \n",
      "fold: TRAIN; iteration: 515; epoch: 0; objective: 0.1789172738790512; \n",
      "fold: TRAIN; iteration: 516; epoch: 0; objective: 0.26673102378845215; \n",
      "fold: TRAIN; iteration: 517; epoch: 0; objective: 0.20096160471439362; \n",
      "fold: TRAIN; iteration: 518; epoch: 0; objective: 0.19312679767608643; \n",
      "fold: TRAIN; iteration: 519; epoch: 0; objective: 0.262199342250824; \n",
      "fold: TRAIN; iteration: 520; epoch: 0; objective: 0.279582142829895; \n",
      "fold: TRAIN; iteration: 521; epoch: 0; objective: 0.28095564246177673; \n",
      "fold: TRAIN; iteration: 522; epoch: 0; objective: 0.2268110066652298; \n",
      "fold: TRAIN; iteration: 523; epoch: 0; objective: 0.2171192765235901; \n",
      "fold: TRAIN; iteration: 524; epoch: 0; objective: 0.2572196424007416; \n",
      "fold: TRAIN; iteration: 525; epoch: 0; objective: 0.23556096851825714; \n",
      "fold: TRAIN; iteration: 526; epoch: 0; objective: 0.2469976395368576; \n",
      "fold: TRAIN; iteration: 527; epoch: 0; objective: 0.2866179347038269; \n",
      "fold: TRAIN; iteration: 528; epoch: 0; objective: 0.11958278715610504; \n",
      "fold: TRAIN; iteration: 529; epoch: 0; objective: 0.17499998211860657; \n",
      "fold: TRAIN; iteration: 530; epoch: 0; objective: 0.23000793159008026; \n",
      "fold: TRAIN; iteration: 531; epoch: 0; objective: 0.19682151079177856; \n",
      "fold: TRAIN; iteration: 532; epoch: 0; objective: 0.2520036995410919; \n",
      "fold: TRAIN; iteration: 533; epoch: 0; objective: 0.18876145780086517; \n",
      "fold: TRAIN; iteration: 534; epoch: 0; objective: 0.18374605476856232; \n",
      "fold: TRAIN; iteration: 535; epoch: 0; objective: 0.14497922360897064; \n",
      "fold: TRAIN; iteration: 536; epoch: 0; objective: 0.16958293318748474; \n",
      "fold: TRAIN; iteration: 537; epoch: 0; objective: 0.24014291167259216; \n",
      "fold: TRAIN; iteration: 538; epoch: 0; objective: 0.11821747571229935; \n",
      "fold: TRAIN; iteration: 539; epoch: 0; objective: 0.18703846633434296; \n",
      "fold: TRAIN; iteration: 540; epoch: 0; objective: 0.14011511206626892; \n",
      "fold: TRAIN; iteration: 541; epoch: 0; objective: 0.2513301968574524; \n",
      "fold: TRAIN; iteration: 542; epoch: 0; objective: 0.3050746023654938; \n",
      "fold: TRAIN; iteration: 543; epoch: 0; objective: 0.17944732308387756; \n",
      "fold: TRAIN; iteration: 544; epoch: 0; objective: 0.23783716559410095; \n",
      "fold: TRAIN; iteration: 545; epoch: 0; objective: 0.20185483992099762; \n",
      "fold: TRAIN; iteration: 546; epoch: 0; objective: 0.1575520634651184; \n",
      "fold: TRAIN; iteration: 547; epoch: 0; objective: 0.15601468086242676; \n",
      "fold: TRAIN; iteration: 548; epoch: 0; objective: 0.21435560286045074; \n",
      "fold: TRAIN; iteration: 549; epoch: 0; objective: 0.11053474247455597; \n",
      "validating model...\n",
      "saving\n",
      "fold: VALID; iteration: 550; epoch: 0; classification/accuracy: 0.936; objective: 0.1713645281891028; \n",
      "fold: TRAIN; iteration: 550; epoch: 0; objective: 0.15319792926311493; \n",
      "fold: TRAIN; iteration: 551; epoch: 0; objective: 0.1813705861568451; \n",
      "fold: TRAIN; iteration: 552; epoch: 0; objective: 0.13642333447933197; \n",
      "fold: TRAIN; iteration: 553; epoch: 0; objective: 0.1771029680967331; \n",
      "fold: TRAIN; iteration: 554; epoch: 0; objective: 0.17172956466674805; \n",
      "fold: TRAIN; iteration: 555; epoch: 0; objective: 0.2103656828403473; \n",
      "fold: TRAIN; iteration: 556; epoch: 0; objective: 0.2354395091533661; \n",
      "fold: TRAIN; iteration: 557; epoch: 0; objective: 0.1517806202173233; \n",
      "fold: TRAIN; iteration: 558; epoch: 0; objective: 0.21146036684513092; \n",
      "fold: TRAIN; iteration: 559; epoch: 0; objective: 0.1926959753036499; \n",
      "fold: TRAIN; iteration: 560; epoch: 0; objective: 0.34162163734436035; \n",
      "fold: TRAIN; iteration: 561; epoch: 1; objective: 0.19660839438438416; \n",
      "fold: TRAIN; iteration: 562; epoch: 1; objective: 0.23113185167312622; \n",
      "fold: TRAIN; iteration: 563; epoch: 1; objective: 0.1668144166469574; \n",
      "fold: TRAIN; iteration: 564; epoch: 1; objective: 0.31791746616363525; \n",
      "fold: TRAIN; iteration: 565; epoch: 1; objective: 0.18624214828014374; \n",
      "fold: TRAIN; iteration: 566; epoch: 1; objective: 0.18381690979003906; \n",
      "fold: TRAIN; iteration: 567; epoch: 1; objective: 0.22024613618850708; \n",
      "fold: TRAIN; iteration: 568; epoch: 1; objective: 0.11072888970375061; \n",
      "fold: TRAIN; iteration: 569; epoch: 1; objective: 0.15904298424720764; \n",
      "fold: TRAIN; iteration: 570; epoch: 1; objective: 0.16242468357086182; \n",
      "fold: TRAIN; iteration: 571; epoch: 1; objective: 0.1903500109910965; \n",
      "fold: TRAIN; iteration: 572; epoch: 1; objective: 0.14506056904792786; \n",
      "fold: TRAIN; iteration: 573; epoch: 1; objective: 0.12776921689510345; \n",
      "fold: TRAIN; iteration: 574; epoch: 1; objective: 0.17519502341747284; \n",
      "fold: TRAIN; iteration: 575; epoch: 1; objective: 0.23584085702896118; \n",
      "fold: TRAIN; iteration: 576; epoch: 1; objective: 0.25147339701652527; \n",
      "fold: TRAIN; iteration: 577; epoch: 1; objective: 0.12743651866912842; \n",
      "fold: TRAIN; iteration: 578; epoch: 1; objective: 0.1451735943555832; \n",
      "fold: TRAIN; iteration: 579; epoch: 1; objective: 0.16156630218029022; \n",
      "fold: TRAIN; iteration: 580; epoch: 1; objective: 0.2701037526130676; \n",
      "fold: TRAIN; iteration: 581; epoch: 1; objective: 0.14835213124752045; \n",
      "fold: TRAIN; iteration: 582; epoch: 1; objective: 0.14147645235061646; \n",
      "fold: TRAIN; iteration: 583; epoch: 1; objective: 0.36205077171325684; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 584; epoch: 1; objective: 0.12842820584774017; \n",
      "fold: TRAIN; iteration: 585; epoch: 1; objective: 0.18731723725795746; \n",
      "fold: TRAIN; iteration: 586; epoch: 1; objective: 0.15742945671081543; \n",
      "fold: TRAIN; iteration: 587; epoch: 1; objective: 0.1970420628786087; \n",
      "fold: TRAIN; iteration: 588; epoch: 1; objective: 0.18344341218471527; \n",
      "fold: TRAIN; iteration: 589; epoch: 1; objective: 0.20230752229690552; \n",
      "fold: TRAIN; iteration: 590; epoch: 1; objective: 0.2499934434890747; \n",
      "fold: TRAIN; iteration: 591; epoch: 1; objective: 0.12143583595752716; \n",
      "fold: TRAIN; iteration: 592; epoch: 1; objective: 0.3028263747692108; \n",
      "fold: TRAIN; iteration: 593; epoch: 1; objective: 0.1849934160709381; \n",
      "fold: TRAIN; iteration: 594; epoch: 1; objective: 0.10593089461326599; \n",
      "fold: TRAIN; iteration: 595; epoch: 1; objective: 0.13589748740196228; \n",
      "fold: TRAIN; iteration: 596; epoch: 1; objective: 0.2509782314300537; \n",
      "fold: TRAIN; iteration: 597; epoch: 1; objective: 0.18752656877040863; \n",
      "fold: TRAIN; iteration: 598; epoch: 1; objective: 0.1089424416422844; \n",
      "fold: TRAIN; iteration: 599; epoch: 1; objective: 0.25208061933517456; \n",
      "validating model...\n",
      "saving\n",
      "fold: VALID; iteration: 600; epoch: 1; classification/accuracy: 0.944; objective: 0.15632830535372097; \n",
      "fold: TRAIN; iteration: 600; epoch: 1; objective: 0.10893958061933517; \n",
      "fold: TRAIN; iteration: 601; epoch: 1; objective: 0.09291502088308334; \n",
      "fold: TRAIN; iteration: 602; epoch: 1; objective: 0.0882015973329544; \n",
      "fold: TRAIN; iteration: 603; epoch: 1; objective: 0.1744246482849121; \n",
      "fold: TRAIN; iteration: 604; epoch: 1; objective: 0.09488404542207718; \n",
      "fold: TRAIN; iteration: 605; epoch: 1; objective: 0.23921199142932892; \n",
      "fold: TRAIN; iteration: 606; epoch: 1; objective: 0.1643109768629074; \n",
      "fold: TRAIN; iteration: 607; epoch: 1; objective: 0.13356739282608032; \n",
      "fold: TRAIN; iteration: 608; epoch: 1; objective: 0.17709778249263763; \n",
      "fold: TRAIN; iteration: 609; epoch: 1; objective: 0.11702609807252884; \n",
      "fold: TRAIN; iteration: 610; epoch: 1; objective: 0.10526110976934433; \n",
      "fold: TRAIN; iteration: 611; epoch: 1; objective: 0.1292509138584137; \n",
      "fold: TRAIN; iteration: 612; epoch: 1; objective: 0.17154918611049652; \n",
      "fold: TRAIN; iteration: 613; epoch: 1; objective: 0.17711523175239563; \n",
      "fold: TRAIN; iteration: 614; epoch: 1; objective: 0.17529067397117615; \n",
      "fold: TRAIN; iteration: 615; epoch: 1; objective: 0.16650797426700592; \n",
      "fold: TRAIN; iteration: 616; epoch: 1; objective: 0.16770608723163605; \n",
      "fold: TRAIN; iteration: 617; epoch: 1; objective: 0.11272963881492615; \n",
      "fold: TRAIN; iteration: 618; epoch: 1; objective: 0.22953489422798157; \n",
      "fold: TRAIN; iteration: 619; epoch: 1; objective: 0.15911659598350525; \n",
      "fold: TRAIN; iteration: 620; epoch: 1; objective: 0.10743838548660278; \n",
      "fold: TRAIN; iteration: 621; epoch: 1; objective: 0.10768947005271912; \n",
      "fold: TRAIN; iteration: 622; epoch: 1; objective: 0.11082758009433746; \n",
      "fold: TRAIN; iteration: 623; epoch: 1; objective: 0.12226519733667374; \n",
      "fold: TRAIN; iteration: 624; epoch: 1; objective: 0.21235467493534088; \n",
      "fold: TRAIN; iteration: 625; epoch: 1; objective: 0.1655896157026291; \n",
      "fold: TRAIN; iteration: 626; epoch: 1; objective: 0.25862300395965576; \n",
      "fold: TRAIN; iteration: 627; epoch: 1; objective: 0.2016104906797409; \n",
      "fold: TRAIN; iteration: 628; epoch: 1; objective: 0.18204741179943085; \n",
      "fold: TRAIN; iteration: 629; epoch: 1; objective: 0.15625448524951935; \n",
      "fold: TRAIN; iteration: 630; epoch: 1; objective: 0.11947419494390488; \n",
      "fold: TRAIN; iteration: 631; epoch: 1; objective: 0.16354504227638245; \n",
      "fold: TRAIN; iteration: 632; epoch: 1; objective: 0.14476747810840607; \n",
      "fold: TRAIN; iteration: 633; epoch: 1; objective: 0.15738779306411743; \n",
      "fold: TRAIN; iteration: 634; epoch: 1; objective: 0.2598494589328766; \n",
      "fold: TRAIN; iteration: 635; epoch: 1; objective: 0.1517832726240158; \n",
      "fold: TRAIN; iteration: 636; epoch: 1; objective: 0.15745992958545685; \n",
      "fold: TRAIN; iteration: 637; epoch: 1; objective: 0.23074007034301758; \n",
      "fold: TRAIN; iteration: 638; epoch: 1; objective: 0.17373384535312653; \n",
      "fold: TRAIN; iteration: 639; epoch: 1; objective: 0.0903640165925026; \n",
      "fold: TRAIN; iteration: 640; epoch: 1; objective: 0.14537380635738373; \n",
      "fold: TRAIN; iteration: 641; epoch: 1; objective: 0.1595802754163742; \n",
      "fold: TRAIN; iteration: 642; epoch: 1; objective: 0.16200529038906097; \n",
      "fold: TRAIN; iteration: 643; epoch: 1; objective: 0.2612053155899048; \n",
      "fold: TRAIN; iteration: 644; epoch: 1; objective: 0.14188505709171295; \n",
      "fold: TRAIN; iteration: 645; epoch: 1; objective: 0.1646387130022049; \n",
      "fold: TRAIN; iteration: 646; epoch: 1; objective: 0.19076788425445557; \n",
      "fold: TRAIN; iteration: 647; epoch: 1; objective: 0.22356298565864563; \n",
      "fold: TRAIN; iteration: 648; epoch: 1; objective: 0.24653072655200958; \n",
      "fold: TRAIN; iteration: 649; epoch: 1; objective: 0.20611131191253662; \n",
      "validating model...\n",
      "saving\n",
      "fold: VALID; iteration: 650; epoch: 1; classification/accuracy: 0.94; objective: 0.14958817288279533; \n",
      "fold: TRAIN; iteration: 650; epoch: 1; objective: 0.1685531586408615; \n",
      "fold: TRAIN; iteration: 651; epoch: 1; objective: 0.13237009942531586; \n",
      "fold: TRAIN; iteration: 652; epoch: 1; objective: 0.16990141570568085; \n",
      "fold: TRAIN; iteration: 653; epoch: 1; objective: 0.19682398438453674; \n",
      "fold: TRAIN; iteration: 654; epoch: 1; objective: 0.21055985987186432; \n",
      "fold: TRAIN; iteration: 655; epoch: 1; objective: 0.1812974512577057; \n",
      "fold: TRAIN; iteration: 656; epoch: 1; objective: 0.09736501425504684; \n",
      "fold: TRAIN; iteration: 657; epoch: 1; objective: 0.16760192811489105; \n",
      "fold: TRAIN; iteration: 658; epoch: 1; objective: 0.12057533860206604; \n",
      "fold: TRAIN; iteration: 659; epoch: 1; objective: 0.1542319357395172; \n",
      "fold: TRAIN; iteration: 660; epoch: 1; objective: 0.16806240379810333; \n",
      "fold: TRAIN; iteration: 661; epoch: 1; objective: 0.15364564955234528; \n",
      "fold: TRAIN; iteration: 662; epoch: 1; objective: 0.13764359056949615; \n",
      "fold: TRAIN; iteration: 663; epoch: 1; objective: 0.25643807649612427; \n",
      "fold: TRAIN; iteration: 664; epoch: 1; objective: 0.20973533391952515; \n",
      "fold: TRAIN; iteration: 665; epoch: 1; objective: 0.11687085777521133; \n",
      "fold: TRAIN; iteration: 666; epoch: 1; objective: 0.12486947327852249; \n",
      "fold: TRAIN; iteration: 667; epoch: 1; objective: 0.09650582075119019; \n",
      "fold: TRAIN; iteration: 668; epoch: 1; objective: 0.20230558514595032; \n",
      "fold: TRAIN; iteration: 669; epoch: 1; objective: 0.29987436532974243; \n",
      "fold: TRAIN; iteration: 670; epoch: 1; objective: 0.14417432248592377; \n",
      "fold: TRAIN; iteration: 671; epoch: 1; objective: 0.2259042114019394; \n",
      "fold: TRAIN; iteration: 672; epoch: 1; objective: 0.11589309573173523; \n",
      "fold: TRAIN; iteration: 673; epoch: 1; objective: 0.16616685688495636; \n",
      "fold: TRAIN; iteration: 674; epoch: 1; objective: 0.1127064898610115; \n",
      "fold: TRAIN; iteration: 675; epoch: 1; objective: 0.20488925278186798; \n",
      "fold: TRAIN; iteration: 676; epoch: 1; objective: 0.14638490974903107; \n",
      "fold: TRAIN; iteration: 677; epoch: 1; objective: 0.17875489592552185; \n",
      "fold: TRAIN; iteration: 678; epoch: 1; objective: 0.2335738241672516; \n",
      "fold: TRAIN; iteration: 679; epoch: 1; objective: 0.22855086624622345; \n",
      "fold: TRAIN; iteration: 680; epoch: 1; objective: 0.18123401701450348; \n",
      "fold: TRAIN; iteration: 681; epoch: 1; objective: 0.11808343231678009; \n",
      "fold: TRAIN; iteration: 682; epoch: 1; objective: 0.12892501056194305; \n",
      "fold: TRAIN; iteration: 683; epoch: 1; objective: 0.14797315001487732; \n",
      "fold: TRAIN; iteration: 684; epoch: 1; objective: 0.11681315302848816; \n",
      "fold: TRAIN; iteration: 685; epoch: 1; objective: 0.1503961682319641; \n",
      "fold: TRAIN; iteration: 686; epoch: 1; objective: 0.11396897584199905; \n",
      "fold: TRAIN; iteration: 687; epoch: 1; objective: 0.16025026142597198; \n",
      "fold: TRAIN; iteration: 688; epoch: 1; objective: 0.16644158959388733; \n",
      "fold: TRAIN; iteration: 689; epoch: 1; objective: 0.23167762160301208; \n",
      "fold: TRAIN; iteration: 690; epoch: 1; objective: 0.12443263828754425; \n",
      "fold: TRAIN; iteration: 691; epoch: 1; objective: 0.1370309293270111; \n",
      "fold: TRAIN; iteration: 692; epoch: 1; objective: 0.16375400125980377; \n",
      "fold: TRAIN; iteration: 693; epoch: 1; objective: 0.10679502785205841; \n",
      "fold: TRAIN; iteration: 694; epoch: 1; objective: 0.14102119207382202; \n",
      "fold: TRAIN; iteration: 695; epoch: 1; objective: 0.1513970047235489; \n",
      "fold: TRAIN; iteration: 696; epoch: 1; objective: 0.119949571788311; \n",
      "fold: TRAIN; iteration: 697; epoch: 1; objective: 0.23090091347694397; \n",
      "fold: TRAIN; iteration: 698; epoch: 1; objective: 0.1412595510482788; \n",
      "fold: TRAIN; iteration: 699; epoch: 1; objective: 0.20753636956214905; \n",
      "validating model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving\n",
      "fold: VALID; iteration: 700; epoch: 1; classification/accuracy: 0.944; objective: 0.13812173306941986; \n",
      "fold: TRAIN; iteration: 700; epoch: 1; objective: 0.1289389580488205; \n",
      "fold: TRAIN; iteration: 701; epoch: 1; objective: 0.13147209584712982; \n",
      "fold: TRAIN; iteration: 702; epoch: 1; objective: 0.1674077808856964; \n",
      "fold: TRAIN; iteration: 703; epoch: 1; objective: 0.09001180529594421; \n",
      "fold: TRAIN; iteration: 704; epoch: 1; objective: 0.1864451766014099; \n",
      "fold: TRAIN; iteration: 705; epoch: 1; objective: 0.1703319102525711; \n",
      "fold: TRAIN; iteration: 706; epoch: 1; objective: 0.16362975537776947; \n",
      "fold: TRAIN; iteration: 707; epoch: 1; objective: 0.15422700345516205; \n",
      "fold: TRAIN; iteration: 708; epoch: 1; objective: 0.11790715903043747; \n",
      "fold: TRAIN; iteration: 709; epoch: 1; objective: 0.12545333802700043; \n",
      "fold: TRAIN; iteration: 710; epoch: 1; objective: 0.10765758156776428; \n",
      "fold: TRAIN; iteration: 711; epoch: 1; objective: 0.09828315675258636; \n",
      "fold: TRAIN; iteration: 712; epoch: 1; objective: 0.15410426259040833; \n",
      "fold: TRAIN; iteration: 713; epoch: 1; objective: 0.14943593740463257; \n",
      "fold: TRAIN; iteration: 714; epoch: 1; objective: 0.10752546042203903; \n",
      "fold: TRAIN; iteration: 715; epoch: 1; objective: 0.17003817856311798; \n",
      "fold: TRAIN; iteration: 716; epoch: 1; objective: 0.1417105793952942; \n",
      "fold: TRAIN; iteration: 717; epoch: 1; objective: 0.12122239172458649; \n",
      "fold: TRAIN; iteration: 718; epoch: 1; objective: 0.12645508348941803; \n",
      "fold: TRAIN; iteration: 719; epoch: 1; objective: 0.08219695836305618; \n",
      "fold: TRAIN; iteration: 720; epoch: 1; objective: 0.15993089973926544; \n",
      "fold: TRAIN; iteration: 721; epoch: 1; objective: 0.12479905784130096; \n",
      "fold: TRAIN; iteration: 722; epoch: 1; objective: 0.12595804035663605; \n",
      "fold: TRAIN; iteration: 723; epoch: 1; objective: 0.194790780544281; \n",
      "fold: TRAIN; iteration: 724; epoch: 1; objective: 0.13562926650047302; \n",
      "fold: TRAIN; iteration: 725; epoch: 1; objective: 0.19529980421066284; \n",
      "fold: TRAIN; iteration: 726; epoch: 1; objective: 0.11100974678993225; \n",
      "fold: TRAIN; iteration: 727; epoch: 1; objective: 0.13537734746932983; \n",
      "fold: TRAIN; iteration: 728; epoch: 1; objective: 0.1437075436115265; \n",
      "fold: TRAIN; iteration: 729; epoch: 1; objective: 0.09550482779741287; \n",
      "fold: TRAIN; iteration: 730; epoch: 1; objective: 0.16775350272655487; \n",
      "fold: TRAIN; iteration: 731; epoch: 1; objective: 0.12777629494667053; \n",
      "fold: TRAIN; iteration: 732; epoch: 1; objective: 0.11964801698923111; \n",
      "fold: TRAIN; iteration: 733; epoch: 1; objective: 0.19649846851825714; \n",
      "fold: TRAIN; iteration: 734; epoch: 1; objective: 0.10971193015575409; \n",
      "fold: TRAIN; iteration: 735; epoch: 1; objective: 0.06122550368309021; \n",
      "fold: TRAIN; iteration: 736; epoch: 1; objective: 0.2458687573671341; \n",
      "fold: TRAIN; iteration: 737; epoch: 1; objective: 0.1621508002281189; \n",
      "fold: TRAIN; iteration: 738; epoch: 1; objective: 0.1297336220741272; \n",
      "fold: TRAIN; iteration: 739; epoch: 1; objective: 0.23219338059425354; \n",
      "fold: TRAIN; iteration: 740; epoch: 1; objective: 0.1714615672826767; \n",
      "fold: TRAIN; iteration: 741; epoch: 1; objective: 0.09712234139442444; \n",
      "fold: TRAIN; iteration: 742; epoch: 1; objective: 0.07767872512340546; \n",
      "fold: TRAIN; iteration: 743; epoch: 1; objective: 0.1458274871110916; \n",
      "fold: TRAIN; iteration: 744; epoch: 1; objective: 0.23351623117923737; \n",
      "fold: TRAIN; iteration: 745; epoch: 1; objective: 0.12255015224218369; \n",
      "fold: TRAIN; iteration: 746; epoch: 1; objective: 0.18870453536510468; \n",
      "fold: TRAIN; iteration: 747; epoch: 1; objective: 0.13486440479755402; \n",
      "fold: TRAIN; iteration: 748; epoch: 1; objective: 0.10258689522743225; \n",
      "fold: TRAIN; iteration: 749; epoch: 1; objective: 0.12704649567604065; \n",
      "validating model...\n",
      "saving\n",
      "fold: VALID; iteration: 750; epoch: 1; classification/accuracy: 0.956; objective: 0.128486542776227; \n",
      "fold: TRAIN; iteration: 750; epoch: 1; objective: 0.06878325343132019; \n",
      "fold: TRAIN; iteration: 751; epoch: 1; objective: 0.1557641625404358; \n",
      "fold: TRAIN; iteration: 752; epoch: 1; objective: 0.1398836374282837; \n",
      "fold: TRAIN; iteration: 753; epoch: 1; objective: 0.07038429379463196; \n",
      "fold: TRAIN; iteration: 754; epoch: 1; objective: 0.10159873217344284; \n",
      "fold: TRAIN; iteration: 755; epoch: 1; objective: 0.10534096509218216; \n",
      "fold: TRAIN; iteration: 756; epoch: 1; objective: 0.11897348612546921; \n",
      "fold: TRAIN; iteration: 757; epoch: 1; objective: 0.21758918464183807; \n",
      "fold: TRAIN; iteration: 758; epoch: 1; objective: 0.19209179282188416; \n",
      "fold: TRAIN; iteration: 759; epoch: 1; objective: 0.16308867931365967; \n",
      "fold: TRAIN; iteration: 760; epoch: 1; objective: 0.198269322514534; \n",
      "fold: TRAIN; iteration: 761; epoch: 1; objective: 0.11670015007257462; \n",
      "fold: TRAIN; iteration: 762; epoch: 1; objective: 0.12662391364574432; \n",
      "fold: TRAIN; iteration: 763; epoch: 1; objective: 0.2153349071741104; \n",
      "fold: TRAIN; iteration: 764; epoch: 1; objective: 0.11075376719236374; \n",
      "fold: TRAIN; iteration: 765; epoch: 1; objective: 0.12707208096981049; \n",
      "fold: TRAIN; iteration: 766; epoch: 1; objective: 0.1574176698923111; \n",
      "fold: TRAIN; iteration: 767; epoch: 1; objective: 0.10650072991847992; \n",
      "fold: TRAIN; iteration: 768; epoch: 1; objective: 0.10659666359424591; \n",
      "fold: TRAIN; iteration: 769; epoch: 1; objective: 0.1855711191892624; \n",
      "fold: TRAIN; iteration: 770; epoch: 1; objective: 0.0994005799293518; \n",
      "fold: TRAIN; iteration: 771; epoch: 1; objective: 0.14187289774417877; \n",
      "fold: TRAIN; iteration: 772; epoch: 1; objective: 0.11422357708215714; \n",
      "fold: TRAIN; iteration: 773; epoch: 1; objective: 0.11628158390522003; \n",
      "fold: TRAIN; iteration: 774; epoch: 1; objective: 0.20183557271957397; \n",
      "fold: TRAIN; iteration: 775; epoch: 1; objective: 0.12819184362888336; \n",
      "fold: TRAIN; iteration: 776; epoch: 1; objective: 0.10076212137937546; \n",
      "fold: TRAIN; iteration: 777; epoch: 1; objective: 0.1602238118648529; \n",
      "fold: TRAIN; iteration: 778; epoch: 1; objective: 0.141201913356781; \n",
      "fold: TRAIN; iteration: 779; epoch: 1; objective: 0.11036372184753418; \n",
      "fold: TRAIN; iteration: 780; epoch: 1; objective: 0.07315479218959808; \n",
      "fold: TRAIN; iteration: 781; epoch: 1; objective: 0.13184456527233124; \n",
      "fold: TRAIN; iteration: 782; epoch: 1; objective: 0.09887400269508362; \n",
      "fold: TRAIN; iteration: 783; epoch: 1; objective: 0.13747304677963257; \n",
      "fold: TRAIN; iteration: 784; epoch: 1; objective: 0.23779016733169556; \n",
      "fold: TRAIN; iteration: 785; epoch: 1; objective: 0.152564138174057; \n",
      "fold: TRAIN; iteration: 786; epoch: 1; objective: 0.09740526229143143; \n",
      "fold: TRAIN; iteration: 787; epoch: 1; objective: 0.14189839363098145; \n",
      "fold: TRAIN; iteration: 788; epoch: 1; objective: 0.17323049902915955; \n",
      "fold: TRAIN; iteration: 789; epoch: 1; objective: 0.18614999949932098; \n",
      "fold: TRAIN; iteration: 790; epoch: 1; objective: 0.118673175573349; \n",
      "fold: TRAIN; iteration: 791; epoch: 1; objective: 0.06569784879684448; \n",
      "fold: TRAIN; iteration: 792; epoch: 1; objective: 0.08111973851919174; \n",
      "fold: TRAIN; iteration: 793; epoch: 1; objective: 0.05389862135052681; \n",
      "fold: TRAIN; iteration: 794; epoch: 1; objective: 0.18034929037094116; \n",
      "fold: TRAIN; iteration: 795; epoch: 1; objective: 0.09387907385826111; \n",
      "fold: TRAIN; iteration: 796; epoch: 1; objective: 0.10985305160284042; \n",
      "fold: TRAIN; iteration: 797; epoch: 1; objective: 0.14562161266803741; \n",
      "fold: TRAIN; iteration: 798; epoch: 1; objective: 0.13265781104564667; \n",
      "fold: TRAIN; iteration: 799; epoch: 1; objective: 0.143087238073349; \n",
      "validating model...\n",
      "saving\n",
      "fold: VALID; iteration: 800; epoch: 1; classification/accuracy: 0.948; objective: 0.12267384454607963; \n",
      "fold: TRAIN; iteration: 800; epoch: 1; objective: 0.04794096574187279; \n",
      "fold: TRAIN; iteration: 801; epoch: 1; objective: 0.08904367685317993; \n",
      "fold: TRAIN; iteration: 802; epoch: 1; objective: 0.06422405689954758; \n",
      "fold: TRAIN; iteration: 803; epoch: 1; objective: 0.09254947304725647; \n",
      "fold: TRAIN; iteration: 804; epoch: 1; objective: 0.084577776491642; \n",
      "fold: TRAIN; iteration: 805; epoch: 1; objective: 0.22379350662231445; \n",
      "fold: TRAIN; iteration: 806; epoch: 1; objective: 0.06612815707921982; \n",
      "fold: TRAIN; iteration: 807; epoch: 1; objective: 0.1615714132785797; \n",
      "fold: TRAIN; iteration: 808; epoch: 1; objective: 0.17293350398540497; \n",
      "fold: TRAIN; iteration: 809; epoch: 1; objective: 0.12996412813663483; \n",
      "fold: TRAIN; iteration: 810; epoch: 1; objective: 0.1358276605606079; \n",
      "fold: TRAIN; iteration: 811; epoch: 1; objective: 0.15332189202308655; \n",
      "fold: TRAIN; iteration: 812; epoch: 1; objective: 0.20626980066299438; \n",
      "fold: TRAIN; iteration: 813; epoch: 1; objective: 0.13348388671875; \n",
      "fold: TRAIN; iteration: 814; epoch: 1; objective: 0.10417395830154419; \n",
      "fold: TRAIN; iteration: 815; epoch: 1; objective: 0.15679752826690674; \n",
      "fold: TRAIN; iteration: 816; epoch: 1; objective: 0.13112320005893707; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 817; epoch: 1; objective: 0.14422506093978882; \n",
      "fold: TRAIN; iteration: 818; epoch: 1; objective: 0.18124322593212128; \n",
      "fold: TRAIN; iteration: 819; epoch: 1; objective: 0.05801723897457123; \n",
      "fold: TRAIN; iteration: 820; epoch: 1; objective: 0.1921648234128952; \n",
      "fold: TRAIN; iteration: 821; epoch: 1; objective: 0.10081424564123154; \n",
      "fold: TRAIN; iteration: 822; epoch: 1; objective: 0.08513560891151428; \n",
      "fold: TRAIN; iteration: 823; epoch: 1; objective: 0.15235203504562378; \n",
      "fold: TRAIN; iteration: 824; epoch: 1; objective: 0.13689284026622772; \n",
      "fold: TRAIN; iteration: 825; epoch: 1; objective: 0.07998739182949066; \n",
      "fold: TRAIN; iteration: 826; epoch: 1; objective: 0.13779029250144958; \n",
      "fold: TRAIN; iteration: 827; epoch: 1; objective: 0.18583449721336365; \n",
      "fold: TRAIN; iteration: 828; epoch: 1; objective: 0.10142841190099716; \n",
      "fold: TRAIN; iteration: 829; epoch: 1; objective: 0.06453096121549606; \n",
      "fold: TRAIN; iteration: 830; epoch: 1; objective: 0.1574546843767166; \n",
      "fold: TRAIN; iteration: 831; epoch: 1; objective: 0.10104119032621384; \n",
      "fold: TRAIN; iteration: 832; epoch: 1; objective: 0.12013337761163712; \n",
      "fold: TRAIN; iteration: 833; epoch: 1; objective: 0.2115945816040039; \n",
      "fold: TRAIN; iteration: 834; epoch: 1; objective: 0.13004842400550842; \n",
      "fold: TRAIN; iteration: 835; epoch: 1; objective: 0.12500661611557007; \n",
      "fold: TRAIN; iteration: 836; epoch: 1; objective: 0.08954302966594696; \n",
      "fold: TRAIN; iteration: 837; epoch: 1; objective: 0.1890771985054016; \n",
      "fold: TRAIN; iteration: 838; epoch: 1; objective: 0.1452314406633377; \n",
      "fold: TRAIN; iteration: 839; epoch: 1; objective: 0.0791919082403183; \n",
      "fold: TRAIN; iteration: 840; epoch: 1; objective: 0.12602508068084717; \n",
      "fold: TRAIN; iteration: 841; epoch: 1; objective: 0.09921921044588089; \n",
      "fold: TRAIN; iteration: 842; epoch: 1; objective: 0.12302646785974503; \n",
      "fold: TRAIN; iteration: 843; epoch: 1; objective: 0.10379386693239212; \n",
      "fold: TRAIN; iteration: 844; epoch: 1; objective: 0.1416131556034088; \n",
      "fold: TRAIN; iteration: 845; epoch: 1; objective: 0.07149297744035721; \n",
      "fold: TRAIN; iteration: 846; epoch: 1; objective: 0.20595374703407288; \n",
      "fold: TRAIN; iteration: 847; epoch: 1; objective: 0.07534826546907425; \n",
      "fold: TRAIN; iteration: 848; epoch: 1; objective: 0.15342207252979279; \n",
      "fold: TRAIN; iteration: 849; epoch: 1; objective: 0.1700284332036972; \n",
      "validating model...\n",
      "saving\n",
      "fold: VALID; iteration: 850; epoch: 1; classification/accuracy: 0.96; objective: 0.11529961849252383; \n",
      "fold: TRAIN; iteration: 850; epoch: 1; objective: 0.12458385527133942; \n",
      "fold: TRAIN; iteration: 851; epoch: 1; objective: 0.1165638417005539; \n",
      "fold: TRAIN; iteration: 852; epoch: 1; objective: 0.11174970865249634; \n",
      "fold: TRAIN; iteration: 853; epoch: 1; objective: 0.08795932680368423; \n",
      "fold: TRAIN; iteration: 854; epoch: 1; objective: 0.17541278898715973; \n",
      "fold: TRAIN; iteration: 855; epoch: 1; objective: 0.059431955218315125; \n",
      "fold: TRAIN; iteration: 856; epoch: 1; objective: 0.10430639237165451; \n",
      "fold: TRAIN; iteration: 857; epoch: 1; objective: 0.09203962236642838; \n",
      "fold: TRAIN; iteration: 858; epoch: 1; objective: 0.1933131068944931; \n",
      "fold: TRAIN; iteration: 859; epoch: 1; objective: 0.12853002548217773; \n",
      "fold: TRAIN; iteration: 860; epoch: 1; objective: 0.09275965392589569; \n",
      "fold: TRAIN; iteration: 861; epoch: 1; objective: 0.0839027464389801; \n",
      "fold: TRAIN; iteration: 862; epoch: 1; objective: 0.13826438784599304; \n",
      "fold: TRAIN; iteration: 863; epoch: 1; objective: 0.07391397655010223; \n",
      "fold: TRAIN; iteration: 864; epoch: 1; objective: 0.05146666616201401; \n",
      "fold: TRAIN; iteration: 865; epoch: 1; objective: 0.09822347015142441; \n",
      "fold: TRAIN; iteration: 866; epoch: 1; objective: 0.1481657326221466; \n",
      "fold: TRAIN; iteration: 867; epoch: 1; objective: 0.16074323654174805; \n",
      "fold: TRAIN; iteration: 868; epoch: 1; objective: 0.2789253890514374; \n",
      "fold: TRAIN; iteration: 869; epoch: 1; objective: 0.11004828661680222; \n",
      "fold: TRAIN; iteration: 870; epoch: 1; objective: 0.128606379032135; \n",
      "fold: TRAIN; iteration: 871; epoch: 1; objective: 0.15882521867752075; \n",
      "fold: TRAIN; iteration: 872; epoch: 1; objective: 0.16376952826976776; \n",
      "fold: TRAIN; iteration: 873; epoch: 1; objective: 0.08681439608335495; \n",
      "fold: TRAIN; iteration: 874; epoch: 1; objective: 0.06408138573169708; \n",
      "fold: TRAIN; iteration: 875; epoch: 1; objective: 0.15039800107479095; \n",
      "fold: TRAIN; iteration: 876; epoch: 1; objective: 0.18948297202587128; \n",
      "fold: TRAIN; iteration: 877; epoch: 1; objective: 0.10984615981578827; \n",
      "fold: TRAIN; iteration: 878; epoch: 1; objective: 0.0702902153134346; \n",
      "fold: TRAIN; iteration: 879; epoch: 1; objective: 0.2011478990316391; \n",
      "fold: TRAIN; iteration: 880; epoch: 1; objective: 0.1090683713555336; \n",
      "fold: TRAIN; iteration: 881; epoch: 1; objective: 0.13955482840538025; \n",
      "fold: TRAIN; iteration: 882; epoch: 1; objective: 0.045337628573179245; \n",
      "fold: TRAIN; iteration: 883; epoch: 1; objective: 0.1272427886724472; \n",
      "fold: TRAIN; iteration: 884; epoch: 1; objective: 0.1271839737892151; \n",
      "fold: TRAIN; iteration: 885; epoch: 1; objective: 0.10607051849365234; \n",
      "fold: TRAIN; iteration: 886; epoch: 1; objective: 0.07240686565637589; \n",
      "fold: TRAIN; iteration: 887; epoch: 1; objective: 0.09002117067575455; \n",
      "fold: TRAIN; iteration: 888; epoch: 1; objective: 0.10036548972129822; \n",
      "fold: TRAIN; iteration: 889; epoch: 1; objective: 0.09829268604516983; \n",
      "fold: TRAIN; iteration: 890; epoch: 1; objective: 0.056093811988830566; \n",
      "fold: TRAIN; iteration: 891; epoch: 1; objective: 0.06804635375738144; \n",
      "fold: TRAIN; iteration: 892; epoch: 1; objective: 0.10310211032629013; \n",
      "fold: TRAIN; iteration: 893; epoch: 1; objective: 0.10771840065717697; \n",
      "fold: TRAIN; iteration: 894; epoch: 1; objective: 0.11638223379850388; \n",
      "fold: TRAIN; iteration: 895; epoch: 1; objective: 0.14846248924732208; \n",
      "fold: TRAIN; iteration: 896; epoch: 1; objective: 0.19367000460624695; \n",
      "fold: TRAIN; iteration: 897; epoch: 1; objective: 0.13899487257003784; \n",
      "fold: TRAIN; iteration: 898; epoch: 1; objective: 0.07462486624717712; \n",
      "fold: TRAIN; iteration: 899; epoch: 1; objective: 0.07321488857269287; \n",
      "validating model...\n",
      "saving\n",
      "fold: VALID; iteration: 900; epoch: 1; classification/accuracy: 0.956; objective: 0.111064034452041; \n",
      "fold: TRAIN; iteration: 900; epoch: 1; objective: 0.11119247227907181; \n",
      "fold: TRAIN; iteration: 901; epoch: 1; objective: 0.11276919394731522; \n",
      "fold: TRAIN; iteration: 902; epoch: 1; objective: 0.18270067870616913; \n",
      "fold: TRAIN; iteration: 903; epoch: 1; objective: 0.1605682224035263; \n",
      "fold: TRAIN; iteration: 904; epoch: 1; objective: 0.18194636702537537; \n",
      "fold: TRAIN; iteration: 905; epoch: 1; objective: 0.2519947290420532; \n",
      "fold: TRAIN; iteration: 906; epoch: 1; objective: 0.0801284983754158; \n",
      "fold: TRAIN; iteration: 907; epoch: 1; objective: 0.08317182213068008; \n",
      "fold: TRAIN; iteration: 908; epoch: 1; objective: 0.09610769897699356; \n",
      "fold: TRAIN; iteration: 909; epoch: 1; objective: 0.09538796544075012; \n",
      "fold: TRAIN; iteration: 910; epoch: 1; objective: 0.13364484906196594; \n",
      "fold: TRAIN; iteration: 911; epoch: 1; objective: 0.14276300370693207; \n",
      "fold: TRAIN; iteration: 912; epoch: 1; objective: 0.152669757604599; \n",
      "fold: TRAIN; iteration: 913; epoch: 1; objective: 0.09654391556978226; \n",
      "fold: TRAIN; iteration: 914; epoch: 1; objective: 0.1480209231376648; \n",
      "fold: TRAIN; iteration: 915; epoch: 1; objective: 0.16727419197559357; \n",
      "fold: TRAIN; iteration: 916; epoch: 1; objective: 0.04253733530640602; \n",
      "fold: TRAIN; iteration: 917; epoch: 1; objective: 0.1013895720243454; \n",
      "fold: TRAIN; iteration: 918; epoch: 1; objective: 0.1188376247882843; \n",
      "fold: TRAIN; iteration: 919; epoch: 1; objective: 0.1959676295518875; \n",
      "fold: TRAIN; iteration: 920; epoch: 1; objective: 0.18813055753707886; \n",
      "fold: TRAIN; iteration: 921; epoch: 1; objective: 0.138977512717247; \n",
      "fold: TRAIN; iteration: 922; epoch: 1; objective: 0.09787044674158096; \n",
      "fold: TRAIN; iteration: 923; epoch: 1; objective: 0.10234566777944565; \n",
      "fold: TRAIN; iteration: 924; epoch: 1; objective: 0.10249777883291245; \n",
      "fold: TRAIN; iteration: 925; epoch: 1; objective: 0.09958508610725403; \n",
      "fold: TRAIN; iteration: 926; epoch: 1; objective: 0.18672549724578857; \n",
      "fold: TRAIN; iteration: 927; epoch: 1; objective: 0.11923650652170181; \n",
      "fold: TRAIN; iteration: 928; epoch: 1; objective: 0.10452506691217422; \n",
      "fold: TRAIN; iteration: 929; epoch: 1; objective: 0.12707503139972687; \n",
      "fold: TRAIN; iteration: 930; epoch: 1; objective: 0.09352007508277893; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: TRAIN; iteration: 931; epoch: 1; objective: 0.21486322581768036; \n",
      "fold: TRAIN; iteration: 932; epoch: 1; objective: 0.1143263503909111; \n",
      "fold: TRAIN; iteration: 933; epoch: 1; objective: 0.19857051968574524; \n",
      "fold: TRAIN; iteration: 934; epoch: 1; objective: 0.10841557383537292; \n",
      "fold: TRAIN; iteration: 935; epoch: 1; objective: 0.09357528388500214; \n",
      "fold: TRAIN; iteration: 936; epoch: 1; objective: 0.05374349281191826; \n",
      "fold: TRAIN; iteration: 937; epoch: 1; objective: 0.12246647477149963; \n",
      "fold: TRAIN; iteration: 938; epoch: 1; objective: 0.17148302495479584; \n",
      "fold: TRAIN; iteration: 939; epoch: 1; objective: 0.10028500854969025; \n",
      "fold: TRAIN; iteration: 940; epoch: 1; objective: 0.045712485909461975; \n",
      "fold: TRAIN; iteration: 941; epoch: 1; objective: 0.12463263422250748; \n",
      "fold: TRAIN; iteration: 942; epoch: 1; objective: 0.18518508970737457; \n",
      "fold: TRAIN; iteration: 943; epoch: 1; objective: 0.15412026643753052; \n",
      "fold: TRAIN; iteration: 944; epoch: 1; objective: 0.07894029468297958; \n",
      "fold: TRAIN; iteration: 945; epoch: 1; objective: 0.16395077109336853; \n",
      "fold: TRAIN; iteration: 946; epoch: 1; objective: 0.07111410796642303; \n",
      "fold: TRAIN; iteration: 947; epoch: 1; objective: 0.12555839121341705; \n",
      "fold: TRAIN; iteration: 948; epoch: 1; objective: 0.07046852260828018; \n",
      "fold: TRAIN; iteration: 949; epoch: 1; objective: 0.13916334509849548; \n",
      "validating model...\n",
      "saving\n",
      "fold: VALID; iteration: 950; epoch: 1; classification/accuracy: 0.968; objective: 0.10500108115375043; \n",
      "fold: TRAIN; iteration: 950; epoch: 1; objective: 0.0698646605014801; \n",
      "fold: TRAIN; iteration: 951; epoch: 1; objective: 0.15812452137470245; \n",
      "fold: TRAIN; iteration: 952; epoch: 1; objective: 0.07121609896421432; \n",
      "fold: TRAIN; iteration: 953; epoch: 1; objective: 0.12433992326259613; \n",
      "fold: TRAIN; iteration: 954; epoch: 1; objective: 0.10460558533668518; \n",
      "fold: TRAIN; iteration: 955; epoch: 1; objective: 0.08054246008396149; \n",
      "fold: TRAIN; iteration: 956; epoch: 1; objective: 0.18473631143569946; \n",
      "fold: TRAIN; iteration: 957; epoch: 1; objective: 0.0599062442779541; \n",
      "fold: TRAIN; iteration: 958; epoch: 1; objective: 0.1089591309428215; \n",
      "fold: TRAIN; iteration: 959; epoch: 1; objective: 0.13315069675445557; \n",
      "fold: TRAIN; iteration: 960; epoch: 1; objective: 0.1842081993818283; \n",
      "fold: TRAIN; iteration: 961; epoch: 1; objective: 0.11287536472082138; \n",
      "fold: TRAIN; iteration: 962; epoch: 1; objective: 0.03955932706594467; \n",
      "fold: TRAIN; iteration: 963; epoch: 1; objective: 0.09791155904531479; \n",
      "fold: TRAIN; iteration: 964; epoch: 1; objective: 0.134857177734375; \n",
      "fold: TRAIN; iteration: 965; epoch: 1; objective: 0.26304906606674194; \n",
      "fold: TRAIN; iteration: 966; epoch: 1; objective: 0.08222357928752899; \n",
      "fold: TRAIN; iteration: 967; epoch: 1; objective: 0.11362408846616745; \n",
      "fold: TRAIN; iteration: 968; epoch: 1; objective: 0.06256677210330963; \n",
      "fold: TRAIN; iteration: 969; epoch: 1; objective: 0.09759458899497986; \n",
      "fold: TRAIN; iteration: 970; epoch: 1; objective: 0.07316237688064575; \n",
      "fold: TRAIN; iteration: 971; epoch: 1; objective: 0.06417205184698105; \n",
      "fold: TRAIN; iteration: 972; epoch: 1; objective: 0.14569762349128723; \n",
      "fold: TRAIN; iteration: 973; epoch: 1; objective: 0.13515864312648773; \n",
      "fold: TRAIN; iteration: 974; epoch: 1; objective: 0.1661347597837448; \n",
      "fold: TRAIN; iteration: 975; epoch: 1; objective: 0.04158425331115723; \n",
      "fold: TRAIN; iteration: 976; epoch: 1; objective: 0.18941934406757355; \n",
      "fold: TRAIN; iteration: 977; epoch: 1; objective: 0.199094757437706; \n",
      "fold: TRAIN; iteration: 978; epoch: 1; objective: 0.17562156915664673; \n",
      "fold: TRAIN; iteration: 979; epoch: 1; objective: 0.11707187443971634; \n",
      "fold: TRAIN; iteration: 980; epoch: 1; objective: 0.06413491070270538; \n",
      "fold: TRAIN; iteration: 981; epoch: 1; objective: 0.1212422251701355; \n",
      "fold: TRAIN; iteration: 982; epoch: 1; objective: 0.14084430038928986; \n",
      "fold: TRAIN; iteration: 983; epoch: 1; objective: 0.06355411559343338; \n",
      "fold: TRAIN; iteration: 984; epoch: 1; objective: 0.08007050305604935; \n",
      "fold: TRAIN; iteration: 985; epoch: 1; objective: 0.2126658856868744; \n",
      "fold: TRAIN; iteration: 986; epoch: 1; objective: 0.0809231773018837; \n",
      "fold: TRAIN; iteration: 987; epoch: 1; objective: 0.19208309054374695; \n",
      "fold: TRAIN; iteration: 988; epoch: 1; objective: 0.0559694804251194; \n",
      "fold: TRAIN; iteration: 989; epoch: 1; objective: 0.12755157053470612; \n",
      "fold: TRAIN; iteration: 990; epoch: 1; objective: 0.09547761082649231; \n",
      "fold: TRAIN; iteration: 991; epoch: 1; objective: 0.07930473983287811; \n",
      "fold: TRAIN; iteration: 992; epoch: 1; objective: 0.07930286228656769; \n",
      "fold: TRAIN; iteration: 993; epoch: 1; objective: 0.0737217366695404; \n",
      "fold: TRAIN; iteration: 994; epoch: 1; objective: 0.10130125284194946; \n",
      "fold: TRAIN; iteration: 995; epoch: 1; objective: 0.12375953793525696; \n",
      "fold: TRAIN; iteration: 996; epoch: 1; objective: 0.11564025282859802; \n",
      "fold: TRAIN; iteration: 997; epoch: 1; objective: 0.07510849833488464; \n",
      "fold: TRAIN; iteration: 998; epoch: 1; objective: 0.12025919556617737; \n",
      "fold: TRAIN; iteration: 999; epoch: 1; objective: 0.10211549699306488; \n",
      "validating model...\n",
      "saving\n",
      "fold: VALID; iteration: 1000; epoch: 1; classification/accuracy: 0.956; objective: 0.10303800615171592; \n"
     ]
    }
   ],
   "source": [
    "docs.watch_job(jobs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d241ae46",
   "metadata": {},
   "source": [
    "Now the training has finished, we can watch the computation of model outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71e3d1cf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing chunk (1/12)\n",
      "finding documents under filter\n",
      "done.\n",
      "processing with lenet\n",
      "bulk writing...\n",
      "done.\n",
      "computing chunk (2/12)\n",
      "finding documents under filter\n",
      "done.\n",
      "processing with lenet\n",
      "bulk writing...\n",
      "done.\n",
      "computing chunk (3/12)\n",
      "finding documents under filter\n",
      "done.\n",
      "processing with lenet\n",
      "bulk writing...\n",
      "done.\n",
      "computing chunk (4/12)\n",
      "finding documents under filter\n",
      "done.\n",
      "processing with lenet\n",
      "bulk writing...\n",
      "done.\n",
      "computing chunk (5/12)\n",
      "finding documents under filter\n",
      "done.\n",
      "processing with lenet\n",
      "bulk writing...\n",
      "done.\n",
      "computing chunk (6/12)\n",
      "finding documents under filter\n",
      "done.\n",
      "processing with lenet\n",
      "bulk writing...\n",
      "done.\n",
      "computing chunk (7/12)\n",
      "finding documents under filter\n",
      "done.\n",
      "processing with lenet\n",
      "bulk writing...\n",
      "done.\n",
      "computing chunk (8/12)\n",
      "finding documents under filter\n",
      "done.\n",
      "processing with lenet\n",
      "bulk writing...\n",
      "done.\n",
      "computing chunk (9/12)\n",
      "finding documents under filter\n",
      "done.\n",
      "processing with lenet\n",
      "bulk writing...\n",
      "done.\n",
      "computing chunk (10/12)\n",
      "finding documents under filter\n",
      "done.\n",
      "processing with lenet\n",
      "bulk writing...\n",
      "done.\n",
      "computing chunk (11/12)\n",
      "finding documents under filter\n",
      "done.\n",
      "processing with lenet\n",
      "bulk writing...\n",
      "done.\n",
      "computing chunk (12/12)\n",
      "finding documents under filter\n",
      "done.\n",
      "processing with lenet\n",
      "bulk writing...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "docs.watch_job(jobs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67384028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('6421b023762a0ec3814f5359'),\n",
       " 'variety': 'imputation',\n",
       " 'identifier': 'predictor',\n",
       " 'model': 'lenet',\n",
       " 'model_key': 'img',\n",
       " 'target': 'label',\n",
       " 'target_key': 'class',\n",
       " 'query_params': ['digits', {}],\n",
       " 'metrics': ['accuracy'],\n",
       " 'objective': 'classification',\n",
       " 'splitter': None,\n",
       " 'loader_kwargs': None,\n",
       " 'trainer_kwargs': {'n_iterations': 1000,\n",
       "  'validation_interval': 50,\n",
       "  'validation_sets': ['classification'],\n",
       "  'loader_suppress': ['_id']},\n",
       " 'metric_values': {'classification': {'accuracy': [0.048,\n",
       "    0.584,\n",
       "    0.736,\n",
       "    0.808,\n",
       "    0.864,\n",
       "    0.884,\n",
       "    0.896,\n",
       "    0.912,\n",
       "    0.916,\n",
       "    0.92,\n",
       "    0.924,\n",
       "    0.936,\n",
       "    0.944,\n",
       "    0.94,\n",
       "    0.944,\n",
       "    0.956,\n",
       "    0.948,\n",
       "    0.96,\n",
       "    0.956,\n",
       "    0.968,\n",
       "    0.956]},\n",
       "  'objective': [2.3110132773717242,\n",
       "   2.0651561578114825,\n",
       "   1.5489568869272867,\n",
       "   0.9873368521531423,\n",
       "   0.6416231413682302,\n",
       "   0.451803328593572,\n",
       "   0.35037993391354877,\n",
       "   0.29230905175209043,\n",
       "   0.24675621291001637,\n",
       "   0.21056613624095916,\n",
       "   0.19069528977076214,\n",
       "   0.1713645281891028,\n",
       "   0.15632830535372097,\n",
       "   0.14958817288279533,\n",
       "   0.13812173306941986,\n",
       "   0.128486542776227,\n",
       "   0.12267384454607963,\n",
       "   0.11529961849252383,\n",
       "   0.111064034452041,\n",
       "   0.10500108115375043,\n",
       "   0.10303800615171592]}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info = docs.database.get_object_info('predictor', 'imputation')\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99a20ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x168a6d8d0>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(info['metric_values']['classification']['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99caf447",
   "metadata": {},
   "source": [
    "Accuracy is good, and we can see the outputs have been added to the documents (`_outputs.img.lenet`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7051b119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('6421b01f762a0ec3814e6cd1'),\n",
       " 'img': <PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>,\n",
       " 'class': 7,\n",
       " '_fold': 'train',\n",
       " '_outputs': {'img': {'lenet': 7}}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.find_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e41ab4c",
   "metadata": {},
   "source": [
    "After training, you'll see that a model **watcher** has been created, which keeps the `img` key up-to-date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0def946d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['predictor']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.list_watchers()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5c2958",
   "metadata": {},
   "source": [
    "When new data are added, the trained model kicks into action \n",
    "and it's outputs are added/ enriched to the newly added data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67f7e156",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_, jobs = docs.insert_many([{'img': x[0], 'class': x[1], 'update': True} for x in mnist_data[-1000:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f964af",
   "metadata": {},
   "source": [
    "We can watch the progress of adding this new data as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1e825dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing chunk (1/1)\n",
      "finding documents under filter\n",
      "done.\n",
      "processing with lenet\n",
      "bulk writing...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "docs.watch_job(jobs['watcher', 'predictor'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4168e3d",
   "metadata": {},
   "source": [
    "After inserting and training the model, the model is automatically served on the SuperDuperDB model-server. If you're deployment is exposed to the internet, then these predictions are available anywhere:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c37b84b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA1klEQVR4nNXPPwtBURgG8IeilJiUmcSia7DI3chguosvwCiLD4HBVzCblMEofxafgMJgoLDgSsmfnsviGpzjZvVMb+d3znnfF/in2MzCFc4p2fq5cpNccnRJkkY/JZqzRnIxm833ekbAEHkougGo411Mgh2zannNU7vYQouKqGoAgDyQ1D4GqpLHsgtI61wrftkq2/XmRA7FTqEmSRokKyICheXFuF2Nh+QlACilRGLEVVCuABqkKq7yShvQvuIUiHxFAD6PBcYDFviODHsTCxzcrb77KU86iVA2ECP35gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = docs.find_one({'_fold': 'valid'})['img']\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3e184633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.apply_model('lenet', im)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
